<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>AD_Papers | Go Further | Stay Hungry, Stay Foolish</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#142421">
    
    
    <meta name="keywords" content="">
    <meta name="description" content="【阅读时间】XXX min XXX words【阅读内容】……">
<meta property="og:type" content="article">
<meta property="og:title" content="AD_Papers">
<meta property="og:url" content="http://yoursite.com/2019/07/10/AD-Papers/index.html">
<meta property="og:site_name" content="Go Further">
<meta property="og:description" content="【阅读时间】XXX min XXX words【阅读内容】……">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-07-29T03:49:35.684Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AD_Papers">
<meta name="twitter:description" content="【阅读时间】XXX min XXX words【阅读内容】……">
    
        <link rel="alternate" type="application/atom+xml" title="Go Further" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">CaptainSE</h5>
          <a href="mailto:841145636@qq.com" title="841145636@qq.com" class="mail">841145636@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/Captainzj" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">AD_Papers</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">AD_Papers</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-10T10:37:04.000Z" itemprop="datePublished" class="page-time">
  2019-07-10
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/">Paper</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/ADNI/">ADNI</a></li></ul></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#基础知识"><span class="post-toc-number">1.</span> <span class="post-toc-text">基础知识</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#1-Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease"><span class="post-toc-number">2.</span> <span class="post-toc-text">1. Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#数据说明"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">数据说明</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#主要贡献"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">主要贡献</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#细节"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">细节</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease"><span class="post-toc-number">3.</span> <span class="post-toc-text">2. Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#细节-1"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">细节</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3-Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data"><span class="post-toc-number">4.</span> <span class="post-toc-text">3. Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#细节-2"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">细节</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#4-Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease"><span class="post-toc-number">5.</span> <span class="post-toc-text">4. Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease</span></a></li></ol>
        </nav>
    </aside>


<article id="post-AD-Papers"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">AD_Papers</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-10 18:37:04" datetime="2019-07-10T10:37:04.000Z"  itemprop="datePublished">2019-07-10</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/">Paper</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/ADNI/">ADNI</a></li></ul></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p>
<a id="more"></a>
<h4 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h4><ul>
<li>氟脱氧葡萄糖正电子发射断层扫描（FDG-PET），提供了大脑代谢活动的定量测量，可以在结构变化发生之前识别与AD相关的变化，具有可接受的敏感性和准确性。 </li>
<li>ASL(Arterial Spin Labeling)：动脉自旋标记，三维伪连续ASL扫描的自动分类可以高精度地检测AD患者（&gt; 82％）</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">No</th>
<th style="text-align:center">Data Source</th>
<th style="text-align:center">Modality</th>
<th style="text-align:center">Method</th>
<th style="text-align:center">Experiment</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1710.04782" target="_blank" rel="noopener">1</a></td>
<td style="text-align:center">ADNI</td>
<td style="text-align:center">PET</td>
<td style="text-align:center">M-CNN</td>
<td style="text-align:center">AD vs NC(93.58),<br>sMCI vs pMCI(81.55),<br>tf sMCI vs pMCI(82.51)</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://pubs.rsna.org/doi/full/10.1148/radiol.2016152703" target="_blank" rel="noopener">2</a></td>
<td style="text-align:center">Alzheimer Center of the VU University <br>Medical Center Dementia Cohort</td>
<td style="text-align:center">MRI</td>
<td style="text-align:center">ASL-W_score-SVM</td>
<td style="text-align:center">i. AD vs. SCD  <br>ii. AD vs. MCI <br> iii. MCI vs. SCD</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1808.06452" target="_blank" rel="noopener">3</a></td>
<td style="text-align:center">ADNI, AIBL,OASIS</td>
<td style="text-align:center">MRI,PET</td>
<td style="text-align:center">SVM\逻辑回归\随机森林</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><a href="">4</a></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h4 id="1-Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease"><a href="#1-Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease" class="headerlink" title="1. Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease"></a>1. <a href="https://arxiv.org/abs/1710.04782" target="_blank" rel="noopener">Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease</a></h4><p>提出了一种新的深度学习框架，使用FDG-PET代谢成像来识别MCI的受试者（患有前AD症状的），并将其与其他MCI（非AD /非进展）受试者区分开来。 我们的多尺度深度神经网络仅使用来自单一模态（FDG-PET代谢数据）的测量获得82.51％的分类准确度，优于最近文献中公布的其他可比较的FDG-PET分类器。</p>
<h5 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h5><ul>
<li>来源：ADNI（<a href="http://adni.loni.usc.edu）" target="_blank" rel="noopener">http://adni.loni.usc.edu）</a><ul>
<li>受试者的人口统计学和临床信息：NC组 304项、sMCI组 409项、pMCI组 112项、AD组 226项</li>
<li>质量控制：1）通过训练有素且专业的神经病理学家对每个脑图像的每个FreeSurfer分段进行手动质量评估。此外，通过手动编辑校正脑膜，白质，皮质或皮质下分割中的任何错误，并重新运行Freesurfer，直到T1 MR图像分割变得准确。2）可视化代谢度量</li>
</ul>
</li>
</ul>
<h5 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h5><ul>
<li>提出了一种新的多尺度深度神经网络框架，以学习基于AD病理学的代谢变化模式，作为正常对照（NC）代谢模式的判别; （该论文是第一个利用深度学习开发多尺度FDG-PET分类器的论文）</li>
<li>发现通过从NC和AD个体转移样本，深层结构可以在早期诊断任务中获得更好的判别能力</li>
<li>证明了具有不同验证设置的多分类器”投票“预测，可以使所提出的方法更加稳定和稳健，并提高其分类性能</li>
</ul>
<h5 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h5><ul>
<li><p><strong>Introduction</strong></p>
<ul>
<li>该论文对迄今为止（21 February 2018）为该项工作发布的最大数据集（1051名受试者的代谢情况）提出了最全面的方法验证，图像严格遵循标准化的成像协议</li>
</ul>
</li>
<li><p><em>Image processing</em></p>
<ul>
<li><em>ROI segmentation</em>：Each T1 structural MRI image was segmented into gray matter and white matter using the freely available <code>FreeSurfer 5.3 package</code> with default parameter settings</li>
<li><em>Patch parcellation</em>： The technique used for this subdivision is a previously published technique where each ROI can be clustered using their spatial coordinates via a <code>k-means clustering algorithm</code></li>
<li><em>Coregistration</em>：The <code>FDG-PET</code> image and <code>skull-stripped MRI</code> scan of each target were then co-registered using the<code>FSL-FLIRT</code> program</li>
<li><em>Normalization</em>：The mean intensity in the <code>brainstem region</code> is hence calculated and used to divide the metabolism measures for all the other ROIs in the brain for each subject.</li>
<li><em>Visualization of metabolism measures</em>：perform visual <code>quality control</code> of the measures across the database</li>
</ul>
</li>
<li><p><em>Multiscale Deep Neural Network</em></p>
<ul>
<li>Unsupervised pre-training.</li>
<li>Supervised fine-tuning. </li>
<li>Dropout strategy.</li>
<li>Early stopping strategy.</li>
</ul>
</li>
<li><p><em>Instance-transfer learning</em>：the networks trained with transferred instances displayed better discriminative ability</p>
</li>
<li><p><em>Ensemble classifiers</em>：词袋法</p>
</li>
<li><p><em>Experimental setup</em>：Three binary classification experiments, (i) <code>NC vs AD</code>, (ii) <code>sMCI vs pMCI</code> and (iii) <code>sMCI vs pMCI with transfer learning from NC and AD</code></p>
</li>
<li><p><strong>Results</strong></p>
<ul>
<li><p><em>Multiscale classification</em>：二分类实验中，粗精度的预测准确率优于细精度</p>
</li>
<li><p><em>Ensemble classifier design</em>：稳健</p>
</li>
</ul>
</li>
<li><p><strong>Discussion</strong></p>
<ul>
<li><em>Comparison with state-of-the-art methods</em>：我们提出的基于深度学习的方法显示sMCI和pMCI之间的分类准确性更高，无论是使用单一模式还是多模式研究</li>
<li><em>Multiscale classification</em>：与单一尺度特征相比，使用所有多尺度特征（包括从每个单尺度特征获得的判别信息）的组合分类性能产生了更高的精度结果。这表明在连锁多尺度特征上训练的网络（图2）仍然能够学习本文中使用的从小到大的补丁大小的隐藏模式。</li>
<li><em>Ensemble classifier</em>：集合分类器的准确性高于单个分类器的平均值，这表明具有不同训练和验证集的分集的集合分类器可以产生更稳健和稳定的分类器，因此可以改善分类性能更好的普遍性。</li>
</ul>
</li>
<li><p><strong>Conclusion</strong></p>
</li>
</ul>
<p>在本文中，我们使用<code>多尺度贴片FDG-PET深度学习</code>功能提出了一种新的AD早期诊断框架。所提出的框架利用<code>转移学习方法</code>和<code>集合分类器策略</code>来改善深度神经网络在区分sMCI和pMCI主体的任务中的性能。在1051名受试者的FDG-PET图像的大型数据库上进行的实验提供了支持三种断言的证据。 （1）所提出的方法，使用仅来自<code>单一FDG-PET模态</code>的特征，能够胜过在sMCI和pMCI分类任务中采用多模态特征的现有方法。 （2）所提出的网络可以从<code>多尺度特征</code>中学习判别模式，以提供具有更好判别性能的更健壮的分类器。 （3）使用不同验证集的<code>多个集成分类器</code>可以使网络更加健壮和稳定，并在统计上提高其分类性能。<br>对于未来的工作，将所提出的框架扩展到包含来自多种模态的信息是自然的，假设所得到的深度神经网络将从多个模态数据中学习更多信息，从而进一步改进所获得的分类准确度。尽管sMCI vs pMCI实验常用于验证近期研究（包括我们的研究）中方法的鉴别能力，但我们只能知道那些sMCI受试者在研究进展中时保持稳定并且可以转化为AD或其他神经退行性疾病。因此，在将来临床诊断的sMCI受试者的基本事实可能不完全准确，因此可能在分类中引入噪声/偏倚。幸运的是，随着更多数据的收集，分类系统将更好地捕获这些和其他噪声和可变性来源，我们提出的深度学习集合分类器可能非常适合这种情况。</p>
<h4 id="2-Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease"><a href="#2-Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease" class="headerlink" title="2. Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease"></a>2. <a href="https://pubs.rsna.org/doi/full/10.1148/radiol.2016152703" target="_blank" rel="noopener">Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease</a></h4><p>关于动脉自旋标记（ASL）的机器学习在治疗轻度认知障碍和阿尔茨海默病中的应用</p>
<p>本研究调查了ASL灌注图的多变量模式识别分析（SVM）是否可用于阿尔茨海默病（AD），轻度认知障碍（MCI）和主观认知衰退（SCD）患者的分类和单一主题预测。 W-score方法可以消除性别和年龄的混杂影响。</p>
<h5 id="细节-1"><a href="#细节-1" class="headerlink" title="细节"></a>细节</h5><p>ABSTRACT</p>
<ul>
<li>Purpose：<ul>
<li><code>ASL</code> → discrimination AD\MCI\SCD</li>
<li><code>W-score</code> → remove confounding effects of gender and age</li>
</ul>
</li>
<li>Materials and Methods<ul>
<li>Training of a Support Vector Machine (<code>SVM</code>) classifier used diagnostic status and perfusion maps.</li>
</ul>
</li>
<li>Results</li>
<li>Conclusion</li>
</ul>
<ol>
<li><p>INTRODUCTION</p>
</li>
<li><p>MATERIALS AND METHODS</p>
<ol>
<li><em>Participants</em></li>
<li><em>Data Acquisition</em> 数据采集</li>
<li><em>Preprocessing of MR imaging data</em></li>
<li><em>W-score maps</em>：<code>[(measured perfusion) – (predicted perfusion)] / (standard deviation of residuals)</code>.</li>
<li><em>SVM: Multivariate Pattern Recognition in Training-Set</em>：SVM接受了 leave-one-out交叉验证框架的训练，以区分AD患者，MCI患者和SCD患者。我们通过比较<code>两个患者组（SCD）</code>的W-得分图来评估分类器的诊断值。通过区分<code>AD和MCI</code>的患者的W-得分图来评估分类器对疾病进展的敏感性。最后，使用<code>MCIc和MCI</code>患者的Wscore图进行探索性分类训练，以研究分类器是否显示预后价值。</li>
<li><em>SVM: Prediction in new Subjects</em>:<code>Discrimination maps</code></li>
<li><em>Statistical Analysis</em>: <code>Evaluation</code></li>
</ol>
</li>
<li>RESULTS<ol>
<li><em>Participant Characteristics</em>:  数据集中受试者MMSE评分差异小</li>
<li><em>Training of the classifiers</em>：i. AD vs. SCD  ii. AD vs. MCI  iii. MCI vs. SCD </li>
<li><em>Predictions: assessment of generalisability</em>: <code>use of discrimination weights</code> i. AD vs. SCD  ii. AD vs. MCI  iii. MCI vs. SCD </li>
<li><em>Exploratory analyses: classifying MCI subgroups</em>: i. MCIc vs. SCD ii. MCIc vs. MCIs; use of the <code>AD vs. SCD training discrimination weights</code> for MCIc vs. SCD;The use of the same discrimination weights in MCIc vs. MCIs </li>
</ol>
</li>
<li>DISCUSSION</li>
<li>CONCLUSION：Using <code>automated methods</code>（即SVM）, age- and gender adjusted（W-score校准） ASL perfusion maps（特殊模态） can be used to classify and predict diagnoses of AD, MCI-converters, stable MCI patients and SCD subjects with good accuracy and AUC values.</li>
</ol>
<h4 id="3-Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data"><a href="#3-Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data" class="headerlink" title="3. Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data"></a>3. <a href="https://arxiv.org/abs/1808.06452" target="_blank" rel="noopener">Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data</a></h4><p>阿尔茨海默病分类方法的<code>再现评估</code>：MRI和PET数据的框架和应用</p>
<blockquote>
<p>提供规范化的AD实验流程，便于结果复现</p>
</blockquote>
<p>在本文中，我们使用三个公开可用的数据集（ADNI，AIBL和OASIS）提出了AD中<code>可再现</code>和客观分类实验的框架。该框架包括：i）将三个数据集自动转换为标准格式（BIDS）; ii）模块化的预处理流水线，特征提取和分类方法，以及评估框架，为不同组件的基准测试提供基准。</p>
<p>我们使用这个框架来证明从三个数据集（ADNI，AIBL和OASIS）获得的T1 MRI和PET数据进行自动分类。 我们评估各种成分对分类性能的影响：<code>模态（T1 MRI或PET）</code>，<code>特征类型（体素或区域特征）</code>，<code>预处理</code>，<code>诊断标准（标准NINCDS / ADRDA标准或淀粉样蛋白精制标准）</code>，<code>分类算法</code>。 首先在ADNI，AIBL和OASIS数据集上独立进行实验，并通过将对ADNI训练的分类器应用于AIBL和OASIS数据来评估结果的推广。</p>
<p>本文的贡献：</p>
<p>i）管理公开数据集的框架及其与新主题的持续<code>更新</code>，特别是全脑自动转换为脑成像数据结构（BIDS）格式的工具<br>ii）一组<code>模块化的预处理管道</code>，特征提取和分类方法，以及评估框架，为不同组件的基准测试提供基准;<br>iii）对来自三个公开可用的神经成像<code>数据集</code>（ADNI，AIBL和OASIS）的T1 MRI和PET数据进行大规模评估。</p>
<p>对于所有分类任务，FDG PET优于T1 MRI。</p>
<p>All the code of the framework and the experiments is publicly available: general- purpose tools have been integrated into the <a href="www.clinica.run">Clinica software</a> and the paper-specific code is available at: <a href="https://gitlab.icm-institute.org/aramislab/AD-ML" target="_blank" rel="noopener">https://gitlab.icm-institute.org/aramislab/AD-ML</a>.</p>
<h5 id="细节-2"><a href="#细节-2" class="headerlink" title="细节"></a>细节</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- ABSTRACT</span><br><span class="line"></span><br><span class="line">1. Introduction</span><br><span class="line"></span><br><span class="line">2. Materials</span><br><span class="line">   2.1. Datasets</span><br><span class="line">   2.2. Participants</span><br><span class="line">     2.2.1. ADNI</span><br><span class="line">     2.2.2. AIBL </span><br><span class="line">     2.2.3. OASIS</span><br><span class="line">   2.3. Imaging data</span><br><span class="line">	   2.3.1. ADNI</span><br><span class="line">  		 2.3.1.1. T1-weighted MRI. </span><br><span class="line">  		 2.3.1.2. PET. </span><br><span class="line">     2.3.2. AIBL</span><br><span class="line">     2.3.3. OASIS</span><br><span class="line">     </span><br><span class="line">3. Methods</span><br><span class="line">	3.1. Converting datasets to a standardized data structure  # 可以借鉴其工具的实现</span><br><span class="line">    3.1.1. Conversion of the ADNI dataset to BIDS： dicom → nifti; Once the images of interest have been selected and the paths to the image files identified, `the imaging data can be converted to BIDS`. ...</span><br><span class="line">    			 - If the modality was acquired for a specific pair of subject-session, and several scans and/or preprocessed images are available, `only one is converted`. </span><br><span class="line">    3.1.2. Conversion of the AIBL dataset to BIDS: like above.</span><br><span class="line">    3.1.3. Conversion of the OASIS dataset to BIDS：Analyze → nifti; create the BIDS folder hierarchy → the images are copied to the appropriate folder and renamed</span><br><span class="line">	</span><br><span class="line">	3.2. Preprocessing pipelines: Two pipelines were developed to preprocess the anatomical `T1w MRI` and `PET` images.</span><br><span class="line">		3.2.1. Preprocessing of T1-weighted MR images:i.the Unified Segmentation procedure(tissue segmentation, bias correction and spatial normalization) ii. create DARTEL template  iii. transformation of the DARTEL template into MNI space</span><br><span class="line">		3.2.2. Preprocessing of PET images：PET(with T1w) → MNI → SUVR图(归一化)	</span><br><span class="line"></span><br><span class="line">	3.3. Feature extraction:Two types of features were extracted from the imaging data: `voxel` and `region features`.T1w MR --- the gray matter density; FDG PET --- SUVR.</span><br><span class="line">		- AAL2</span><br><span class="line">		- AICHA</span><br><span class="line">		- Hammers</span><br><span class="line">		- LPBA40</span><br><span class="line">		- Neuromorphometrics10</span><br><span class="line">	</span><br><span class="line">	3.4. Classification models: We considered three different classifiers: `linear SVM`(with both the voxel and the regional features), `logistic regression with L2 regularization` and `random forest`(only used for the region-based analyses), all available in Clinica. </span><br><span class="line">		3.4.1. Linear SVM</span><br><span class="line">		3.4.2. Logistic regression with L2 regularization</span><br><span class="line">		3.4.3. Random forest</span><br><span class="line">	3.5. Evaluation strategy</span><br><span class="line">			3.5.1. Cross-validation</span><br><span class="line">			3.5.2. Metrics</span><br><span class="line">	3.6. Classification experiments</span><br><span class="line">	</span><br><span class="line">4. Results</span><br><span class="line">	4.1. Influence of the atlas：no specific atlas provides the highest classification accuracy for all the tasks. → the `AAL2` atlas was chosen as reference atlas as it leads to good classification accuracies and is widely used in the neuroimaging community.</span><br><span class="line">	4.2. Influence of the smoothing: for most classification tasks, the balanced accuracy does not vary to a great extent with the smoothing kernel size. → As the degree of smoothing does `not have a clear impact` on the classification performance, we chose to present the subsequent results related to the voxel-based classification `with a reference smoothing of 4 mm`.</span><br><span class="line">	4.3. Influence of the type of features: do not show notable differences between the mean balanced accuracies obtained using voxel or regional features.</span><br><span class="line">	4.4. Influence of the classification method: both the linear SVM and logistic regression with L2 regularization models lead to similar balanced accuracies, consistently higher than the one obtained with random forest for all the tasks and imaging modalities tested.</span><br><span class="line">	4.5. Influence of the partial volume correction of PET images： little difference between the balanced accuracies obtained with and without PVC. </span><br><span class="line">	4.6. Influence of the magnetic field strength：no matter the experiment, the balanced accuracy is always `higher for the 3 T scan` subset compared to the 1.5 T scan subset, which is not surprising as 3 T images should have a better signal-to-noise ratio.</span><br><span class="line">	4.7. Influence of class imbalance:It thus seems that a very strong class imbalance (as in the case of AIBL where the proportion is 6 to 1) leads to lower performance but that moderate class imbalance (up to 2 to 1 in ADNI) are adequately handled.</span><br><span class="line">	4.8. Influence of the dataset：Performances obtained on ADNI and AIBL were comparable and much higher than those obtained on OASIS. → classifiers trained on ADNI generalized well to the other datasets. In particular, training on ADNI substantially improved the classification performances on OASIS. (ADNI has the larger training set size, higher image quality or stricter diagnostic criteria.)</span><br><span class="line">	4.9. Influence of the training dataset size:the balanced accuracy in- creases with the number of training samples.</span><br><span class="line">	4.10. Influence of the diagnostic criteria: 淀粉样蛋白状态信息有助于提高任务性能</span><br><span class="line">	4.11. Computation time: SVM和逻辑回归实验的运算时间远远少于随机森林实验所需的运算时间</span><br><span class="line">	</span><br><span class="line">5. Discussion</span><br><span class="line">	 - FDG PET与MRI相比具有优越的性能</span><br><span class="line">6. Conclusions</span><br></pre></td></tr></table></figure>
<h4 id="4-Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease"><a href="#4-Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease" class="headerlink" title="4. Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease"></a>4. <a href="https://scholar.google.com/scholar?q=Multimodal+Neuroimaging+Feature+Learning+With+Multimodal+Stacked+Deep+Polynomial+Networks+for+Diagnosis+of+Alzheimer&#39;s+Disease&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart" target="_blank" rel="noopener">Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease</a></h4><p>该研究提出了一种<code>多模式堆叠DPN</code>（MM-SDPN）算法，MM-SDPN由两级SDPN组成，用于融合和学习用于AD诊断的<code>多模态神经成像数据</code>的特征表示。具体而言，两个SDPN首先用于分别学习<code>MRI</code>和<code>PET</code>的高级特征，然后将其输入另一个SDPN以融合多模态神经影像信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">I. INTRODUCTION</span><br><span class="line">	The most commonly used feature extraction methods for neuroimaging data can be roughly divided into four categories: 1) The voxel-based approaches that simply and directly extract features from voxel intensity; 2) The vertex-based approaches whose features are defined at the vertex-level on the cortical surface; 3) The region of interest (ROI) based approaches that extract features from predefined brain regions; 4) patch-based approaches that learn new feature representation from local patches.  As a result, these features usually obtain superior classification results.</span><br><span class="line">  - The voxel- and vertex-based features usually have very high dimensionality, and therefore dimensionality reduction is important to achieve more compact and effective features. </span><br><span class="line">  - The ROI-based features are widely used, because they not only have relatively low feature dimensionality, but also cover the whole brain. However, the features extracted from ROIs are somewhat coarse and cannot reflect small or subtle changes involved in the brain diseases. </span><br><span class="line">  - The patch-based features are learned from the whole brain, and can effectively capture the diseased-related pathologies.  貌似最佳</span><br><span class="line"></span><br><span class="line">Why need MM-SDPN？</span><br><span class="line">受监督的DPN将潜在地从用于AD诊断的小神经影像数据中学习优越的特征表示。另一方面，特征提取的逐层堆叠通常在DL中产生更好的表示，例如`DBN和SAE`，这促使开发堆叠DPN（SDPN）算法以学习更高级别的特征表示。此外，已经证明，可以同时学习和融合`多模态神经影像数据`的多模式DL算法优于用于AD分类的单模态DL算法。因此，值得研究多模堆叠DPN算法。</span><br><span class="line"></span><br><span class="line">II. METHODS</span><br><span class="line">A. Deep Polynomial Networks Algorithm  # 拟合？</span><br><span class="line">B. Stacked Deep Polynomial Networks: 每个基本DPN都采用有监督的分块方式进行训练，无需反向传播，这与其他流行的深层架构不同。因此，与具有反向传播策略的其他DL算法相比，SDPN非常简单，具有相对低的计算复杂度。</span><br><span class="line">C. Multimodal Stacked DPN:在第一阶段，每个神经影像数据将被馈送到其相应的SDPN模块，以学习高级特征表示。每种特定模态的高级特征反映了它自己的属性，但不同模态之间没有相关信息。然后，所有学习的特征在第二阶段被馈送到新的SDPN模块，以便与所有模态相关联。因此，最终学习的高级特征既包含每种模态的内在属性，也包含所有模态之间的相关性。因此，SDPN学到的特征更具有辨别力和鲁棒性。在我们的MM-SDPN算法中，由于DPN在每个网络层中执行前馈监督学习而没有精细转向，因此难以执行与[38]中相同的学习策略来推断MRI和PET之间的相关性。因此，通过联合训练第二阶段SDPN与在第一阶段中学习的级联MRI和PET特征来学习`共享表示`。它类似于[42]中使用的简单融合方法。</span><br><span class="line"></span><br><span class="line">III. EXPERIMENTS AND RESULTS</span><br><span class="line">A. Neuroimaging Data Preprocessing</span><br><span class="line">具体而言，预处理首先在`MRI图像`上进行，包括前连合（AC） - 后连合（PC）校正，N3算法强度不均匀，以及由小脑提取的颅骨剥离和去除小脑。然后通过FSL包中的FAST算法将MR图像`分割成三种不同的组织`，即灰质，白质和脑脊液[49]。在通过`HAMMER算法`[50]注册后，每个MR图像被分成93个ROI，基于模板，Kabani等人使用93个手动标记的ROI。 [51]。然后计算灰质组织的体积作为每个ROI的特征，产生93个特征。然后通过刚性配准将每个PET图像与其对应的MRI图像`对准`。将相同ROI的平均强度计算为PET图像的特征。因此，分别从MRI和PET图像中`提取93个特征`。</span><br><span class="line">B. Performance Evaluation: Four classification tasks are performed, namely `AD vs. NC`, `MCI vs. NC`, `MCI-C vs. MCI-NC`, and `AD vs. MCI-C vs. MCI- NC vs. NC`.</span><br><span class="line">DPN-3-MRI、DPN-6-MRI、SDPN-MRI、DPN-3-PET、DPN-6-PET、SDPN-PET、SDPN-MRI-PET、MM-SDPN + SVM/LINEAR CLASSIFIER</span><br><span class="line">C. Results on AD vs. NC：</span><br><span class="line">MM-SDPN算法达到最佳性能，平均分类精度为97.13±4.44％，灵敏度为95.93±7.84％，特异性为98.53±5.05％，因为它成功地融合了MRI和PET信息。另一方面，尽管DPN-6（具有6层网络的DPN）在基于单一模态成像的AD分类的MRI和PET数据上优于DPN-3，但SDPN仍然比DPN-6略好，这表明其有效性由于堆叠技术的SDPN。</span><br><span class="line">MM-SDPN在所有评估指标上都优于所有其他具有SVM和线性分类器的算法。</span><br><span class="line">D. Results on MCI vs. NC：尽管DPN-6优于DPN-3，但SDPN在基于单模态成像的MRI和PET数据上的MCI分类方面优于DPN。</span><br><span class="line">E. Results on MCI-C vs. MCI-NC: SDPN对于单一模态神经成像数据的性能要比DPN-6和DPN-3好得多。</span><br><span class="line">F. Results on AD vs. MCI-C vs. MCI-NC vs. NC:与最先进的基于SAE的算法[38]相比，我们提出的具有SVM分类器的MM-SDPN算法实现了分类精度提高3.21％和灵敏度提高1.51％。</span><br><span class="line"></span><br><span class="line">IV. DISCUSSION  # 核心、优质总结</span><br><span class="line">在这项工作中，我们提出了一种MM-SDPN算法，可以有效地学习基于多模态神经影像学的AD诊断的特征。 ADNI数据集上的四组实验结果表明，与最先进的基于多模态学习的算法相比，所提出的MM-SDPN算法实现了最佳性能。</span><br><span class="line">分析：</span><br><span class="line">原始ROI特征是低级特征，不能以良好区分的方式表示AD的属性。当应用DPN来学习ROI特征的特征时，提供了更复杂的表示，因此DPN已经实现了显着的改进。在多次堆叠基本DPN块之后，获得更高级别的表示。因此，对于基于单模态神经成像的AD分类，SDPN比原始DPN具有更好的性能。</span><br><span class="line">值得注意的是，尽管随着隐层的增加，6层DPN优于3层DPN，但是根据神经网络中的通用逼近定理，太深的网络将增加计算复杂度，而近似的精度没有明显增加。</span><br><span class="line">另一方面，结果还表明，具有两个3层DPN的SDPN优于6层DPN，因为第二层基本DPN中第一层的基础建立在更高级别的特征上，即串联特征第一级基本DPN，这个基础将在学习二级DPN后生成更有效和更高级别的功能。此外，与具有更深网络的DPN相比，SDPN更容易调整参数以实现相同的性能。</span><br><span class="line">在这项研究中，两个分类器，即SVM和线性分类器，用于评估SDPN和MM-SDPN的性能。两个分类器都给出了类似的结果，这表明AD分类的良好性能更多地取决于学习的特征而不是分类器。因此，MM-SDPN真正有效地学习了一个好的特征表示。</span><br><span class="line"></span><br><span class="line">DPN的算法结构使其适用于小型数据集。 由于神经影像数据通常仅提供有限的标记地面实况样本，并且先验标签信息有利于小数据的分类任务，因此监督DPN比不受控制的DL算法更适合于小神经成像数据集。</span><br><span class="line"></span><br><span class="line">V. CONCLUSION</span><br><span class="line">在这项工作中，提出了一种MM-SDPN算法。它由两阶段SDPN组成，可以有效地学习和融合多模态数据，用于诊断阿尔茨海默病。 MM-SDPN实现了最先进的表现，用于对AD进展的两个阶段和四个阶段进行分类。因此，所提出的MM-SDPN不仅可以作为多模神经成像数据的强大表示算法，还可以用于其他医学数据。</span><br></pre></td></tr></table></figure>
<ol start="5">
<li><p><a href="https://scholar.google.com/scholar?q=Multimodal+Neuroimaging+Feature+Learning+for+Multiclass+Diagnosis+of+Alzheimer%E2%80%99s+Disease&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart" target="_blank" rel="noopener">Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer’s Disease</a></p>
<p>该框架使用<code>零掩蔽策略</code>进行数据融合，以从多种数据模式中提取补充信息。与之前最先进的工作流程相比，我们的方法能够在一个设置中<code>融合多模态神经成像功能</code>，并且可能需要<code>较少标记的数据</code>。 AD的二元分类和多类分类均实现了性能提升。讨论了拟议框架的优点和局限性。</p>
</li>
</ol>
<p>我们提出了一种新的多层AD诊断框架，其中嵌入了深度学习架构，其受益于多模态神经影像学特征之间的协同作用。该框架由<code>SAE</code>和soft-max逻辑回归器构成。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">I. INTRODUCTION</span><br><span class="line"></span><br><span class="line">II. METHODOLOGY</span><br><span class="line">A. Data Acquisition and Feature Extraction</span><br><span class="line">B. Learning Framework</span><br><span class="line">C. Feature Examination</span><br><span class="line"></span><br><span class="line">III. EXPERIMENTS AND RESULTS</span><br><span class="line">A. Visualization of High-Level Biomarkers</span><br><span class="line">B. Performance Evaluation</span><br><span class="line"></span><br><span class="line">IV. DISCUSSION</span><br><span class="line">A. Model Designing and Training</span><br><span class="line">B. Limitations and Future Work</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">V. CONCLUSION</span><br></pre></td></tr></table></figure>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2019-07-29T03:49:35.684Z" itemprop="dateUpdated">2019-07-29 11:49:35</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="CaptainSE">
            CaptainSE
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            

            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/10/AD-Papers/&title=《AD_Papers》 — Go Further&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/10/AD-Papers/&title=《AD_Papers》 — Go Further&source=【阅读时间】XXX min XXX words【阅读内容】……" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/10/AD-Papers/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《AD_Papers》 — Go Further&url=http://yoursite.com/2019/07/10/AD-Papers/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/10/AD-Papers/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/07/15/致Snorlax/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">致Snorlax</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/07/02/Generative-Adversarial-Network-in-Medical-Imaging-A-Review/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Generative Adversarial Network in Medical Imaging A Review</h4>
      </a>
    </div>
  
</nav>



    

















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢老板~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>CaptainSE &copy; 2015 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/10/AD-Papers/&title=《AD_Papers》 — Go Further&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/10/AD-Papers/&title=《AD_Papers》 — Go Further&source=【阅读时间】XXX min XXX words【阅读内容】……" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/10/AD-Papers/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《AD_Papers》 — Go Further&url=http://yoursite.com/2019/07/10/AD-Papers/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/10/AD-Papers/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABw0lEQVR42u3aQY7CMAwFUO5/6c4BZlq+4ziC0csKUZU8s7AS269XvK5fK3mavPWaWLi4uG3u9bh+//TzNndP78LIDbi4uOe5+QbPmyXv5n8BLi7ut3Dv3sqPPri4uP+Je0dPAsDFxf1Gbn6Iia4oxYBH7mq4uLgNbl6lnPs8Ut/FxcVd4l6NVT0kbdgRFxf3CLeadPIyaN6OrZZfcXFxP4G7q+2ah/FcfMHFxT3JTcoQyTadwkdUCsHFxR3mrhUv8iJpp3H7x2dcXNyP4ebDVf2q7ZtjEy4u7hHuWmLKRzGqYUfB4+LiDnPzEYc8kXWGugpzIri4uGPcatpaC7UTWHTcwcXF3cpdG5vIv1+7/EQ9H1xc3GFudZCiOnJRTYtvBi9wcXGHuWuDFNWhjWpIhVMYLi7uALe6Zedik+zSarLi4uJu4q5ddZIyaL/VevuX4eLiDnOv4poonRRCxcXFPcJdSy6dy09+6WqhcXFx29wkeeWpLR/zWtwLFxf3ILdaHt3bSik0XHFxcT+Mm5dL+lemVnUWFxf3ILc/QvGcEMutVlxc3GFu//Kzd5ijPE2Gi4u7lVs9VySIPEl1xj5wcXEHuD/zxucer+2MsAAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Go Further | Stay Hungry, Stay Foolish';
            clearTimeout(titleTime);
        } else {
            document.title = 'Go Further | Stay Hungry, Stay Foolish';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
