<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>AD-Papers-Abstract | Go Further | Stay Hungry, Stay Foolish</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#142421">
    
    
    <meta name="keywords" content="">
    <meta name="description" content="【阅读时间】XXX min XXX words【阅读内容】……">
<meta property="og:type" content="article">
<meta property="og:title" content="AD-Papers-Abstract">
<meta property="og:url" content="http://yoursite.com/2019/07/29/AD-Papers-Abstract/index.html">
<meta property="og:site_name" content="Go Further">
<meta property="og:description" content="【阅读时间】XXX min XXX words【阅读内容】……">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-07-30T07:38:09.729Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AD-Papers-Abstract">
<meta name="twitter:description" content="【阅读时间】XXX min XXX words【阅读内容】……">
    
        <link rel="alternate" type="application/atom+xml" title="Go Further" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">CaptainSE</h5>
          <a href="mailto:841145636@qq.com" title="841145636@qq.com" class="mail">841145636@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/Captainzj" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">AD-Papers-Abstract</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">AD-Papers-Abstract</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-29T12:11:30.000Z" itemprop="datePublished" class="page-time">
  2019-07-29
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/">Paper</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/ADNI/">ADNI</a></li></ul></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease"><span class="post-toc-number">1.</span> <span class="post-toc-text">Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease"><span class="post-toc-number">2.</span> <span class="post-toc-text">Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data"><span class="post-toc-number">3.</span> <span class="post-toc-text">Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease"><span class="post-toc-number">4.</span> <span class="post-toc-text">Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Multimodal-Neuroimaging-Feature-Learning-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease"><span class="post-toc-number">5.</span> <span class="post-toc-text">Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer’s Disease</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Joint-Classification-and-Regression-via-Deep-Multi-Task-Multi-Channel-Learning-for-Alzheimer’s-Disease-Diagnosis"><span class="post-toc-number">6.</span> <span class="post-toc-text">Joint Classification and Regression via Deep Multi-Task Multi-Channel Learning for Alzheimer’s Disease Diagnosis</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Automated-classification-of-Alzheimer’s-disease-and-mild-cognitive-impairment-using-a-single-MRI-and-deep-neural-networks"><span class="post-toc-number">7.</span> <span class="post-toc-text">Automated classification of Alzheimer’s disease and mild cognitive impairment using a single MRI and deep neural networks</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Multimodal-and-Multiscale-Deep-Neural-Networks-for-the-Early-Diagnosis-of-Alzheimer’s-Disease-using-structural-MR-and-FDG-PET-images"><span class="post-toc-number">8.</span> <span class="post-toc-text">Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer’s Disease using structural MR and FDG-PET images</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Corpus-Callosum-Radiomics-Based-Classification-Model-in-Alzheimer’s-Disease-A-Case-Control-Study"><span class="post-toc-number">9.</span> <span class="post-toc-text">Corpus Callosum Radiomics-Based Classification Model in Alzheimer’s Disease: A Case-Control Study</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#An-Ensemble-Learning-System-for-a-4-Way-Classification-of-Alzheimer’s-Disease-and-Mild-Cognitive-Impairment"><span class="post-toc-number">10.</span> <span class="post-toc-text">An Ensemble Learning System for a 4-Way Classification of Alzheimer’s Disease and Mild Cognitive Impairment</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#alzheimer-Disease-and-Behavioral-Variant-Frontotemporal-Dementia-Automatic-Classification-Based-on-Cortical-Atrophy-for-Single-Subject-Diagnosis"><span class="post-toc-number">11.</span> <span class="post-toc-text">alzheimer Disease and Behavioral Variant Frontotemporal Dementia: Automatic Classification Based on Cortical Atrophy for Single-Subject Diagnosis</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#ALZHEIMER’S-DISEASE-DIAGNOSTICS-BY-A-DEEPLY-SUPERVISED-ADAPTABLE-3D-CONVOLUTIONAL-NETWORK"><span class="post-toc-number">12.</span> <span class="post-toc-text">ALZHEIMER’S DISEASE DIAGNOSTICS BY A DEEPLY SUPERVISED ADAPTABLE 3D CONVOLUTIONAL NETWORK</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Early-Diagnosis-of-Alzheimer’s-Disease-Based-on-Resting-State-Brain-Networks-and-Deep-Learning"><span class="post-toc-number">13.</span> <span class="post-toc-text">Early Diagnosis of Alzheimer’s Disease Based on Resting-State Brain Networks and Deep Learning</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Auto-Detection-of-Alzheimer’s-Disease-Using-Deep-Convolutional-Neural-Networks"><span class="post-toc-number">14.</span> <span class="post-toc-text">Auto-Detection of Alzheimer’s Disease Using Deep Convolutional Neural Networks</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#A-Deep-CNN-based-Multi-class-Classification-of-Alzheimer’s-Disease-using-MRI"><span class="post-toc-number">15.</span> <span class="post-toc-text">A Deep CNN based Multi-class Classification of Alzheimer’s Disease using MRI</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Classification-of-Alzheimer-Disease-on-Imaging-Modalities-with-Deep-CNNs-using-Cross-Modal-Transfer-Learning"><span class="post-toc-number">16.</span> <span class="post-toc-text">Classification of Alzheimer Disease on Imaging Modalities with Deep CNNs using Cross-Modal Transfer Learning</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#A-Deep-Learning-Pipeline-to-Classify-Different-Stages-of-Alzheimer’s-Disease-From-fMRI-Data"><span class="post-toc-number">17.</span> <span class="post-toc-text">A Deep Learning Pipeline to Classify Different Stages of Alzheimer’s Disease From fMRI Data</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Brain-MRI-analysis-for-Alzheimer’s-disease-diagnosis-using-an-ensemble-system-of-deep-convolutional-neural-networks"><span class="post-toc-number">18.</span> <span class="post-toc-text">Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Combining-Convolutional-and-Recurrent-Neural-Networks-for-Alzheimer’s-Disease-Diagnosis-Using-PET-Images"><span class="post-toc-number">19.</span> <span class="post-toc-text">Combining Convolutional and Recurrent Neural Networks for Alzheimer’s Disease Diagnosis Using PET Images</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#A-Deep-Neural-Network-Approach-For-Early-Diagnosis-of-Mild-Cognitive-Impairment-Using-Multiple-Features"><span class="post-toc-number">20.</span> <span class="post-toc-text">A Deep Neural Network Approach For Early Diagnosis of Mild Cognitive Impairment Using Multiple Features</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Visual-Explanations-From-Deep-3D-Convolutional-Neural-Networks-for-Alzheimer’s-Disease-Classification"><span class="post-toc-number">21.</span> <span class="post-toc-text">Visual Explanations From Deep 3D Convolutional Neural Networks for Alzheimer’s Disease Classification</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Visualizing-Convolutional-Networks-for-MRI-based-Diagnosis-of-Alzheimer’s-Disease"><span class="post-toc-number">22.</span> <span class="post-toc-text">Visualizing Convolutional Networks for MRI-based Diagnosis of Alzheimer’s Disease</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Shearlet-based-Stacked-Convolutional-Network-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease-using-the-Florbetapir-PET-Amyloid-Imaging-Data"><span class="post-toc-number">23.</span> <span class="post-toc-text">Shearlet based Stacked Convolutional Network for Multiclass Diagnosis of Alzheimer’s Disease using the Florbetapir PET Amyloid Imaging Data</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Alzheimer’s-disease-Classification-from-Brain-MRI-based-on-transfer-learning-from-CNN"><span class="post-toc-number">24.</span> <span class="post-toc-text">Alzheimer’s disease Classification from Brain MRI based on transfer learning from CNN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#A-Novel-Multimodal-MRI-Analysis-for-Alzheimer’s-Disease-Based-on-Convolutional-Neural-Network"><span class="post-toc-number">25.</span> <span class="post-toc-text">A Novel Multimodal MRI Analysis for Alzheimer’s Disease Based on Convolutional Neural Network</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#DISCRIMINATIVE-ANALYSIS-OF-THE-HUMAN-CORTEX-USING-SPHERICAL-CNNS-A-STUDY-ON-ALZHEIMER’S-DISEASE-DIAGNOSIS"><span class="post-toc-number">26.</span> <span class="post-toc-text">DISCRIMINATIVE ANALYSIS OF THE HUMAN CORTEX USING SPHERICAL CNNS - A STUDY ON ALZHEIMER’S DISEASE DIAGNOSIS</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3D-Inception-based-CNN-with-sMRI-and-MD-DTI-data-fusion-for-Alzheimer’s-Disease-diagnostics"><span class="post-toc-number">27.</span> <span class="post-toc-text">3D Inception-based CNN with sMRI and MD-DTI data fusion for Alzheimer’s Disease diagnostics</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3D-CNN-based-classification-using-sMRI-and-MD-DTI-images-for-Alzheimer-disease-studies"><span class="post-toc-number">28.</span> <span class="post-toc-text">3D CNN-based classification using sMRI and MD-DTI images for Alzheimer disease studies</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#MRI-to-FDG-PET-Cross-Modal-Synthesis-Using-3D-U-Net-For-Multi-Modal-Alzheimer’s-Classification"><span class="post-toc-number">29.</span> <span class="post-toc-text">MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer’s Classification</span></a></li></ol>
        </nav>
    </aside>


<article id="post-AD-Papers-Abstract"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">AD-Papers-Abstract</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-29 20:11:30" datetime="2019-07-29T12:11:30.000Z"  itemprop="datePublished">2019-07-29</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/">Paper</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Paper/ADNI/">ADNI</a></li></ul></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p>
<a id="more"></a>
<h4 id="Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease"><a href="#Multiscale-deep-neural-network-based-analysis-of-FDG-PET-images-for-the-early-diagnosis-of-Alzheimer’s-disease" class="headerlink" title="Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease"></a>Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer’s disease</h4><blockquote>
<p> 基于多尺度深度神经网络的FDG-PET图像分析早期诊断阿尔茨海默病</p>
</blockquote>
<p>Alzheimer’s disease (AD) is one of the most common neurodegenerative diseases with a commonly seen prodromal mild cognitive impairment (MCI) phase where memory loss is the main complaint progressively worsening with behavior issues and poor self-care. However, not all individuals clinically diagnosed with MCI progress to AD. A fraction of subjects with MCI either progress to non-AD dementia or remain stable at the MCI stage without progressing to dementia. Although a curative treatment of AD is currently unavailable, it is extremely important to correctly identify the individuals in the MCI phase that will go on to develop AD so that they may benefit from a curative treatment when one becomes avail- able in the near future. At the same time, it would be highly desirable to also correctly identify those in the MCI phase that do not have AD pathology so they may be spared from unnecessary pharmocologic interventions that, at best, may provide them no benefit, and at worse, could further harm them with adverse side-effects. Additionally, it may be easier and simpler to identify the cause of the cognitive impairment in these non-AD cases, and hence proper identification of prodromal AD will be of benefit to these individuals as well.<br>Fluorodeoxy glucose positron emission tomography (FDG-PET) captures the metabolic activity of the brain, and this imaging modality has been reported to identify changes related to AD prior to the on- set of structural changes. Prior work on designing classifier using FDG-PET imaging has been promising. Since deep-learning has recently emerged as a powerful tool to mine features and use them for accu- rate labeling of the group membership of given images, we propose a novel deep-learning framework using FDG-PET metabolism imaging to identify subjects at the MCI stage with presymptomatic AD and discriminate them from other subjects with MCI (non-AD / non-progressive). Our multiscale deep neural network obtained 82.51% accuracy of classification just using measures from a single modality (FDG-PET metabolism data) outperforming other comparable FDG-PET classifiers published in the recent literature.</p>
<p>阿尔茨海默病（AD）是最常见的神经退行性疾病之一，具有常见的前驱性轻度认知障碍（MCI）期，其中记忆丧失是随着行为问题和自我护理不良而逐渐恶化的主要原因。然而，并非所有临床诊断为MCI的个体都进展为AD。一小部分患有MCI的受试者进展至非AD痴呆或在MCI阶段保持稳定而未进展至痴呆。虽然目前无法对AD进行治愈性治疗，但正确识别MCI阶段的个体将非常重要，这些个体将继续发展AD，以便在不久的将来可以获得治愈性治疗。同时，非常需要正确识别那些没有AD病理的MCI期患者，这样他们就可以免于不必要的药物干预，这些干预最多可能不会给他们带来任何好处，更糟糕的是，进一步伤害他们的副作用。另外，在这些非AD病例中识别认知障碍的原因可能更容易和更简单，因此正确鉴定前驱AD也将对这些个体有益。<br>氟脱氧葡萄糖正电子发射断层扫描（FDG-PET）捕获大脑的代谢活动，据报道这种成像方式可以在结构变化发生之前识别与AD相关的变化。使用FDG-PET成像设计分类器的先前工作一直很有前景。由于深度学习最近已成为挖掘特征的有力工具，并将其用于精确标记给定图像的群组成员，我们提出了一种新的深度学习框架，使用FDG-PET代谢成像来识别MCI的受试者患有症状前AD的阶段，并将其与其他MCI（非AD /非进展）受试者区分开来。我们的多尺度深度神经网络仅使用来自单一模态（FDG-PET代谢数据）的测量获得82.51％的分类准确度，优于最近文献中公布的其他可比较的FDG-PET分类器。</p>
<h4 id="Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease"><a href="#Application-of-Machine-Learning-to-Arterial-Spin-Labeling-in-Mild-Cognitive-Impairment-and-Alzheimer’s-Disease" class="headerlink" title="Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease"></a>Application of Machine Learning to Arterial Spin Labeling in Mild Cognitive Impairment and Alzheimer’s Disease</h4><blockquote>
<p>机器学习在动脉自旋标记治疗轻度认知障碍和阿尔茨海默病中的应用</p>
</blockquote>
<p><code>Purpose</code>: This current study investigates whether multivariate pattern recognition analysis of arterial spin labeling (ASL) perfusion maps can be used for classification and single-subject prediction of patients with Alzheimer’s disease (AD), mild cognitive impairment (MCI), and subjective cognitive decline (SCD), after using the W-score method to remove confounding effects of gender and age. Materials and Methods: The local institutional review board approved the study. Subjects provided written informed consent. 3.0-T pseudo-continuous ASL images were acquired from 100 probable AD patients, 60 MCI patients, of which 12 remained stable (MCIs), 12 converted to AD (MCIc), and 36 without follow-up, 100 SCD subjects, and 26 healthy controls. The three main groups (i.e. AD, MCI, SCD) were divided into a gender and age-matched training-set (N = 130) and independent prediction-set (N = 130). Standardized perfusion scores adjusted for age and gender (W-scores) were computed per voxel for each subject. Training of a Support Vector Machine (SVM) classifier used diagnostic status and perfusion maps. Discrimination maps were extracted and used for single-subject classification in the prediction-set. Prediction performance was assessed by means of a ROC analysis, generating an area under the curve (AUC) and sensitivity/specificity distribution.<br><code>Results</code>: Single-subject diagnosis in the prediction-set using the discrimination maps yielded excellent performance for AD vs. SCD (AUC .96, p &lt; .01), good performance for AD vs. MCI (AUC = 0.89, p &lt; .01), and poor performance for MCI vs. SCD (AUC = 0.63, p = .06). Application of the AD vs. SCD discrimination map for prediction of MCI subgroups resulted in good performance for MCIc vs. SCD (AUC = .84, p &lt; .01) and fair performance for MCIc vs. MCIs (AUC = .71, p &gt; .05).<br><code>Conclusion</code>: Using automated methods, age- and gender adjusted ASL perfusion maps can be used to classify and predict diagnoses of AD, MCI-converters, stable MCI patients and SCD subjects with good to excellent accuracy and AUC values.<br><code>目的</code>：本研究调查动脉自旋标记（ASL）灌注图的多变量模式识别分析是否可用于阿尔茨海默病（AD），轻度认知障碍（MCI）和主观认知能力下降患者的分类和单一主题预测（SCD），使用W-score方法消除性别和年龄的混杂影响。材料与方法：当地机构审查委员会批准了该研究。受试者提供书面知情同意书。从100例可能的AD患者，60例MCI患者中获得3.0-T假连续ASL图像，其中12例保持稳定（MCI），12例转换为AD（MCIc），36例未随访，100例SCD受试者和26例健康的控制。三个主要组（即AD，MCI，SCD）被分为性别和年龄匹配的训练集（N = 130）和独立预测集（N = 130）。对于每个受试者，针对每个体素计算针对年龄和性别（W分数）调整的标准化灌注分数。支持向量机（SVM）分类器的训练使用诊断状态和灌注图。提取歧视图并将其用于预测集中的单主题分类。通过ROC分析评估预测性能，产生曲线下面积（AUC）和灵敏度/特异性分布。<br><code>结果</code>：使用鉴别图在预测集中进行单一主题诊断，对AD与SCD（AUC .96，p &lt;.01）表现出优异的表现，AD与MCI的良好表现（AUC = 0.89，p &lt;.01 ），MCI与SCD的表现不佳（AUC = 0.63，p = .06）。应用AD与SCD鉴别图预测MCI亚组导致MCIc与SCD的良好表现（AUC = .84，p &lt;.01），MCIc与MCI的公平表现（AUC = .71，p&gt; .05）。<br><code>结论</code>：使用自动化方法，年龄和性别调整的ASL灌注图可用于分类和预测AD，MCI转换器，稳定MCI患者和SCD受试者的诊断，具有良好至极好的准确度和AUC值。</p>
<h4 id="Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data"><a href="#Reproducible-evaluation-of-classification-methods-in-Alzheimer’s-disease-Framework-and-application-to-MRI-and-PET-data" class="headerlink" title="Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data"></a>Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data</h4><blockquote>
<p>阿尔茨海默病分类方法的可重复评估：MRI和PET数据的框架和应用</p>
</blockquote>
<p>A large number of papers have introduced novel machine learning and feature extraction methods for automatic classification of Alzheimer’s disease (AD). However, while the vast majority of these works use the public dataset ADNI for evaluation, they are difficult to reproduce because different key components of the validation are often not readily available. These components include selected participants and input data, image preprocessing and cross-validation procedures. The performance of the different approaches is also difficult to compare objectively. In particular, it is often difficult to assess which part of the method (e.g. preprocessing, feature extraction or classification algorithms) provides a real improvement, if any. In the present paper, we propose a framework for reproducible and objective classification experiments in AD using three publicly available datasets (ADNI, AIBL and OASIS). The framework comprises: i) automatic conversion of the three datasets into a standard format (BIDS); ii) a modular set of preprocessing pipelines, feature extraction and classification methods, together with an evaluation framework, that provide a baseline for benchmarking the different components. We demonstrate the use of the framework for a large-scale evaluation on 1960 participants using T1 MRI and FDG PET data. In this evaluation, we assess the influence of different modalities, preprocessing, feature types (regional or voxel-based features), classifiers, training set sizes and datasets. Performances were in line with the state-of-the-art. FDG PET outperformed T1 MRI for all classification tasks. No difference in performance was found for the use of different atlases, image smoothing, partial volume correction of FDG PET images, or feature type. Linear SVM and L2- logistic regression resulted in similar performance and both outperformed random forests. The classification performance increased along with the number of subjects used for training. Classifiers trained on ADNI gener- alized well to AIBL and OASIS. All the code of the framework and the experiments is publicly available: general- purpose tools have been integrated into the Clinica software (<a href="http://www.clinica.run" target="_blank" rel="noopener">www.clinica.run</a>) and the paper-specific code is available at: <a href="https://gitlab.icm-institute.org/aramislab/AD-ML" target="_blank" rel="noopener">https://gitlab.icm-institute.org/aramislab/AD-ML</a>.</p>
<p>大量论文引入了用于阿尔茨海默病（AD）自动分类的新型机器学习和特征提取方法。然而，虽然绝大多数这些作品使用公共数据集ADNI进行评估，但它们很难再现，因为验证的不同关键组件通常不易获得。这些组件包括选定的参与者和输入数据，图像预处理和交叉验证程序。不同方法的表现也难以客观地比较。特别地，通常难以评估方法的哪个部分（例如，预处理，特征提取或分类算法）提供真正的改进（如果有的话）。在本文中，我们使用三个公开可用的数据集（ADNI，AIBL和OASIS）提出了AD中可重复和客观分类实验的框架。该框架包括：i）将三个数据集自动转换为标准格式（BIDS）; ii）模块化的预处理流水线，特征提取和分类方法，以及评估框架，为不同组件的基准测试提供基准。我们使用T1 MRI和FDG PET数据证明该框架用于对1960名参与者进行大规模评估。在此评估中，我们评估不同模态，预处理，要素类型（基于区域或体素的特征），分类器，训练集大小和数据集的影响。表演符合最新技术水平。对于所有分类任务，FDG PET优于T1 MRI。使用不同的图册，图像平滑，FDG PET图像的部分体积校正或特征类型没有发现性能差异。线性SVM和L2逻辑回归导致相似的性能，并且都优于随机森林。分类性能随着用于训练的受试者数量而增加。在ADNI上训练的分类器很好地适用于AIBL和OASIS。框架和实验的所有代码都是公开的：通用工具已集成到Clinica软件（<a href="http://www.clinica.run）中，特定于纸张的代码可从以下网址获得：https://gitlab.icm-institute.ORG/aramislab/AD-ML。" target="_blank" rel="noopener">www.clinica.run）中，特定于纸张的代码可从以下网址获得：https://gitlab.icm-institute.ORG/aramislab/AD-ML。</a></p>
<h4 id="Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease"><a href="#Multimodal-Neuroimaging-Feature-Learning-With-Multimodal-Stacked-Deep-Polynomial-Networks-for-Diagnosis-of-Alzheimer’s-Disease" class="headerlink" title="Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease"></a>Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer’s Disease</h4><blockquote>
<p> 多模态神经影像学特征学习多模态叠加深度多项式网络诊断阿尔茨海默病</p>
</blockquote>
<p><code>Abstract</code>—The accurate diagnosis of Alzheimer’s disease (AD) and its early stage, i.e., mild cognitive impairment, is essential for timely treatment and possible delay of AD. Fu- sion of multimodal neuroimaging data, such as magnetic resonance imaging (MRI) and positron emission tomogra- phy (PET), has shown its effectiveness for AD diagnosis. The deep polynomial networks (DPN) is a recently proposed deep learning algorithm, which performs well on both large- scale and small-size datasets. In this study, a multimodal stacked DPN (MM-SDPN) algorithm, which MM-SDPN con- sists of two-stage SDPNs, is proposed to fuse and learn feature representation from multimodal neuroimaging data for AD diagnosis. Specifically speaking, two SDPNs are first used to learn high-level features of MRI and PET, respec- tively, which are then fed to another SDPN to fuse multi- modal neuroimaging information. The proposed MM-SDPN algorithm is applied to the ADNI dataset to conduct both binary classification and multiclass classification tasks. Ex- perimental results indicate that MM-SDPN is superior over the state-of-the-art multimodal feature-learning-based algo- rithms for AD diagnosis.<br><code>Index Terms</code>—Alzheimer’s disease, deep learning, deep polynomial networks, multimodal stacked deep polynomial networks, multimodal neuroimaging.</p>
<p><code>摘要</code> - 阿尔茨海默病（AD）及其早期的准确诊断，即轻度认知障碍，对于及时治疗和可能的AD延迟至关重要。多模态神经影像数据的融合，如磁共振成像（MRI）和正电子发射断层扫描（PET），已显示其对AD诊断的有效性。深度多项式网络（DPN）是最近提出的深度学习算法，其在大规模和小尺寸数据集上都表现良好。在这项研究中，提出了一种多模式堆叠DPN（MM-SDPN）算法，MM-SDPN由两级SDPN组成，用于融合和学习用于AD诊断的多模态神经成像数据的特征表示。具体而言，两个SDPN首先用于分别学习MRI和PET的高级特征，然后将其输入另一个SDPN以融合多模态神经影像信息。建议的MM-SDPN算法应用于ADNI数据集，以进行二进制分类和多类分类任务。实验结果表明，MM-SDPN优于最先进的基于多模态特征学习的算法用于AD诊断。<br><code>索引术语</code> - 阿尔茨海默病，深度学习，深度多项式网络，多模态叠加深度多项式网络，多模态神经成像。</p>
<h4 id="Multimodal-Neuroimaging-Feature-Learning-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease"><a href="#Multimodal-Neuroimaging-Feature-Learning-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease" class="headerlink" title="Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer’s Disease"></a>Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer’s Disease</h4><blockquote>
<p>多模式神经影像学特征学习用于阿尔茨海默病的多类诊断</p>
</blockquote>
<p><code>Abstract</code>—The accurate diagnosis of Alzheimer’s disease (AD) is essential for patient care and will be increasingly important as disease modifying agents become available, early in the course of the disease. Although studies have applied machine learning meth- ods for the computer-aided diagnosis of AD, a bottleneck in the diagnostic performance was shown in previous methods, due to the lacking of efficient strategies for representing neuroimaging biomarkers. In this study, we designed a novel diagnostic frame- work with deep learning architecture to aid the diagnosis of AD. This framework uses a zero-masking strategy for data fusion to ex- tract complementary information from multiple data modalities. Compared to the previous state-of-the-art workflows, our method is capable of fusing multimodal neuroimaging features in one setting and has the potential to require less labeled data. A performance gain was achieved in both binary classification and multiclass clas- sification of AD. The advantages and limitations of the proposed framework are discussed.<br><code>Index Terms</code>—Alzheimer’s disease (AD), classification, deep Learning, MRI, neuroimaging, positron emission tomography (PET).</p>
<p><code>摘要</code> - 阿尔茨海默病（AD）的准确诊断对于患者护理至关重要，并且随着疾病调节剂的出现在疾病早期将变得越来越重要。虽然研究已将机器学习方法应用于AD的计算机辅助诊断，但由于缺乏表示神经影像生物标记物的有效策略，因此在先前的方法中显示出诊断性能的瓶颈。在这项研究中，我们设计了一个新的诊断框架与深度学习架构，以帮助诊断AD。该框架使用零掩蔽策略进行数据融合，以从多种数据模式中提取补充信息。与之前最先进的工作流程相比，我们的方法能够在一个设置中融合多模态神经成像功能，并且可能需要较少标记的数据。 AD的二元分类和多类分类均实现了性能提升。讨论了拟议框架的优点和局限性。<br><code>索引术语</code> - 阿尔茨海默病（AD），分类，深度学习，MRI，神经影像学，正电子发射断层扫描（PET）。</p>
<h4 id="Joint-Classification-and-Regression-via-Deep-Multi-Task-Multi-Channel-Learning-for-Alzheimer’s-Disease-Diagnosis"><a href="#Joint-Classification-and-Regression-via-Deep-Multi-Task-Multi-Channel-Learning-for-Alzheimer’s-Disease-Diagnosis" class="headerlink" title="Joint Classification and Regression via Deep Multi-Task Multi-Channel Learning for Alzheimer’s Disease Diagnosis"></a><strong>Joint Classification and Regression via Deep Multi-Task Multi-Channel Learning for Alzheimer’s Disease Diagnosis</strong></h4><blockquote>
<p>多模式神经影像学特征学习用于阿尔茨海默病的多类诊断</p>
</blockquote>
<p><code>Abstract</code>—In the field of computer-aided Alzheimer’s disease (AD) diagnosis, jointly identifying brain diseases and predicting clinical scores using magnetic resonance (MR) imaging have attracted increasing attention since these two tasks are highly correlated. Most of existing joint learning approaches require hand-crafted feature representations for MR images. Since hand- crafted features of MRI and classification/regression models may not coordinate well with each other, conventional methods may lead to sub-optimal learning performance. Also, demographic information (e.g., age, gender, and education) of subjects may also be related to brain status, and thus can help improve the di- agnostic performance. However, conventional joint learning meth- ods seldom incorporate such demographic information into the learning models. To this end, we propose a deep multi-task multi-channel learning (DM2L) framework for simultaneous brain dis- ease classification and clinical score regression, using MR imaging data and demographic information of subjects. Specifically, we first identify the discriminative anatomical landmarks from MR images in a data-driven manner, and then extract multiple image patches around these detected landmarks. We then propose a deep multi-task multi-channel convolutional neural network for joint classification and regression. Our DM2L framework can not only automatically learn discriminative features for MR images, but also explicitly incorporate the demographic information of subjects into the learning process. We evaluate the proposed method on four large multi-center cohorts with 1, 984 subjects, and the experimental results demonstrate that DM2L is superior to several state-of-the-art joint learning methods in both the tasks of disease classification and clinical score regression.</p>
<p><code>摘要</code> - 在计算机辅助阿尔茨海默病（AD）诊断领域，联合识别脑疾病和使用磁共振（MR）成像<code>预测</code>临床评分已引起越来越多的关注，因为这两个任务高度相关。大多数现有的联合学习方法需要手工制作的MR图像特征表示。由于MRI和分类/回归模型的手工制作特征可能彼此不能很好地协调，因此传统方法可能导致次优的学习性能。此外，受试者的人口统计信息（例如，年龄，性别和教育）也可能与大脑状态有关，因此可以帮助改善诊断性能。然而，传统的联合学习方法很少将这些人口统计信息纳入学习模型。为此，我们提出了一个深层多任务多通道学习（$DM^2L$）框架，用于同时进行脑部疾病分类和临床评分回归，使用MR成像数据和受试者的人口统计信息。具体地，我们首先以数据驱动的方式从MR图像识别辨别解剖标志，然后围绕这些检测到的标志提取多个图像块。然后，我们提出了一种用于<code>联合分类和回归的深度多任务多通道卷积神经网络</code>。我们的$DM^2L$框架不仅可以自动学习MR图像的判别特征，还可以明确地将受试者的人口统计信息纳入学习过程。我们对具有1,984名受试者的四个大型多中心队列进行了评估，实验结果表明$DM^2L$在疾病分类和临床评分回归的任务中均优于几种最先进的联合学习方法。</p>
<h4 id="Automated-classification-of-Alzheimer’s-disease-and-mild-cognitive-impairment-using-a-single-MRI-and-deep-neural-networks"><a href="#Automated-classification-of-Alzheimer’s-disease-and-mild-cognitive-impairment-using-a-single-MRI-and-deep-neural-networks" class="headerlink" title="Automated classification of Alzheimer’s disease and mild cognitive impairment using a single MRI and deep neural networks"></a>Automated classification of Alzheimer’s disease and mild cognitive impairment using a single MRI and deep neural networks</h4><blockquote>
<p>使用单个MRI和深度神经网络自动分类阿尔茨海默病和轻度认知障碍</p>
</blockquote>
<p>We built and validated a deep learning algorithm predicting the individual diagnosis of Alzheimer’s disease (AD) and mild cognitive impairment who will convert to AD (c-MCI) based on a single cross-sectional brain structural MRI scan. Convolutional neural networks (CNNs) were applied on 3D T1-weighted images from ADNI and subjects recruited at our Institute (407 healthy controls [HC], 418 AD, 280 c-MCI, 533 stable MCI [s-MCI]). CNN performance was tested in distinguishing AD, c-MCI and s-MCI. High levels of accuracy were achieved in all the classifications, with the highest rates achieved in the AD vs HC classification tests using both the ADNI dataset only (99%) and the combined ADNI + non-ADNI dataset (98%). CNNs discriminated c-MCI from s-MCI patients with an accuracy up to 75% and no difference between ADNI and non-ADNI images. CNNs provide a powerful tool for the automatic individual patient diagnosis along the AD continuum. Our method performed well without any prior feature engineering and regardless the variability of imaging protocols and scanners, demonstrating that it is exploitable by not-trained operators and likely to be generalizable to unseen patient data. CNNs may accelerate the adoption of structural MRI in routine practice to help assessment and management of patients.</p>
<p>我们建立并验证了一种深度学习算法，该算法<code>预测阿尔茨海默病（AD）和轻度认知障碍的个体诊断</code>，他们将基于单个横断面脑结构MRI扫描转换为AD（c-MCI）。将卷积神经网络（CNN）应用于来自ADNI的3D T1加权图像和我们研究所招募的受试者（407健康对照[HC]，418 AD，280 c-MCI，533稳定MCI [s-MCI]）。测试CNN性能以区分AD，c-MCI和s-MCI。在所有分类中都实现了高水平的准确性，使用仅ADNI数据集（99％）和组合ADNI +非ADNI数据集（98％），在AD与HC分类测试中实现了最高的准确率。 CNN从s-MCI患者中区分c-MCI，准确度高达75％，ADNI和非ADNI图像之间没有差异。 CNN为AD连续体中的自动个体患者诊断提供了强大的工具。我们的方法在没有任何先前特征工程的情况下表现良好，并且无论成像协议和扫描仪的可变性如何，都表明它可以被未经过培训的操作员利用，并且可能被推广到看不见的患者数据。 CNN可以在常规实践中加速结构MRI的采用，以帮助评估和管理患者。</p>
<h4 id="Multimodal-and-Multiscale-Deep-Neural-Networks-for-the-Early-Diagnosis-of-Alzheimer’s-Disease-using-structural-MR-and-FDG-PET-images"><a href="#Multimodal-and-Multiscale-Deep-Neural-Networks-for-the-Early-Diagnosis-of-Alzheimer’s-Disease-using-structural-MR-and-FDG-PET-images" class="headerlink" title="Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer’s Disease using structural MR and FDG-PET images"></a>Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer’s Disease using structural MR and FDG-PET images</h4><blockquote>
<p>使用结构MR和FDG-PET图像进行早期诊断阿尔茨海默病的多模态和多尺度深度神经网络</p>
</blockquote>
<p>Alzheimer’s Disease (AD) is a progressive neurodegenerative disease. Amnestic mild cognitive impairment (MCI) is a common first symptom before the conversion to clinical impairment where the individual becomes unable to perform activities of daily living independently. Although there is currently no treatment available, the earlier a conclusive diagnosis is made, the earlier the potential for interventions to delay or perhaps even prevent progression to full-blown AD. Neuroimaging scans acquired from MRI and metabolism images obtained by FDG-PET provide in-vivo view into the structure and function (glucose metabolism) of the living brain. It is hypothesized that combining different image modalities could better characterize the change of human brain and result in a more accuracy early diagnosis of AD. In this paper, we proposed a novel framework to discriminate normal control(NC) subjects from subjects with AD pathology (AD and NC, MCI subjects convert to AD in future). Our novel approach utilizing a multimodal and multiscale deep neural network was found to deliver a 85.68% accuracy in the prediction of subjects within 3 years to conversion. Cross validation experiments proved that it has better discrimination ability compared with results in existing published literature.</p>
<p>阿尔茨海默病（AD）是一种进行性神经退行性疾病。遗忘性轻度认知障碍（MCI）是转变为临床损伤之前的常见首发症状，其中个体变得不能独立地进行日常生活活动。虽然目前没有可用的治疗方法，但早期确定的诊断结果越早，干预的可能性就越早，甚至可能阻止进展为完全AD。从MRI获得的神经成像扫描和通过FDG-PET获得的代谢图像提供了对活脑的结构和功能（葡萄糖代谢）的体内观察。假设结合不同的图像模态可以更好地表征人脑的变化，从而更准确地早期诊断AD。在本文中，我们提出了一种新的框架，<code>以区分正常对照（NC）受试者与AD病理对象</code>（AD和NC，MCI受试者将来转换为AD）。我们利用多模态和多尺度深度神经网络的新方法被发现<code>在转换后3年内</code>对受试者的预测提供了85.68％的准确度。交叉验证实验证明，与现有已发表文献的结果相比，它具有更好的辨别能力。</p>
<h4 id="Corpus-Callosum-Radiomics-Based-Classification-Model-in-Alzheimer’s-Disease-A-Case-Control-Study"><a href="#Corpus-Callosum-Radiomics-Based-Classification-Model-in-Alzheimer’s-Disease-A-Case-Control-Study" class="headerlink" title="Corpus Callosum Radiomics-Based Classification Model in Alzheimer’s Disease: A Case-Control Study"></a>Corpus Callosum Radiomics-Based Classification Model in Alzheimer’s Disease: A Case-Control Study</h4><blockquote>
<p>基于胼Call体基于放射学的阿尔茨海默病分类模型：病例对照研究</p>
</blockquote>
<p><strong>Background</strong>: Alzheimer’s disease (AD) is a progressive neurodegenerative disease that causes the decline of some cognitive impairments. The present study aimed to identify the corpus callosum (CC) radiomic features related to the diagnosis of AD and build and evaluate a classification model.<br><strong>Methods</strong>: Radiomics analysis was applied to the three-dimensional T1-weighted magnetization-prepared rapid gradient echo (MPRAGE) images of 78 patients with AD and 44 healthy controls (HC). The CC, in each subject, was segmented manually and 385 features were obtained after calculation. Then, the feature selection were carried out. The logistic regression model was constructed and evaluated according to identified features. Thus, the model can be used for distinguishing the AD from HC subjects.<br><strong>Results</strong>: Eleven features were selected from the three-dimensional T1-weighted MPRAGE images using the LASSO model, following which, the logistic regression model was constructed. The area under the receiver operating characteristic curve values (AUC), sensitivity, specificity, accuracy, precision, and positive and negative predictive values were 0.720, 0.792, 0.500, 0.684, 0.731, 0.731, and 0.583, respectively.<br><strong>Conclusion</strong>: The results demonstrated the potential of CC texture features as a biomarker for the diagnosis of AD. This is the first study showing that the radiomics model based on machine learning was a valuable method for the diagnosis of AD.</p>
<p><strong>背景</strong>：阿尔茨海默病（AD）是一种进行性神经退行性疾病，导致一些认知障碍的减少。本研究旨在确定与AD诊断相关的胼call体（CC）<code>放射学特征</code>，并建立和评估分类模型。<br><strong>方法</strong>：将自由基分析应用于78例AD患者和44例健康对照（HC）的三维T1加权磁化制备快速梯度回波（MPRAGE）图像。在每个受试者中，CC被手动分割，并且在计算后获得385个特征。然后，进行特征选择。根据已识别的特征构建并评估逻辑回归模型。因此，该模型可用于区分AD与HC受试者。<br><strong>结果</strong>：使用LASSO模型从三维T1加权MPRAGE图像中选择11个特征，然后构建逻辑回归模型。接收器操作特征曲线值（AUC），灵敏度，特异性，准确度，精确度以及阳性和阴性预测值下的面积分别为0.720,0.729,0.500,0.684,0.731,0.731和0.583。<br><strong>结论</strong>：结果证明了<code>CC纹理特征作为诊断AD的生物标志物的潜力</code>。这是第一项研究表明，基于机器学习的放射学模型是诊断AD的有效方法。</p>
<p><strong>Keywords</strong>: magnetic resonance imaging, Alzheimer’s disease, corpus callosum, radiomics, neuroimaging</p>
<p><strong>关键词</strong>：磁共振成像，阿尔茨海默病，胼call体，放射学，神经影像学</p>
<h4 id="An-Ensemble-Learning-System-for-a-4-Way-Classification-of-Alzheimer’s-Disease-and-Mild-Cognitive-Impairment"><a href="#An-Ensemble-Learning-System-for-a-4-Way-Classification-of-Alzheimer’s-Disease-and-Mild-Cognitive-Impairment" class="headerlink" title="An Ensemble Learning System for a 4-Way Classification of Alzheimer’s Disease and Mild Cognitive Impairment"></a>An Ensemble Learning System for a 4-Way Classification of Alzheimer’s Disease and Mild Cognitive Impairment</h4><blockquote>
<p>一种用于阿尔茨海默病和轻度认知障碍的四向分类的集成学习系统</p>
</blockquote>
<p>Discriminating Alzheimer’s disease (AD) from its prodromal form, mild cognitive impairment (MCI), is a significant clinical problem that may facilitate early diagnosis and intervention, in which a more challenging issue is to classify MCI subtypes, i.e., those who eventually convert to AD (cMCI) versus those who do not (MCI). To solve this difficult 4-way classification problem (AD, MCI, cMCI and healthy controls), a competition was hosted by Kaggle to invite the scientific community to apply their machine learning approaches on pre-processed sets of T1-weighted magnetic resonance images (MRI) data and the demographic information from the international Alzheimer’s disease neuroimaging initiative (ADNI) database. This paper summarizes our competition results. We first proposed a hierarchical process by turning the 4-way classification into five binary classification problems. A new feature selection technology based on relative importance was also proposed, aiming to identify a more informative and concise subset from 426 sMRI morphometric and 3 demographic features, to ensure each binary classifier to achieve its highest accuracy. As a result, about 2% of the original features were selected to build a new feature space, which can achieve the final four-way classification with a 54.38% accuracy on testing data through hierarchical grouping, higher than several alternative methods in comparison. More importantly, the selected discriminative features such as hippocampal volume, parahippocampal surface area, and medial orbitofrontal thickness, etc. as well as the MMSE score, are reasonable and consistent with those reported in AD/MCI deficits. In summary, the proposed method provides a new framework for multi-way classification using hierarchical grouping and precise feature selection.</p>
<p>辨别阿尔茨海默病（AD）从其前驱形式，轻度认知障碍（MCI），是一个重要的临床问题，可能有助于早期诊断和干预，其中一个更具挑战性的问题是分类MCI亚型，即最终转换为AD（cMCI）与不参与者（MCI）。为解决这一困难的<code>四向分类问题（AD，MCI，cMCI和NC）</code>，Kaggle主办了一项竞赛，邀请科学界将其机器学习方法应用于预处理的T1加权磁共振图像集（ MRI）数据和来自国际阿尔茨海默病神经影像学倡议（ADNI）数据库的人口统计信息。本文总结了我们的比赛结果。我们首先通过将4路分类转换为<code>五个二元分类问题</code>来提出分层过程。还提出了一种基于相对重要性的新特征选择技术，旨在从426个sMRI形态测量和3个人口统计特征中识别出更具信息性和简洁性的子集，以确保每个二元分类器达到其最高精度。因此，大约2％的原始特征被选择用于构建新的特征空间，这可以通过分层分组实现最终的四向分类，测试数据的准确率为54.38％，高于几种替代方法。更重要的是，选择的辨别特征，如海马体积，海马旁表面积和内侧眶额厚度等，以及MMSE评分，是合理的，与AD / MCI缺陷报道的一致。总之，所提出的方法提供了一种使用分层分组和精确特征选择的多路分类的新框架。</p>
<p><strong>Keywords</strong>: multi-class classification, feature selection, Alzheimer’s disease(AD), mild cognitive impairment (MCI), structural MRI, hierarchical classification, relative importance.</p>
<p><strong>关键字</strong>：多级分类，特征选择，阿尔茨海默病（AD），轻度认知障碍（MCI），结构MRI，等级分类，相对重要性</p>
<h4 id="alzheimer-Disease-and-Behavioral-Variant-Frontotemporal-Dementia-Automatic-Classification-Based-on-Cortical-Atrophy-for-Single-Subject-Diagnosis"><a href="#alzheimer-Disease-and-Behavioral-Variant-Frontotemporal-Dementia-Automatic-Classification-Based-on-Cortical-Atrophy-for-Single-Subject-Diagnosis" class="headerlink" title="alzheimer Disease and Behavioral Variant Frontotemporal Dementia: Automatic Classification Based on Cortical Atrophy for Single-Subject Diagnosis"></a>alzheimer Disease and Behavioral Variant Frontotemporal Dementia: Automatic Classification Based on Cortical Atrophy for Single-Subject Diagnosis</h4><blockquote>
<p>阿尔茨海默病和行为变异性额颞叶痴呆：基于皮层萎缩的单一主题诊断自动分类</p>
</blockquote>
<p><strong>Purpose:</strong>To investigate the diagnostic accuracy of an image-based classifier to distinguish between Alzheimer disease (AD) and behavioral variant frontotemporal dementia (bvFTD) in individual patients by using gray matter (GM) density maps computed from standard T1-weighted structural images obtained with multiple imagers and with indepen- dent training and prediction data.<br><strong>Materials and Methods:</strong>The local institutional review board approved the study. Eighty-four patients with AD, 51 patients with bvFTD, and 94 control subjects were divided into independent training (n = 115) and prediction (n = 114) sets with identical diagno- sis and imager type distributions. Training of a support vec- tor machine (SVM) classifier used diagnostic status and GM density maps and produced voxelwise discrimination maps. Discriminant function analysis was used to estimate suitabil- ity of the extracted weights for single-subject classification in the prediction set. Receiver operating characteristic (ROC) curves and area under the ROC curve (AUC) were calculated for image-based classifiers and neuropsychological z scores.<br><strong>Results:</strong>Training accuracy of the SVM was 85% for patients with AD versus control subjects, 72% for patients with bvFTD versus control subjects, and 79% for patients with AD ver- sus patients with bvFTD (P  .029). Single-subject diag- nosis in the prediction set when using the discrimination maps yielded accuracies of 88% for patients with AD ver- sus control subjects, 85% for patients with bvFTD versus control subjects, and 82% for patients with AD versus pa- tients with bvFTD, with a good to excellent AUC (range, 0.81–0.95; P  .001). Machine learning-based categori- zation of AD versus bvFTD based on GM density maps outperforms classification based on neuropsychological test results.<br><strong>Conclusion:</strong>The SVM can be used in single-subject discrimination and can help the clinician arrive at a diagnosis. The SVM can be used to distinguish disease-specific GM patterns in patients with AD and those with bvFTD as compared with normal aging by using common T1-weighted structural MR imaging.</p>
<p><strong>目的：</strong>通过使用从多个获得的标准T1加权结构图像计算的灰质（GM）密度图，研究基于图像的分类器在个体患者中区分阿尔茨海默病（<code>AD</code>）和行为变异额颞叶痴呆（<code>bvFTD</code>）的诊断准确性成像仪以及独立的训练和预测数据。<br><strong>材料和方法：</strong>当地机构审查委员会批准了该研究。将84名AD患者，51名bvFTD患者和94名对照受试者分为独立训练组（n = 115）和预测组（n = 114），具有相同的诊断和成像者类型分布。培训支持向量机（SVM）分类器使用诊断状态和GM密度图并生成体素识别图。判别函数分析用于估计预测集中单主题分类的提取权重的适用性。针对基于图像的分类器和神经心理学z分数计算接收器操作特征（ROC）曲线和ROC曲线下面积（AUC）。<br><strong>结果：</strong>AD患者与对照组相比，SVM的训练准确率为85％，bvFTD患者与对照组相比，72％，对于患有bvFTD的AD患者，则为79％（P &lt;.029）。使用鉴别图时预测集中的单一主体诊断对AD患者的对照组产生了88％的准确率，对于bvFTD患者与对照组相比，准确率为85％，AD患者与对照组相比，82％。 bvFTD患者，具有良好至优良的AUC（范围，0.81-0.95; P &lt;0.001）。基于机器学习的基于GM密度图的AD与bvFTD的分类优于基于神经心理学测试结果的分类。<br><strong>结论：</strong>SVM可用于单一主体辨别，可帮助临床医生做出诊断。通过使用常见的T1加权结构MR成像，SVM可用于区分AD患者和bvFTD患者的疾病特异性GM模式与正常衰老相比。</p>
<h4 id="ALZHEIMER’S-DISEASE-DIAGNOSTICS-BY-A-DEEPLY-SUPERVISED-ADAPTABLE-3D-CONVOLUTIONAL-NETWORK"><a href="#ALZHEIMER’S-DISEASE-DIAGNOSTICS-BY-A-DEEPLY-SUPERVISED-ADAPTABLE-3D-CONVOLUTIONAL-NETWORK" class="headerlink" title="ALZHEIMER’S DISEASE DIAGNOSTICS BY A DEEPLY SUPERVISED ADAPTABLE 3D CONVOLUTIONAL NETWORK"></a>ALZHEIMER’S DISEASE DIAGNOSTICS BY A DEEPLY SUPERVISED ADAPTABLE 3D CONVOLUTIONAL NETWORK</h4><blockquote>
<p>ALZHEIMER通过深度监控的适应性3D卷积网络诊断疾病</p>
</blockquote>
<p>Early diagnosis, playing an important role in preventing progress and treating the Alzheimer’s disease (AD), is based on classification of features extracted from brain images. The features have to accurately capture main AD-related varia- tions of anatomical brain structures, such as, e.g., ventricles size, hippocampus shape, cortical thickness, and brain vol- ume. This paper proposes to predict the AD with a deep 3D convolutional neural network (3D-CNN), which can learn generic features capturing AD biomarkers and adapt to dif- ferent domain datasets. The 3D-CNN is built upon a 3D convolutional autoencoder, which is pre-trained to capture anatomical shape variations in structural brain MRI scans. Fully connected upper layers of the 3D-CNN are then fine- tuned for each task-specific AD classification. Experiments on the ADNI MRI dataset with no skull-stripping preprocess- ing have shown our 3D-CNN outperforms several conven- tional classifiers by accuracy and robustness. Abilities of the 3D-CNN to generalize the features learnt and adapt to other domains have been validated on the CADDementia dataset.<br><strong>Index Terms</strong>— Alzheimer’s disease, deep learning, 3D convolutional neural network, autoencoder, brain MRI.</p>
<p>早期诊断，在预防进展和治疗阿尔茨海默病（AD）中发挥重要作用，是基于从脑图像中提取的特征的分类。这些特征必须准确地捕获解剖学大脑结构的主要AD相关变异，例如，心室大小，海马体形状，皮质厚度和脑容积。本文提出用深度3D卷积神经网络（3D-CNN）预测AD，其可以学习捕获AD生物标记物并适应不同域数据集的通用特征。 3D-CNN基于<code>3D卷积自动编码器</code>，其经过预先训练以捕获结构脑MRI扫描中的解剖学形状变化。然后，针对每个特定于任务的AD分类，对3D-CNN的完全连接的上层进行微调。在没有颅骨剥离预处理的ADNI MRI数据集上进行的实验表明，我们的3D-CNN在准确性和稳健性方面优于几种传统的分类器。已经在CADDementia数据集上验证了3D-CNN概括所学习的特征并适应其他领域的能力。<br><strong>索引术语</strong> - 阿尔茨海默病，深度学习，3D卷积神经网络，自动编码器，脑MRI。</p>
<h4 id="Early-Diagnosis-of-Alzheimer’s-Disease-Based-on-Resting-State-Brain-Networks-and-Deep-Learning"><a href="#Early-Diagnosis-of-Alzheimer’s-Disease-Based-on-Resting-State-Brain-Networks-and-Deep-Learning" class="headerlink" title="Early Diagnosis of Alzheimer’s Disease Based on Resting-State Brain Networks and Deep Learning"></a>Early Diagnosis of Alzheimer’s Disease Based on Resting-State Brain Networks and Deep Learning</h4><blockquote>
<p>基于静息状态脑网络和深度学习的阿尔茨海默病早期诊断</p>
</blockquote>
<p><strong>Abstract</strong>—Computerized healthcare has undergone rapid development thanks to the advances in medical imaging and machine learning technologies. Especially, recent progress on deep learning opens a new era for multimedia based clinical decision support.<br>In this paper, we use deep learning with brain network and clinical relevant text information to make early diagnosis of Alzheimer’s Disease (AD). The clinical relevant text information includes age, gender, and ApoE gene of the subject. The brain network is constructed by computing the functional connectivity of brain regions using resting-state functional magnetic resonance imaging (R-fMRI) data. A targeted autoencoder network is built to distinguish normal aging from mild cognitive impairment, an early stage of AD. The proposed method reveals discriminative brain network features effectively and provides a reliable classifier for AD detection. Compared to traditional classifiers based on R-fMRI time series data, about 31.21 percent improvement of the prediction accuracy is achieved by the proposed deep learning method, and the standard deviation reduces by 51.23 percent in the best case that means our prediction model is more stable and reliable compared to the traditional methods. Our work excavates deep learning’s advantages of classifying high-dimensional multimedia data in medical services, and could help predict and prevent AD at an early stage.</p>
<p><strong>摘要</strong> - 由于医学成像和机器学习技术的进步，计算机化医疗保健业得到了快速发展。特别是，最近深度学习的进展开启了基于多媒体的临床决策支持的新时代。<br>在本文中，我们使用脑网络和临床相关文本信息的深度学习来早期诊断阿尔茨海默病（AD）。临床相关文本信息包括受试者的年龄，性别和ApoE基因。通过使用静止状态功能磁共振成像（R-fMRI）数据计算脑区域的功能连接来构建脑网络。建立一个有针对性的<code>自动编码器网</code>络，以<code>区分正常老化与AD早期阶段的轻度认知障碍</code>。该方法有效地揭示了有区别的脑网络特征，为AD检测提供了可靠的分类器。与基于R-fMRI时间序列数据的传统分类器相比，所提出的深度学习方法提高了预测精度约31.21％，在最佳情况下标准差减少了51.23％，这意味着我们的预测模型更稳定与传统方法相比可靠。我们的工作挖掘了深度学习在医疗服务中对高维多媒体数据进行分类的优势，并有助于在早期阶段预测和预防AD。</p>
<p><strong>Index Terms</strong>—Brain network, deep learning, early diagnosis, Alzheimer’s disease</p>
<p><strong>索引术语</strong> - 脑网络，深度学习，早期诊断，阿尔茨海默病</p>
<h4 id="Auto-Detection-of-Alzheimer’s-Disease-Using-Deep-Convolutional-Neural-Networks"><a href="#Auto-Detection-of-Alzheimer’s-Disease-Using-Deep-Convolutional-Neural-Networks" class="headerlink" title="Auto-Detection of Alzheimer’s Disease Using Deep Convolutional Neural Networks"></a>Auto-Detection of Alzheimer’s Disease Using Deep Convolutional Neural Networks</h4><blockquote>
<p>利用深度卷积神经网络自动检测阿尔茨海默病</p>
</blockquote>
<p><code>Abstract</code>—Alzheimer’s disease(AD) is a kind of progressive neurodegenerative disease. One who is diagnosed as an Alzheimer’s disease patient may has many symptoms, such as deterioration of memory and language. Once those symptoms was noticed, they usually can survive 4 to 20 years. So far, Alzheimer’s disease has become the sixth leading cause of death, and it has become a worldwide health and social challenge. Traditional methods of diagnosing AD and mild cognitive impairment(MCI), mostly depend on capturing features from variable modalities of brain image data. It is a big challenge to pick out the MCI from normal controller (NC) and AD, especially for those who are lacking experience. In this article, we employ deep convolutional neural network (DCNN) to extract the most useful features of the structural magnetic resonance imaging (MRI). Firstly, the structural MRIs are pre-processed in a strict pipeline. Then, instead of parcellating regions of interest, we re-slice each volume, and put the resliced images into a DCNN directly. Finally, four stages of Alzheimer’s are identified, and the average accuracy is 94.5% for NC versus LMCI, 96.9% for NC versus AD, 97.2% for LMCI and AD, 97.81% for EMCI versus AD, 94.8% for LMCI versus EMCI. The results show that the DCNN outperforms existing methods.</p>
<p><code>摘要</code> - 阿尔茨海默病（AD）是一种进行性神经退行性疾病。被诊断为阿尔茨海默病患者的人可能有许多症状，例如记忆和语言的恶化。一旦发现这些症状，它们通常可以存活4到20年。到目前为止，阿尔茨海默病已成为第六大死亡原因，并已成为全球健康和社会的挑战。诊断AD和轻度认知障碍（MCI）的传统方法主要依赖于从脑图像数据的可变模态捕获特征。从NC和AD中挑选出MCI是一个很大的挑战，特别是那些缺乏经验的人。在本文中，我们采用深度卷积神经网络（DCNN）来提取结构磁共振成像（MRI）最有用的特征。首先，结构MRI在严格的管道中进行预处理。然后，我们不是分割感兴趣的区域，而是重新切片每个卷，并将重新分割的图像直接放入DCNN。最后，确定了阿尔茨海默氏症的四个阶段，<code>NC与LMCI</code>的平均准确度为94.5％，<code>NC与AD</code>的平均准确度为96.9％，<code>LMCI和AD</code>为97.2％，<code>EMCI与AD</code>相比为97.81％，<code>LMCI与EMCI</code>相比为94.8％。结果表明DCNN优于现有方法。</p>
<p><code>Keywords</code>-Deep Learning; Alzheimer’s Disease; MRI; Early Diagnose</p>
<p><code>关键词</code> - 深度学习;阿尔茨海默氏病; MRI;早期诊断</p>
<h4 id="A-Deep-CNN-based-Multi-class-Classification-of-Alzheimer’s-Disease-using-MRI"><a href="#A-Deep-CNN-based-Multi-class-Classification-of-Alzheimer’s-Disease-using-MRI" class="headerlink" title="A Deep CNN based Multi-class Classification of Alzheimer’s Disease using MRI"></a>A Deep CNN based Multi-class Classification of Alzheimer’s Disease using MRI</h4><h4 id="Classification-of-Alzheimer-Disease-on-Imaging-Modalities-with-Deep-CNNs-using-Cross-Modal-Transfer-Learning"><a href="#Classification-of-Alzheimer-Disease-on-Imaging-Modalities-with-Deep-CNNs-using-Cross-Modal-Transfer-Learning" class="headerlink" title="Classification of Alzheimer Disease on Imaging Modalities with Deep CNNs using Cross-Modal Transfer Learning"></a>Classification of Alzheimer Disease on Imaging Modalities with Deep CNNs using Cross-Modal Transfer Learning</h4><blockquote>
<p>利用跨模式转移学习分析阿尔茨海默病对深部CNN成像模式的影响</p>
</blockquote>
<p><code>Abstract</code>—A recent imaging modality Diffusion Tensor Imag- ing completes information used from Structural MRI in studies of Alzheimer disease. A large number of recent studies has explored pathologic staging of Alzheimer disease using the Mean Diffusivity maps extracted from the Diffusion Tensor Imaging modality. The Deep Neural Networks are seducing tools for classification of subjects’ imaging data in computer- aided diagnosis of Alzheimer’s disease. The major problem here is the lack of a publicly available large amount of training data in both modalities. The lack number of training data yields over-fitting phenomena. We propose a method of a cross- modal transfer learning: from Structural MRI to Diffusion Tensor Imaging modality. Models pre-trained on a structural MRI dataset with domain-depended data augmentation are used as initialization of network parameters to train on Mean Diffusivity data. The method shows a reduction of the over-fitting phenomena, improves learning performance, and thus increases the accuracy of prediction. Classifiers are then fused by a majority vote resulting in augmented scores of classification between Normal Control, Alzheimer Patients and Mild Cognitive Impairment subjects on a subset of ADNI dataset.</p>
<p><code>摘要</code> - 最近的成像模式Diffusion Tensor Imaging完成了结构MRI在阿尔茨海默病研究中使用的信息。最近的大量研究使用从扩散张量成像模式中提取的平均扩散系数图来探索阿尔茨海默病的病理分期。深度神经网络是用于在计算机辅助诊断阿尔茨海默病中对受试者成像数据进行分类的诱导工具。这里的主要问题是两种模式都缺乏公开提供的大量培训数据。缺乏训练数据会产生过度拟合现象。我们提出了一种跨模式转移学习的方法：从结构MRI到扩散张量成像模式。在具有依赖于域的数据增强的结构MRI数据集上预训练的模型被用作网络参数的初始化以训练平均扩散率数据。该方法显示了过拟合现象的减少，提高了学习性能，从而提高了预测的准确性。然后通过多数投票来对分类器进行融合，从而在ADNI数据集的子集上对正常对照，<code>阿尔茨海默病患者和轻度认知障碍受试者之间的分类</code>进行增强评分。</p>
<p><code>Keywords</code>-Multi-Modal ; Alzheimer’s Disease ; Hippocampus ; Mild Cognitive Impairment ; Convolutional Neural Networks ; Transfer Learning ; Deep Learning ; Medical Imaging.</p>
<p><code>关键词</code> - 多模态;阿尔茨海默氏病 ;海马;轻度认知障碍 ;卷积神经网络;转学习;深度学习;医学影像</p>
<h4 id="A-Deep-Learning-Pipeline-to-Classify-Different-Stages-of-Alzheimer’s-Disease-From-fMRI-Data"><a href="#A-Deep-Learning-Pipeline-to-Classify-Different-Stages-of-Alzheimer’s-Disease-From-fMRI-Data" class="headerlink" title="A Deep Learning Pipeline to Classify Different Stages of Alzheimer’s Disease From fMRI Data"></a>A Deep Learning Pipeline to Classify Different Stages of Alzheimer’s Disease From fMRI Data</h4><blockquote>
<p>从fMRI数据分类阿尔茨海默病不同阶段的深度学习流程</p>
</blockquote>
<p><code>Abstract</code>—Alzheimer’s disease (AD) is an irreversible, pro- gressive neurological disorder that causes memory and thinking skill loss. Many different methods and algorithms have been applied to extract patterns from neuroimaging data in order to distinguish different stages of Alzheimer’s disease (AD). However, the similarity of the brain patterns in older adults and in different stages makes the classification of different stages a challenge for researchers.<br>In this paper, convolutional neuronal network architecture AlexNet was applied to fMRI datasets to classify different stages of the disease. We classified five different stages of Alzheimer’s us- ing a deep learning algorithm. The method successfully classified normal healthy control (NC), significant memory concern (SMC), early mild cognitive impair (EMCI), late cognitive mild impair (LMCI), and Alzheimer’s disease (AD). The model was imple- mented using GPU high performance computing. Before applying any classification, the fMRI data were strictly preprocessed. Then, low to high level features were extracted and learned using the AlexNet model. Our experiments show significant improvement in classification. The average accuracy of the model was 97.63%. We then tested our model on test datasets to evaluate the accuracy of the model per class, obtaining an accuracy of 94.97% for AD, 95.64% for EMCI, 95.89% for LMCI, 98.34% for NC, and 94.55% for SMC.</p>
<p><code>摘要</code> - 阿尔茨海默病（AD）是一种不可逆转的进行性神经系统疾病，可引起记忆和思维技能的丧失。已经应用许多不同的方法和算法从神经成像数据中提取模式以区分阿尔茨海默病（AD）的不同阶段。然而，老年人和不同阶段的大脑模式的相似性使得不同阶段的分类成为研究人员的挑战。<br>在本文中，卷积神经网络结构AlexNet被应用于fMRI数据集，以分类疾病的不同阶段。我们使用深度学习算法<code>对阿尔茨海默氏症的五个不同阶段进行了分类</code>。该方法成功地分类了正常健康对照（NC），显着记忆关注（SMC），早期轻度认知障碍（EMCI），晚期认知轻度损伤（LMCI）和阿尔茨海默氏病（AD）。该模型使用GPU高性能计算实现。在应用任何分类之前，fMRI数据是严格预处理的。然后，使用AlexNet模型提取和学习低到高级别的特征。我们的实验显示分类显着改善。该模型的平均准确度为97.63％。然后，我们在测试数据集上测试我们的模型，以评估每类模型的准确性，AD的准确度为94.97％，EMCI为95.64％，LMCI为95.89％，NC为98.34％，SMC为94.55％。</p>
<h4 id="Brain-MRI-analysis-for-Alzheimer’s-disease-diagnosis-using-an-ensemble-system-of-deep-convolutional-neural-networks"><a href="#Brain-MRI-analysis-for-Alzheimer’s-disease-diagnosis-using-an-ensemble-system-of-deep-convolutional-neural-networks" class="headerlink" title="Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks"></a>Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks</h4><blockquote>
<p>使用深度卷积神经网络的集合系统进行阿尔茨海默病诊断的脑MRI分析</p>
</blockquote>
<p><code>Abstract</code>：Alzheimer’s disease is an incurable, progressive neurologicalbrain disorder. Earlier detection of Alzheimer’s disease can help with proper treatment and prevent brain tissue damage. Several statistical and machine learning models have been exploited by researchers for Alzheimer’s disease diagnosis. Analyzing magnetic resonance imaging (MRI) is a common practice for Alzheimer’s disease diagnosis in clinical research. Detection of Alzheimer’s disease is exacting due to the similarity in Alzheimer’s disease MRI data and standard healthy MRI data of older people. Recently, advanced deep learning techniques have successfully demonstrated human-level performance in numerous fields including medical image analysis. We propose a deep convolutional neural network for Alzheimer’s disease diagnosis using brainMRI data analysis. While most of the existing approaches perform binary classification, our model can iden- tify different stages of Alzheimer’s disease and obtains superior performance for early-stage diagnosis. We conducted ample experiments to demonstrate that our proposed model outperformed comparative baselines on the Open Access Series of Imaging Studies dataset.<br><code>Keywords</code>: Neurological disorder, Alzheimer’s disease, Deep learning, Convolutional neural network, MRI, Brain imaging</p>
<p><code>摘要</code>：阿尔茨海默病是一种无法治愈的进行性神经系统疾病。早期发现阿尔茨海默病有助于正确治疗和预防脑组织损伤。研究人员已经开发了几种统计学和机器学习模型用于阿尔茨海默病的诊断。分析磁共振成像（MRI）是临床研究中阿尔茨海默病诊断的常见做法。由于阿尔茨海默病MRI数据与老年人的标准健康MRI数据相似，阿尔茨海默病的检测非常严格。最近，先进的深度学习技术成功地证明了包括医学图像分析在内的众多领域的人类水平表现。我们使用brainMRI数据分析提出了一种用于阿尔茨海默病诊断的深度卷积神经网络。虽然大多数现有方法都进行二元分类，但我们的模型可以识别阿尔茨海默病的不同阶段，并在早期诊断中获得优异的表现。我们进行了大量实验，以证明我们提出的模型在开放获取系列成像研究数据集上的表现优于比较基线。<br><code>关键词</code>：神经障碍，阿尔茨海默病，深度学习，卷积神经网络，MRI，脑成像</p>
<h4 id="Combining-Convolutional-and-Recurrent-Neural-Networks-for-Alzheimer’s-Disease-Diagnosis-Using-PET-Images"><a href="#Combining-Convolutional-and-Recurrent-Neural-Networks-for-Alzheimer’s-Disease-Diagnosis-Using-PET-Images" class="headerlink" title="Combining Convolutional and Recurrent Neural Networks for Alzheimer’s Disease Diagnosis Using PET Images"></a>Combining Convolutional and Recurrent Neural Networks for Alzheimer’s Disease Diagnosis Using PET Images</h4><blockquote>
<p>结合卷积和回归神经网络用于PET图像的阿尔茨海默病诊断</p>
</blockquote>
<p><code>Abstract</code>—Alzheimer’s disease (AD) is a progressive and irreversible brain degenerative disorder which often happens in people aged more than 65 years old. Accurate and early diagnosis of AD is vital for the patient care and development of future treatment. Positrons Emission Tomography (PET) is a functional molecular imaging modality, which proves to be a powerful tool to help understand the brain changes related to AD. Most existing methods extract the handcraft features from images, and then train a classifier to distinguish AD from other groups. The success of these computer-aided diagnosis methods highly depends on the image preprocessing, including rigid registration and segmentation. Motivated by the success of deep learning in image classification, this paper proposes a new classification framework based on combination of 2D convolutional neural networks (CNN) and recurrent neural networks (RNN), which learns the features of 3D PET images by decomposing the 3D image into a sequence of 2D slices. In this framework, the hierarchical 2D CNNs are built to capture the intra-slice features while the gated recurrent unit (GRU) of RNN is used to extract the inter-slice features for final classification. No rigid image registration and segmentation are required for PET images. Our method is evaluated on the baseline PET images from 339 subjects including 93 AD patients, 146 mild cognitive impairments (MCI) and 100 normal controls (NC) from Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an AUC of 95.28% for classification of AD vs. NC and 83.90% for classification of MCI vs. NC, respectively, demonstrating the promising classification performance.</p>
<p><code>摘要</code> - 阿尔茨海默病（AD）是一种进行性和不可逆转的脑退行性疾病，常见于65岁以上的人群。 AD的准确和早期诊断对于患者护理和未来治疗的发展至关重要。正电子发射断层扫描（PET）是一种功能性分子成像模式，被证明是一种有助于理解与AD相关的大脑变化的有力工具。大多数现有方法从图像中提取手工艺特征，然后训练分类器以区分AD与其他组。这些计算机辅助诊断方法的成功很大程度上取决于图像预处理，包括刚性配准和分割。在深度学习图像分类成功的推动下，本文提出了<code>一种基于二维卷积神经网络（CNN）和递归神经网络（RNN）相结合的新分类框架</code>，通过分解三维图像来学习三维PET图像的特征。进入一系列2D切片。在该框架中，构建分层2D CNN以捕获片内特征，同时使用RNN的门控重复单元（GRU）来提取片间特征以用于最终分类。 <code>PET图像不需要严格的图像配准和分割</code>。我们的方法评估来自339名受试者的基线PET图像，包括93名AD患者，146名轻度认知障碍（MCI）和100名来自阿尔茨海默病神经影像学倡议（ADNI）数据库的正常对照（NC）。实验结果表明，该方法对AD与NC分类的AUC分别为95.28％，对MCI与NC的分类分别为83.90％，表明分类性能良好。</p>
<p><code>Keywords</code>—Alzheimer’s disease; Convolutional neural network ; Recurrent neural network; Deep learning; Positron emission tomography; Image classification</p>
<p><code>关键词</code> - 阿尔茨海默病;卷积神经网络;递归神经网络;深度学习;正电子发射断层扫描;图像分类</p>
<h4 id="A-Deep-Neural-Network-Approach-For-Early-Diagnosis-of-Mild-Cognitive-Impairment-Using-Multiple-Features"><a href="#A-Deep-Neural-Network-Approach-For-Early-Diagnosis-of-Mild-Cognitive-Impairment-Using-Multiple-Features" class="headerlink" title="A Deep Neural Network Approach For Early Diagnosis of Mild Cognitive Impairment Using Multiple Features"></a>A Deep Neural Network Approach For Early Diagnosis of Mild Cognitive Impairment Using Multiple Features</h4><h4 id="Visual-Explanations-From-Deep-3D-Convolutional-Neural-Networks-for-Alzheimer’s-Disease-Classification"><a href="#Visual-Explanations-From-Deep-3D-Convolutional-Neural-Networks-for-Alzheimer’s-Disease-Classification" class="headerlink" title="Visual Explanations From Deep 3D Convolutional Neural Networks for Alzheimer’s Disease Classification"></a>Visual Explanations From Deep 3D Convolutional Neural Networks for Alzheimer’s Disease Classification</h4><blockquote>
<p>深度3D卷积神经网络对阿尔茨海默病分类的视觉解释</p>
</blockquote>
<p><code>Abstract</code> — We develop three efficient approaches for generating visual explanations from 3D convolutional neural networks (3D- CNNs) for Alzheimer’s disease classification. One approach conducts sensitivity analysis on hierarchical 3D image segmentation, and the other two visualize network activations on a spatial map. Visual checks and a quantitative localization benchmark indicate that all approaches identify important brain parts for Alzheimer’s disease diagnosis. Comparative analysis show that the sensitivity analysis based approach has difficulty handling loosely distributed cerebral cortex, and approaches based on visualization of activations are constrained by the resolution of the convo- lutional layer. The complementarity of these methods improves the understanding of 3D-CNNs in Alzheimer’s disease classification from different perspectives.</p>
<p><code>摘要</code> — 我们开发了三种有效的方法，用于从三维卷积神经网络（3D-CNN）生成<code>视觉解释</code>，用于阿尔茨海默病的分类。 一种方法对分层3D图像分割进行灵敏度分析，另外两种方法在空间地图上可视化网络激活。 视觉检查和定量定位基准测试表明，所有方法都可以识别阿尔茨海默病诊断的重要大脑部分。 对比分析表明，基于灵敏度分析的方法难以处理松散分布的大脑皮层，基于激活可视化的方法受到旋转层分辨率的限制。 这些方法的互补性从不同角度提高了对阿尔茨海默病分类中3D-CNN的理解。</p>
<h4 id="Visualizing-Convolutional-Networks-for-MRI-based-Diagnosis-of-Alzheimer’s-Disease"><a href="#Visualizing-Convolutional-Networks-for-MRI-based-Diagnosis-of-Alzheimer’s-Disease" class="headerlink" title="Visualizing Convolutional Networks for MRI-based Diagnosis of Alzheimer’s Disease"></a>Visualizing Convolutional Networks for MRI-based Diagnosis of Alzheimer’s Disease</h4><blockquote>
<p>可视化卷积网络用于基于MRI的阿尔茨海默病诊断</p>
</blockquote>
<p>Abstract. Visualizing and interpreting convolutional neural networks (CNNs) is an important task to increase trust in automatic medical decision making systems. In this study, we train a 3D CNN to detect Alzheimer’s disease based on structural MRI scans of the brain. Then, we apply four different gradient-based and occlusion-based visualization methods that explain the network’s classification decisions by highlight- ing relevant areas in the input image. We compare the methods qualita- tively and quantitatively. We find that all four methods focus on brain regions known to be involved in Alzheimer’s disease, such as inferior and middle temporal gyrus. While the occlusion-based methods focus more on specific regions, the gradient-based methods pick up distributed rel- evance patterns. Additionally, we find that the distribution of relevance varies across patients, with some having a stronger focus on the temporal lobe, whereas for others more cortical areas are relevant. In summary, we show that applying different visualization methods is important to understand the decisions of a CNN, a step that is crucial to increase clinical impact and trust in computer-based decision support systems.<br>Keywords: Alzheimer · Visualization · MRI · Deep Learning · CNN · 3D · Brain</p>
<p><code>摘要</code>. <code>可视化</code>和解释卷积神经网络（CNN）是增加对自动医疗决策系统的信任的重要任务。在这项研究中，我们根据大脑的结构MRI扫描训练3D CNN来检测阿尔茨海默病。然后，我们应用四种不同的基于梯度和基于遮挡的可视化方法，通过突出显示输入图像中的相关区域来解释网络的分类决策。我们定性和定量地比较这些方法。我们发现所有四种方法都集中在已知与阿尔茨海默病有关的大脑区域，例如下颞中回和下颞中回。虽然基于遮挡的方法更侧重于特定区域，但基于梯度的方法可以获取分布式相关模式。此外，我们发现相关性的分布因患者而异，其中一些人更关注颞叶，而另一些则更多的皮质区域是相关的。总之，我们表明应用不同的可视化方法对于理解CNN的决策非常重要，这对于增加临床影响和对基于计算机的决策支持系统的信任至关重要。<br>关键词：阿尔茨海默病·可视化·MRI·深度学习·CNN·3D·脑</p>
<h4 id="Shearlet-based-Stacked-Convolutional-Network-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease-using-the-Florbetapir-PET-Amyloid-Imaging-Data"><a href="#Shearlet-based-Stacked-Convolutional-Network-for-Multiclass-Diagnosis-of-Alzheimer’s-Disease-using-the-Florbetapir-PET-Amyloid-Imaging-Data" class="headerlink" title="Shearlet based Stacked Convolutional Network for Multiclass Diagnosis of Alzheimer’s Disease using the Florbetapir PET Amyloid Imaging Data"></a>Shearlet based Stacked Convolutional Network for Multiclass Diagnosis of Alzheimer’s Disease using the Florbetapir PET Amyloid Imaging Data</h4><blockquote>
<p>基于Shearlet的堆叠卷积网络用于使用Florbetapir PET淀粉样蛋白成像数据进行阿尔茨海默病的多类诊断</p>
</blockquote>
<p><code>Abstract</code>—Although there is no cure for Alzheimer’s disease (AD), an accurate early diagnosis is essential for health and social care, and will be of great significance when the course of the disease could be reversed through treatment options. Florbetapir positron emission tomography (18F-AV-45 PET) is proven to be the most powerful imaging technique to investigate the deposition of amyloid plaques, one of the potential hallmarks of AD, signify- ing the onset of AD before it changes the brains structure. In this paper, we propose a novel classification algorithm to discriminate the patients having AD, early mild cognitive impairment (MCI), late MCI, and normal control in 18F-AV-45 PET using shearlet based deep convolutional neural network (CNN). It is known that the conventional CNNs involve convolution and pooling layers, which in fact produce the smoothed representation of data, and this results in losing detailed information. In view of this fact, the conventional CNN is integrated with shearlet transform incorporating the multiresolution details of the data. Once the model is pretrained to transform the input data into a better stacked representation, the resulting final layer is passed to softmax classifier, which returns the probabilities of each class. Through experimental results, it is shown that the performance of the proposed classification framework is superior to that of the traditional CNN in Alzheimer’s disease neuroimaging initiative (ADNI) database in terms of classification accuracy. As a result, it has the potential to distinguish the different stages of AD progression with less clinical prior information.<br><code>Index Terms</code>—Alzheimer’s disease (AD), Florbetapir positron emission tomography (18F-AV-45 PET) amyloid imaging, Shearlet transform (ST), Convolutional neural network (CNN), Softmax, Deep learning.</p>
<p><code>摘要</code> - 虽然阿尔茨海默病（AD）无法治愈，但准确的早期诊断对于健康和社会护理至关重要，并且当通过治疗方案可以逆转疾病病程时具有重要意义。 Florbetapir正电子发射断层扫描（18F-AV-45 PET）被证明是最有效的成像技术，用于研究淀粉样斑块的沉积，淀粉样斑块是AD的潜在标志之一，在改变大脑结构之前表示AD的发作 。在本文中，我们提出了一种新的分类算法，使用基于剪切的深度卷积神经网络（CNN）来区分患有<code>AD，EMCI，LMCI和18F-AV-45 PET中的正常对照的患者</code>。众所周知，传统的CNN涉及卷积和汇集层，这实际上产生了<code>数据的平滑表示，并且这导致丢失详细信息</code>。鉴于这一事实，<code>传统的CNN与剪切变换相结合</code>，并结合了数据的多分辨率细节。一旦模型被预训练以将输入数据转换为更好的堆叠表示，则将得到的最终层传递给softmax分类器，其返回每个类的概率。通过实验结果表明，在分类准确性方面，所提出的分类框架的性能优于传统CNN在阿尔茨海默病神经影像学计划（ADNI）数据库中的表现。因此，它有可能用较少的临床先验信息区分AD进展的不同阶段。<br><code>索引术语</code> - 阿尔茨海默病（AD），Florbetapir正电子发射断层扫描（18F-AV-45 PET）淀粉样蛋白成像，Shearlet变换（ST），卷积神经网络（CNN），Softmax，深度学习。</p>
<h4 id="Alzheimer’s-disease-Classification-from-Brain-MRI-based-on-transfer-learning-from-CNN"><a href="#Alzheimer’s-disease-Classification-from-Brain-MRI-based-on-transfer-learning-from-CNN" class="headerlink" title="Alzheimer’s disease Classification from Brain MRI based on transfer learning from CNN"></a>Alzheimer’s disease Classification from Brain MRI based on transfer learning from CNN</h4><blockquote>
<p>阿尔茨海默病从脑MRI分类基于CNN转移学习</p>
</blockquote>
<p><code>Abstract</code>— Various Convolutional Neural Network (CNN) architecture has been proposed for image classification and Object recognition. For the image based classification, it is a complex task for CNN to deal with hundreds of MRI Image slices, each of almost identical nature in a single patient. So, classifying a number of patients as an AD, MCI or NC based on 3D MRI becomes vague technique using 2D CNN architecture. Hence, to address this issue, we have simplified the idea of classifying patients on basis of 3D MRI but acknowledging the 2D features generated from the CNN framework. We present our idea regarding how to obtain 2D features from MRI and transform it to be applicable to classify using machine learning algorithm. Our experiment shows the result of classifying 3 class subjects patients. We employed scratched trained CNN or pretrained Alexnet CNN as generic feature extractor of 2D image which dimensions were reduced using PCA+TSNE, and finally classifying using simple Machine learning algorithm like KNN, Navies Bayes Classifier. Although the result is not so impressive but it definitely shows that this can be better than scratch trained CNN softmax classification based on probability score. The generated feature can be well manipulated and refined for better accuracy, sensitivity, and specificity.<br><code>Keywords</code>—CNN, MRI, generic feature, PCA, TSNE, Classifier</p>
<p><code>摘要</code> - 已经提出了各种卷积神经网络（CNN）架构用于图像分类和对象识别。对于基于图像的分类，CNN处理数百个MRI图像切片是一项复杂的任务，每个切片在单个患者中具有几乎相同的性质。因此，基于3D MRI将许多患者分类为AD，MCI或NC变为使用2D CNN架构的模糊技术。因此，为了解决这个问题，我们简化了基于3D MRI对患者进行分类的想法，但承认了CNN框架产生的2D特征。我们提出了如何从MRI获取2D特征并将其转换为适用于使用机器学习算法进行分类的想法。我们的实验显示了对3名受试者患者进行分类的结果。我们采用划痕训练的CNN或预训练的Alexnet CNN作为2D图像的通用特征提取器，使用PCA + TSNE减小尺寸，最后使用简单的机器学习算法（如KNN，Navies Bayes分类器）进行分类。虽然<code>结果并不那么令人印象深刻</code>，但它肯定表明这可能比基于概率得分的刮刮训练的CNN softmax分类更好。生成的特征可以很好地操作和细化，以获得更好的准确性，灵敏度和特异性。<br><code>关键词</code> -  CNN，MRI，通用特征，PCA，TSNE，分类器</p>
<h4 id="A-Novel-Multimodal-MRI-Analysis-for-Alzheimer’s-Disease-Based-on-Convolutional-Neural-Network"><a href="#A-Novel-Multimodal-MRI-Analysis-for-Alzheimer’s-Disease-Based-on-Convolutional-Neural-Network" class="headerlink" title="A Novel Multimodal MRI Analysis for Alzheimer’s Disease Based on Convolutional Neural Network"></a>A Novel Multimodal MRI Analysis for Alzheimer’s Disease Based on Convolutional Neural Network</h4><blockquote>
<p> 基于卷积神经网络的阿尔茨海默病多模式MRI分析</p>
</blockquote>
<p>Abstract—Recent years, Alzheimer’s disease (AD) has be- come a significant threat to human health while the accurate screening and diagnosis of AD remain a tough problem. Multimodal Magnetic resonance imaging (MRI) can help to identify the variation of brain function and structure in a non-invasive way. Deep learning, especially the convolutional neural networks (CNN), can be utilized to automatically detect appropriate features for classification, which is well adapted for computer-aided AD screening and identification. This paper proposed a multimodal MRI analytical method based on CNN, which is also suitable for single type MRI data analysis. First, the human brain network connectivity matrix were extracted from multimodal MRI data, used as the input data for CNN. Then a novel CNN framework was proposed to process the network matrix and classify AD, amnestic mild cognitive impairment (aMCI) patients and normal controls (NC). The advantage of this method lies in that we combined multi- modal MRI information through CNN convolution kernel, and achieved a higher classification accuracy. In our experiments, the comprehensive classification accuracy of AD, aMCI patients and NC was as high as 92.06% when using multimodal MRI data as input, which is effective enough to provide a reference for multimodal MRI data analysis.</p>
<p>摘要 - 近年来，阿尔茨海默病（AD）已经成为人类健康的重大威胁，而AD的准确筛查和诊断仍然是一个棘手的问题。多模式磁共振成像（MRI）可以帮助以非侵入性方式识别脑功能和结构的变化。深度学习，尤其是卷积神经网络（CNN），可用于自动检测适当的分类特征，这非常适合于计算机辅助AD筛选和识别。本文提出了一种基于CNN的多模态MRI分析方法，该方法也适用于单一类型的MRI数据分析。首先，从多模式MRI数据中提取人脑网络连接矩阵，用作CNN的输入数据。然后提出了一种新的CNN框架来处理网络矩阵并对AD，遗忘型轻度认知障碍（aMCI）患者和正常对照（NC）进行分类。该方法的优点在于我们通过CNN卷积核将多模态MRI信息结合起来，实现了更高的分类精度。在我们的实验中，当使用多模式MRI数据作为输入时，<code>AD，aMCI患者和NC的综合分类准确率高达92.06％</code>，这足以为多模式MRI数据分析提供参考。</p>
<h4 id="DISCRIMINATIVE-ANALYSIS-OF-THE-HUMAN-CORTEX-USING-SPHERICAL-CNNS-A-STUDY-ON-ALZHEIMER’S-DISEASE-DIAGNOSIS"><a href="#DISCRIMINATIVE-ANALYSIS-OF-THE-HUMAN-CORTEX-USING-SPHERICAL-CNNS-A-STUDY-ON-ALZHEIMER’S-DISEASE-DIAGNOSIS" class="headerlink" title="DISCRIMINATIVE ANALYSIS OF THE HUMAN CORTEX USING SPHERICAL CNNS - A STUDY ON ALZHEIMER’S DISEASE DIAGNOSIS"></a>DISCRIMINATIVE ANALYSIS OF THE HUMAN CORTEX USING SPHERICAL CNNS - A STUDY ON ALZHEIMER’S DISEASE DIAGNOSIS</h4><blockquote>
<p>球形CNNS对人体皮质的判别分析 - 阿尔茨海默病的诊断研究</p>
</blockquote>
<p><code>ABSTRACT</code> — In neuroimaging studies, the human cortex is commonly mod- eled as a sphere to preserve the topological structure of the cortical surface. Cortical neuroimaging measures hence can be modeled in spherical representation. In this work, we ex- plore analyzing the human cortex using spherical CNNs in an Alzheimer’s disease (AD) classification task using corti- cal morphometric measures derived from structural MRI. Our results show superior performance in classifying AD versus cognitively normal and in predicting MCI progression within two years, using structural MRI information only. This work demonstrates for the first time the potential of the spherical CNNs framework in the discriminative analysis of the human cortex and could be extended to other modalities and other neurological diseases.<br><code>Index Terms</code>— Spherical CNNs, cortex, Alzheimer’s disease, structural MRI</p>
<p><code>摘要</code> — 在神经影像学研究中，人体皮层通常被建模为球体，以保持皮质表面的拓扑结构。 因此，皮质神经成像测量可以以球形表示来建模。 在这项工作中，我们使用来自结构MRI的皮质形态测量指标，在阿尔茨海默病（AD）分类任务中使用球形CNN分析人体皮层。 我们的结果显示，在仅使用结构MRI信息的情况下，在分类AD与认知正常以及预测MCI在两年内的进展方面表现优异。 这项工作首次证明了球形CNN框架在人类皮层的辨别分析中的潜力，并可能扩展到其他形式和其他神经系统疾病。<br><code>索引术语</code> - 球形CNN，皮层，阿尔茨海默病，结构MRI</p>
<h4 id="3D-Inception-based-CNN-with-sMRI-and-MD-DTI-data-fusion-for-Alzheimer’s-Disease-diagnostics"><a href="#3D-Inception-based-CNN-with-sMRI-and-MD-DTI-data-fusion-for-Alzheimer’s-Disease-diagnostics" class="headerlink" title="3D Inception-based CNN with sMRI and MD-DTI data fusion for Alzheimer’s Disease diagnostics"></a>3D Inception-based CNN with sMRI and MD-DTI data fusion for Alzheimer’s Disease diagnostics</h4><blockquote>
<p>3D基于初始的CNN，具有用于阿尔茨海默病诊断的sMRI和MD-DTI数据融合</p>
</blockquote>
<p><code>Abstract</code>: In the last decade, computer-aided early diagnostics of Alzheimers Disease (AD) and its prodromal form, Mild Cognitive Impair- ment (MCI), has been the subject of extensive research. Some recent studies have shown promising results in the AD and MCI determination using structural and functional Magnetic Resonance Imaging (sMRI, fMRI), Positron Emission Tomography (PET) and Diffusion Tensor Imaging (DTI) modalities. Furthermore, fusion of imaging modalities in a supervised machine learning framework has shown promising direction of research.<br>In this paper we first review major trends in automatic classification methods such as feature extraction based methods as well as deep learning approaches in medical image analysis applied to the field of Alzheimer’s Disease diagnostics. Then we propose our own design of a 3D Inception-based Convolutional Neural Network (CNN) for Alzheimer’s Disease diagnostics. The network is designed with an emphasis on the interior resource utilization and uses sMRI and DTI modalities fusion on hippocampal ROI. The comparison with the conventional AlexNet-based network using data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset (<a href="http://adni.loni.usc.edu" target="_blank" rel="noopener">http://adni.loni.usc.edu</a>) demonstrates significantly better performance of the proposed 3D Inception-based CNN.<br><code>Keywords</code>: MedicalImaging,AlzheimersDisease,MildCognitiveImpairment,MachineLearning,Deeplearning,Convolutional Neural Networks, Data Fusion.</p>
<p><code>摘要</code>：在过去十年中，计算机辅助阿尔茨海默病（AD）的早期诊断及其前驱形式，轻度认知障碍（MCI），已成为广泛研究的主题。一些最近的研究已经显示使用结构和功能磁共振成像（sMRI，fMRI），正电子发射断层扫描（PET）和扩散张量成像（DTI）模式的AD和MCI测定中的有希望的结果。此外，在监督机器学习框架中融合成像模式已经显示出有前途的研究方向。<br>在本文中，我们首先回顾自动分类方法的主要趋势，例如基于特征提取的方法以及应用于阿尔茨海默病诊断领域的医学图像分析中的深度学习方法。然后我们提出了我们自己设计的基于3D初始的卷积神经网络（CNN）的阿尔茨海默病诊断。该网络的设计重点是内部资源的利用，并使用sMRI和DTI模式融合海马ROI。使用来自Alzheimers Disease Neuroimaging Initiative（ADNI）数据集（<a href="http://adni.loni.usc.edu）的数据与传统的基于AlexNet的网络的比较证明了所提出的基于3D" target="_blank" rel="noopener">http://adni.loni.usc.edu）的数据与传统的基于AlexNet的网络的比较证明了所提出的基于3D</a> Inception的CNN的显着更好的性能。<br><code>关键词</code>：医学成像，老年痴呆症，轻度认知障碍，机器学习，去学习，卷积神经网络，数据融合。</p>
<h4 id="3D-CNN-based-classification-using-sMRI-and-MD-DTI-images-for-Alzheimer-disease-studies"><a href="#3D-CNN-based-classification-using-sMRI-and-MD-DTI-images-for-Alzheimer-disease-studies" class="headerlink" title="3D CNN-based classification using sMRI and MD-DTI images for Alzheimer disease studies"></a>3D CNN-based classification using sMRI and MD-DTI images for Alzheimer disease studies</h4><blockquote>
<p> 基于3D CNN的分类使用sMRI和MD-DTI图像进行阿尔茨海默病研究</p>
</blockquote>
<p><code>Abstract</code>: Computer-aided early diagnosis of Alzheimers Disease (AD) and its prodromal form, Mild Cognitive Impairment (MCI), has been the subject of extensive research in recent years. Some recent studies have shown promising results in the AD and MCI determination using structural and functional Magnetic Resonance Imaging (sMRI, fMRI), Positron Emission Tomography (PET) and Diffusion Tensor Imaging (DTI) modalities. Furthermore, fusion of imaging modalities in a supervised machine learning framework has shown promising direction of research.<br>In this paper we first review major trends in automatic classification methods such as feature extraction based methods as well as deep learning approaches in medical image analysis applied to the field of Alzheimer’s Disease diagnostics. Then we propose our own algorithm for Alzheimer’s Disease diagnostics based on a convolutional neural network and sMRI and DTI modalities fusion on hippocampal ROI using data from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (<a href="http://adni" target="_blank" rel="noopener">http://adni</a>. loni.usc.edu). Comparison with a single modality approach shows promising results. We also propose our own method of data augmentation for balancing classes of different size and analyze the impact of the ROI size on the classification results as well.<br><code>Keywords</code>: MedicalImaging,AlzheimersDisease,MildCognitiveImpairment,MachineLearning,Deeplearning,Convolutional Neural Networks, Image Fusion.</p>
<p><code>摘要</code>：计算机辅助早期诊断阿尔茨海默病（AD）及其前驱形式，轻度认知障碍（MCI），近年来已成为广泛研究的主题。一些最近的研究已经显示使用结构和功能磁共振成像（sMRI，fMRI），正电子发射断层扫描（PET）和扩散张量成像（DTI）模式的AD和MCI测定中的有希望的结果。此外，在监督机器学习框架中融合成像模式已经显示出有前途的研究方向。<br>在本文中，我们首先回顾自动分类方法的主要趋势，例如基于特征提取的方法以及应用于阿尔茨海默病诊断领域的医学图像分析中的深度学习方法。然后，我们使用来自阿尔茨海默病神经影像学倡议（ADNI）数据库（<a href="http://adni.loni.usc.edu）的数据，基于卷积神经网络和海马ROI上的sMRI和DTI模态融合，提出我们自己的阿尔茨海默病诊断算法。" target="_blank" rel="noopener">http://adni.loni.usc.edu）的数据，基于卷积神经网络和海马ROI上的sMRI和DTI模态融合，提出我们自己的阿尔茨海默病诊断算法。</a> 。与单一模态方法的比较显示出有希望的结果。我们还提出了自己的数据增强方法，用于平衡不同大小的类，并分析ROI大小对分类结果的影响。<br><code>关键词</code>：医学成像，老年痴呆症，轻度认知障碍，机器学习，深度学习，卷积神经网络，图像融合。</p>
<h4 id="MRI-to-FDG-PET-Cross-Modal-Synthesis-Using-3D-U-Net-For-Multi-Modal-Alzheimer’s-Classification"><a href="#MRI-to-FDG-PET-Cross-Modal-Synthesis-Using-3D-U-Net-For-Multi-Modal-Alzheimer’s-Classification" class="headerlink" title="MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer’s Classification"></a>MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer’s Classification</h4><blockquote>
<p>MRI到FDG-PET：使用3D U-Net进行多模态阿尔茨海默病分类的交叉模态综合</p>
</blockquote>
<p><code>Abstract</code>. Recent studies suggest that combined analysis of Magnetic resonance imaging (MRI) that measures brain atrophy and positron emission tomography (PET) that quantifies hypo-metabolism provides improved accuracy in diagnosing Alzheimer’s disease. However, such tech- niques are limited by the availability of corresponding scans of each modality. Current work focuses on a cross-modal approach to estimate FDG-PET scans for the given MR scans using a 3D U-Net architecture. The use of the complete MR image instead of a local patch based ap- proach helps in capturing non-local and non-linear correlations between MRI and PET modalities. The quality of the estimated PET scans is measured using quantitative metrics such as MAE, PSNR and SSIM. The efficacy of the proposed method is evaluated in the context of Alzheimer’s disease classification. The accuracy using only MRI is 70.18% while joint classification using synthesized PET and MRI is 74.43% with a p-value of 0.06. The significant improvement in diagnosis demonstrates the utility of the synthesized PET scans for multi-modal analysis.</p>
<p><code>摘要</code>.最近的研究表明，测量脑萎缩的磁共振成像（MRI）和量化低代谢的正电子发射断层扫描（PET）的联合分析提高了诊断阿尔茨海默病的准确性。然而，这些技术受到每种模态的相应扫描的可用性的限制。目前的工作重点是使用<code>3D U-Net架构</code>估算给定MR扫描的FDG-PET扫描的跨模态方法。使用完整的MR图像而不是基于局部补丁的方法有助于捕获MRI和PET模态之间的非局部和非线性相关性。使用诸如MAE，PSNR和SSIM的定量指标来测量估计的PET扫描的质量。在阿尔茨海默病分类的背景下评估所提出的方法的功效。仅使用MRI的准确率为70.18％，而使用合成PET和MRI的联合分类为74.43％，p值为0.06。诊断的显着改进证明了合成的PET扫描用于多模态分析的效用。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2019-07-30T07:38:09.729Z" itemprop="dateUpdated">2019-07-30 15:38:09</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="CaptainSE">
            CaptainSE
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            

            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&title=《AD-Papers-Abstract》 — Go Further&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&title=《AD-Papers-Abstract》 — Go Further&source=【阅读时间】XXX min XXX words【阅读内容】……" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/29/AD-Papers-Abstract/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《AD-Papers-Abstract》 — Go Further&url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/07/26/AD-dataset/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">AD-dataset</h4>
      </a>
    </div>
  
</nav>



    

















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢老板~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>CaptainSE &copy; 2015 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&title=《AD-Papers-Abstract》 — Go Further&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&title=《AD-Papers-Abstract》 — Go Further&source=【阅读时间】XXX min XXX words【阅读内容】……" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/29/AD-Papers-Abstract/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《AD-Papers-Abstract》 — Go Further&url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/29/AD-Papers-Abstract/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACKklEQVR42u3aS3LCMBAFQO5/abLNxua9sUnKUmtFQSHUXgzz0esVr/evNXv/6HWy220LAwPjsYz36Zoxjo6e7HP+rcNfxMDA2ICRHKINtS2vDc0YGBgYydb5oc+Pm5AwMDAwZgE3R+apJAYGBsaVIjYJlDn432pxDAyMBzLyrvvfv/7KfAMDA+NRjHe5rrfk2lI2OhUGBsbSjDzA5bzz3e4KuBgYGPsw8pI1OW4eHGfl8eGvY2BgLM1oU717221t8pcPGDAwMFZl5IeYtc/ah5IPEjAwMHZg5FccrqSGszZcgcTAwFiUMStW2wbZlasY0SPGwMDYgNG20mal6SwdjNJKDAyMDRiz5n47nmwvexXJJQYGxjaM9qpWkpUlzbJkDPChhMbAwNiAcX645P1vjxCigIuBgbEo43prLA+UsyFB8jeAgYGxNuPeMWQ7TshL2Q+fYmBgbMPIrz7MUsY2ccwLYAwMjLUZSQKXh862+GwvhxUX1zAwMJZjzNr0+WDySqOtaMNhYGBsw5gNLNvBZ/s4on4hBgbGloy2fdaG4CJjDdJKDAyMVRnvcuXDyKgpVobpwzNgYGAszWhHie1Gs6MkRe9sIIqBgfFcxpV2W95Ey5/cDTMNDAyMRRl3NfTbJLL9B/hwwQIDAwNjNMJMdhsOAzAwMDDihG92wWt2XePwIWJgYGzAyI+Vp4ztlYsr7T8MDIy1GbPE7vxwySWwdrQ5SzExMDAezvgB1XlqmAPPAx8AAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Go Further | Stay Hungry, Stay Foolish';
            clearTimeout(titleTime);
        } else {
            document.title = 'Go Further | Stay Hungry, Stay Foolish';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
