{"meta":{"title":"Go Further","subtitle":"Stay Hungry, Stay Foolish","description":"CaptainSE","author":"CaptainSE","url":"http://yoursite.com"},"pages":[{"title":"My Blog Name | 404","date":"2018-08-17T17:00:22.326Z","updated":"2018-08-17T17:00:18.631Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":""},{"title":"categories","date":"2018-08-15T18:36:38.000Z","updated":"2018-08-16T04:54:47.591Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-15T18:34:59.000Z","updated":"2018-08-16T04:53:15.699Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"CS231n_Lecture_SVM","slug":"CS231n-Lecture-SVM","date":"2018-10-18T12:01:32.000Z","updated":"2018-10-20T08:50:48.533Z","comments":true,"path":"2018/10/18/CS231n-Lecture-SVM/","link":"","permalink":"http://yoursite.com/2018/10/18/CS231n-Lecture-SVM/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… 课程链接 Linear classification: Support Vector Machine, Softmax 线性分类笔记(上)/线性分类笔记(中)/线性分类笔记(下) 线性分类器 图像空间的示意图,其中每个图像是一个点,且有3个分类器.以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低. Interactive web demo 评分函数 Score function线性映射 $$ f(x_i,W,b)=Wx_i+b $$ W(Weights 权重) : [K*D] (W的每一行为对应一个分类的模板(“原型”)) 如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转. x_i(输入数据) : [D*1] b(bias vector 偏差向量) : [K*1] 允许分类器对应的直线平移.如果没有偏差,无论权重如何,在x_i=0时分类分值始终为0.这样所有分类器的线都不得不穿过原点. 该函数的输出值为对应各类别的score 我们的目的就是找到最优化的参数W、b,即为每一个分类找到最好的模板. 评分函数在正确的分类的位置应当得到最高的评分（score） 偏差和权重的合并Bias trick $$ f(x_i,W,b)=Wx_i+b\\rightarrow f(x_i,W) = Wx_i $$ 其中，W[K*D]→W[K*(D+1)], x_i[D,1] → x_i[(D+1),1] 将线性分类器看作模板匹配 Interpretation of linear classifiers as template matching W的每一行为对应一个分类的模板(“原型”).注意，船的模板如期望的那样有很多蓝色像素。如果图像是一艘船行驶在大海上，那么这个模板利用内积计算图像将给出很高的分数。 图像数据预处理 Image data preprocessing 对于输入的特征做归一化（normalization）处理 对每个特征减去平均值来中心化数据 归一. 区间变为[-1,1] 损失函数 Loss function我们将使用损失函数（Loss Function）（有时也叫代价函数Cost Function或目标函数Objective）来衡量我们对结果的不满意程度。直观地讲，当评分函数输出结果与真实结果之间差异越大，损失函数输出越大，反之越小。，对训练集中数据做出准确分类预测和让损失值最小化这两件事是等价的。 多类支持向量机损失 Multiclass Support Vector Machine Loss SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高,且至少高出一个边界值delta.如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。 Hinge Loss 针对第i个数据的多类SVM的损失函数定义：$$ L_i=\\sum_{j\\not=y_i}max(0,s_j-s_{y_i}+\\Delta) $$ Data Loss $$ L = { \\frac{1}{N} \\sum_i L_i } $$ 正则化 Regularization防止过拟合：向损失函数增加一个正则化惩罚（regularization penalty） R(W)部分，使其不能完全匹配训练集.最常用的正则化惩罚是L2范式，L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重.对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响.$$R(W) = \\sum_k\\sum_l W_{k,l}^2$$ 需要注意的是，和权重不同，偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常只对权重$W$正则化，而不正则化偏差$b$。因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当$W=0$的特殊情况下，才能得到损失值为0 完整的多类SVM损失函数$$ L = \\underbrace{ \\frac{1}{N} \\sum_i L_i }_\\text{data loss} + \\underbrace{ \\lambda R(W) }_\\text{regularization loss} \\\\\\\\ $$ 将其展开完整公式是：$$ L = \\frac{1}{N} \\sum_i \\sum_{j\\neq y_i} \\left[ \\max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \\Delta) \\right] + \\lambda \\sum_k\\sum_l W_{k,l}^2 $$ 对于每一个输入数据$x_i$都有一个L值 设置超参$\\Delta$和λ超参数$\\Delta$和λ失函数中的数据损失和正则化损失之间的权衡。理解这一点的关键是要知道，权重W的大小对于分类分值有直接影响（当然对他们的差异也有直接影响）：当我们将W中值缩小，分类分值之间的差异也变小，反之亦然。因此，不同分类分值之间的边界的具体值（比如$\\Delta$=1或$\\Delta$=100).从某些角度来看是没意义的，因为权重自己就可以控制差异变大和缩小。也就是说，真正的权衡是我们允许权重能够变大到何种程度（通过正则化强度λ来控制） Softmax分类器与SVM不同，Softmax的输出（归一化的分类概率）更加直观，并且从概率上可以解释。在Softmax分类器中，函数映射$f(x_i;W)=Wx_i$保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将折叶损失（hinge loss）替换为交叉熵损失（cross-entropy loss） 公式如下：$\\displaystyle Li=-log(\\frac{e^{f_{y_i}}}{\\sum_je^{f_j}})$ 或等价于 $L_i=-f_{y_i}+log(\\sum_je^{f_j})$ softmax函数函数$f_j(z)=\\frac{e^{z_j}}{\\sum_ke^{z_k}}$被称作softmax 函数.函数对输入向量z(score值)进行压缩，输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1.$$P(y_i|x_i,W)=\\frac{e^{f_{y_i}}}{\\sum_je^{f_j}}$$可以解释为是给定图像数据$x_i$，以$W$为参数，分配给正确分类标签$y_i$的归一化概率。从概率论的角度来理解，我们就是在最小化正确分类的负对数概率(令正确分类的概率尽趋近于1，即令错误分类的概率均趋近于0)，这可以看做是在进行最大似然估计（MLE）。 交叉熵在“真实”分布(未知)$p$和估计分布(样本分布)$q$之间的交叉熵定义： $\\displaystyle H(p,q)=-\\sum_xp(x) logq(x)$ 交叉熵损失函数“想要”预测分布的所有概率密度都在正确分类上,让预测分布与真实分布保持一致。Softmax分类器所做的就是最小化在估计分类概率（就是上面的$e^{f_{y_i}}/\\sum_je^{f_j}$）和“真实”分布之间的交叉熵，在这个解释中，“真实”分布就是所有概率密度都分布在正确的类别上（比如：$p=[0,…1,…,0]$中在$y_i$的位置就有一个单独的1） SVM和Softmax的比较 针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量f（本节中是通过矩阵乘来实现）。不同之处在于对f中分值的解释： SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。SVM的最终的损失值是1.58。 Softmax分类器将这些数值看做是每个分类没有归一化的对数概率，鼓励正确分类的归一化的对数概率变高，其余的变低。Softmax的最终的损失值是0.452。但要注意SVM和Softmax的最终损失值(1.58和0.452)两个数值没有可比性。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。 Softmax分类器为每个分类提供了“可能性”：可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，softmax分类器算出来的概率最好是看成一种对于分类正确性的置信水平。 在实际使用中，SVM和Softmax经常是相似的：通常说来，两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。 SVM更加“局部目标化（local objective）”.SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM($\\Delta$=1)来说没什么不同，只要满足超过边界值等于1，那么损失值就等于0。SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。 softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。 小结 定义了从图像像素映射到不同类别的分类评分的评分函数。在本节中，评分函数是一个基于权重W和偏差b的线性函数。 与kNN分类器不同，参数方法的优势在于一旦通过训练学习到了参数，就可以将训练数据丢弃了。同时该方法对于新的测试数据的预测非常快，因为只需要与权重W进行一个矩阵乘法运算。 介绍了偏差技巧，让我们能够将偏差向量和权重矩阵合二为一，然后就可以只跟踪一个矩阵。 定义了损失函数（介绍了SVM和Softmax线性分类器最常用的2个损失函数）。损失函数能够衡量给出的参数集与训练集数据真实类别情况之间的一致性。在损失函数的定义中可以看到，对训练集数据做出良好预测与得到一个足够低的损失值这两件事是等价的。 现在我们知道了如何基于参数，将数据集中的图像映射成为分类的评分，也知道了两种不同的损失函数，它们都能用来衡量算法分类预测的质量。但是，如何高效地得到能够使损失值最小的参数呢？这个求得最优参数的过程被称为最优化，将在下节课中进行介绍。 参考：cs231n assignment1 svm","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://yoursite.com/categories/MachineLearning/"}],"tags":[{"name":"CS231n","slug":"CS231n","permalink":"http://yoursite.com/tags/CS231n/"}]},{"title":"Concept_Note","slug":"Concept-Note","date":"2018-10-18T08:48:07.000Z","updated":"2018-10-20T01:37:30.372Z","comments":true,"path":"2018/10/18/Concept-Note/","link":"","permalink":"http://yoursite.com/2018/10/18/Concept-Note/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… @card{ Linear classification score function: 得分函数的目的：我们要做的就是对于一个给定的输入，比如一张小猫的图片，通过一系列复杂的变换（中间的过程咱们暂且当做一个黑盒子）能得到这个输入对应于每个类别的得分数值. Loss Fuction: 量化我们对训练结果的满意程度，换句话说，是衡量分类器的错误程度 }","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://yoursite.com/categories/MachineLearning/"}],"tags":[{"name":"CS231n","slug":"CS231n","permalink":"http://yoursite.com/tags/CS231n/"}]},{"title":"CS231n_Assignment_Step","slug":"CS231n-Assignment-Step","date":"2018-10-17T12:57:13.000Z","updated":"2018-10-20T01:41:03.215Z","comments":true,"path":"2018/10/17/CS231n-Assignment-Step/","link":"","permalink":"http://yoursite.com/2018/10/17/CS231n-Assignment-Step/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… @card{ 完成代码，跑通 （保存page.pdf） 查找资料(多找些博客，择优)，理解细节 理清思路，写博客总结 upload博客(博客代码标题链接到git code 以及 pdf 链接)、 git push “CS231n_ssignment” } @card{ 博客思路12 }","categories":[],"tags":[]},{"title":"Assignment_1_KNN","slug":"CS231n-Assignment-1-KNN","date":"2018-10-17T09:39:40.000Z","updated":"2018-10-19T11:10:11.381Z","comments":true,"path":"2018/10/17/CS231n-Assignment-1-KNN/","link":"","permalink":"http://yoursite.com/2018/10/17/CS231n-Assignment-1-KNN/","excerpt":"【阅读时间】8 min 2043 words【阅读内容】……","text":"【阅读时间】8 min 2043 words【阅读内容】…… 效果演示代码实现部分 计算test样本与training样本的L2距离.L2距离的定义：$$ L_2(I_1,I_2) = \\sqrt{{\\sum_p{(I_1^p - I_2^p)^2}}} $$ @card{ Open cs231n/classifiers/k_nearest_neighbor.py and implement compute_distances_two_loops.123456789101112131415161718192021def compute_distances_two_loops(self, X): num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) for i in range(num_test): for j in range(num_train): ##################################################################### # TODO: # # Compute the l2 distance between the ith test point and the jth # # training point, and store the result in dists[i, j]. You should # # not use a loop over dimension. # ##################################################################### pass ### X - X_test.shape == (500,3072) X_train.shape = (5000,3072) # dists[i][j] = np.sqrt(np.sum((X[i]-self.X_train[j])**2)) dists[i][j] = np.sqrt(np.sum(np.square(X[i,:] - self.X_train[j,:]))) ##################################################################### # END OF YOUR CODE # ##################################################################### return dists #dists.shape = (500, 5000) } @card{ Now lets speed up distance matrix computation by using partial vectorization with one loop. Implement the function compute_distances_one_loop 123456789101112131415161718def compute_distances_one_loop(self, X): num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) for i in range(num_test): ####################################################################### # TODO: # # Compute the l2 distance between the ith test point and all training # # points, and store the result in dists[i, :]. # ####################################################################### pass # dists[i] = np.sqrt(np.sum((self.X_train - X[i]) ** 2, 1)) dists[i] = np.sqrt(np.sum(np.square(self.X_train - X[i]), axis=1)) ####################################################################### # END OF YOUR CODE # ####################################################################### return dists # dists.shape = (500, 5000) } @card{ Now implement the fully vectorized version inside compute_distances_no_loops 数学说明 123456789101112131415161718192021222324252627def compute_distances_no_loops(self, X): num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) ######################################################################### # TODO: # # Compute the l2 distance between all test points and all training # # points without using any explicit loops, and store the result in # # dists. # # # # You should implement this function using only basic array operations; # # in particular you should not use functions from scipy. # # # # HINT: Try to formulate the l2 distance using matrix multiplication # # and two broadcast sums. # ######################################################################### pass dists += np.sum(self.X_train ** 2, axis=1).reshape(1, num_train) dists += np.sum(X ** 2, axis=1).reshape(num_test, 1) # reshape for broadcasting dists -= 2 * np.dot(X, self.X_train.T) dists = np.sqrt(dists) ######################################################################### # END OF YOUR CODE # ######################################################################### return dists # dists.shape = (500, 5000) } @card{ Now implement the function predict_labels 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def predict_labels(self, dists, k=1): num_test = dists.shape[0] y_pred = np.zeros(num_test) for i in range(num_test): # A list of length k storing the labels of the k nearest neighbors to # the ith test point. closest_y = [] ######################################################################### # TODO: # # Use the distance matrix to find the k nearest neighbors of the ith # # testing point, and use self.y_train to find the labels of these # # neighbors. Store these labels in closest_y. # # Hint: Look up the function numpy.argsort. # ######################################################################### pass # sorted_index = np.argsort(dists[i]) # closest_y = self.y_train[sorted_index[:k]] closest_y = self.y_train[np.argsort(dists[i])[:k]] ######################################################################### # TODO: # # Now that you have found the labels of the k nearest neighbors, you # # need to find the most common label in the list closest_y of labels. # # Store this label in y_pred[i]. Break ties by choosing the smaller # # label. # ######################################################################### pass y_pred[i] = np.bincount(closest_y).argmax() # timeLabel = sorted([(np.sum(np.array(closest_y) == y_), y_) for y_ in set(closest_y)])[-1] # y_pred[i] = timeLabel[1] # appear_times = &#123;&#125; # for label in closest_y: # if label in appear_times: # appear_times[label] += 1 # else: # appear_times[label] = 0 # # find most commen label # y_pred[i] = max(appear_times, key=lambda x: appear_times[x]) ######################################################################### # END OF YOUR CODE # ######################################################################### return y_pred } @card{ We will now determine the best value of this hyperparameter with cross-validation.使用cross validation的方法，来选择hyper-parameter超参数k的值.cross validation的原理是，将training样本集分成n份（如下图中的例子，是5份），每一份叫做一个fold，然后依次迭代这n个fold，将其作为validation集合，其余的n-1个fold一起作为training集合，然后进行训练并计算准确率。选择一组候选k值，依次迭代执行上面描述的过程，最终根据准确率，进行评估选择最合适的k值. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970num_folds = 5k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]X_train_folds = []y_train_folds = []################################################################################# TODO: ## Split up the training data into folds. After splitting, X_train_folds and ## y_train_folds should each be lists of length num_folds, where ## y_train_folds[i] is the label vector for the points in X_train_folds[i]. ## Hint: Look up the numpy array_split function. ################################################################################## Your codeX_train_folds = np.array_split(X_train, num_folds)y_train_folds = np.array_split(y_train, num_folds)################################################################################# END OF YOUR CODE ################################################################################## A dictionary holding the accuracies for different values of k that we find# when running cross-validation. After running cross-validation,# k_to_accuracies[k] should be a list of length num_folds giving the different# accuracy values that we found when using that value of k.k_to_accuracies = &#123;&#125;################################################################################# TODO: ## Perform k-fold cross validation to find the best value of k. For each ## possible value of k, run the k-nearest-neighbor algorithm num_folds times, ## where in each case you use all but one of the folds as training data and the ## last fold as a validation set. Store the accuracies for all fold and all ## values of k in the k_to_accuracies dictionary. ################################################################################## Your codefor k_candi in k_choices: k_to_accuracies[k_candi] = [] for i in range(num_folds): X_test_hy = X_train_folds[i] y_test_hy = y_train_folds[i] X_train_hy = np.vstack(X_train_folds[0:i]+X_train_folds[i+1:]) y_train_hy = np.hstack(y_train_folds[0:i]+y_train_folds[i+1:]) # x_trai = np.array(X_train_folds[:f] + X_train_folds[f+1:])# y_trai = np.array(Y_train_folds[:f] + Y_train_folds[f+1:]) # x_trai = x_trai.reshape(-1, x_trai.shape[2])# y_trai = y_trai.reshape(-1) classifier.train(X_train_hy, y_train_hy) dists_hy = classifier.compute_distances_no_loops(X_test_hy) y_test_pred_hy = classifier.predict_labels(dists_hy, k=k_candi) # Compute the fraction of correctly predicted examples num_correct_hy = np.sum(y_test_pred_hy == y_test_hy) accuracy_hy = float(num_correct_hy) / len(y_test_hy) k_to_accuracies[k_candi].append(accuracy_hy)################################################################################# END OF YOUR CODE #################################################################################print(k_to_accuracies)# Print out the computed accuraciesfor k in sorted(k_to_accuracies): for accuracy in k_to_accuracies[k]: print('k = %d, accuracy = %f' % (k, accuracy)) } @card{ numpy/matplotlib 部分函数说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263641. numpy.flatnonzero(): 输入一个矩阵，返回了其中非零元素的位置2. numpy.random.choice(a, size=None, replace=True, p=None) - a: If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if a was np.arange(n) - size : int or tuple of ints, optional - replace : boolean, optional If you want only unique samples then this should be false. - p : 1-D array-like, optional The probabilities associated with each entry in a. If not given the sample assumes a uniform distribution over all entries in a.3. matplotlib.pyplot.subplot(X,X,X)： - 前两个数表示子图组成的矩阵的行列数，比如有6个子图，排列成3行2列，那就是subplot(3,2,X)。最后一个数表示要画第X个图了。4. matplotlib.pyplot.imshow(X,interpolation='none',cmap=None) - X: 要绘制的图像或数组. - interpolation 插值方式 [None, 'none', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'] - cmap: 颜色图谱（colormap), 默认绘制为RGB(A)颜色空间.5. numpy.reshape(a, newshape, order='C') - 注：给出一个m*n的矩阵，如果newshape给的参数是（x, -1）,那么函数会自动判别newshape为（x, m*n/x）,这里的x一定要能被m*n整除！6. numpy.argsort()：输出排好序的元素下标, a[np.argsort(a)]的结果才是最终排好序的结果.7. numpy.binicount(x, weight = None, minlength = None) &gt;&gt;&gt; x = np.array([0, 1, 1, 3, 2, 1, 7]) &gt;&gt;&gt; np.bincount(x) array([1, 3, 1, 1, 0, 0, 0, 1])8. x_norm=np.linalg.norm(x, ord=None, axis=None, keepdims=False) - linalg=linear（线性）+algebra（代数），norm则表示范数 - x: 表示矩阵（也可以是一维） - ord：范数类型 - ord=1：列和的最大值 - ord=2：|λE-ATA|=0，求特征值，然后求最大特征值的算术平方根 - ord=np.inf：行和的最大值 - axis：处理类型 - axis=1表示按行向量处理，求多个行向量的范数 - axis=0表示按列向量处理，求多个列向量的范数 - axis=None表示矩阵范数 - keepding：是否保持矩阵的二维特性 - True表示保持矩阵的二维特性，False相反9. np.dot(A, B)：对于二维矩阵，计算真正意义上的矩阵乘积，同线性代数中矩阵乘法的定义.10. sum(a, axis=None, dtype=None, out=None, keepdims=&lt;class 'numpy._globals._NoValue'&gt;) - axis : - axis = None: 对所有元素求和 - axis = 0: 对所有在同一列的元素求和 - axis = 1: 对所有在同一行的元素求和11. np.vstack(tup): 沿着竖直方向将矩阵堆叠起来 - Note: the arrays must have the same shape along all but the first axis. 除开第一维外，被堆叠的矩阵各维度要一致.12. np.hstack(tup):沿着水平方向将数组堆叠起来13. plt.scatter(X, Y)： 散点图 (x,y)即坐标14. np.random.randn(d0,d1,…,dn) - randn函数返回一个或一组样本，具有标准正态分布。 - d表示维度 - 返回值为指定维度的array } @card{ Summary即使经过调优，knn算法的准确率也不足30%，可以知道knn算法并不适合用于图像分类学习任务. } @card{ 参考： 【实验小结】cs231n assignment1 knn 部分 cs231n 课程作业 Assignment 1、standford-cs231n-assignment1 }","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://yoursite.com/categories/MachineLearning/"}],"tags":[{"name":"CS231n","slug":"CS231n","permalink":"http://yoursite.com/tags/CS231n/"}]},{"title":"Python_Note","slug":"Python-Note","date":"2018-10-04T05:28:48.000Z","updated":"2018-10-06T06:25:05.122Z","comments":true,"path":"2018/10/04/Python-Note/","link":"","permalink":"http://yoursite.com/2018/10/04/Python-Note/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… 字符串 字符串是一个sequence 123word = 'hello'for letter in word: print(letter) 函数 python函数参数传递可以理解为就是变量传值操作 enumerate()使用 如果对一个列表，既要遍历索引又要遍历元素时，首先可以这样写： 123list1 = [\"这\", \"是\", \"一个\", \"测试\"]for i in range (len(list1)): print i ,list1[i]123 上述方法有些累赘，利用enumerate()会更加直接和优美： 12345678list1 = [\"这\", \"是\", \"一个\", \"测试\"]for index, item in enumerate(list1): print index, item&gt;&gt;&gt;0 这1 是2 一个3 测试12345678 enumerate还可以接收第二个参数，用于指定索引起始值，如： 12345678list1 = [\"这\", \"是\", \"一个\", \"测试\"]for index, item in enumerate(list1, 1): print index, item&gt;&gt;&gt;1 这2 是3 一个4 测试","categories":[],"tags":[]},{"title":"Morvan_Python","slug":"Morvan-Python","date":"2018-09-27T03:14:01.000Z","updated":"2018-09-28T02:51:32.623Z","comments":true,"path":"2018/09/27/Morvan-Python/","link":"","permalink":"http://yoursite.com/2018/09/27/Morvan-Python/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… 基础语法自调用如果想要在执行脚本的时候执行一些代码，比如单元测试，可以在脚本最后加上单元测试 代码，但是该脚本作为一个模块对外提供功能的时候单元测试代码也会执行，这些往往我们不想要的，我们可以把这些代码放入脚本最后： 12if __name__ == '__main__': #code_here 如果执行该脚本的时候，该 if 判断语句将会是 True,那么内部的代码将会执行。 如果外部调用该脚本，if 判断语句则为 False,内部代码将不会执行。 可变参数顾名思义，函数的可变参数是传入的参数可以变化的，1个，2个到任意个。当然可以将这些 参数封装成一个 list 或者 tuple 传入，但不够 pythonic。使用可变参数可以很好解决该问题，注意可变参数在函数定义不能出现在特定参数和默认参数前面，因为可变参数会吞噬掉这些参数。 12345def report(name, *grades): total_grade = 0 for grade in grades: total_grade += grade print(name, 'total grade is ', total_grade) 定义了一个函数，传入一个参数为 name, 后面的参数 *grades 使用了 * 修饰，表明该参数是一个可变参数，这是一个可迭代的对象。该函数输入姓名和各科的成绩，输出姓名和总共成绩。所以可以这样调用函数 report(&#39;Mike&#39;, 8, 9)，输出的结果为 Mike total grade is 17, 也可以这样调用 report(&#39;Mike&#39;, 8, 9, 10)，输出的结果为 Mike total grade is 27 关键字参数关键字参数可以传入0个或者任意个含参数名的参数，这些参数名在函数定义中并没有出现，这些参数在函数内部自动封装成一个字典(dict). 1234def portrait(name, **kw): print('name is', name) for k,v in kw.items(): print(k, v) 定义了一个函数，传入一个参数 name, 和关键字参数 kw，使用了 ** 修饰。表明该参数是关键字参数，通常来讲关键字参数是放在函数参数列表的最后。如果调用参数portrait(&#39;Mike&#39;, age=24, country=&#39;China&#39;, education=&#39;bachelor&#39;) 输出: 1234name is Mikeage 24country Chinaeducation bachelor 通过可变参数和关键字参数，任何函数都可以用 universal_func(*args, **kw) 表达。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[]},{"title":"LibraryManagementSystem_Notes","slug":"LibraryManagementSystem-Notes","date":"2018-09-26T08:35:09.000Z","updated":"2018-09-26T11:38:30.838Z","comments":true,"path":"2018/09/26/LibraryManagementSystem-Notes/","link":"","permalink":"http://yoursite.com/2018/09/26/LibraryManagementSystem-Notes/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… 基于bean层(ENTITY层 — 实体层 数据库在项目中的类 )中Table的设计,在DAO/Service/Controller层进行填充 DAO层(database access object 数据持久层 — 主要与数据库进行交互) 123456public interface UserBkunitDAO extends JpaRepository&lt;UserBkunit, Integer&gt;&#123; Page&lt;UserBkunit&gt; findAllByUser(User reader, Pageable pageable); &#125;// 注：DAO层首先会创建DAO接口，然后会在配置文件中定义该接口的实现类.DAO设计的总体规划需要和设计的表，和实现类之间一一对应. Service层(业务逻辑层 — 负责业务模块的逻辑应用设计) 12345678910111213141516171819202122@Servicepublic class ReaderFunctionService &#123; @Autowired private UserService userService; @Autowired private UserBkunitDAO userBkunitDAO; public Page&lt;UserBkunit&gt; queryborrowedBooks(int start, int size) &#123; User reader = userService.getUser(); start = start &lt; 0 ? 0 : start; Sort sort = new Sort(Sort.Direction.DESC, \"date\"); Pageable pageable = PageRequest.of(start, size, sort); Page&lt;UserBkunit&gt; page = userBkunitDAO.findAllByUser(reader, pageable); return page; &#125;&#125;// 注：Service层应该既调用DAO层的接口，又要提供接口给Controller层的类来进行调用. Controller层(action层/控制层 — 控制业务逻辑，与View层结合紧密) 1234567891011121314151617@Controllerpublic class ReaderFunctionController &#123; @Autowired private ReaderFunctionService readerfunctionservice; @RequestMapping(value = \"/reader/borrowedBooks\",method = RequestMethod.GET) @ResponseBody public String queryBorrowTools(Model model, @RequestParam(value = \"start\", defaultValue = \"0\") int start,@RequestParam(value = \"size\", defaultValue = \"10\") int size) &#123; Page&lt;UserBkunit&gt; page = readerfunctionservice.queryborrowedBooks(start, size); model.addAttribute(\"page\", page); return \"queryBorrowedBooks\"; &#125;&#125;// 注：不关心业务逻辑的具体实现,仅仅需要调用service层里的一个方法即可.","categories":[{"name":"XD","slug":"XD","permalink":"http://yoursite.com/categories/XD/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"【2】一维随机变量及其分布","slug":"二、一维随机变量及其分布","date":"2018-08-28T10:20:53.000Z","updated":"2018-08-28T10:35:58.314Z","comments":true,"path":"2018/08/28/二、一维随机变量及其分布/","link":"","permalink":"http://yoursite.com/2018/08/28/二、一维随机变量及其分布/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… @column-2{ @card{ 离散$$ F(x,y) = P \\{ X \\leqslant x,Y \\leqslant y\\}=\\int_{-\\infty}^{x} du \\int_{-\\infty}^{y} f(u,v)dv $$ $$F_{x}(x)$$ 就是这样 $$F(x,y) = P \\{ X \\leqslant x,Y \\leqslant y\\}$$$$ 就是这样 } @card{ 连续} }","categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"http://yoursite.com/tags/概率论/"}]},{"title":"分布函数与数字特征","slug":"概率论","date":"2018-08-24T15:28:24.000Z","updated":"2018-08-24T16:56:35.566Z","comments":true,"path":"2018/08/24/概率论/","link":"","permalink":"http://yoursite.com/2018/08/24/概率论/","excerpt":"【阅读时间】XXX min XXX words【阅读内容】……","text":"【阅读时间】XXX min XXX words【阅读内容】…… @column-2{ @card{ 分布函数一维离散型r.v.$$F(x)=\\sum_{x{i}\\leqslant x} P_{i}$$一维连续型r.v.$$ F(x)= P \\{ X \\leqslant x \\}=\\int_{-\\infty}^{x}f(t)dt $$ 二维连续型r.v.$$ F(x,y) = P \\{ X \\leqslant x,Y \\leqslant y\\}=\\int_{-\\infty}^{x} du \\int_{-\\infty}^{y} f(u,v)dv $$ } @card{ 数学期望一维离散型r.v.$$E(x)=\\sum x_{i}P_{i}$$一维连续型r.v.$$E(X) = \\int_{-\\infty}^{+ \\infty} xf(x)dx$$ } }","categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"http://yoursite.com/tags/概率论/"}]},{"title":"编译原理知识点","slug":"编译原理知识汇总","date":"2018-08-17T17:32:07.000Z","updated":"2018-08-18T03:22:02.614Z","comments":true,"path":"2018/08/18/编译原理知识汇总/","link":"","permalink":"http://yoursite.com/2018/08/18/编译原理知识汇总/","excerpt":"【阅读时间】20min 11001words【阅读内容】XD编译原理教材知识汇总","text":"【阅读时间】20min 11001words【阅读内容】XD编译原理教材知识汇总 第一章 引言1.从面向机器的语言到面向人类的语言汇编指令：用符号表示的指令被称为汇编指令汇编语言：汇编指令的集合称为汇编语言 2.语言之间的翻译转换(也被称为预处理)：高级语言之间的翻译，如FORTRAN到ADA的转换编译：高级语言可以直接翻译成机器语言，也可以翻译成汇编语言，这两个翻译过程称为编译汇编：从汇编语言到机器语言的翻译被称为汇编交叉汇编：将一个汇编语言程序汇编成为可在另一机器上运行的机器指令成为交叉汇编反汇编：把机器语言翻译成汇编语言反编译：把汇编语言翻译成高级语言 3. 编译器与解释器（1）语言翻译的两种基本形态 解释器与编译器的主要区别:运行目标程序时的控制权在解释器而不在目标程序. （2）各自特点 编译器:工作效率高,即时间快、空间省；交互性与动态性差,可移植性差. 解释器:工作效率低,,即时间慢、空间费；交互性与动态性好,可移植性好. 共同点:均完成对源程序的翻译.差异:编译器采用先翻译后执行,解释器采用边翻译边执行. 4. 编译器的工作原理与基本组成（0）通用程序设计语言的主要成份 声明＋操作＝完整定义 （1）以过程为基本结构的程序设计语言的组成 声明性语句：提供操作对象的性质，如数据类型、值、作用域等； 操作性语句：确定操作的计算次序，完成实际操作。 过程定义 = 过程头＋过程体 （2）以阶段划分编译器 注：符号表管理器和出错处理贯穿编译器工作的各个阶段. （3）编译器各阶段工作 1&gt; 词法分析：词法分析的输入是源程序,输出是识别出的记号流.目的是识别单词. 至少分以下几类：关键字(保留字)、标识符、字面量、特殊符号 2&gt; 语法分析： 输入是词法分析器返回的记号流,输出是语法树.目的是得到语言结构并以树的形式表示.对于声明性语句,进行符号表的查填,对于可执行语句,检查结构合理的表达式运算是否有意义. 3&gt; 语义分析：根据语义规则对语法树中的语法单元进行静态语义检查,如类型检查和转换等,目的在于保证语法正确的结构在语义分析上也是合法的. 4&gt; 中间代码生成(可选)：生成一种既接近目标语言,又与具体机器无关的表示,便于代码优化与代码生成. (到目前为止，编译器与解释器可以一致) 5&gt; 中间代码优化(可选)：局部优化、循环优化、全局优化等；优化实际上是一个等价变换，变换前后的指令序列完成同样的功能，但在占用的空间上和程序执行的时间上都更省、更有效 6&gt; 目标代码生成：不同形式的目标代码—汇编语言形式、可重定位二进制代码形式、内存形式(Load-and-Go) 7&gt; 符号表管理：合理组织符号,便于各阶段查找\\填写等. 8&gt; 出错处理： 1234动态错误：源程序中的逻辑错误，发生在程序运行的时候。也称为动态语义错误静态错误：静态错误分为语法错误和静态语义错误. &lt;1&gt; 语法错误：有关语言结构上的错误，如单词拼写错误、表达式缺少操作数、begin和end不匹配&lt;2&gt; 静态语义错误：分析源程序时可以发现的语言意义上的错误，如加法的两个操作数一个是整形变量，另一个是数组名 （4）编译器的分析\\综合模式 逻辑上把编译器分为分析(前端)部分和综合(后端)部分.1&gt; 分析(前端)：语言结构和意义的分析； 从词法分析到中间代码生成各阶段的工作2&gt; 综合(后端)：语言意义处理；从中间代码生成到目标代码生成的各阶段的工作3&gt; 编译器和解释器的区别往往是在形成中间代码之后开始的. 5. 编译器扫描的遍数每个阶段将程序完整分析一遍的工作模式称为一遍扫描。(将源程序或源程序的某种形式的中间表示完整分析一遍，亦称作一遍扫描) 第二章 词法分析1. 词法分析中的若干问题(1) 记号、模式与单词 单词的分类：关键字(保留字)、标识符、字面量、特殊符号模式（pattern）：产生/识别单词的规则记号（token）：按照某个模式(或规则)识别出的元素(一组)单词（lexeme）：被识别出的元素的值(字符串本身) ，也称为词值 (2) 词法分析器的作用与工作方式 词法分析器的作用： 1&gt; 识别记号并交给语法分析器(根据模式识别记号)2&gt; 滤掉源程序中的无用成分,如注释、空格和回车等3&gt; 处理与具体平台有关的输入(如文件结束符的不同表示等)4&gt; 调用符号表管理器和出错处理器，进行相关处理 工作方式：1.单独一遍扫描2.作为语法分析器的子程序3.并行方式 2. 模式的形式化描述(1) 字符串与语言 语言L是有限字母表∑上有限长度字符串的集合.定义中强调两个有限，因为计算机的表示能力有限 ：1&gt; 字母表是有限的，即字母表中元素是有限多个；2&gt; 字符串的长度是有限的，即字符串中字符个数是有限多个。 (字符串与字符串集合相关的概念与运算,如前缀、后缀、子串、子序列等，字符串的并、交、连接、差、闭包) (2) 正规式与正规集 123456789令Σ是一个有限字母表，则Σ上的 正规式 及其表示的集合递归定义如下: 1. ε是正规式，它表示集合 L(ε) = &#123;ε&#125; 2. 若a是Σ上的字符，则a是正规式，它表示集合L(a)=&#123;a&#125; 3. 若正规式r和s分别表示集合L(r)和L(s)，则 （a） r|s是正规式，表示集合L(r)∪L(s)， （b） rs是正规式，表示集合L(r)L(s)， （c） r*是正规式，表示集合(L(r))*， （d）(r)是正规式，表示的集合仍然是L(r)。 括弧用来改变运算的先后次序！ 可用正规式描述(其结构)的语言称为 正规语言 或 正规集 。 1234若运算的优先级和结合性做下述约定: 1. 三种运算均具有左结合性质； 2. 优先级从高到低顺序排列为:闭包运算、连接运算、或运算。则正规式中不必要的括号可以被省略。 若正规式P和Q表示了同一个正规集，则称P和Q是等价的，记为P=Q (3) 简化正规式描述(主要是简化书写上的复杂) 123456789(a) 正闭包 若r是表示L(r)的正规式，则r+是表示(L(r))+的正规式，且下述等式成立:r+ = rr* = rr，r = r+|ε; +与*具有相同的运算结合性和优先级(b) 可缺省 若r是正规式，则r?是表示L(r)∪&#123;ε&#125;的正规式，且下述等式成立:r? = r|ε ? 与 * 具有相同的运算结合性和优先级(c) 串 若r是若干字符进行连接运算构成的正规式，则:串“r” = r ，且: ε= “”， a = “a”（a是Σ的任一字符）(d) 字符组 若r是若干字符进行|运算构成的正规式，则可改写为 [r’]，其中r’可以有如下两种书写形式： 枚举: 如 a|b|e|h，可写为 [abeh]： 分段: 如0|1|2|3|4|5|6|7|8|9|a|b|c|d|e , 可写为： [0-9a-e](e) 非字符组 若[r]是一个字符组形式的正规式，则[^r]是表示∑- L([r])的正规式。 3. 记号的识别——有限自动机(1) 不确定的有限自动机（NondeterministicFinite Automaton, NFA） 123456NFA是一个五元组（5-tuple）：M =（S，∑，move，s0，F），其中（1） S是有限个状态（state）的集合；（2） ∑是有限个输入字符（包括ε）的集合；（3） move是一个状态转移函数，move(si，ch)=sj表示，当前状态si下若遇到输入字符ch，则转移到状态sj；（4） s0是唯一的初态（也称开始状态）；（5） F是终态集（也称接受状态集），它是S的子集，包含了所有的终态。 直观的表示方式 ① 状态转换图：用一个有向图来直观表示NFA② 状态转换矩阵：用一个矩阵来直观表示NFA (矩阵中，状态对应行，字符对应列) NFA(识别记号)的特点NFA识别记号的最大特点是它的不确定性，即在当前状态下对同一字符有多于一个的下一状态转移。 1234具体体现：定义： move函数是1对多的；状态转换图：从同一状态出发，可通过多于一条标记相同字符的边转移到不同的状态；状态转换矩阵： M[si,a]是一个状态的集合 NFA识别记号存在的问题 1.只有尝试了全部可能的路径,才能确定一个输入序列不被接受,而这些路径的条数随着路径长度的增长成指数增长2.识别过程中需要进行大量回朔，时间复杂度升高且算法复杂 (2) 确定的有限自动机（Deterministic Finite Automaton, DFA） 123456789定义: DFA是NFA的一个特例，其中： （1）没有状态具有ε状态转移(ε-transition)，即状态转换图中没有标记ε的边； （2）对每个状态s和每个字符a，最多有一个下一状态。 特点：与NFA相比，DFA的特征：确定性 定义：move（si, a)函数都是 1对1 的； 转换图 从一个状态出发的任2条边上的标记均不同； 转换矩阵：M[si,a]是一个状态 且字母表不包括ε。提示：正规式和有限自动机从两个侧面表示正规式。正规式是描述，自动机是识别。 4. 从正规式到词法分析器123456构造词法分析器的一般方法和步骤：1. 用正规式描述模式（为记号设计正规式）；2. 为每个正规式构造一个NFA，它识别正规式所表示的正规集；3. 将构造的NFA转换成等价的DFA，这一过程也被称为确定化；4. 优化DFA，使其状态数最少，这一过程也被称为最小化；5. 根据优化后的DFA构造词法分析器。 (1) 从正规式到NFA Thompson 算法 (2) 从NFA到DFA 123- smove(S, a)：从状态集S出发，标记为a的下一状态全体。与move(s, a)的唯一区别：用状态集取代状态- ε-闭包(T)：从状态集T出发，不经任何字符达到的状态全体- “子集法”构造DFA (3) 最小化DFA ​ ① 对于任何两个状态t和s，若从一状态出发接受输入字符串ω，而从另一状态出发不接受ω. 或者，② 从t出发和从s出发到达不同的接受状态，则称ω对状态t和s是可区分的. ​ 不可区分的状态位于一个组内，可以合并成一个状态. 主要步骤：​ 1.初始划分：终态组 ， 非终态组；​ 2.利用可区分的概念，反复分裂划分中的组Gi，直到不可再分裂；​ 3.由最终划分构造D’，关键是选代表和修改状态转移；​ 4.消除可能的死状态和不可达状态。 5. 从DFA构造词法分析器分类：表驱动型的词法分析器；直接编码的词法分析器比较： 表驱动 直接编码 分析器的速度 慢 快 程序与模式的关系 无关 有关 适合的编写方法 工具生成 手工编写 分析器的规模 较大 较小 第三章 语法分析词法分析：记号的集合，字符串由字母组成，线性结构语法分析：句子的集合，句子由记号组成，非线性结构（树） 语法分析的双重含义： 语法规则：上下文无关文法（子集：LL文法或LR文法） 语法分析：下推自动机（LL或LR分析器）、自上而下分析、自下而上分析 1. 语法分析的若干问题许多编译器，特别是由自动生成工具构造的编译器，往往其前端的中心部件就是语法分析器 （1）语法分析器的作用 根据词法分析器提供的记号流，为语法正确的输入构造分析树（或语法树） 检查输入中的语法（可能包括词法）错误，并调用出错处理器进行适当处理 （2）语法错误的处理原则 源程序中可能出现的错误 语法(包括词法)错误和语义错误(静态语义错误和动态语义错误) 注：跟第一章的分类角度不同，第一章是从静态错误(语法错误，静态语义错误)和动态错误(动态语义错误)分类的，但是殊途同归。 词法错误：指非法字符或拼写错关键字、标识符等语法错误：指语法结构出错，如少分号、括号不匹配、begin/end不配对等静态语义错误：如类型不一致、参数不匹配等动态语义错误(逻辑错误)：如死循环、变量为零时作除数等 2. 上下文无关文法(CFG)（1）上下文无关文法(Context Free Grammar,CFG) 123456 CFG是一个四元组G =（N，T，P，S），其中（1） N是非终结符（Nonterminals）的有限集合；（2） T是终结符（Terminals）的有限集合，且N∩T=Φ；（3） P是产生式（Productions）的有限集合，A→α，其中A∈N(左部),α∈(N∪T)*(右部),若α=ε，则称A→ε为空产生式(也可以记为A →);（4） S是非终结符，称为文法的开始符号（Start symbol） 注： S ∈ N , N可以出现在产生式左边和右边，T绝不出现在产生式左边. （2）CFG产生语言的基本方法－推导 CFG（产生式）通过推导的方法产生语言，即（通俗地讲）从开始符号S开始，反复使用产生式：将产生式左部的非终结符替换为右部的文法符号序列(展开产生式，用=&gt;表示)，直到得到一个终结符序列。 1&gt; 直接推导：利用产生式产生句子的过程中，将用产生式A→γ的右部代替文法符号序列αAβ中的A得到αγβ的过程，称αAβ直接推导出αγβ，记作：αAβ=&gt;αγβ 2&gt; 零步或多步推导：若对于任意文法符号序列α1，α2，…αn，有α1=&gt;α2=&gt;…=&gt;αn，则称此过程为零步或多步推导，记为：α1 =*&gt; αn，其中α1=αn的情况为零步推导。 3&gt; 至少一次推导：若α1≠αn，即推导过程中至少使用一次产生式,则称此过程为至少一步推导，记为：α1 =+&gt; αn (推导具有自反性和传递性) 4&gt; 由 CFGG 所产生的语言L(G)被定义为: L(G) = { ω┃S ωand ω∈T }，​ L(G)称为上下文无关语言(Context Free Language, CFL)，ω称为句子。​ 若S = &gt; α，α∈(N∪T)*，则称α为G的一个句型。句子一定是句型，反之不是。 5&gt; 在推导过程中，若每次直接推导均替换句型中最左边的非终结符，则称为最左推导，由最左推导产生的句型被称为左句型。 类似的可以定义最右推导与右句型，最右推导也被称为规范推导。 （3）推导、分析树与语法树 1、分析树既反映语言结构的实质，也反映推导过程。 2、对CFGG的句型，分析树被定义为具有下述性质的一棵树。 （1） 根由开始符号所标记； （2） 每个叶子由一个终结符、非终结符、或ε标记； （3） 每个内部结点由一个非终结符标记； （4） 若A是某内部节点的标记，且X1，X2，…，Xn是该节点从左到右所有孩子的标记，则A→X1X2…Xn是一个产生式。若A→ε，则标记为A的结点可以仅有一个标记为ε的孩子。 注：分析树的叶子，从左到右构成G的一个句型。若叶子仅由终结符标记，则构成一个句子。 3、对CFG G的句型，表达式的语法树被定义为具有下述性质的一棵树: （1） 根与内部节点由表达式中的操作符标记； （2） 叶子由表达式中的操作数标记； （3）用于改变运算优先级和结合性的括号，被隐含在语法树的结构中。 语法树是表示表达式结构的最好形式 （4）二义性与二义性的消除 二义性：若文法G对 同 一句子产生不止一棵分析树，则称G是二义的. 结论：1&gt; 一个句子有多于一棵分析树，仅与文法和句子有关，与采用的推导方法无关；2&gt; 造成文法二义的根本原因：文法中缺少对文法符号优先级和结合性的规定 二义性消除的方法：① 改写二义文法为非二义文法；② 规定二义文法中符号的优先级和结合性，使仅产生一棵分析树。 3. 语法与文法简介（1）正规式与上下文无关文法 记号可以用正规式描述，正规式适合描述线性结构，如标识符、关键字、注释等. 句子可以用CFG描述，CFG适合描述具有嵌套(层次)性质的非线性结构，如不同结构的句子if-then-else\\while-do等 正规式所描述的语言结构均可以用CFG描述，反之不一定. （2）上下文有关文法CSG 典型的这类语言结构包含：计数问题的抽象、变量的声明与引用、过程调用时形参与实参的一致性检查等.描述它们的文法被称为上下文有关文法(Context Sensitive Grammar，CSG).这些语言结构无法用上下文无关文法CSG来描述. （3）形式语言与自动机简介 ​ 若文法G=(N，T，P，S)的每个产生式α→β中，均有α∈(N∪T)，且至少含有一个非终结符，β∈(N∪T)，则称G为0型文法. ​ 对0型文法施加以下第i条限制，即得到i型文法。 ​ 1&gt; G的任何产生式α→β（S→ε除外）满足|α|≤|β|；​ 2&gt; G的任何产生式形如A→β，其中A∈N，β∈(N∪T)*；​ 3&gt; G的任何产生式形如A→a或者A→aB(或者A→Ba)，其中A和B∈N，a∈T。 文法 语言 自动机 短语文法(0型) 短语结构语言 图灵机 CSG(1型) CSL 线性界线自动机 CFG(2型) CFL 下推自动机 正规文法(3型) 正规集 有限自动机 4. 自上而下语法分析分为：递归下降分析法、预测分析法 基本思想：对任何一个输入序列ω，从S开始进行最左推导，直到得到一个合法的句子或发现一个非法结构。整个自上而下分析是一个试探的过程，是反复使用不同产生式谋求与输入序列匹配的过程。 提前准备——重写文法：1.消除左递归，以避免陷入死循环； 2.提取左因子，以避免回溯. （1）消除左递归 定义：若文法G中的非终结符A，对某个文法符号序列α存在推导A =+&gt; Aα，则称G是左递归的。若G中有形如A→Aα的产生式，则称该产生式对A直接左递归。 消除文法的直接左递归 12A→Aα|β 替换为 A →βA&apos; A&apos;→αA&apos;|ε 首先，整理A产生式为如下形式：A→ Aα1|Aα2|…|Aαm|β1|β2|…|βn然后用下述产生式代替A产生式：A→ β1 A’|β2 A’| …|βn A’​ A’→ α1 A’ | α2 A’ | … | αm A’ |ε 消除文法的左递归 核心思想：将无直接左递归的非终结符展开到其他产生式,然后消除其他产生式中的直接左递归(如果有的话) 若G产生句子的过程中出现A=+A的推导，则无法消除左递归(出现回路) （2）提取左因子 提取文法的左因子 左因子产生原因：公共前缀：A → αβ1|αβ2方法：将 A → αβ1|αβ2|γ​ 替换为 A→αA’|γ A’→β1|β2 （3）递归下降分析 直接以程序代码（的方式）模拟产生式产生语言的过程: 基本思想：每个非终结符对应一个子程序（函数），过程体中： 产生式右部的非终结符：对应子程序调用， 产生式右部的终结符： 与输入记号序列进行匹配。 特点：1&gt; 子程序是递归的（因为文法是递归的）；2&gt; 程序与文法相关；3&gt; 它对文法的限制是不能有公共左因子和左递归；4&gt; 它是一种非形式化的方法，只要能写出子程序，用什么样的方法和步骤均可。 （4）预测分析器 ☆ 预测分析器由一张预测分析表、一个符号栈和一个驱动器组成，数学模型是下推自动机。☆ 对文法的限制是不能有公共左因子和左递归 预测分析器的核心概念：1&gt; 分析方法：格局与格局变换2&gt; 分析表+驱动器（模拟算法）3&gt; 预测分析表的构造4&gt; LL（文法、语言、分析器） ☆ 开始格局的剩余输入是全部输入序列，而接收格局中剩余输入应该为空，任何其他格局或出错格局中的剩余输入应该是全部输入序列的一个后缀. ☆ 改变格局的动作： ① 匹配终结符： 若top^=ip^(但≠#)，则pop且next(ip)；② 展开非终结符：若top^= X且M[X,ip^]=α(X→α)，则pop且push(α)；③ 报告分析成功： 若top ^= ip^ = #，则分析成功并结束；④ 报告出错：其它情况，调用错误恢复例程. ☆ 驱动器算法 ☆ 构造预测分析表 步骤：1. 构造文法符号X的FIRST集合和非终结符的FOLLOW集合；2. 根据两个集合构造预测分析表. 通俗地讲，α的FIRST集合就是从α开始可以导出的文法符号序列中的开头终结符。而A的FOLLOW集合，就是从开始符号可以导出的所有含A的文法符号序列中紧跟A之后的终结符. 计算X的FIRST集合 —–自下而上计算 计算所有非终结符的FOLLOW集合 —— 自上而下计算 构造预测分析表 LL(1)文法 文法G被称为是LL(1)文法，当且仅当为它构造的预测分析表中不含多重定义的条目。由此分析表所组成的分析器被称为LL(1)分析器，它所分析的语言被称为LL(1)语言。 ☆ 第一个L代表从左到右扫描输入序列，第二个L表示产生最左推导，1表示在确定分析器的每一步动作时向前看一个终结符. 1234推论3.2 G是LL(1)的，当且仅当G的任何两个产生式A→α|β满足:1. 对任何终结符a，α和β不能同时推导出以a开始的串；即First(α) ∩ First(β) = ∅2. α和β最多有一个可以推导出ε；3. 若β =*&gt; ε,则α不能导出以FOLLOW(A)中终结符开始的任何串. 即First(α) ∩ Follow(A) = ∅ ☆ 无论是递归下降子程序法还是非递归的预测分析法，他们都只能处理LL(1)文法. 5. 自下而上语法分析☆ 自上而下分析采用的是推导;自下而上分析采用的是归约(规范归约—剪句柄—移进/归约分析—SLR(1)分析器). （1）自下而上分析的基本方法 ☆ 基本思想：最左归约. 对于每个输入序列ω：从左到右扫描ω; 从ω开始,反复用产生式的左部替换产生式的右部(即当前句型中的句柄)、谋求对ω的匹配,最终得到文法的开始符号，或者发现一个错误。 ☆ 基本概念： 1234567891011121314151617181920212223242526272829a) &gt; 设αβδ是文法G的一个句型，若存在S=*&gt;αAδ，A=+&gt;β， 则称β是句型αβδ相对于A的&quot;短语&quot;. &gt; 特别的，若 有A→β，则 称β是句型αβδ相对于产生式A→β的&quot;直接短语&quot;. &gt; 一个句型的最左直接短语被称为&quot;句柄&quot;. 特征： 1. 短语：以非终结符为根子树中所有从左到右的叶子； 2. 直接短语：只有父子关系的子树中所有从左到右排列的叶子（树高为2）； 3. 句柄：最左边父子关系树中所有从左到右排列的叶子（句柄是唯一的） b)最左归约：若 α是文法G的句子且满足下述条件，则称序列αn，αn-1，...，α0是α的一个最左归约。 1) αn = α 2) α0 = S（S是G 的开始符号） 3) 对任何i(0&lt;i&lt;=n)，αi-1是将αi中句柄替换为相应产生式左部非终结符得到的 ☆ 最左归约的逆过程是一个最右推导，分别称最右推导和最左归约为规范推导和规范归约. c）移进-归约分析器 1. 工作方式：格局与格局变换 2. 分析表 3. 驱动器（模拟算法） 4. SLR分析表的构造 5. LR（文法、语言、分析器）☆ 改变格局的动作：1. 移进(shift)：当前剩余输入的下一终结符进栈。2.归约(reduce)：将栈顶句柄替换为对应非终结符(最左归约)3.接受(accept)：宣告分析成功4. 报错(error)：发现语法错误，调用错误恢复例程 (2) LR分析 a) LR分析与LR文法LR分析：允许左递归，但不能有二义 1定义3.15 若为文法G构造的移进-归约分析表中不含多重定义的条目，则称G为&quot;LR(k)文法&quot;，分析器被称为是&quot;LR(k)分析器&quot;，它所识别的语言被称为&quot;LR(k)语言&quot;。&quot;L&quot;表示从左到右扫描输入序列，&quot;R&quot;表示逆序的最右推导，&quot;k&quot;表示为确定下一动作向前看的终结符个数，一般情况下k&lt;=1。当k=1时，简称&quot;LR&quot;。 构造SLR(1)分析器 活前缀与LR(0)项目 第1步 第2~N步 状态 词法–DFA ε-closure(S) ε-closure(smove(S,a)) 状态集 语法–DFA closure(I) closure(goto(I,x)) 项目集 出现在移进-归约分析器栈中的右句型的前缀，被称为文法G的活前缀(viable prefix).LR(0)项目(简称项目)是这样一个产生式，在它右边的某个位置有一个点”.”。对于A→ε，它仅有一个项目A→.。项目A→α.β显示了分析过程中看到(移进)了产生式的多少。β不为空的项目称为可移进项目，β为空的项目称为可归约项目. 拓广文法与识别活前缀的DFA G’ = G ∪ {S’ → S}其中：S’ → S是识别S的初态，S’ → S. 是识别S的终态. 目的是使最终构造的DFA状态集中具有唯一的初态和终态. ① closure(I)：从项目集I不经任何文法符号到达的项目全体； ② goto(I，x)：所有从I经文法符号x能直接到达的项目全体。 12345项目[S’→.S]和所有“.”不在产生式右部最左边的项目称为核心项目(kernel items)，其它“.”在产生式右部最左边的项目(不包括[S’→.S])称为非核心项目(nonkernel items).核心项目：J=goto(I，X)，S&apos;→.S（作为项目集的代表）非核心项目：closure(J)-J（特点：可由J某中某项目算得） 识别活前缀 1定义3.21 若存在最右推导S’=*&gt; αAω =&gt; αβ1β2ω，则称项目[A→β1.β2] 对活前缀αβ1有效。 1234567891011当一个项目集中同时存在： 1. A→β1.β2和B→β.：既可移进又可归约，移进/归约冲突 2.A→α.和B→β.：均可指导下一步分析，归约/归约冲突解决方法：简单向前看一个终结符： 1. 移进/归约冲突：若FIRST(β2)∩FOLLOW(B)=Φ，冲突可解决 2. 归约/归约冲突：若FOLLOW(A)∩FOLLOW(B)=Φ，冲突可解决若冲突可以解决，则称文法为SLR(1)文法，构造的分析表为SLR(1)分析表。SLR(1)文法：简单向前看一个终结符即可解决冲突☆ 二义文法不是SLR(1)文法 第四章 静态语义分析采用语法制导翻译生成中间代码 1. 语法制导翻译简介（1）语法与语义的关系 语法是指语言的结构、即语言的“样子”；语义是指附着于语言结构上的实际含意，即语言的“意义”.一个语法上正确的句子，它所代表的意义并不一定正确. ☆ 语义分析的作用 • 检查结构正确的句子所表示的意思是否合法；• 执行规定的语义动作，如：表达式求值、符号表的查询/填写、中间代码生成等 ☆ 应用最广的语义分析方法是语法制导翻译，他的基本思想是将语言结构的语义以属性的形式赋予代表此结构的文法符号，而属性的计算以语义规则的形式赋予由文法符号组成的产生式. （2）属性/语义规则的定义 12345678定义4.1 对于产生式A→α，其中α是由文法符号X1X2...Xn组成的序列，它的语义规则可以表示为(4.1)所示关于属性的函数f： b := f(c1, c2, ..., ck) (4.1)语义规则中的属性存在下述性质与关系： (1) 称(4.1)中属性b依赖于属性c1, c2, ..., ck。 (2) 若b是A的属性，c1, c2, ..., ck是α中文法符号的属性，或者A的其它属性，则称b是A的综合属性。 (3) 若b是α中某文法符号Xi的属性，c1, c2, ..., ck是A的属性，或者是α中其它文法符号的属性，则称b是Xi的继承属性。 (4) 若语义规则的形式如下述(4.2)，则可将其想像为产生式左部文法符号A的一个虚拟属性。属性之间的依赖关系，在虚拟属性上依然存在。 f(c1, c2, ..., ck) (4.2) ■ ☆ 继承属性从前辈和兄弟的属性计算得到,综合属性从子孙和自身的其他属性计算得到. 即,继承属性“自上而下,包括兄弟”,综合属性“自下而上,包括自身”. （3）语义规则的两种形式 ☆ 语义规则的两种形式（忽略实现细节，二者作用等价） 语法制导定义(Syntax Directed Definition) 1用抽象的属性和运算表示的语义规则；(公式，做什么) 翻译方案(Translation Scheme) 1用具体的属性和运算表示的语义规则。(程序段，如何做) ☆ 继承属性是自上而下计算的，综合属性是自下而上计算的. （4）LR分析翻译方案的设计 ☆ LR分析中的语法制导翻译实质上是对LR语法分析的扩充： 扩充LR分析器的功能 当执行归约产生式的动作时，也执行相应产生式对应的语义动作。由于是归约时执行语义动作， ​ 因此限制语义动作仅能放在产生式右部的最右边； 扩充分析栈 ​ 增加一个与分析栈并列的语义栈，用于存放分析栈中文法符号所对应的属性值。 ☆ 扩充后的LR分析最适合对综合属性的计算，而对于继承属性的计算还需要进行适当的处理. 2. 中间代码简介☆ 中间代码应具备的特性1）便于语法制导翻译2）既与机器指令的结构相近,又与具体机器无关. 使用中间代码的好处:一是便于编译器程序的开发和移植,二是代码进行优化处理. ☆ 中间代码的主要形式：后缀式、树、三地址码等.最基本的中间代码形式是树🌲；最常用的中间代码形式是三地址码，它的实现形式常采用四元式形式。 ☆ 符号表是帮助声明语句实现存储空间分配的重要数据结构。 （1）后缀式 操作数在前，操作符紧随其后，无需用括号限制运算的优先级和结合性；便于求值. （2）三地址码 ① 三元式 形式： (i) (op, arg1, arg2) ​ 三地址码：(i):= arg1 op arg2 序号的双重含义：既代表此三元式，又代表三元式存放的结果 存放方式：数组结构，三元式在数组中的位置由下标决定 弱点：给代码的优化带来困难 ② 四元式 形式： ( i ) (op，arg1，arg2，result) ​ 所表示的计算： result:= arg1 op arg2 四元式与三元式的唯一区别：将由序号所表示的运算结果改为：用(临时)变量来表示。 此改变使得四元式的运算结果与其在四元式序列中的位置无关.为代码的优化提供了极大方便，因为这样可以删除或移动四元式而不会影响运算结果. ③ 树形表示 1&gt; 语法树真实反映句子结构，对语法树稍加修改（加入语义信息），即可以作为中间代码的一种形式(注释语法树)2&gt; 树的优化表示－DAG3&gt; 树与其他中间代码的关系 ☆ 树表示的中间代码与后缀式和三地址码之间有内在联系 树 → 后缀式 ​ 方法：对树进行深度优先后序遍历，得到的线性序列就是后缀式，或者说后缀式是树的一个线性化序列； 树 → 三元式/四元式 特点：树的每个非叶子节点和它的儿子对应一个三元式或四元式； 方法：对树的非叶子节点进行深度优先后序遍历，即得到一个三元式或四元式序列。 3. 符号表简介 符号表的作用：连接声明与引用的桥梁，记住每个符号的相关信息，如作用域和类型等，帮助编译的各个阶段正确有效地工作。 符号表的基本目标：有效记录信息、快速准确查找。 符号表设计的基本要求： 正确存储各类信息； 适应不同阶段的需求； 便于有效地进行查找、插入、删除和修改等操作； 空间可以动态扩充. （1）构成名字的字符串 构成名字的字符串的存储方式：直接存储—定长数据(直接将构成名字的字符串放在符号表条目中)和间接存储—变长数据(将构成名字的字符串统一存放在一个大的连续空间内，字符串与字符串之间采用特殊的分隔符隔开，符号表条目中仅存放指向该字符串首字符的指针). （2）名字的作用域 ☆ 程序语言范围的划分可以有两种划分范围的方式：并列和嵌套 ☆ 名字的作用域规则：规定一个名字在什么样的范围内应该表示什么意义. 12&lt;1&gt; 静态作用域规则（static-scope rule）：编译时就可以确定名字的作用域,即仅从静态读程序就可确定名字的作用域&lt;2&gt; 最近嵌套规则（most closely nested）：名字的声明在离其最近的内层起作用 （3）线性表 符号表以栈(线性表)的方式组织. 线性表上的操作：查找、插入、删除、修改 查找：从表头(栈顶)开始，遇到的第一个符合条件的名字；插入：先查找，再加入在表头（栈顶）； 关键字 = 名字＋作用域； （4）散列表 名字挂在两个链上(便于删除操作)： 散列链(hash link)： 链接所有具有相同hash值的元素，表头在表头数组中； 作用域链(scope link)：链接所有在同一作用域中的元素，表头在作用域表中. ☆ 操作：查找、插入、删除 4. 声明语句的翻译（1）变量的声明 ☆ 一个变量的声明应该由两部分来完成：类型的定义和变量的声明 类型定义：为编译器提供存储空间大小的信息 变量声明：为变量分配存储空间 组合数据的类型定义和变量声明：定义与声明在一起，定义与声明分离. 1&gt; 简单数据类型的存储空间是预先确定的，如int可以占4个字节，double可以占8个字节，char可以占1个字节等 2&gt; 组合数据类型变量的存储空间，需要编译器根据程序员提供的信息计算而定. （2） 过程 1234567891011121314151617181920212223242526271．过程（procedure）：过程头(做什么) ＋ 过程体(怎么做)； - 函数: 有返回值的过程 - 主程序: 被操作系统调用的过程/函数2．过程的三种形式：过程定义、过程声明和过程调用。 过程定义：过程头+过程体； 过程声明：过程头；3. 左值与右值 1&gt; 直观上，出现在赋值号左边和右边的量分别称为左值和右值； 2&gt; 实质上，左值必须具有存储空间，右值可以仅是一个值，而没有存储空间. 3&gt; 形象地讲，左值是容器，右值是内容. 4. 参数传递 1&gt; 形参与实参 - 声明时的参数称为形参(parameter或formal parameter) - 引用时的参数称为实参(argument或actual parameter) 2&gt; 常见的参数传递形式：（不同的语言提供不同的形式） - 值调用（call by value）---过程内部对参数的修改，不影响作为实参的变量原来的值. - 引用调用（call by reference）--- 过程内部对形参的修改，实质上是对实参的修改. - 复写－恢复（copy-in/copy-out）--- ① 过程内对参数的修改不直接影响实参，避免了副作用; ② 返回时将形参内容恢复给实参，实现参数值的返回. - 换名调用（call by name）--- 宏调换 3&gt; 参数传递方法的本质区别： 实参是代表左值、右值、还是实参本身的正文. 5. 作用域信息的保存☆ 能够画出嵌套过程的嵌套关系树(P191 4.33),根据语法制导翻译(P193 4.35)画出分析树,写出推导步骤,构造的符号表 5. 简单算术表达式与赋值句P197 例4.36 主要是变量类型的转换 6. 数组元素的引用（1）数组元素的地址计算 注意是行主存储还是列主存储 （2）☆数组元素引用的语法制导翻译(考试热点之一) P201 例4.37 7. 布尔表达式布尔表达式的计算有两种方法：数值表示的直接计算和逻辑表示的短路计算 ☆ 布尔表达式短路计算的翻译：短路计算的控制流，真出口与假出口，真出口链与假出口链，拉链回填技术(P207 例4.41)（考试热点之一） 8. 控制语句控制语句的分类：①无条件转移、②条件转移、③循环语句、④分支语句 无条件转移(goto)\\条件转移(if、while) 条件转移的语法制导翻译：P213 例4.42 1多看课件PPT，多做题练手","categories":[{"name":"XD","slug":"XD","permalink":"http://yoursite.com/categories/XD/"}],"tags":[{"name":"Compiler","slug":"Compiler","permalink":"http://yoursite.com/tags/Compiler/"}]},{"title":"高等数学18讲","slug":"高数18讲","date":"2018-08-16T05:01:38.481Z","updated":"2018-08-18T03:21:04.382Z","comments":true,"path":"2018/08/16/高数18讲/","link":"","permalink":"http://yoursite.com/2018/08/16/高数18讲/","excerpt":"【阅读时间】【阅读内容】张宇高数18讲各部分知识图谱","text":"【阅读时间】【阅读内容】张宇高数18讲各部分知识图谱 第1讲 高等数学常用基础知识点.png 第2讲 极限与连续 第5讲 中值定理 积分学汇总 第8讲 一元函数积分学的应用 第10讲 多元函数微分学 第17讲 三重积分、第一型曲线曲面积分.png","categories":[{"name":"XD","slug":"XD","permalink":"http://yoursite.com/categories/XD/"}],"tags":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/tags/Math/"},{"name":"Knowledge Map","slug":"Knowledge-Map","permalink":"http://yoursite.com/tags/Knowledge-Map/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-08-15T17:41:32.591Z","updated":"2018-10-17T14:01:17.862Z","comments":true,"path":"2018/08/16/hello-world/","link":"","permalink":"http://yoursite.com/2018/08/16/hello-world/","excerpt":"【阅读时间】2min 122words【阅读内容】Hexo 的基础操作——new、clean、generate、server、deploy","text":"【阅读时间】2min 122words【阅读内容】Hexo 的基础操作——new、clean、generate、server、deploy Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"postName\" #新建文章 More info: Writing Run server1$ hexo server More info: Server Clean public files1$ hexo clean Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 报错：Template render error原因：_post中某MD文件数学公式的格式有问题 解决：$$ ​$$","categories":[{"name":"Annotation","slug":"Annotation","permalink":"http://yoursite.com/categories/Annotation/"}],"tags":[]},{"title":"Indigo Grammar","slug":"Indigo Grammar","date":"2018-04-03T17:17:28.000Z","updated":"2018-08-24T15:50:53.836Z","comments":true,"path":"2018/04/04/Indigo Grammar/","link":"","permalink":"http://yoursite.com/2018/04/04/Indigo Grammar/","excerpt":"【阅读时间】10min 1032words【阅读内容】Indigo主题在page布局下的页面编辑语法","text":"【阅读时间】10min 1032words【阅读内容】Indigo主题在page布局下的页面编辑语法 Image Blockquote 当blockquote、img、pre、figure为第一级内容时，在page布局中拥有card阴影，所有标题居中展示。 Content@card{ 目前的想法是预定义一系列内容模块，通过像输入 Markdown 标记一样来简单调用。好在 Markdown 没有把所有便于输入的符号占用，最终我定义了@moduleName{ ... }这种标记格式。如果你使用过Asp.Net MVC，一定会很熟悉这种用法，没错，就是razor。 page布局中的title和subtitle对应 Markdown 中的title和description。 基本的内容容器还是card，你可以这样使用card： 12345@card&#123;在`page`页中，建议把内容都放到`card`中。&#125; 需要注意的是：标记与内容之间必须空一行隔开。至于为何要这样，看到最后就明白了。 } Column@column-2{ @card{ 左与card标记类似，分栏的标记是这样的： 123456789101112131415@column-2&#123;@card&#123;# 左&#125;@card&#123;# 右&#125;&#125; 为了移动端观感，当屏幕宽度小于 480 时，column将换行显示。 } @card{ 右column中的每一列具有等宽、等高的特点，最多支持三栏： 123456789101112131415161718192021@column-3&#123;@card&#123;左&#125;@card&#123;中&#125;@card&#123;右&#125;&#125; } } Three columns@column-3{ @card{ 话式片平九业影查类办细开被支，置军争里老5备才才目板。 且数置百容机，规的空界往，十陕志入。料解格清收权厂值动且习，识生能化路速年边，类儿2带杏性热求已。 } @card{ 话式片平九业影查类办细开被支，置军争里老5备才才目板。 且数置百容机，规的空界往，十陕志入。料解格清收权厂值动且习，识生能化路速年边，类儿2带杏性热求已。 } @card{ 话式片平九业影查类办细开被支，置军争里老5备才才目板。 且数置百容机，规的空界往，十陕志入。料解格清收权厂值动且习，识生能化路速年边，类儿2带杏性热求已。 } } Timeline@card{ 在timeline模块中，你的 5 号标题#####和六号标题######将被“征用”，用作时间线上的标记点： 123456789101112@timeline&#123;##### 2016@item&#123;###### 11月6日为 Card theme 添加 page layout。&#125;&#125; @item中多行内容可以换行输入，目前不允许隔行： 12345678910111213141516171819202122@timeline&#123;##### 2016@item&#123;###### 11月6日第一行 第二行 /* ok */&#125;@item&#123;###### 11月6日第一行第二行 /* error */&#125;&#125; } @timeline{ 2016@item{ 11月6日为 Card theme 添加 page layout。加快绿化空间好看 } @item{ 10月31日本地化多说。 } @item{ 10月24日为 Indigo 主题创建 Card 分支。 } 2015@item{ 2月24日发布 Indigo 主题到 hexo.io。 } @item{ 1月22日创建 Indigo 主题。 } } CodeBlock12345// 自定义内容块实现page.content.replace(/&lt;p&gt;&#125;&lt;\\/p&gt;/g, '&lt;/div&gt;') .replace(/&lt;p&gt;@([\\w-]+)&#123;&lt;\\/p&gt;/g, function(match, $1)&#123; return '&lt;div class=\"'+ $1 +'\"&gt;' &#125;) @card{ 这里可以解释，为什么标记之间必须要隔一行了。 当你在 Markdown 中隔行输入时，会形成新的段落，而如果一个段落中的内容仅仅是我们约定的标记，就可以用很容易的用正则匹配到替换为对应的模块容器。 } End@card{ 为了解决 Hexo 自定义页面slug为空不能很好的使用多说评论这个问题，现在已经给每个自定义页面自动生成了hexo-page-path这种格式的slug。本来准备用date做格式的最后一节，测试中发现 page 中的date值为修改时间，是动态的。综合考虑使用了路径path。 以后可以根据需要添加更多模块支持。 打赏和评论默认开启，可根据需要在 Markdown 头部定义是否关闭。 }","categories":[{"name":"Annotation","slug":"Annotation","permalink":"http://yoursite.com/categories/Annotation/"}],"tags":[]}]}