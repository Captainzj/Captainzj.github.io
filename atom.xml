<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Go Further</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-12-27T11:56:24.036Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>CaptainSE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>医学数据格式</title>
    <link href="http://yoursite.com/2018/12/27/Medical-Data-Format/"/>
    <id>http://yoursite.com/2018/12/27/Medical-Data-Format/</id>
    <published>2018-12-27T09:08:13.000Z</published>
    <updated>2018-12-27T11:56:24.036Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>ToRead：</p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_12" target="_blank" rel="noopener">Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_47" target="_blank" rel="noopener">Unsupervised Domain Adaptation in Brain Lesion Segmentation with Adversarial Networks</a></p><p>Paper：</p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=2ahUKEwjXyObB2r_fAhXjRt8KHROrC5cQFjABegQIAxAB&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1702.05747&amp;usg=AOvVaw3kBlBAYVhnDhZxU1aBbgxG" target="_blank" rel="noopener">A Survey on Deep Learning in Medical Image Analysis</a></p><table><thead><tr><th>数据格式</th><th>含义（字段）</th><th>头部-&gt; 内容</th></tr></thead><tbody><tr><td>DICOM</td><td></td><td></td></tr><tr><td>nii</td><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><table><thead><tr><th>数据</th><th>Kind</th><th>knowledge point + theory</th></tr></thead><tbody><tr><td>MRI</td><td>T1\T2\Flair</td><td>区别， 各自针对的内容</td></tr><tr><td>CT</td><td>腹部CT\胸部\全身CT</td><td>扫描方式</td></tr><tr><td>PET</td><td></td></tr></tbody></table><h2 id="医学图像数据类型"><a href="#医学图像数据类型" class="headerlink" title="医学图像数据类型"></a>医学图像数据类型</h2><h3 id="MRI"><a href="#MRI" class="headerlink" title="MRI"></a>MRI</h3><h3 id="CT"><a href="#CT" class="headerlink" title="CT"></a>CT</h3><h3 id="PET"><a href="#PET" class="headerlink" title="PET"></a>PET</h3><h2 id="医学图像数据格式"><a href="#医学图像数据格式" class="headerlink" title="医学图像数据格式"></a>医学图像数据格式</h2><h3 id="DICOM"><a href="#DICOM" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>医学图像采用数字成像和通信（DICOM）作为存储和交换医学图像数据的标准解决方案。这个标准的第一个版本是在1985年发布的。发展到现在，该方案有了一些改变。该标准使用文件格式和通信协议。</p><p><strong>文件格式</strong> - 所有患者医疗图像都以DICOM文件格式保存。除了其他图像相关数据（例如用于拍摄图像的设备以及医疗处理的一些背景）之外，该格式具有关于患者的PHI（受保护的健康信息），例如姓名，性别，年龄。医学影像设备创建DICOM文件。医生使用DICOM查看器，可显示DICOM图像的计算机软件应用程序，读取和诊断图像中的发现。</p><p><strong>通信协议</strong> - DICOM通信协议用于搜索档案中的成像研究，并将成像研究恢复到工作站以显示。连接到医院网络的所有医疗成像应用程序都使用DICOM协议来交换信息，主要是DICOM图像，还包括患者和手术信息。还有更先进的网络命令，用于控制和跟踪治疗，调度程序，报告状态，分担医生和成像设备之间的工作量。关于DICOM标准细节，在这里推荐一个很好的博客<a href="http://link.zhihu.com/?target=http%3A//dicomiseasy.blogspot.com" target="_blank" rel="noopener">http://dicomiseasy.blogspot.com</a></p><h4 id="分析DICOM图像"><a href="#分析DICOM图像" class="headerlink" title="分析DICOM图像"></a><strong>分析DICOM图像</strong></h4><ul><li><strong>了解DICOM 格式数据</strong></li></ul><p>CT扫描的测量单位是Hounsfield单位（HU），它是放射性强度的量度。 仔细校准CT扫描仪以准确测量。 关于这方面的详细了解可以在这里到。<a href="https://web.archive.org/web/20070926231241/http://www.intl.elsevierhealth.com/e-books/pdf/940.pdf" target="_blank" rel="noopener">Introduction to CT physics</a></p><p>每个像素被分配一个数值（CT值），它是相应体素中所有衰减值的平均值。 将这个数字与水的衰减值进行比较，并在戈弗雷·豪斯菲尔德爵士（Sir Godfrey Hounsfield）之后以胡恩斯菲尔德单位（Hounsfield units，HU）的任意单位的比例显示。</p><ul><li><p>获得DICOM 数据库</p><ul><li>kaggle competitions and Datasets</li><li>Dicom Library</li><li>Osirix Datasets</li><li>Visible Human Datasets</li><li><p>The Zubal Phantom</p></li><li><p>杜克大学他们有公开的数据集</p></li></ul></li></ul><h3 id="nii"><a href="#nii" class="headerlink" title="nii"></a>nii</h3><h2 id="Matlab-python-医学工具包"><a href="#Matlab-python-医学工具包" class="headerlink" title="Matlab/python 医学工具包"></a>Matlab/python 医学工具包</h2><h3 id="DICOM-1"><a href="#DICOM-1" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="python-package"><a href="#python-package" class="headerlink" title="python package"></a>python package</h4><ul><li><strong>pydiocm</strong></li></ul><h2 id="浏览image数据工具"><a href="#浏览image数据工具" class="headerlink" title="浏览image数据工具"></a>浏览image数据工具</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/30915590" target="_blank" rel="noopener">医学图像处理与深度学习[知乎]</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深度学习之PyTorch实战计算机视觉</title>
    <link href="http://yoursite.com/2018/12/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8BPyTorch%E5%AE%9E%E6%88%98%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    <id>http://yoursite.com/2018/12/17/深度学习之PyTorch实战计算机视觉/</id>
    <published>2018-12-17T03:46:57.000Z</published>
    <updated>2018-12-17T05:50:00.292Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="第6章-PyTorch基础"><a href="#第6章-PyTorch基础" class="headerlink" title="第6章 PyTorch基础"></a>第6章 PyTorch基础</h4><ul><li><p><strong>Why PyTorch</strong></p><p>pytorch可以说是torch的python版，然后增加了很多新的特性。pytorch在编写模型的时候最大的特点就是利用autograd技术来实现<code>自动求导</code>，也就是不需要我们再去麻烦地写一些反向的计算函数，这点上继承了torch。<a href="https://oldpan.me/archives/pytorch-torch-relation" target="_blank" rel="noopener">浅谈Pytorch与Torch的关系</a></p></li><li><p><strong>pytorch document</strong></p><p>Link：<a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></p></li></ul><h4 id="第7章-迁移学习"><a href="#第7章-迁移学习" class="headerlink" title="第7章 迁移学习"></a>第7章 迁移学习</h4><p>如果我们用这么多资源训练的模型能够<code>解决同一类问题</code>，那么模型的性价比会提高很多，这就促使使用迁移模型解决同 一类问题的方法出现 。因为该方法的出现，我们通过对 一个训练好的模型进行细微调整，就能将其应用到相似的问题中，最后还能取得很好的效果 ; 另外，对于原始数据较少的问题，我们也能够通过采用迁移模型进行有效解决 ，所以，如果能够选取合适的迁移学习方法，则会对解决我们所面临的问题有很大的帮助 。</p><h4 id="第8章-图像风格迁移实战"><a href="#第8章-图像风格迁移实战" class="headerlink" title="第8章 图像风格迁移实战"></a>第8章 图像风格迁移实战</h4><center class="third"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/cat.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/2-style1.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/y-output.jpg" width="200"><br></center><h4 id="第9章-多模型融合"><a href="#第9章-多模型融合" class="headerlink" title="第9章 多模型融合"></a>第9章 多模型融合</h4><blockquote><p>“集百家之所长”  </p></blockquote><ul><li><p><strong>结果融合法</strong></p><p>通用理论：各个模型的输出结果的差异性越高 ， 多模型融合的效果就会越好 。</p><ul><li><p>结果多数表决</p></li><li><p>结果直接平均</p><p>融合各模型的平均预测水平，<code>弥补个别模型的明显劣势</code>，预防过拟合和欠拟合的发生</p><p>评价：虽然在总体的准确率上有所提升，但在单个数据的预测能力上并不优秀</p></li><li><p>结果加权平均</p><p>评价：调节各个模型的权重参数对最后的融合模型的结果影响较大。 所以在使用权重平均的过程中，我们需要<code>不断尝试</code>使用不同的权重值组合，以达到多模型融合的最优解决方案 。</p></li></ul></li></ul><h4 id="第10章-循环神经网络"><a href="#第10章-循环神经网络" class="headerlink" title="第10章 循环神经网络"></a>第10章 循环神经网络</h4><p>在循环神经网络中循环单元可以随意控制输入数据及输出数据的数量，具有非常大的灵活性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://deeplearning4j.org/images/guide/rnn_masking_2.png" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>循环神经网络的网络简化模型，通过不断地对自身的网络结构进行复制来构造不同的循环神经网络模型。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>将上图展开，</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>虽然循环神经网络已经能够很好地对输入的序列数据进行处理 ，是不能进行长期记忆，其带来的影响就是如果近期输入的数据发生了变化，则会对当前的输出结果产生重大影响 。 为了避免这种情况的出现，研究者开发了 LSTM ( Long Short Term Memory)类型 的循环神经网络模型 。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn lstm" title="">                </div>                <div class="image-caption">Image result for rnn lstm</div>            </figure><h4 id="第11章-自动编码器"><a href="#第11章-自动编码器" class="headerlink" title="第11章 自动编码器"></a>第11章 自动编码器</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for autoEncoder" title="">                </div>                <div class="image-caption">Image result for autoEncoder</div>            </figure><p>自动编码器模型的最大用途就是实现输入数据的清洗，比如去除输入数据中的噪声数据、对输入数据的某些关键特征进行增强和放大，等等 。 举一个比较简单的例子，假设我们现在有一些被打上了马赛克的图片需要进行除码处理，这时就可以通过自动编码器模型来解决这个 问题 。 其实可以将这个除码的过程看作对数据进行除噪的过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>PyTorch_Docs</title>
    <link href="http://yoursite.com/2018/12/15/PyTorch-Package/"/>
    <id>http://yoursite.com/2018/12/15/PyTorch-Package/</id>
    <published>2018-12-15T12:22:24.000Z</published>
    <updated>2018-12-24T05:01:31.838Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><h4 id="torch-Tensor-view"><a href="#torch-Tensor-view" class="headerlink" title="torch.Tensor.view"></a>torch.Tensor.view</h4><p><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view" target="_blank" rel="noopener"><code>view</code>(*<em>shape</em>) → Tensor</a> Returns a new tensor with the same data as the <code>self</code> tensor but of a different <code>shape</code>.</p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.view(<span class="number">16</span>)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred(推导) from other dimensions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>])  <span class="comment"># 2 = (4*4)/8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=x.view(<span class="number">2</span>,<span class="number">-1</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>]) <span class="comment"># 8 = (4*4)/2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=x.view(<span class="number">4</span>,<span class="number">-1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>]) <span class="comment"># 4 = (4*4)/4</span></span><br></pre></td></tr></table></figure><ul><li><strong>Parameters:</strong> <strong>shape</strong> (<em>torch.Size</em> <em>or</em> <em>int…</em>) – the desired size</li></ul><h4 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h4><p><a href="https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops" target="_blank" rel="noopener">Docs</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)  <span class="comment"># dim:0 按列级联(排成一列)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">1</span>)  <span class="comment"># dim:1 按行级联(排成一行)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>,</span><br><span class="line">         <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>,</span><br><span class="line">         <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br></pre></td></tr></table></figure><h2 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h2><h3 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h3><h4 id="torch-nn-Module"><a href="#torch-nn-Module" class="headerlink" title="torch.nn.Module"></a>torch.nn.Module</h4><h5 id="forward-input"><a href="#forward-input" class="headerlink" title="forward(*input)"></a>forward(*<em>input</em>)</h5><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward" target="_blank" rel="noopener"><code>forward</code>(*<em>input</em>)</a>  Defines the computation performed at every call.</p><h4 id="torch-nn-Sequential"><a href="#torch-nn-Sequential" class="headerlink" title="torch.nn.Sequential"></a>torch.nn.Sequential</h4><p><a href="https://pytorch.org/docs/stable/nn.html#sequential" target="_blank" rel="noopener">torch.nn.Sequential</a> 类是 torch.nn 中的一种序列容器，通过在容器中嵌套各种实现神经网络中具体功能相关的类，来完成对神 经网络模型 的搭建，最主要的是，<code>参数会按照我们定义好的序列自动传递下去</code>。我们可以将嵌套在容器中的各个部分看作各种不同的模块，这些模块可以自由组合。模块的加入 一般有两种方式 ， 一种是<strong>直接嵌套</strong>，另 一 种是以 <strong>orderdict</strong> 有序字典的方式进行传入，这两种方式的唯一区别是，使用后者搭建的模型的每个模块都有我们自定义的名字 ， 而前者默认使用从零开始的数字序列作为每个模块的名字。</p><h3 id="Convolution-Layers"><a href="#Convolution-Layers" class="headerlink" title="Convolution Layers"></a>Convolution Layers</h3><center><br>    <img src="/2018/12/15/PyTorch-Package/channel.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/SimpleCNN.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/LinearSize.png" width="600"><br></center><p><a href="https://www.youtube.com/watch?v=LgFNRIFxuUo" target="_blank" rel="noopener">PyTorch Lecture 10: Basic CNN</a></p><h4 id="torch-nn-Conv1d"><a href="#torch-nn-Conv1d" class="headerlink" title="torch.nn.Conv1d"></a>torch.nn.Conv1d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv1d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv1d(<span class="number">16</span>,  , <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">24</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$ (N, C_{\text{in}}, L)$  —  $\text{input.size :} (20, 16, 50)$</li><li><p>$ (N, C_{\text{out}}, L_{\text{out}})$ — $\text{output.size :} (20,  33, 24)$ </p><ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation}<br>\times (\text{kernel_size} - 1) - 1}{\text{stride}} + 1\right\rfloor \Rightarrow  24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size)}$.</p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) –the learnable bias of the module of shape $\text{(out_channels)}$.</li></ul><h4 id="torch-nn-Conv2d"><a href="#torch-nn-Conv2d" class="headerlink" title="torch.nn.Conv2d"></a>torch.nn.Conv2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnconv2din95channels-out95channels-kernel95size-stride1-padding0-dilation1-groups1-biastrue" target="_blank" rel="noopener">文档说明</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding and dilation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">26</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, H_{in}, W_{in})$  — $\text{input.size :} (20, 16, 50, 100)$</li><li>$(N, C_{out}, H_{out}, W_{out})$ — $\text{output.size :} (20, 33, 26, 100)$<ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor  \Rightarrow 26  = \left\lfloor\frac{50  + 2 \times 4- 3<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 100 =  \left\lfloor\frac{100  + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size[0], kernel_size[1])}$.</li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h4 id="torch-nn-Conv3d"><a href="#torch-nn-Conv3d" class="headerlink" title="torch.nn.Conv3d"></a>torch.nn.Conv3d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv3d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">8</span>, <span class="number">50</span>, <span class="number">99</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, D_{in}, H_{in}, W_{in})$  — $\text{input.size :}20, 16, 10, 50, 100)$</li><li><p>$(N, C_{out}, D_{out}, H_{out}, W_{out})$  — $\text{output.size :} (20, 33, 8, 50, 99)$ </p><ul><li>$H_{out} = \left\lfloor\frac{H{in} + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \<br>\Rightarrow 50 =  \left\lfloor\frac{50 + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li><li>$D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor \\Rightarrow 8 =  \left\lfloor\frac{10 + 2 \times 4 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2]<br>\times (\text{kernel_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor \\Rightarrow 99 = \left\lfloor\frac{100 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape$\text{ (out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2])}$ </p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h3 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h3><h4 id="torch-nn-MaxPool2d"><a href="#torch-nn-MaxPool2d" class="headerlink" title="torch.nn.MaxPool2d"></a>torch.nn.MaxPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#maxpool2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnmaxpool2dkernel95size-stridenone-padding0-dilation1-return95indicesfalse-ceil95modefalse" target="_blank" rel="noopener">文档说明</a></p><p>Applies a 2D max pooling over an input signal composed of several input planes.</p><p>In the simplest case, the output value of the layer with input size$(N, C, H, W)​$, output $(N, C, H_{out}, W_{out})​$ and <code>kernel_size</code> $(kH, kW)​$can be precisely described as:</p><p>$\begin{aligned}<br>out(N_i, C_j, h, w) ={} &amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \text{input}(N_i, C_j, \text{stride[0]} \times h + m,<br>\text{stride[1]} \times w + n)<br>\end{aligned}$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li><p>$(N, C, H_{in}, W_{in})$ — $\text{input.size:}(20, 16, 50, 32) $</p></li><li><p>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</p></li><li><p>$H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]}<br>\times (\text{kernel_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor \\Rightarrow 24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor $</p></li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]}<br>\times (\text{kernel_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor \ \Rightarrow 31 = \left\lfloor\frac{32 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul><h4 id="torch-nn-AvgPool2d"><a href="#torch-nn-AvgPool2d" class="headerlink" title="torch.nn.AvgPool2d"></a>torch.nn.AvgPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#avgpool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C, H_{in}, W_{in})$ — $\text{input.size: } (20, 16, 50, 32)$</li><li>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] -<br>\text{kernel_size}[0]}{\text{stride}[0]} + 1\right\rfloor \Rightarrow 24 = \left\lfloor\frac{50  + 2 \times 0 -<br>3}{2} + 1\right\rfloor$</li><li><p>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] -<br>\text{kernel_size}[1]}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 31 = \left\lfloor\frac{32  + 2 \times 0 -<br>2}{1} + 1\right\rfloor$</p></li><li><p><strong><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#dropout-layers" target="_blank" rel="noopener">torch.nn.Dropout</a></strong> torch.nn.Dropout 类用于防止卷积神经网络在训练的过程中发生过拟合 ， 其工作原理简单来说就是在模型训练的过程中，以一定的随机概率将卷积神经网络模型的部分参数归零(“丢弃”)， 以达到减少相邻两层神经连接的目的。</p></li></ul><h3 id="Non-Linear-Activations"><a href="#Non-Linear-Activations" class="headerlink" title="Non-Linear Activations"></a>Non-Linear Activations</h3><h4 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h4><p><a href="https://pytorch.org/docs/stable/nn.html#relu" target="_blank" rel="noopener">Docs</a></p><center><br>    <img src="https://pytorch.org/docs/stable/_images/ReLU.png" width="400"><br></center><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.ReLU()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">-0.5070</span>, <span class="number">0.4540</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.0000</span>, <span class="number">0.4540</span>])</span><br></pre></td></tr></table></figure><ul><li>Input:$(N, <em>)$ where </em> means, any number of additional dimensions</li><li>Output: $(N, *)$, same shape as the input</li></ul><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><h4 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h4><p><a href="https://pytorch.org/docs/stable/nn.html#linear" target="_blank" rel="noopener">Docs</a></p><p>Applies a linear transformation to the incoming data: $y = xA^T + b$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Linear(<span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">128</span>, <span class="number">20</span>)  <span class="comment"># (N,∗,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(output.size())</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">30</span>])   <span class="comment"># (N,∗,out_features)</span></span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[<span class="number">-0.8833</span>,  <span class="number">0.1130</span>,  <span class="number">0.0446</span>,  ..., <span class="number">-0.2786</span>,  <span class="number">2.0762</span>,  <span class="number">0.6139</span>],</span><br><span class="line">        [<span class="number">-0.9236</span>,  <span class="number">3.1720</span>, <span class="number">-0.9857</span>,  ...,  <span class="number">0.1017</span>, <span class="number">-0.4042</span>, <span class="number">-0.1072</span>],</span><br><span class="line">        [ <span class="number">0.0153</span>,  <span class="number">0.8800</span>, <span class="number">-0.6031</span>,  ..., <span class="number">-0.2836</span>,  <span class="number">0.7584</span>, <span class="number">-2.3324</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.9628</span>, <span class="number">-0.3177</span>, <span class="number">-0.7577</span>,  ...,  <span class="number">0.2819</span>,  <span class="number">0.9684</span>, <span class="number">-1.8474</span>],</span><br><span class="line">        [ <span class="number">0.3380</span>,  <span class="number">1.0946</span>, <span class="number">-1.3399</span>,  ..., <span class="number">-0.0043</span>, <span class="number">-0.9811</span>,  <span class="number">0.3067</span>],</span><br><span class="line">        [ <span class="number">0.6834</span>,  <span class="number">0.5804</span>, <span class="number">-0.8192</span>,  ...,  <span class="number">1.2167</span>,  <span class="number">1.3583</span>, <span class="number">-1.5123</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">1.0747</span>,  <span class="number">1.2864</span>,  <span class="number">0.6512</span>,  ...,  <span class="number">0.1053</span>, <span class="number">-0.0487</span>, <span class="number">-0.1705</span>],</span><br><span class="line">        [ <span class="number">0.2707</span>, <span class="number">-0.7018</span>, <span class="number">-0.4553</span>,  ..., <span class="number">-0.2100</span>, <span class="number">-0.3003</span>,  <span class="number">1.0038</span>],</span><br><span class="line">        [ <span class="number">0.1943</span>, <span class="number">-0.3070</span>, <span class="number">-0.3651</span>,  ...,  <span class="number">1.1940</span>, <span class="number">-0.2991</span>,  <span class="number">0.0455</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.4118</span>, <span class="number">-0.3984</span>,  <span class="number">0.2089</span>,  ...,  <span class="number">0.7984</span>, <span class="number">-0.6598</span>,  <span class="number">0.2150</span>],</span><br><span class="line">        [<span class="number">-0.1639</span>, <span class="number">-1.5081</span>, <span class="number">-0.4011</span>,  ...,  <span class="number">0.9673</span>,  <span class="number">0.3524</span>,  <span class="number">0.0993</span>],</span><br><span class="line">        [ <span class="number">0.5961</span>, <span class="number">-0.4150</span>, <span class="number">-0.1207</span>,  ...,  <span class="number">0.3189</span>, <span class="number">-0.0829</span>,  <span class="number">0.5195</span>]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">30</span>, <span class="number">20</span>])  <span class="comment"># (out_features,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">30</span>])   <span class="comment">#  (out_features)</span></span><br></pre></td></tr></table></figure><h3 id="NormalizationLayers"><a href="#NormalizationLayers" class="headerlink" title="NormalizationLayers"></a>NormalizationLayers</h3><p><a href="https://www.youtube.com/watch?v=NGO0oxdz-zs" target="_blank" rel="noopener">Batch Normalization 批标准化 (PyTorch tutorial 神经网络 教学)</a> </p><p><a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)_Morvan</a>让数值保持在激活函数的有效区间，可避免梯度消失。Batch Normalization (BN) 就被添加在每一个全连接和激励函数之间.</p><p><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">深度学习中 Batch Normalization为什么效果好？</a> </p><h4 id="BatchNorm2d"><a href="#BatchNorm2d" class="headerlink" title="BatchNorm2d"></a>BatchNorm2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#batchnorm2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>])  <span class="comment">#  (same shape as input）</span></span><br></pre></td></tr></table></figure><h3 id="Dropout-Layers"><a href="#Dropout-Layers" class="headerlink" title="Dropout Layers"></a>Dropout Layers</h3><h4 id="torch-nn-Dropout"><a href="#torch-nn-Dropout" class="headerlink" title="torch.nn.Dropout"></a>torch.nn.Dropout</h4><p><a href="https://pytorch.org/docs/stable/nn.html#dropout" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])  <span class="comment">#  Output is of the same shape as input</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[ <span class="number">1.7224</span>,  <span class="number">1.3201</span>, <span class="number">-0.8480</span>],</span><br><span class="line">        [ <span class="number">1.8960</span>, <span class="number">-0.1245</span>,  <span class="number">0.6991</span>],</span><br><span class="line">        [ <span class="number">1.1756</span>,  <span class="number">0.2378</span>,  <span class="number">1.4059</span>],</span><br><span class="line">        [ <span class="number">0.2427</span>,  <span class="number">0.2278</span>, <span class="number">-0.7612</span>],</span><br><span class="line">        [<span class="number">-0.8882</span>,  <span class="number">0.2088</span>,  <span class="number">1.5004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">2.1530</span>,  <span class="number">1.6501</span>, <span class="number">-1.0601</span>],</span><br><span class="line">        [ <span class="number">2.3700</span>, <span class="number">-0.1556</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">1.4694</span>,  <span class="number">0.2972</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.3034</span>,  <span class="number">0.0000</span>, <span class="number">-0.9515</span>],</span><br><span class="line">        [<span class="number">-0.0000</span>,  <span class="number">0.2610</span>,  <span class="number">1.8755</span>]])</span><br></pre></td></tr></table></figure><h3 id="torch-nn-init"><a href="#torch-nn-init" class="headerlink" title="torch.nn.init"></a>torch.nn.init</h3><h4 id="torch-nn-init-kaiming-uniform"><a href="#torch-nn-init-kaiming-uniform" class="headerlink" title="torch.nn.init.kaiming_uniform_"></a>torch.nn.init.kaiming_uniform_</h4><p><a href="https://pytorch.org/docs/stable/nn.html?highlight=nn.init#torch.nn.init.kaiming_normal_" target="_blank" rel="noopener">Docs</a></p><h2 id="torch-nn-functional"><a href="#torch-nn-functional" class="headerlink" title="torch.nn.functional"></a>torch.nn.functional</h2><h3 id="Pooling-functions"><a href="#Pooling-functions" class="headerlink" title="Pooling functions"></a>Pooling functions</h3><h4 id="adaptive-avg-pool2d"><a href="#adaptive-avg-pool2d" class="headerlink" title="adaptive_avg_pool2d"></a>adaptive_avg_pool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#adaptive-avg-pool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 5x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d((<span class="number">5</span>,<span class="number">7</span>))  <span class="comment"># output_size – (H, W) </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 7x7 (square)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d(<span class="number">7</span>)  <span class="comment"># a single H for a square image H x H</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 10x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool2d((<span class="keyword">None</span>, <span class="number">7</span>))  <span class="comment"># None, which means the size will be the same as that of the input.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">7</span>])</span><br></pre></td></tr></table></figure><h4 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h4><ul><li><p><strong>torchvision.transforms.Resize:</strong>用于对载入的图片数据按我们需求的大小进行缩放。 传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列， 其中 ， h 代表高度， w 代表宽度，但是如果使用的是 一 个整型数据，那么表示缩放的宽度和高度都是这个整型数据的值 。 </p></li><li><p><strong>torchvision.transforms.Scale</strong>: 用于对载入的图片数据按我 们 需求的大小进 行缩 放，用法和 torchvision.transforms.Resize类似。 </p></li><li><p><strong>torchvision.transforms.CenterCrop:</strong>用 于对载入的图片以图片中心为参考点 ， 按我们需要的大小进行裁剪 。传递给这个类 的参数可以是一个整型数据 ，也可以 是一个类似 于( h,w)的序列 。 </p></li><li><p><strong>torchvision.transforms.RandomCrop:</strong> 用于对载入的图片按我们需要的大小进行随机裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列。 </p></li><li><p><strong>torchvision.transforms.RandomHorizontaIFlip:</strong> 用于对载入的图片按随机概率进行水平翻转。我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则使用 默认的概率值 0.5。</p></li><li><p><strong>torchvision.transforms.RandomVerticalFlip:</strong> 用于对载入的图片按随机概率进行垂直翻转。 我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则 使用默 认的概率值 0.5。 </p></li><li><p><strong>torchvision.transforms.ToTensor:</strong> 用于对载入的图片数据进行类型转换 ， 将之前构成 PIL 图片的数据转换成 Tensor数据类型的变量 ，让 PyTorch 能够对其进行计算和处理。 </p></li><li><p><strong>torchvision.transforms.ToPILlmage:</strong> 用于将 Tensor变量的数据转换成 PIL 图片数据， 主要是为了方便图片内容的显示。</p></li></ul><h2 id="torch-utils-model-zoo"><a href="#torch-utils-model-zoo" class="headerlink" title="torch.utils.model_zoo"></a>torch.utils.model_zoo</h2><p><a href="https://pytorch.org/docs/stable/model_zoo.html#module-torch.utils.model_zoo" target="_blank" rel="noopener">torch.utils.model_zoo.load_url</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>state_dict = torch.utils.model_zoo.load_url(<span class="string">'https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GraduationDesign</title>
    <link href="http://yoursite.com/2018/12/13/GraduationDesign/"/>
    <id>http://yoursite.com/2018/12/13/GraduationDesign/</id>
    <published>2018-12-13T09:51:23.000Z</published>
    <updated>2018-12-21T07:04:46.434Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="毕设要求"><a href="#毕设要求" class="headerlink" title="毕设要求"></a>毕设要求</h4><table><thead><tr><th>课题名称</th><th>基于densenet的图像分类算法研究与实现</th></tr></thead><tbody><tr><td>课题简介</td><td>随着深度学习网络越来越深，架构越来越复杂，解决反向传播时梯度消失的问题也越来越严重。densenetdensenet的每一层都和损失函数的梯度以及原始输入直接相连，用更少的参数减轻了反向梯度消失，可以令网络规模更大。该课题研究基于densenet的图像分类算法，提高分类效率。</td></tr></tbody></table><h4 id="代码调研"><a href="#代码调研" class="headerlink" title="代码调研"></a>代码调研</h4><ul><li><p><a href="https://blog.csdn.net/mdjxy63/article/details/76401145" target="_blank" rel="noopener">DenseNet的使用</a></p><p>Github link: <a href="https://github.com/liuzhuang13/DenseNetCaffe" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNetCaffe</a>  <strong>Star 243</strong></p></li><li><p><a href="https://blog.csdn.net/u014380165/article/details/75142664" target="_blank" rel="noopener">DenseNet算法详解</a></p><p>代码的github链接：<a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet</a>    <strong>Star 3090</strong><br>MXNet版本代码（有ImageNet预训练模型）: <a href="https://github.com/miraclewkf/DenseNet" target="_blank" rel="noopener">https://github.com/miraclewkf/DenseNet</a>    <strong>Star 41</strong></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/28190802" target="_blank" rel="noopener">Densely Connected Convolutional Networks》论文笔记</a></p><p><a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet</a>   <strong>Star 3090</strong></p></li><li><p>pytorch官方已经提供了Resnet、densenet的实现代码及权重文件</p></li><li><p><a href="https://www.leiphone.com/news/201708/0MNOwwfvWiAu43WO.html" target="_blank" rel="noopener">CVPR 2017最佳论文作者解读</a></p><p><a href="https://github.com/gaohuang/MSDNet" target="_blank" rel="noopener"> https://github.com/gaohuang/MSDNet</a>  <strong>Star 351</strong></p><p>代码参见：</p><p>Torch implementation: <a href="https://github.com/liuzhuang13/DenseNet/tree/master/models" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet/tree/master/models</a>    <strong>Star 3090</strong></p><p>PyTorch implementation: <a href="https://github.com/gpleiss/efficient_densenet_pytorch" target="_blank" rel="noopener">https://github.com/gpleiss/efficient_densenet_pytorch</a>    <strong>Star 771</strong></p><p>MxNet implementation: <a href="https://github.com/taineleau/efficient_densenet_mxnet" target="_blank" rel="noopener">https://github.com/taineleau/efficient_densenet_mxnet</a>    </p><p>Caffe implementation: <a href="https://github.com/Tongcheng/DN_CaffeScript" target="_blank" rel="noopener">https://github.com/Tongcheng/DN_CaffeScript</a>    <strong>Star 123</strong></p></li></ul><h4 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h4><ul><li>Torch implementation: <a href="https://github.com/liuzhuang13/DenseNet/tree/master/models" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet/tree/master/models</a>    <strong>Star 3090</strong></li><li>PyTorch <a href="https://blog.csdn.net/u014380165/article/details/79119664" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/79119664</a></li></ul><p><a href="https://pytorch.org/docs/master/torchvision/models.html" target="_blank" rel="noopener">https://pytorch.org/docs/master/torchvision/models.html</a></p><ul><li><p><a href="https://www.ctolib.com/article/wiki/34431" target="_blank" rel="noopener">DenseNet的一个PyTorch实现</a></p></li><li><p><a href="https://www.jianshu.com/p/9e5d68369a38" target="_blank" rel="noopener">Pytorch 使用预训练模型</a></p></li></ul><p>Q: pytorch.model.densenet 使用</p><h4 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h4><ul><li><p>_DenseLayer  命名方式_</p><p>$\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t$</p></li></ul><table><thead><tr><th style="text-align:center">model version</th><th style="text-align:center">num_init_features</th><th style="text-align:center">growth_rate</th><th style="text-align:center">block_config</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet121</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 24, 16)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet169</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 32, 32)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet201</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 48, 32)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet161</a></td><td style="text-align:center">96</td><td style="text-align:center">48</td><td style="text-align:center">(6, 12, 36, 24)</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>白话深度学习与TensorFlow_笔记</title>
    <link href="http://yoursite.com/2018/12/12/%E7%99%BD%E8%AF%9D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8ETensorFlow-%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/12/12/白话深度学习与TensorFlow-笔记/</id>
    <published>2018-12-12T09:32:42.000Z</published>
    <updated>2018-12-17T06:24:01.592Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读说明】这本书适合零基础的初学者</p><a id="more"></a><h4 id="第5章-手写板功能"><a href="#第5章-手写板功能" class="headerlink" title="第5章 手写板功能"></a>第5章 手写板功能</h4><ul><li><p>手写识别</p><p>Github Link：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p><p>文件目录：<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist</a></p></li></ul><h4 id="第6章-卷积神经网络"><a href="#第6章-卷积神经网络" class="headerlink" title="第6章 卷积神经网络"></a>第6章 卷积神经网络</h4><ul><li><p><strong>卷积</strong></p><center><br><img src="https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-59-29-pm.png?w=748" style="zoom:80%"><br></center></li><li><p><strong>卷积核</strong> </p><center><br>    <img src="https://www.oreilly.com/library/view/neural-networks-with/9781788397872/assets/2009c470-759a-4fb7-a1a3-982c4bae841c.png" style="zoom:30%"><br></center></li></ul><ul><li><p><strong>池化层 Pooling Layer</strong></p><blockquote><p>池化层的作用实际上对 Feature Map 所做的数据处理又进行了一次所谓的池化处理。常见的池化层处理有两种方式:一种叫 Max Pooling，一种叫 Mean Pooling (也叫 Average Pooling)</p></blockquote><center><br>    <img src="https://i.stack.imgur.com/bhXRN.png" style="zoom:60%"><br></center></li></ul><h4 id="第7章-综合问题"><a href="#第7章-综合问题" class="headerlink" title="第7章 综合问题"></a>第7章 综合问题</h4><ul><li><p><strong>ReLU 函数 Activation Function</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/ReLU.png"><br></center><p><strong>优点：</strong></p><p>其一 ，在第一象限中<code>不会有明显的梯度消失问题</code>，因为导数恒为 1，而 w 在初始化的 时候也是有大有小，连乘的时候不会轻易出现很小或者很大的数值，这就是一个非常好的 特性了 。 </p><p>其二，由于导数为 1，所以求解它的导数要比求解 Sigmoid 函数的导数<code>时间代价要小</code> 一些.</p><blockquote><p>因而现在的工程人员在近几年的网络中都喜欢大量使用 ReLU 函数 。 在笔者的工程经验中也是至少 80% 以上的工程都是倾向于优先使用 ReLU 函数作为激励函数的 。 </p></blockquote></li><li><p><strong>归一化 normalization</strong></p><blockquote><p>统一“单位”，让模型对各参数数值变化的敏感程度保持一致，“没有偏见”</p></blockquote></li><li><p><strong>正则化 regulization</strong></p><blockquote><p>防止过拟合，提高泛化能力</p></blockquote></li><li><p><strong>超参数 hyper parameter</strong></p><blockquote><p>不能通过算法学习到的参数，例如 K-Means 算法中的簇数 N，还有就是像在深度学习中涉及的学习率 $\eta $</p></blockquote></li><li><p><strong>Dropout</strong></p><blockquote><p>在一轮训练阶段丢弃一部分网络节点 。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</span><br></pre></td></tr></table></figure></li></ul><h4 id="第8章-循环神经网络"><a href="#第8章-循环神经网络" class="headerlink" title="第8章 循环神经网络"></a>第8章 循环神经网络</h4><ul><li><p><strong><a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">隐马尔可夫模型</a></strong></p><center><br>    <img src="data:image/png;base64,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"><br></center></li></ul><blockquote><p>马尔可夫链的核心是说，在给定当前知识或信息的情况下，观察对象过去的历史状态对于<br>将来的预测来说预测是无关的 。 也可以说，在观察一个系统变化的时候，它下一个状态(第<br>n+l个状态)如何的概率只需要观察和统计<code>当前状态</code>(第n个状态)即可以正确得出。</p></blockquote><ul><li><p><strong>RNN 和 BPTT 算法</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/BPTT.png" style="zoom:50%"><br></center></li><li><p><strong>LSTM算法</strong></p><center><br>    <img src="data:image/png;base64,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" style="zoom:150%"><br></center></li><li><p><strong>聊天机器人</strong></p><p>Github链接：<a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener">https://github.com/Conchylicultor/DeepQA</a></p><p>issue:</p><ul><li><p>OK <a href="https://github.com/Conchylicultor/DeepQA/issues/68" target="_blank" rel="noopener">Error about BasicLSTMCell </a></p></li><li><p>After using Nicholas C.’s pre-trained model ,<code>still not work</code>.</p><p>To resolve  <a href="https://github.com/Conchylicultor/DeepQA/issues/149" target="_blank" rel="noopener">WARNING: Restoring previous model</a></p><ul><li><p>I think the pretrained model is not work</p></li><li><p><a href="https://mcastedu-my.sharepoint.com/personal/nicholas_cutajar_a100636_mcast_edu_mt/Documents/Forms/All.aspx?slrid=ba91ab9e-d04d-7000-6ce2-3d1610bc6c24&amp;FolderCTID=0x012000ACF25C8BFBFE2F4A85CE16FF1E3C2BBC&amp;id=%2Fpersonal%2Fnicholas_cutajar_a100636_mcast_edu_mt%2FDocuments%2FDeepQA%20-%20Pre%20Trained%20Models" target="_blank" rel="noopener">N C</a></p></li></ul></li></ul></li></ul><h4 id="第9章-深度残差网络"><a href="#第9章-深度残差网络" class="headerlink" title="第9章 深度残差网络"></a>第9章 深度残差网络</h4><p>Github Link：</p><p><a href="https://github.com/ry/tensorflow-resnet" target="_blank" rel="noopener">https://github.com/ry/tensorflow-resnet</a></p><p><a href="https://github.com/raghakot/keras-resnet" target="_blank" rel="noopener">https://github.com/raghakot/keras-resnet</a></p><p><a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">https://github.com/KaimingHe/deep-residual-networks</a></p><h4 id="第10章-受限玻尔兹曼机"><a href="#第10章-受限玻尔兹曼机" class="headerlink" title="第10章 受限玻尔兹曼机"></a>第10章 受限玻尔兹曼机</h4><p><a href="https://github.com/meownoid/tensorfow-rbm" target="_blank" rel="noopener">https://github.com/meownoid/tensorfow-rbm</a>  解码器(autodecoder)</p><p><a href="https://github.com/Cospel/rbm-ae-tf" target="_blank" rel="noopener">https://github.com/Cospel/rbm-ae-tf</a> 降维工具</p><h4 id="第11章-强化学习"><a href="#第11章-强化学习" class="headerlink" title="第11章 强化学习"></a>第11章 强化学习</h4><ul><li><p><strong><a href="http://gym.openai.com/" target="_blank" rel="noopener">OpenAI Gym</a></strong></p><p>Github Link：<a href="https://github.com/openai/gym" target="_blank" rel="noopener">https://github.com/openai/gym</a></p></li><li><p><strong>Playing Atari with Deep Reinforcement Learning</strong></p><p>Github Link：<a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" target="_blank" rel="noopener">https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner</a></p></li></ul><h4 id="第12章-对抗学习"><a href="#第12章-对抗学习" class="headerlink" title="第12章 对抗学习"></a>第12章 对抗学习</h4><ul><li><p><strong>DCGAN</strong></p><p>Github Link：<a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">https://github.com/carpedm20/DCGAN-tensorflow</a></p></li></ul><h4 id="第13章-有趣的深度学习应用"><a href="#第13章-有趣的深度学习应用" class="headerlink" title="第13章 有趣的深度学习应用"></a>第13章 有趣的深度学习应用</h4><ul><li><p>人脸识别</p><p>GIthub link：<a href="https://github.com/davidsandberg/facenet" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet</a></p><p>LFW datasets: <a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p></li><li><p>作诗姬</p><p>Github link：<a href="https://github.com/XingxingZhang/rnnpg" target="_blank" rel="noopener">https://github.com/XingxingZhang/rnnpg</a></p></li><li><p>VGG</p><p>Github link：<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python neural_style.py --content &lt;content file&gt; --styles &lt;style file&gt; --output &lt;output file&gt;</span><br><span class="line"></span><br><span class="line">Example:</span><br><span class="line">python neural_style.py –content examples/cat.jpg –styles examples/2-style1.jpg –output y-output.jpg</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(tensorflow) ➜  neural-style-master python neural_style.py --content examples/cat.jpg --styles examples/2-style1.jpg --output y-output.jpg --network imagenet-vgg-verydeep-19.mat</span><br><span class="line">Optimization started...</span><br><span class="line">Iteration    1/1000</span><br><span class="line">Iteration    2/1000 (16 sec elapsed, 4 hr 26 min remaining)</span><br><span class="line">Iteration    3/1000 (30 sec elapsed, 4 hr 10 min remaining)</span><br><span class="line">Iteration    4/1000 (43 sec elapsed, 4 hr 0 min remaining)</span><br><span class="line">Iteration    5/1000 (55 sec elapsed, 3 hr 50 min remaining)</span><br><span class="line">...</span><br><span class="line">Iteration  999/1000 (3 hr 22 min elapsed, 24 sec remaining)</span><br><span class="line">Iteration 1000/1000 (3 hr 23 min elapsed, 12 sec remaining)</span><br><span class="line">content loss: 796114</span><br><span class="line">  style loss: 234885</span><br><span class="line">     tv loss: 44175.5</span><br><span class="line">  total loss: 1.07517e+06</span><br></pre></td></tr></table></figure><center class="third"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/cat.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/2-style1.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/y-output.jpg" width="200"><br></center></li></ul><h4 id="Other-Concepts"><a href="#Other-Concepts" class="headerlink" title="Other Concepts"></a>Other Concepts</h4><ul><li><p><strong>VC维 Vapnik-Chervonenkis Dimension</strong></p><blockquote><p>H的VC维表示为VC(H) ，指能够被H分散的最大集合的大小。若H能分散任意大小的集合，那么VC(H)为无穷大。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读说明】这本书适合零基础的初学者&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>软件过程与项目管理</title>
    <link href="http://yoursite.com/2018/12/10/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2018/12/10/软件过程与项目管理/</id>
    <published>2018-12-10T11:02:40.000Z</published>
    <updated>2018-12-10T12:23:08.557Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><h3 id="Introduction-to-Project-Management"><a href="#Introduction-to-Project-Management" class="headerlink" title="Introduction to Project Management"></a>Introduction to Project Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-c0568a46ba885ed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="The-Project-Management-and-Information-Technology-Context"><a href="#The-Project-Management-and-Information-Technology-Context" class="headerlink" title="The Project Management and Information Technology Context"></a>The Project Management and Information Technology Context</h3><h3 id="The-Project-Management-Process-Groups"><a href="#The-Project-Management-Process-Groups" class="headerlink" title="The Project Management Process Groups"></a>The Project Management Process Groups</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Initiating processes - 启动过程</span><br><span class="line">Planning processes - 计划过程</span><br><span class="line">Executing processes - 执行过程组</span><br><span class="line">Monitoring and controlling processes- 监控过程</span><br><span class="line">Closing processes -闭合过程</span><br></pre></td></tr></table></figure><h3 id="Project-Integration-Management"><a href="#Project-Integration-Management" class="headerlink" title="Project Integration Management"></a>Project Integration Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-0ea7fa98a3c3eb4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Scope-Management"><a href="#Project-Scope-Management" class="headerlink" title="Project Scope Management"></a>Project Scope Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a0e80e3077f6b3c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Schedule-Management"><a href="#Project-Schedule-Management" class="headerlink" title="Project Schedule Management"></a>Project Schedule Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-34622539853a259b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Cost-Management"><a href="#Project-Cost-Management" class="headerlink" title="Project Cost Management"></a>Project Cost Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-cc09a65d92af001a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="630"><br></center><center><br>        <img src="https://upload-images.jianshu.io/upload_images/5267500-0170a5c22ef465af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="Project-Quality-Management"><a href="#Project-Quality-Management" class="headerlink" title="Project Quality Management"></a>Project Quality Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-6ee33da505abded3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Resource-Management"><a href="#Project-Resource-Management" class="headerlink" title="Project Resource Management"></a>Project Resource Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-7374cb810a56778a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Communications-Management"><a href="#Project-Communications-Management" class="headerlink" title="Project Communications Management"></a>Project Communications Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-e1777f730d2a1f31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Risk-Management"><a href="#Project-Risk-Management" class="headerlink" title="Project Risk Management"></a>Project Risk Management</h3><h4 id="processes"><a href="#processes" class="headerlink" title="processes"></a>processes</h4><ol><li><p><strong>Planning risk management:</strong> deciding how to approach and plan the risk management activities for the project 决定如何处理和规划项目的风险管理活动</p><ul><li>The project team should review project documents as well as corporate risk management <code>policies</code>, <code>risk categories</code>,<code>lessons-learned</code> reports from past projects, and<code>templates</code> for creating a risk management plan</li></ul></li><li><p><strong>Identifying risks</strong>: determining which risks are likely to affect a project and documenting the characteristics of each 确定哪些风险可能影响项目并记录每个风险的特征</p><ul><li>tools and techniques <ul><li>Brainstorming</li><li>The Delphi Technique: 专家小组；匿名输入；书面答复</li><li>Interviewing</li><li>SWOT analysis: Strengths,weaknesses, opportunities, and threats</li></ul></li><li>Output<ul><li>Risk Register </li></ul></li></ul></li><li><p><strong>Performing qualitative risk analysis</strong>: prioritizing risks based on their probability and impact of occurrence 根据风险的概率和发生的影响确定风险的优先级</p><ul><li>tools and techniques <ul><li>Probability/impact matrixes</li><li>The Top Ten Risk Item Tracking</li><li>Expert judgment</li></ul></li></ul></li><li><p><strong>Performing quantitative risk analysis</strong>: numerically estimating the effects of risks on project objectives 数字估算风险对项目目标的影响</p><ul><li>Main techniques <ul><li>Decision tree analysis 决策树分析  EMV(Expected Monetary Value )</li><li>Simulation 模拟   <strong>Monte Carlo analysis</strong></li><li>Sensitivity analysis 敏感性分析</li></ul></li></ul></li><li><p><strong>Planning risk responses</strong>: taking steps to enhance opportunities and reduce threats to meeting project objectives  采取措施增加机会并减少对实现项目目标的威胁</p><ul><li><p>Negative</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-401c059f77196a16.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="500"><br></center></li><li><p>Positive</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-d40395b0292ca1c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="300"><br></center></li></ul></li><li><p><strong>Implementing risk responses</strong>: implementing the risk response plans  实施风险应对计划</p></li><li><p><strong>Monitoring risk</strong>: monitoring identified and residual risks, identifying new risks, carrying out risk response plans, and evaluating the effectiveness of risk strategies throughout the life of the project 监控已识别和剩余风险，识别新风险，执行风险应对计划，并在项目的整个生命周期内评估风险策略的有效性</p></li></ol><ul><li>Main output of this process is a <code>risk management plan</code></li></ul><h3 id="PROJECT-PROCUREMENT-MANAGEMENT"><a href="#PROJECT-PROCUREMENT-MANAGEMENT" class="headerlink" title="PROJECT PROCUREMENT MANAGEMENT"></a>PROJECT PROCUREMENT MANAGEMENT</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-141f7fc025e82374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h4 id="Types-of-outsourcing"><a href="#Types-of-outsourcing" class="headerlink" title="Types of outsourcing"></a>Types of outsourcing</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Local outsourcing</span><br><span class="line">- Offshore outsourcing</span><br><span class="line">- Nearshore outsourcing</span><br></pre></td></tr></table></figure><h4 id="Types-of-Contracts"><a href="#Types-of-Contracts" class="headerlink" title="Types of Contracts"></a>Types of Contracts</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 'Fixed price' or lump sum contracts: involve a fixed total price for a well-defined product or service   #卖家不利</span><br><span class="line">- `Point of Total Assumption` (PTA): cost at which the contractor assumes total responsibility for each additional dollar of contract cost</span><br><span class="line">- 'Fixed Price' / Lump Sum / Firm Fixed Price : Risk is on the seller</span><br><span class="line">- Fixed Price with Economic Price Adjustment Contracts ('FP-EPA'): 旨在保护买方和卖方免受其无法控制的外部条件的影响。 如`通货膨胀变化`，或成本增加。</span><br><span class="line">- Fixed Price Incentive Fee ('FPIF') 固定价格激励: 根据卖家表现支付额外奖励，例如更快/更便宜/更好,比如 项目早期每月完成一次，向卖方支付额外的10,000美元</span><br><span class="line">- Fixed Price Award Fee ('FPAF')固定价格奖励: 买方根据业绩支付固定价格和奖励金额（奖金）</span><br><span class="line"></span><br><span class="line">- 'Cost-reimbursable' contracts: involve payment to the seller for direct and indirect costs   #买家不利</span><br><span class="line">- Cost plus incentive fee, cost plus fixed fee, and cost plus percentage of costs</span><br><span class="line">- Cost + Fee (CPF)/ Cost Plus Percentage of Costs ('CPPC') :涉及向卖方支付已完成工作所产生的`所有合法实际费用`，以及费用的百分比。</span><br><span class="line">- Cost Plus Fixed Fee.('CPFF'). 成本加固定费用</span><br><span class="line">- Cost Plus Incentive Fee ('CPIF'). 成本加奖励</span><br><span class="line">- Cost Plus Award Fee ('CPAF'). 成本加奖励费</span><br><span class="line"></span><br><span class="line">- 'Time and material' contracts: hybrid of both fixed price and cost reimbursable contracts  用于在授予合同时`无法确定工作量`的服务工作 例如: 合同=每天1美元加上每线性木材5美元的材料</span><br><span class="line"></span><br><span class="line">- 'Unit price' contracts: require the buyer to pay the seller a predetermined amount per unit of service</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-91e6cc7316e81548.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ContractRisk.png" title="">                </div>                <div class="image-caption">ContractRisk.png</div>            </figure><h3 id="PROJECT-STAKEHOLDER-MANAGEMENT"><a href="#PROJECT-STAKEHOLDER-MANAGEMENT" class="headerlink" title="PROJECT STAKEHOLDER MANAGEMENT"></a>PROJECT STAKEHOLDER MANAGEMENT</h3><h4 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h4><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-f52bfa58c3aa23aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><ol><li><p><strong>Identifying stakeholders</strong>: identifying everyone involved in the project or affected by it, and determining the best ways to manage relationships with them.</p><ul><li><p>output: <code>stakeholder register</code> includes basic information on stakeholders</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a78cfe957aaaa2b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width=""><br></center><ul><li><p><strong>Identification information</strong>: stakeholders’ names, positions, locations, roles in the project, and contact information</p></li><li><p><strong>Assessment information</strong>: stakeholders’ major requirements and expectations, potential influences, and phases of the project in which stakeholders have the most interest</p></li><li><p><strong>Stakeholder classification</strong>: is the stakeholder internal or external to the organization? Is the stakeholder a supporter of the project or resistant to it?</p></li></ul></li></ul></li><li><p><strong>Planning stakeholder management</strong>: determining strategies to effectively engage stakeholders in project decisions and activities based on their needs, interests, and potential impact.</p><ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Managing stakeholder engagement:</strong> communicating and working with project stakeholders to satisfy their needs and expectations, resolving issues, and fostering engagement in project decisions and activities<ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Monitoring stakeholder engagement</strong>:monitoring stakeholder relationships and adjusting plans and strategies for engaging stakeholders as needed<ul><li>Outputs: <code>work performance information</code>, <code>change requests</code>, <code>project management plan updates</code>, and <code>project documents updates</code>.</li></ul></li></ol><h2 id="Exam"><a href="#Exam" class="headerlink" title="Exam"></a>Exam</h2><h3 id="考后说明"><a href="#考后说明" class="headerlink" title="考后说明"></a>考后说明</h3><ul><li><strong>True or False</strong>： 只要理解<a href="#知识点啊~朋友们">知识点</a>部分的内容，就够了，不必去记忆。考卷的”False”很明显</li><li><strong>Single choice</strong>：刷一遍题库，对题目有印象就行。考试都是原题，选项次序都不变</li><li><strong>Fill in the blanks</strong>：刷一遍题库，考试都是原题</li><li><strong>Writing</strong>：still 背题库，<strong>默写</strong>式答题</li></ul><blockquote><p><strong>Summary：</strong> 此门课程难点还是 前期完成的项目本身  笔试部分则是”记到便是赚到“  (2018.12.10)</p></blockquote><h3 id="知识点啊-朋友们"><a href="#知识点啊-朋友们" class="headerlink" title="知识点啊~朋友们"></a>知识点啊~朋友们</h3><h4 id="项目管理简介"><a href="#项目管理简介" class="headerlink" title="项目管理简介"></a>项目管理简介</h4><p>1.<code>项目</code>与运营不同，因为它们在达到目标或项目终止时<code>结束</code>。<br>2.使用<code>渐进式细化</code>开发项目。项目通常在开始时被广泛定义，随着时间的推移，项目的具体细节变得更加清晰。因此，应该<code>逐步开发</code>项目。</p><p>3.一个项目涉及<code>不确定性</code>。每个项目都是独一无二的，因此有时很难明确定义目标，估计完成所需的时间，或确定需要多少费用。这种不确定性是项目管理如此具有挑战性的主要原因之一。<br>4.管理<code>三重约束</code>涉及在项目的范围，时间和成本目标之间进行权衡。经验丰富的项目经理知道必须决定三重约束的哪个方面最重要。<br>5.<code>利益相关者</code>是参与或受项目活动影响的人，包括项目发起人，项目团队，支持人员，客户，用户，供应商，甚至是项目的反对者。<br>6.<code>项目管理知识领域</code>描述了项目经理必须发展的关键能力。<code>项目采购管理</code>涉及从执行组织外部为项目获取或采购商品和服务。<br>7.<code>项目经理</code>不仅<code>负责</code>项目成果的交付。他们是<code>负责</code>这些项目开发的产品和流程成功的变革推动者。</p><p>8.<code>IT项目经理</code>必须愿意发展不仅仅是他们的<code>技术技能</code>，才能成为富有成效的团队成员和成功的项目经理。每个人，无论他们多么技术，都应该培养<code>商业和软技能</code>。</p><h4 id="项目管理和信息技术背景"><a href="#项目管理和信息技术背景" class="headerlink" title="项目管理和信息技术背景"></a>项目管理和信息技术背景</h4><p>1.使用<code>系统方法</code>对于成功的项目管理至关重要。如果高层管理人员和项目经理要了解项目与整个组织的关系，他们必须<code>遵循</code>系统理念。<br>2.矩阵组织的<code>项目经理</code>有来自<code>各个职能领域的工作人员</code>从事项目工作。<br>3.<code>组织文化</code>非常强大，许多人认为许多公司问题的根本原因不在于组织结构或员工;他们在文化中。<br>4.在围绕团体或团队而不是个人组织工作活动的组织中，项目工作最为成功。强调团队工作的<code>组织文化</code>最适合管理项目。<br>5.在项目生命周期的<code>早期阶段</code>，资源需求通常最低，不确定性水平最高。在<code>后期阶段</code>对项目进行重大改变要昂贵得多。<br>6.由于组织通常会在项目<code>持续时投入更多资金</code>，因此应在每个阶段之后进行<code>管理评审</code>，以评估进度，潜在成功以及与组织目标的持续兼容性。<br>7.<code>虚拟团队</code>是一群使用通信技术在时间和空间边界上一起工作的人。团队成员可能都在同一个国家的同一家公司工作，或者他们可能包括员工以及独立顾问，供应商，甚至志愿者，他们提供来自全球的专业知识。</p><h4 id="项目管理流程组"><a href="#项目管理流程组" class="headerlink" title="项目管理流程组"></a>项目管理流程组</h4><p>1.<code>启动流程</code>包括定义和授权项目或项目阶段。启动过程在项目的<code>每个阶段</code>进行。<br>2.<code>启动和关闭任务通常是最短的</code>（分别在项目或阶段的开始和结束时），并且它们需要最少的资源和时间。<br>3.<code>监控和控制流程</code>与所有其他项目管理流程组<code>重叠</code>，因为可以随时进行更改。<br>4.<code>敏捷</code>是一种适应性产品生命周期，当可交付成果具有<code>高度变化</code>和<code>高交付频率</code>时使用。<br>5.六西格玛项目使用两种主要方法：<code>DMAIC</code>（定义，测量，分析，改进和控制）用于改进现有业务流程，并使用<code>DMADV</code>（定义，测量，分析，设计和验证）创建新产品或流程设计，以实现可预测的，无缺陷的性能。<br>6.<code>启动会议</code>是在项目开始时举行的会议，以便利益相关者可以相互见面，审查项目的目标，并讨论未来的计划。启动会议通常在<code>业务案例和项目章程完成后</code>举行，但可以根据需要提前举行。</p><p>7.<code>WBS</code>是项目管理中非常重要的工具，因为它为决定如何开展工作提供了基础。 WBS还为<code>创建项目进度表</code>和<code>执行挣值管理</code>提供了基础，用于<code>衡量和预测项目绩效</code>。<br>8.因为<code>Scrum</code>暗示团队成员是由ScrumMaster指导的<code>自我导向组</code>，所以<code>团队合同不是必需的</code>。<br>9.燃尽图表(<code>burndown chart</code>)显示了每天冲刺中<code>剩余的累积工作量</code>。<br>10.<code>冲刺审查</code>是团队向产品所有者展示冲刺期间<code>完成的内容</code>的会议。</p><p>11.Scrum框架中<code>监控和控制</code>的两个主要项目是<code>每日Scrum</code>和<code>冲刺审查</code>。<br>12.<code>结账流程</code>包括正式接受项目或项目阶段并有效结束。作为阶段或项目的一部分，<code>管理活动</code>（例如归档项目文件，结束合同，记录经验教训以及接受正式接受交付的工作）通常涉及此流程组。</p><h4 id="项目集成管理"><a href="#项目集成管理" class="headerlink" title="项目集成管理"></a>项目集成管理</h4><p>1.<code>界面管理</code>涉及识别和管理项目各个元素之间的<code>交互点</code>。<br>2.<code>项目集成管理包括界面管理</code>，涉及识别和管理项目各个元素之间的交互点。随着项目涉及的人数增加，<code>接口数量可能呈指数级增长</code>。<br>3.有些人喜欢使用<code>思维导图</code>进行SWOT分析，这种技术使用从核心思想辐射出来的分支来构建思想和想法。<br>4.许多信息系统被归类为<code>“战略性”</code>，因为它们直接支持<code>关键业务战略</code>。例如，信息系统可以帮助组织支持作为低成本生产者的战略。<br>5.随着项目的进展，组织必须<code>重新评估</code>每个项目的需求，资金和意愿，以确定是否应该继续，重新定义或终止项目。<br>6.由于要求和期望不明确，许多项目都失败了，所以从<code>项目章程</code>开始就很有意义。<br>7.<code>项目管理计划</code>不仅仅是甘特图。</p><h4 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a><a href="#第5章 - 项目范围管理">项目范围管理</a></h4><p>1.<code>范围基准</code>包括已批准的项目范围声明及其关联的WBS和WBS字典。</p><p>2.<code>WBS的主要目的</code>是定义完成项目所需的所有工作。<br>3.<code>工作包</code>是WBS最低级别的任务。它表示项目经理监视和控制的工作级别。<br>4.创建一个好的WBS非常<code>困难</code>。为此，您必须了解项目及其范围，并纳入利益相关方的需求和知识。<br>5.执行任务executing task在项目之间<code>变化最大</code>，但其他项目管理过程组下的许多任务对于所有项目都是类似的。<br>6.创建一个好的WBS及其WBS字典的基本原则是，<code>一个工作单元应该只出现在WBS中的一个地方</code>。<br>7.即使项目范围相当明确，许多IT项目仍然存在<code>范围蔓延</code> - 项目范围越来越大的趋势。许多IT项目因范围蔓延而失败。</p><h4 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a><a href="#第6章 - 项目进度管理">项目进度管理</a></h4><p>1.<code>活动或任务</code>是通常在工作分解结构（WBS）上找到的工作要素，其具有预期的持续时间，成本和资源要求。<br>2.在项目进度管理中，定义活动的<code>主要输出</code>是活动列表，活动属性，里程碑列表和项目管理计划更新。<br>3.<code>项目进度表</code>从发起项目的基本文件中发展而来。<code>项目章程</code>经常提到计划的项目开始和结束日期，作为更详细的计划的起点。<br>4.<code>时间表管理计划</code>包括有关报告格式的信息。此信息描述了项目所需的计划报告的格式和频率。此外，它还包括有关流程描述的信息，并描述了如何执行所有计划管理流程。<br>5.项目的<code>里程碑</code>是一个重要事件，通常<code>没有持续时间</code>。通常需要多次活动和大量工作来完成里程碑，但里程碑本身就像是帮助识别必要活动的<code>标记</code>。<br>6.<code>依赖关系</code>或关系涉及项目活动或任务的<code>顺序</code>。确定活动之间的这些关系或依赖关系对于开发和管理项目进度表具有重大影响。<br>7.<code>网络图</code>是显示<code>活动排序</code>的首选技术。网络图是项目活动及其排序之间逻辑关系的示意图。<br>8.网络图是项目活动及其排序之间逻辑关系的示意图。网络图中的箭头表示活动顺序或任务之间的关系。<br>9.当两个或多个节点在单个节点之前时发生<code>合并</code>。另一方面，当两个或多个活动跟随单个节点时发生<code>突发</code>。<br>10.<code>甘特图</code>提供了一种标准格式，用于通过以日历形式列出项目活动及其相应的开始和结束日期来显示项目进度信息。在甘特图中，黑色菱形符号代表了一个里程碑<br>11.<code>跟踪甘特图</code>基于项目任务完成的工作百分比或实际开始和结束日期。它允许项目经理<code>监控</code>各个任务和整个项目的进度。<br>12.在<code>关键路径分析</code>中，几个任务在项目上并行完成，大多数项目通过网络图有多条路径。包含关键任务的最长路径或路径是驱动项目完成日期的原因。<br>13.<code>crashing</code>的主要优点是缩短了完成项目所需的时间。主要缺点是它通常会增加项目总成本。<br>14.<code>关键链调度</code>是一种在创建项目计划时考虑有限资源的方法，并包含用于保护项目完成日期的<code>缓冲区</code>。它假设资源不是多任务或至少最小化多任务处理。</p><h4 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a><a href="#第7章 - 项目成本管理">项目成本管理</a></h4><p>1.<code>超支</code>是实际成本超过估计值的额外百分比或金额。<br>2.<code>现金流量分析</code>是确定项目的估计年度成本和收益以及由此产生的年度现金流量的一种方法。项目经理必须进行现金流量分析以<code>确定净现值</code>。<br>3.<code>沉没成本</code>是过去花费的钱。在决定投资或继续投资哪些项目时，不应包括沉没成本。<br>4.<code>管理储备</code>允许未来<code>不可预测</code>的情况。例如，如果项目经理生病了两周或者一个重要的供应商停业，可以留出管理储备来支付由此产生的费用。<br>5.<code>估算</code>通常在项目的<code>不同阶段进行</code>，随着时间的推移应该变得更加准确。<br>6.<code>类似的估计</code>需要大量的专家判断，并且通常比其他技术成本更低。但是，它也不太准确。<br>7.项目<code>成本估算不准确</code>的原因之一是<code>人类偏向于低估</code>。因此，项目经理和高层管理人员必须审核估算并提出重要问题，以确保估算不会有偏差<br>8.方差和指数的公式以<code>EV</code>（赢得值）开头。通过从EV中减去实际成本或计划值来计算差异，并且通过将EV除以实际成本或计划值来计算指数。<br>9.如果<code>CPI</code>小于1或小于100％，则该项目超出预算。另一方面，如果CPI大于1％或超过100％，则项目预算可控。</p><h4 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a><a href="#第8章 - 项目质量管理">项目质量管理</a></h4><p>1.<code>实验设计</code>是一种有助于确定哪些变量对过程总体结果影响最大的技术。您还可以将实验设计应用于<code>项目管理问题</code>，例如成本和进度权衡。<br>2.<code>可靠性</code>是指产品或服务在正常条件下按<strong>预期</strong>运行的能力。<br>3.所有项目利益相关方必须<strong>共同努力</strong>，以<code>平衡项目</code>的质量，范围，时间和成本方面。但是，<code>项目经理最终负责</code>其项目的质量管理。<br>4.<code>接受决定确定</code>作为项目一部分生产的产品或服务是否将被接受或拒绝。如果他们被接受，他们被认为是<strong>经过验证的可交付成果</strong>。<br>5.<code>运行图表</code>显示过程随时间变化的<strong>历史和模式</strong>。它是一个折线图，显示按发生顺序绘制的数据点。<br>6.<code>测试</code>需要在系统开发生命周期的几乎<code>每个阶段进行</code>，而不仅仅是在组织发布或将产品交给客户之前。<br>7.在全面质量控制中，产品质量比生产率更重要，工人可以在<code>出现质量问题时停止生产</code>。<br>8.符合要求意味着项目的流程和产品<code>符合书面规范</code>。例如，如果项目范围声明要求交付100台具有特定处理器和内存的计算机，则可以轻松检查是否已交付合适的计算机。</p><h4 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a><a href="#第9章 - 项目资源管理">项目人力资源管理</a></h4><p>1.<code>马斯洛的需求层次</code>表明人们的行为受到一系列需求的<code>指导或激励</code>。<br>2.根据赫兹伯格的说法，<code>激励者</code>，如更高的工资，更多的监督，或更有吸引力的工作环境，将激励工人做更多的工作。他提到导致工作满意度的因素作为激励因素和可能导致不满意的因素作为卫生因素。<br>3.需要制度权力或社会<code>权力的人</code>希望组织其他人来推进组织的目标。<br>4.相信<code>X理论</code>的人认为工人在可能的情况下不喜欢和避免工作，因此管理者必须使用<strong>强制，威胁和各种控制方案</strong>让工人做出足够的努力来实现目标。他们认为普通工人希望被指导并且更愿意避免责任，没有什么野心，并且希望安全高于一切。</p><p>5.Thamhain和Wilemon发现，当项目经理过于依赖权力，金钱或惩罚来影响人们时，项目更有可能失败。当项目经理使用<code>工作挑战和专业知识来影响人们</code>时，项目更有可能成功。<br>6.<code>合法的权力</code>使人们根据权威的地位做事。这种权力类似于权威的影响基础。<br>7.如OBS中所述，责任分配矩阵（<code>RAM</code>）将WBS中描述的项目工作映射到负责执行工作的人员。<br>8.<code>资源调配</code>可以减少项目人员和会计部门的问题。劳动力水平和人力资源的增加和减少往往会产生<code>额外的工作和混乱</code>。<br>9.<code>平滑模式</code>是项目经理强调或避免差异领域并强调协议领域的模式。这种方法也称为适应性，当关系具有高度重要性且任务不重要时，最好使用这种方法。</p><h4 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a><a href="#第10章 - 项目沟通管理">项目沟通管理</a></h4><p>1.举行会议的准则之一是确定是否可以<code>避免会议</code>。如果有更好的方法来实现手头的目标，就不要开会。<br>2.项目经理经常将所有<code>经验教训</code>报告中的信息合并到项目总结报告中。<br>3.提高组织的沟通能力需要组织中的<code>文化变革</code>，这需要花费大量时间，努力工作和耐心。<br>4.要使项目取得成功，每个项目团队成员都需要这<code>两种技能</code>，并需要通过正规教育和在职培训不断开发这些技能。<br>5.<code>地理位置和文化背景影响项目沟通的复杂性</code>。如果项目利益相关者在不同的国家，通常很难或不可能在正常工作时间内安排双向沟通的时间。<br>6.<strong>项目沟通管理</strong>涉及包含影响项目中开发的产品或服务的关键性能特征的<code>详细技术信息</code>。记录可能影响产品性能的<code>技术规范</code>的任何<strong>变更</strong>甚至更为重要。<br>7.沟通的一个重要方面是<code>参与项目的人数</code>。随着数量的增加，通信的复杂性也会增加，因为人们可以通过更多的渠道或途径进行交流。随着团队规模的增加，沟通变得更加复杂。</p><h4 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a><a href="第11章 - 项目风险管理">项目风险管理</a></h4><p>1.项目风险管理<code>涉及</code>了解项目可能出现的潜在问题以及它们如何阻碍项目成功。但是，也有积极的风险或机会，可以为项目带来良好的结果。<br>2.<code>寻求风险的人</code>更喜欢更不确定的结果，并且通常愿意支付惩罚来承担风险。<br>3.项目风险管理的第一步是通过<code>执行风险管理计划</code>来决定如何处理特定项目的知识领域。<br>4.<code>应急计划</code>是预定义的行动，如果发生已识别的风险事件，项目团队将采取这些行动。<br>5.<code>头脑风暴</code>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<code>德尔菲技术</code>是一种基于对未来事件的独立和匿名输入的系统化交互式预测程序。<br>6.项目经理可以绘制风险对<code>概率/影响矩阵或图表</code>的概率和影响，其中列出了风险发生的相对概率和风险发生的相对影响。<br>7.<code>十大风险项目跟踪</code>是一种定性风险分析工具。<br>8.已识别的风险可能<code>无法实现</code>，或者其发生或丧失的可能性可能会<code>减少</code>。</p><h4 id="项目采购管理"><a href="#项目采购管理" class="headerlink" title="项目采购管理"></a><a href="#第12章-项目采购管理">项目采购管理</a></h4><p>1.提供采购服务的组织或个人称为<code>供应商</code>。供应商也称为供应商，承包商，分包商或销售商。<br>2.在外包时，组织应谨慎保护可能在供应商手中易受攻击的<code>战略信息</code>。<br>3.计划采购涉及通过使用组织外部的产品或服务来确定最佳地满足哪些项目需求。如果不需要从组织外部购买产品或服务，则<code>不需要进一步的采购管理</code>。<br>4.成本可偿还合同通常包括费用，例如利润百分比或达到或超过选定项目目标的激励。与固定价格合同相比，买方通过<code>成本可偿还合同</code>承担更多风险。<br>5.<code>固定价格（FFP）</code>合约对买方的风险最小，其次是<code>固定价格激励费（FPIF）</code>合约。<br>6.制造或购买分析涉及估算提供产品或服务的内部成本，并将估算与外包成本进行<code>比较</code>。<br>7.如果公司使用设备20天，他们最好<code>租赁</code>，总费用为10,000美元（20 x 500美元）。 10,000美元的购买成本将增加2,000美元的运营成本（20 x 100美元）。<br>8.评估投标的关键因素，特别是涉及IT的项目，是投标人<code>过去的业绩记录</code>。检查性能记录和参考可以<code>降低</code>选择跟踪记录不佳的供应商的<code>风险</code>。<br>9.控制采购可确保卖方的<code>业绩符合合同要求</code>。合同关系是一种法律关系，这意味着它受州和联邦合同法的约束。</p><h4 id="项目利益相关者管理"><a href="#项目利益相关者管理" class="headerlink" title="项目利益相关者管理"></a>项目利益相关者管理</h4><p>1.与通信和人力资源管理相关的许多概念也<code>适用</code>于利益相关者管理，但需要开展<code>独特的活动</code>以实现良好的利益相关者管理。<br>2.<code>识别</code>利益相关者涉及识别参与项目或受其影响的每个人，并确定<code>管理</code>与他们之间关系的最佳方式。该过程的主要输出是<code>利益相关者登记</code>。<br>3.内部项目利益相关者通常<code>包括</code>项目发起人，项目团队，支持人员和项目的内部客户。其他内部利益相关者包括高层管理人员，其他职能经理和其他项目经理，因为组织资源有限。<br>4.由于员工流动，合作伙伴关系和其他事件，利益相关者可能在项目期间发生<code>变化</code>。<br>5.领先的利益相关者是了解项目及其潜在影响并积极参与<code>帮助项目成功</code>的人<br>6.项目经理必须了解并与各利益相关方合作;因此，他们应该专门讨论如何使用各种沟通方法及其人际关系和管理技能来<code>吸引利益相关者</code>。<br>7.您无法控制利益相关者，但您可以<code>监控干系人的参与程度</code>。参与涉及对话，人们寻求理解和解决共同关心的问题。<br>8.应邀请主要利益攸关方积极<code>参加启动会议</code>，而不仅仅是参加会议。项目经理应该强调，会议<code>期望进行对话</code>，包括利益相关者喜欢的文本或任何沟通方式。</p><h3 id="填空题"><a href="#填空题" class="headerlink" title="填空题"></a>填空题</h3><h4 id="第4章-项目集成管理"><a href="#第4章-项目集成管理" class="headerlink" title="第4章 - 项目集成管理"></a>第4章 - 项目集成管理</h4><ol><li>____涉及通过分析优势和劣势，研究机会和威胁，预测未来趋势以及预测新产品和服务的需求来确定长期目标。<br>答案：战略规划</li><li>____涉及分析公司的优势，劣势，机会和威胁，并用于协助战略规划。<br>答案：SWOT分析</li><li>____是一种技术，它使用从核心思想辐射出来的分支来构建思想和想法。<br>答案：思维导图</li><li>____指的是改善组织的机会。<br>答案：机遇</li><li>____是从效益中减去项目成本然后除以成本的结果。<br>答案：投资回报率（ROI）</li><li>____是一种工具，它提供了一个基于许多标准选择项目的系统过程。<br>答案：加权评分模型</li><li>____是记录的起点，测量或观察，以便可以用于将来的比较。变化。<br>答案：基线</li><li>____涉及在整个项目生命周期中识别，评估和管理变更。<br>答案：综合变更控制</li></ol><h4 id="第5章-项目范围管理"><a href="#第5章-项目范围管理" class="headerlink" title="第5章 - 项目范围管理"></a>第5章 - 项目范围管理</h4><ol><li>____创建涉及将主要项目可交付成果细分为更小，更易于管理的组件。<br>答案：工作分解结构（WBS）</li><li>____是指“项目必须满足的条件或能力，或者在产品，服务或结果中出现以满足协议或其他正式规定的条件或能力。”<br>答案：要求</li><li>____包括已批准的项目范围声明及其关联的WBS和WBS字典。<br>答案：范围基线</li><li>工作包是WBS的____级任务。<br>答案：最低</li><li>____在创建WBS的方法中，团队成员首先确定尽可能多的与项目相关的特定任务。<br>答案：自下而上</li><li>____是一种技术，它使用从核心思想中散发出来的分支来构建创建WBS时的思想和想法。<br>答案：思维导图</li><li>____是项目范围越来越大的趋势。<br>答案：范围蔓延</li><li>____执行范围验证的主要工具是和小组决策制定技术。<br>答案：检查</li><li>____涉及开发系统的工作副本或系统的某些方面。<br>答案：原型设计</li></ol><h4 id="第6章-项目进度管理"><a href="#第6章-项目进度管理" class="headerlink" title="第6章 - 项目进度管理"></a>第6章 - 项目进度管理</h4><ol><li>____是完成任务所需的工作日或工作小时数。<br>答案：努力</li><li>在项目进度表中，灵活性最小的变量是____。<br>答案：时间</li><li>____涉及确保及时完成项目所需的过程。<br>答案：项目进度管理</li><li>____是要列入项目进度表的活动的表格。<br>答案：活动清单</li><li>____是项目活动及其排序之间逻辑关系的示意图。<br>答案：网络图</li><li>在____关系中，“from”活动必须在“to”活动完成之前开始。<br>答案：从头到尾</li><li>____没有持续时间和资源，但偶尔需要在AOA网络图上显示活动之间的逻辑关系。<br>答案：虚拟活动</li></ol><h4 id="第7章-项目成本管理"><a href="#第7章-项目成本管理" class="headerlink" title="第7章 - 项目成本管理"></a>第7章 - 项目成本管理</h4><ol><li>____过程的主要成果是活动成本估算，估算基础和项目文件更新。<br>答案：成本估算</li><li>____流程的主要成果是成本绩效基准，项目资金要求和项目文件更新。<br>答案：成本预算</li><li>____理论指出，当重复生产许多物品时，随着生产更多单位，这些物品的单位成本会以规律的方式减少。<br>答案：学习曲线</li><li>____估算是在项目的早期阶段或甚至在项目正式启动之前完成的。<br>答案：粗略的数量级（ROM）</li><li>____是项目经理用来衡量和监控成本绩效的分阶段预算。<br>答案：成本基准</li></ol><h4 id="第8章-项目质量管理"><a href="#第8章-项目质量管理" class="headerlink" title="第8章 - 项目质量管理"></a>第8章 - 项目质量管理</h4><ol><li>____这个词意味着产品可以按照预期使用。<br>答案：适合使用</li><li>____是一种质量计划技术，有助于确定哪些变量对过程的总体结果影响最大。<br>答案：实验设计</li><li>____图表将有关质量问题的投诉追溯到负责任的生产操作。<br>答案：因果关系<br>鱼刺<br>石川</li><li>Watts S. Humphrey将____定义为在交付程序之前必须更改的任何内容。<br>答案：软件缺陷</li><li>____是一个公司部门的非监督人员和工作领导小组，他们自愿组织如何提高部门工作效率的小组研究。<br>答案：质量圈子</li><li>____意味着对失败负责或不满足质量期望。<br>答案：不合格的成本</li><li>Genichi Taguchi的____方法着重于通过用科学探究替代试错法来消除缺陷。<br>答案：稳健的设计</li></ol><h4 id="第9章-项目资源管理"><a href="#第9章-项目资源管理" class="headerlink" title="第9章 - 项目资源管理"></a>第9章 - 项目资源管理</h4><ol><li>根据马斯洛的说法，只有满足____需求后，个人才能满足增长需求。<br>答案：缺陷</li><li>赫茨伯格称之为导致工作满意度的因素____。<br>答案：激励者</li><li>____是整体等于其各部分之和的概念。<br>答案：协同作用</li><li>____正在倾听，意图理解。<br>答案：移情倾听</li><li>____是和谐，一致，一致或亲和的关系，对沟通很重要。<br>答案：交流</li><li>____根据所需的详细程度将工作分配给负责任和执行的组织，团队或个人。<br>答案：责任分配矩阵（RAM）</li><li>____是一种特定类型的组织结构图，显示哪些组织单位负责哪些工作项。<br>答案：OBS（组织分解结构）</li></ol><h4 id="第10章-项目沟通管理"><a href="#第10章-项目沟通管理" class="headerlink" title="第10章 - 项目沟通管理"></a>第10章 - 项目沟通管理</h4><ol><li><p>许多信息技术专业人员在<strong>_</strong>项目中工作，他们从未与项目赞助商，其他团队成员或其他项目利益相关者会面。<br>答案：虚拟</p></li><li><p>____分析包括信息的联系人，信息到期时以及信息的首选格式等信息。<br>答案：利益相关方沟通</p></li><li>在试图评估项目利益相关者的承诺时，<strong>_</strong>会议或网络会议可能是最合适的媒介。<br>答案：面对面</li><li>控制通信的主要目标是确保整个____的最佳信息流。<br>答案：项目生命周期</li><li>所有会议必须有____和预期结果。<br>答案：目的</li><li>____强制会议组织者计划会议，并让潜在参与者有机会决定是否需要参加。<br>答案：议程</li></ol><h4 id="第11章-项目风险管理"><a href="#第11章-项目风险管理" class="headerlink" title="第11章 - 项目风险管理"></a>第11章 - 项目风险管理</h4><ol><li>项目<strong>_</strong>是一种不确定性，可能对实现项目目标产生负面或正面影响。<br>答案：风险</li><li>是从潜在收益中获得的满足或愉悦的数量。<br>答案：风险效用</li><li>是项目潜在风险类别的等级。<br>答案：风险分解结构</li><li>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<br>答案：头脑风暴</li><li>是包含各种风险管理流程结果的文件。<br>答案：风险登记</li><li>是风险事件概率和风险事件货币价值的乘积。<br>答案：EMV<br>预期的货币价值<br>预期货币价值（EMV）<br>EMV（预期货币价值）</li><li>风险是在实施所有应对策略后仍然存在的风险。<br>答案：剩余</li></ol><h4 id="第12章-项目采购管理"><a href="#第12章-项目采购管理" class="headerlink" title="第12章-项目采购管理"></a>第12章-项目采购管理</h4><ol><li>____是指从外部来源获取商品和/或服务的过程。<br>答案：采购</li><li>____是一项具有相互约束力的协议，规定卖方有义务提供指定的产品或服务，并规定买方有义务支付这些产品或服务。<br>答案：合同</li><li>____决定是指组织决定在组织内部制造某些产品或执行某些服务是否符合其最佳利益，或者是否最好从外部组织购买。<br>答案：制造或购买</li><li>____合同包括由于通货膨胀等条件的变化而对合同价格进行预定义的最终调整的特殊规定。<br>答案：固定价格与经济价格调整（FP-EPA），固定价格与经济，价格调整，FP-EPA</li><li>____合同是固定价格和成本可偿还合同的混合体。<br>答案：时间和材料（T＆M），时间和材料，T＆M</li><li>____是允许买方或供应商终止合同的合同条款。<br>答案：终止条款</li><li>____是卖方在满足买方需求时采用不同方法编制的文件。<br>答案：提案</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GooLeNet</title>
    <link href="http://yoursite.com/2018/12/07/GooLeNet/"/>
    <id>http://yoursite.com/2018/12/07/GooLeNet/</id>
    <published>2018-12-07T02:44:09.000Z</published>
    <updated>2018-12-11T12:40:45.132Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】未完待续</p><a id="more"></a><p>参考链接：<a href="https://blog.csdn.net/shuzfan/article/details/50738394#googlenet-inception-v2" target="_blank" rel="noopener">GoogLeNet系列解读</a>、<a href="https://blog.csdn.net/qq_31531635/article/details/72232651" target="_blank" rel="noopener">深度学习之GoogLeNet解读</a>、<a href="https://www.jianshu.com/p/33197e469414" target="_blank" rel="noopener">GoogLeNet的心路历程</a></p><p>ToRead：<a href="https://blog.csdn.net/docrazy5351/article/details/78993269" target="_blank" rel="noopener">深入理解GoogLeNet结构</a></p><h2 id="GoogLeNet-Incepetion-V1"><a href="#GoogLeNet-Incepetion-V1" class="headerlink" title="GoogLeNet Incepetion V1"></a>GoogLeNet Incepetion <a href="https://www.jianshu.com/p/a2ad00eddbd5" target="_blank" rel="noopener">V1</a></h2><p>GoogLeNet, 一个22层的深度网络，2014年ILSVRC挑战赛冠军，将Top5 的错误率降低到6.67%。这是一种 类似于 <strong>网中网（Network In Network）</strong>的结构，即原来的结点也是一个网络。</p><p>这是GoogLeNet的最早版本，出现在2014年的《<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Going deeper with convolutions</a>》。之所以名为“GoogLeNet”而非“GoogleNet”,文章说是为了向早期的LeNet致敬。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>深度学习以及神经网络快速发展，人们不再只关注更给力的硬件、更大的数据集、更大的模型，而是更在意新的idea、新的算法以及模型的改进。</p><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生<strong>过拟合</strong>也会大大<strong>增加计算量</strong>。</p><p>文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献1表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。<strong>这点表明臃肿的稀疏网络可能被不失性能地简化。</strong> 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。</p><p>早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了<code>随机稀疏连接</code>。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。</p><p>所以，现在的问题是有没有一种方法，<strong>既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能</strong>。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。</p><h3 id="Architectural-Details"><a href="#Architectural-Details" class="headerlink" title="Architectural Details"></a>Architectural Details</h3><p>Inception 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。<br>作者首先提出下图这样的基本结构： </p><center><br>    <img src="/2018/12/07/GooLeNet/V1_Figure2(a).jpg" style="zoom:60%"><br></center><p>对上图做以下说明：<br>1 . 采用不同大小的卷积核意味着不同大小的感受野，最后拼接<code>意味着不同尺度特征的融合</code>；<br>2 . 之所以卷积核大小采用1、3和5，主要是<code>为了方便对齐</code>。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以<code>直接拼接</code>在一起了；<br>3 . 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。<br>4 . 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p><p><strong>但是，使用5x5的卷积核仍然会带来巨大的计算量</strong>。 为此，文章借鉴NIN，采用<code>1x1卷积核来进行降维</code>。<br>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。<a href="https://blog.csdn.net/capecape/article/details/78296796#4维度计算" target="_blank" rel="noopener">详细的降维计算过程</a></p><p>具体改进后的Inception Module如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure2(b).jpg" style="zoom:60%"><br></center><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p>GoogLeNet的整体结构如下图：</p><center><br><img src="/2018/12/07/GooLeNet/GooLeNet.jpg" style="zoom:60%"><br></center><p>对上图做如下说明：<br>1 . 显然GoogLeNet采用了模块化的结构，方便增添和修改；<br>2 . 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；<br>3 . 虽然移除了全连接，但是网络中依然使用了Dropout ;<br>4 . 为了<code>避免梯度消失</code>，网络额外增加了2个辅助的softmax（average pooling）用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</p><p>下图是一个比较清晰的结构图：</p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure3.jpg" style="zoom:60%"><br></center><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>GoogLeNet是谷歌团队为了参加ILSVRC 2014比赛而精心准备的，为了达到最佳的性能，除了使用上述的网络结构外，还做了大量的辅助工作：包括训练多个model求平均、裁剪不同尺度的图像做多次验证等等。详细的这些可以参看文章的实验部分。</p><p>本文的主要想法其实是想通过<code>构建密集的块结构来近似最优的稀疏结构</code>，从而达到<code>提高性能而又不大量增加计算量</code>的目的。GoogleNet的caffemodel大小约50M，但性能却很优异。</p><h2 id="GoogLeNet-Inception-V2"><a href="#GoogLeNet-Inception-V2" class="headerlink" title="GoogLeNet Inception V2"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/4270f5acc066" target="_blank" rel="noopener">V2</a></h2><ul><li><a href="https://link.jianshu.com?t=http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>，top5 error 4.8%</li></ul><p>这篇文章做出的贡献不是一般的大，它提出了Batch Normalization（BN），以至于网上关于它的介绍铺天盖地，但中文优秀原创没几个，都是转载来转载去，挑几个好的比如：<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/u012816943/article/details/51691868" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="noopener"><strong>这个</strong></a>。</p><h2 id="GoogLeNet-Inception-v3"><a href="#GoogLeNet-Inception-v3" class="headerlink" title="GoogLeNet Inception v3"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/0cc42b8e6d25" target="_blank" rel="noopener">v3</a></h2><p>GoogLeNet凭借其优秀的表现，得到了很多研究人员的学习和使用，因此Google团队又对其进行了进一步发掘改进，产生了升级版本的GoogLeNet。这一节介绍的版本记为V2，文章为：《<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a>》。</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>14年以来，构建更深的网络逐渐成为主流，但是模型的变大也使计算效率越来越低。这里，文章试图找到一种方法在<strong>扩大网络的同时又尽可能地发挥计算性能</strong>。</p><p>首先，GoogLeNet V1出现的同期，性能与之接近的大概只有VGGNet了，并且二者在图像分类之外的很多领域都得到了成功的应用。但是相比之下，GoogLeNet的计算效率明显高于VGGNet，大约只有500万参数，只相当于Alexnet的1/12(GoogLeNet的caffemodel大约50M，VGGNet的caffemodel则要超过600M)。</p><p>GoogLeNet的表现很好，但是，如果想要通过简单地放大Inception结构来构建更大的网络，则会立即提高计算消耗。此外，在V1版本中，文章也没给出有关构建Inception结构注意事项的清晰描述。因此，在文章中作者<strong>首先给出了一些已经被证明有效的用于放大网络的通用准则和优化方法</strong>。这些准则和方法适用但不局限于Inception结构。</p><h3 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h3><p>下面的准则来源于大量的实验，因此包含一定的推测，但实际证明基本都是有效的。</p><p><strong>1 . 避免表达瓶颈，特别是在网络靠前的地方</strong>。 信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。<br>另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）</p><p><strong>2 . 高维特征更易处理</strong>。 高维特征更易区分，会加快训练。</p><p><strong>3. 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息</strong>。 比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。</p><p><strong>4 . 平衡网络的宽度与深度</strong>。</p><p>上述的这些并不能直接用来提高网络质量，而<code>仅用来在大环境下作指导</code>。</p><h3 id="Factorizing-Convolutions-with-Large-Filter-Size"><a href="#Factorizing-Convolutions-with-Large-Filter-Size" class="headerlink" title="Factorizing Convolutions with Large Filter Size"></a>Factorizing Convolutions with Large Filter Size</h3><p>大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。为此，作者提出可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量)如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure1.jpg" style="zoom:80%"><br></center><p>然后就会有2个疑问：</p><p><strong>1 . 这种替代会造成表达能力的下降吗？</strong><br>后面有大量实验可以表明<code>不会造成表达缺失</code>；</p><p><strong>2 . 3x3卷积之后还要再加激活吗？ </strong><br>作者也做了对比试验，表明添加非线性激活会提高性能。</p><p>从上面来看，大卷积核完全可以由一系列的3x3卷积核来替代，那能不能分解的更小一点呢。文章考虑了 <strong>nx1</strong> 卷积核。<br>如下图所示的取代3x3卷积： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure3.jpg" style="zoom:80%"><br></center><p>于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，作者发现<strong>在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好</strong>。（对于mxm大小的feature map,建议m在12到20之间）。</p><p>总结如下图：</p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure4_5_6.jpg" style="zoom:80%"><br></center><p><strong>(1)</strong> 图4是GoogLeNet V1中使用的Inception结构；</p><p><strong>(2)</strong> 图5是用3x3卷积序列来代替大卷积核；</p><p><strong>(3)</strong> 图6是用nx1卷积来代替大卷积核，这里设定n=7来应对17x17大小的feature map。该结构被正式用在GoogLeNet V2中。</p><h2 id="GoogLeNet-Inception-v4"><a href="#GoogLeNet-Inception-v4" class="headerlink" title="GoogLeNet Inception v4"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/e0464e8d6db4" target="_blank" rel="noopener">v4</a></h2><ul><li><a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1602.07261" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>，top5 error 3.08%</li></ul><p>Szegedy读了此<a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener"><strong>论文</strong></a>后，蹦出了结合GoogLeNet与Residual Connections的奇思妙想，于是就有了上面那篇论文，主要贡献如下：</p><ul><li>1、在Inception v3的基础上发明了Inception v4，v4比v3更加复杂，复杂到不可思议</li><li>2、结合ResNet与GoogLeNet，发明了Inception-ResNet-v1、Inception-ResNet-v2，其中Inception-ResNet-v2效果非常好，但相比ResNet，Inception-ResNet-v2的复杂度非常惊人，跟Inception v4差不多</li><li>3、加入了Residual Connections以后，网络的训练速度加快了</li><li>4、在网络复杂度相近的情况下，Inception-ResNet-v2略优于Inception-v4</li><li>5、Residual Connections貌似只能加速网络收敛，真正提高网络精度的是“<strong>更大的网络规模</strong>”</li></ul><p>以上就是Inception v4论文的主要贡献了，没有什么创新，只是在前人的基础上修修补补、移花接木，但这篇文章工作量不小，需要花费大量时间训练作者提出的3种网络。</p><blockquote><p>至此，GoogLeNet四篇相关论文就介绍完了，纵观GoogLeNet的发展历程，Szegedy为我们提供了许多可以借鉴的网络设计方法，比如Inception结构、非对称卷积、Batch Normalization、取消全连层……等等。就连Szegedy本人，也汲取了ResNet的精髓，合体两种网络设计出了Inception-ResNet。所以多读论文，多学习别人的idea，是非常重要的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】未完待续&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>DenseNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/03/DenseNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/03/DenseNet-Introduction/</id>
    <published>2018-12-03T08:39:14.000Z</published>
    <updated>2018-12-03T15:26:59.184Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>原文链接：<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">Densely Connected Convolutional Netwroks</a></p><p>译文链接：<a href="https://zhuanlan.zhihu.com/p/31647627" target="_blank" rel="noopener">DenseNet论文翻译及pytorch实现解析（上）</a>、<a href="https://blog.csdn.net/tumi678/article/details/78667966" target="_blank" rel="noopener">Densely Connected Convolutional Networks翻译</a></p><p>参考链接：<a href="https://blog.csdn.net/u014380165/article/details/75142664" target="_blank" rel="noopener">DenseNet算法详解(ToRead  评价最高)</a>、<a href="https://zhuanlan.zhihu.com/p/28190802" target="_blank" rel="noopener">《Densely Connected Convolutional Networks》论文笔记（精而简）</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络（简明）</a>、<a href="https://www.leiphone.com/news/201708/0MNOwwfvWiAu43WO.html" target="_blank" rel="noopener">DenseNet 的“what”、“why”和“how”(思路清晰)</a>、<a href="https://zhuanlan.zhihu.com/p/43057737" target="_blank" rel="noopener">DenseNet详解(图解清晰)</a></p><p>ToRead：<a href="https://blog.csdn.net/Bryan__/article/details/77337109" target="_blank" rel="noopener">DenseNet 简介(数学说明)</a>、<a href="https://zhuanlan.zhihu.com/p/37189203" target="_blank" rel="noopener">DenseNet：比ResNet更优的CNN模型(形象细致)</a></p><p><strong>DenseNet的优点</strong>：</p><ul><li>减轻梯度消失的问题；</li><li>加强了特征的<code>传导</code>和<code>利用</code>；</li><li>减少了参数量（与ResNet相比，在实现同等准确率的条件下，DenseNet的参数量要小于ResNet）</li><li>减少了计算量</li></ul><h4 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h4><h5 id="Dense-block"><a href="#Dense-block" class="headerlink" title="Dense block"></a><strong>Dense block</strong></h5><p>​    网络的每一层都直接与其前面层相连（可以直接将梯度从后层传向前层），实现<code>特征的重复利用</code>，这就使得网络更加“参数高效”。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure1.jpg" style="zoom:80%"><br></center><h5 id="Transition-layer"><a href="#Transition-layer" class="headerlink" title="Transition layer"></a><strong>Transition layer</strong></h5><p>​    该层位于两个dense block之间，由conv层和pooling层组成。之前说过，在一个dense block里，空间维度是保持不变的，为了能进行下采样，故而在两个dense block之间插入transition layer，进一步减少特征图的数量，提升模型的紧凑程度。</p><h5 id="Growth-rate"><a href="#Growth-rate" class="headerlink" title="Growth rate"></a><strong>Growth rate</strong></h5><p>​    论文里涉及到growth rate这个概念。它指的是一个dense block里各个层输出feature maps的通道数，在同一个dense block里bn-relu-conv输出的通道数都是一样的。如上图，它的growth rate=4。一般，为了不使网络变得太宽，以及增加参数的利用效率，growth rate一般不会设得太大。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table1.jpg"><br></center><h5 id="Bottleneck-layers"><a href="#Bottleneck-layers" class="headerlink" title="Bottleneck layers "></a><strong>Bottleneck layers </strong></h5><p>​    在一个dense block里，尽管每层输出的通道数并不大（growth rate一般不会设得很大），但是输入是由前面层的feature maps串接起来的，所以输入的通道数会很大。为了提高计算效率，作者<code>引进1*1 conv层作为bottleneck layer，放置在每层的前面，用来降低通道数(减小参数量)</code>。带有bottleneck layer的DenseNet被称为DenseNet-B。</p><h5 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a><strong>Compression</strong></h5><p>​    如果transition layer对上一个dense block进行了通道数的降维（即压缩），则称这类DenseNet为    <code>DenseNet-C</code>。同时使用了bottleneck layer和compression的DenseNet称为<code>DenseNet-BC</code>。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure4_left.png"><br></center><p>上图是DenseNet和它的几种变体进行parameter efficiency 的比较，可以看出在实现同等accuracy的条件下，DenseNet-BC所用的参数量最少，实现最大的parameter efficiency。</p><hr><p>完整的DenseNet网络结构：</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure2.png"><br>    <figcaption>Figure 2</figcaption><br></center><p>上图是由三个dense block组成的，两个block之间的conv+pool为transition layer。dense block3后面的pooling是global average pooling，然后再接一个全连接层+softmax。</p><hr><h4 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><strong>算法分析</strong></h4><h5 id="Model-compactness"><a href="#Model-compactness" class="headerlink" title="Model compactness"></a>Model compactness</h5><p>由于DenseNet对输入进行cat操作,一个直观的影响就是每一层学到的feature map都能被之后所有层直接使用,这使得特征可以在整个网络中重用,也使得模型更加简洁.</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure4.jpg"><br></center><p>从上图中我们可以看出DenseNet的参数效率:左图包含了对多种DenseNet结构参数和最终性能的统计,我们可以看出当模型实现相同的test error时,原始的DenseNet往往要比DenseNet-BC拥有2-3倍的参数量.中间图为DenseNet-BC与ResNet的对比,在相同的模型精度下,DenseNet-BC只需要ResNet约三分之一的参数数量.右图为1001层超过10M参数量的ResNet与100层只有0.8M参数量的DenseNet-BC在训练时的对比,虽然他们在约相同的训练epoch时收敛,但DenseNet-BC却只需要ResNet不足十分之一的参数量.</p><h5 id="Implicit-Deep-Supervision"><a href="#Implicit-Deep-Supervision" class="headerlink" title="Implicit Deep Supervision"></a>Implicit Deep Supervision</h5><p>解释DenseNet为何拥有如此高性能的另一个原因是网络中的每一层不仅接受了原始网络中来自loss的监督,同时由于存在多个bypass与shortcut,网络的监督是多样的.Deep supervision的优势同样在deeply-supervised nets (DSN)中也被证实.(DSN中每一个Hidden layer都有一个分类器,强迫其学习一些有区分度的特征).与DSN不同的是,DenseNet拥有单一的loss function, 模型构造和梯度计算更加简易.</p><h5 id="Feature-Reuse"><a href="#Feature-Reuse" class="headerlink" title="Feature Reuse"></a>Feature Reuse</h5><p>在设计初,DenseNet便被设计成让一层网络可以使用所有之前层网络feature map的网络结构,为了探索feature的复用情况,作者进行了相关实验.作者训练的L=40,K=12的DenseNet,对于任意Denseblock中的所有卷积层,计算之前某层feature map在该层权重的绝对值平均数.这一平均数表明了这一层对于之前某一层feature的利用率,下图为由该平均数绘制出的热力图:</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure5.jpg" style="zoom:60%"><br></center><p>从图中我们可以得出以下结论:</p><p>a) 一些较早层提取出的特征仍可能被较深层直接使用<br>b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征<br>c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,即Compression的必要性.<br>d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生.</p><h4 id="实现结果"><a href="#实现结果" class="headerlink" title="实现结果"></a>实现结果</h4><p>作者在多个benchmark数据集上训练了多种DenseNet模型,并与state-of-art的模型(主要是ResNet和其变种)对比:</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table2.jpg"><br></center><p>由上表我们可以看出,DenseNet只需要较小的Growth rate(12,24)便可以实现state-of-art的性能,结合了Bottleneck和Compression的DenseNet-BC具有远小于ResNet及其变种的参数数量,且无论DenseNet或者DenseNet-BC,都在原始数据集和增广数据集上实现了超越ResNet的性能.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ResNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/02/ResNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/02/ResNet-Introduction/</id>
    <published>2018-12-02T11:03:11.000Z</published>
    <updated>2018-12-03T14:35:38.115Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>论文出处：<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>译文链接：<a href="http://blog.csdn.net/wspba/article/details/57074389" target="_blank" rel="noopener">http://blog.csdn.net/wspba/article/details/57074389</a></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/32085715" target="_blank" rel="noopener">ResNet学习笔记</a>、<a href="https://www.jianshu.com/p/46d76bd56766" target="_blank" rel="noopener">深度详解ResNet及其六大变体</a>、<a href="https://www.jianshu.com/p/e58437f39f65" target="_blank" rel="noopener">残差网络ResNet笔记</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络</a></p><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>随着CNN网络的发展，尤其的VGG网络的提出，大家发现网络的层数是一个关键因素，貌似越深的网络效果越好。但是<code>随着网络层数的增加，问题也随之而来</code>。</p><p>首先出现的问题是<strong>梯度消失/梯度爆炸</strong>，这就导致训练难以收敛。<code>归一初始化</code>（normalized initialization）和<code>中间归一化</code>（intermediate normalization）在很大程度上解决了这一问题，它使得数十层的网络在反向传播的随机梯度下降（SGD）上能够收敛。</p><p>当深层网络能够收敛时，一个<strong>退化</strong>问题又出现了：随着网络深度的增加，准确率达到饱和然后迅速退化。意外的是，这种退化<strong>并不是由过拟合造成的</strong>，并且在一个合理的深度模型中增加更多的层却导致了<strong>更高的错误率</strong>。<strong>Fig.1</strong>展示了一个典型的例子：</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 1.jpg" style="zoom:80%"><br></center><br>对于更深的模型，这有一种通过构建的解决方案：<strong>恒等映射identity mapping</strong>(所谓的恒等映射，即输入$x$经过某一个函数（设为$G(x)$）作用输出还是$x$本身，即$G(x)=x$)，来构建增加的层，而其它层直接从浅层模型中复制而来。这个构建的解决方案也表明了，一个更深的模型不应当产生比它的浅层版本更高的训练错误率。但是，<strong>相关的实验结果说明传统的网络（”plain” networks）很难去学习恒等映射</strong>，即会出现因为深度增加而导致性能下降的问题（即使采用了恒等映射方法）。<br><br>#### Identity Mapping by Shortcuts<br><br>本文中，我们提出了一种<strong>深度残差学习</strong>框架来解决这种因为深度增加而导致性能下降的问题。<br>我们假设$F(x)$代表某个只包含有两三层的block的映射函数， $x$ 是block的输入，$F(x)$ 是block的输出。假设他们具有相同的维度。在训练的过程中我们希望能够通过修改网络中的 $w$ 和 $b$ 去拟合一个理想的 $\mathcal{H}(x)$ (从输入到输出的一个理想的映射函数)。也就是我们的目标是修改 $\mathcal{F}(x)$ 中的 $w$ 和 $b$ 逼近 $\mathcal{H}(x)$ 。<br>如果我们改变思路，用$\mathcal{F}(x)$  来逼近$\mathcal{H}(x)-x$，那么我们最终得到bolck的输出$\mathcal{H}(x)$就由 $\mathcal{F}(x)$ 变为$\mathcal{F}(x)+x$ （这里的加指的是对应位置上的元素相加，也就是element-wise addition），这里的直接将输入连接到输出的结构也称为shortcut。 这里我们假设优化残差映射$\mathcal{F}({x})$比优化原来的映射 $\mathcal{H}({x})$容易。<br><br>- 改变前目标： 训练$\mathcal{F}(x)$ 逼近 $\mathcal{H}(x)$<br>- 改变后目标：训练 $\mathcal{F}(x)$ 逼近$\mathcal{H}(x)-x$   (即 $\mathcal{F}(x)+x$ 逼近$\mathcal{H}(x)$)<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 2.1.jpg" style="zoom:80%"><br></center><br>左边的original block需要调整其内部参数，使得输入的x经过卷积操作后最终输出的F(x)等于x，即实现了恒等映射F(x)=x，等号左边是block的输出，右边是block的输入。但是这种结构的卷积网络很难调整其参数完美地实现F(x)=x。再看右边的Res block。因为shortcut的引入，整个block的输出变成了F(x)+x，block的输入还是x。此时网络需要调整其内部参数使得F(x)+x=x，也就是直接令其内部的所有参数为0，使得F(x)=0，F(x)+x=x就变成了0+x = x，等号左边是block的输出，右边是block的输入。输出等于输入，即<strong>完美地完成了恒等映射</strong>。因此使用ResNet结构搭建的深度网络至少与浅层网络具有相同的拟合能力，不会出现之前的网络退化问题。<br><br>——<br><br><br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 2.png" style="zoom:40%"><br></center><br><strong>We consider a building block defined as</strong>：  $\begin{equation} {y}= \mathcal{F}({x}, {W_{i}}) + W_{s}{x}. \end{equation}$<br><br><br>#### Shortcut的三种方式<br><br>由于ResNet要求 $F(x)$与 $x$ 的维度大小要一致才能够相加，因此在$F(x)$ 与$x$ 维度不相同时就需要对$x$的维度做调整，文章中提出了三种调整的方式：<br><br>1. 如果 $x$ 的维度增加，就使用0来填充增加出来的维度（A方式）<br>2. 如果 $x$ 的维度增加，使用线性变换来增加多出来的维度，在程序里表现为使用一个1x1的卷积核进行调整维度（B方式）<br>3. 对于所有的shortcut，都使用线性变换，也就是1x1的卷积（C方式）<br><br>由下面的实验结果可以，分析ABC这三种方式。A方式采用0填充.，完全不存在任何的残差学习能力。B方式与C方式相比，错误率略高。但是B方式的模型复杂度要远低于C方式，因此，作者最终在所有的网络中采用方式B。B方式在 $x$ 的维度与$F(x)$的维度相同时，直接用 $x$ 加上 $F(x)$，在 $x$ 的维度与 $F(x)$的维度不同时，才采用1x1的卷积层对 $x$ 的维度进行调整。<br><br>——<br><br>#### 对ResNet的解读<br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/shortcuts_1.png" style="zoom:80%"><br></center><p>ResNet架构有很多独立有效路径（或者说残差网络其实是很多并行子网络的组合），而且大部分路径在移除了部分层之后会保持完整无损。相反，VGG网络只有一个有效路径，因此移除一个层都会对它的唯一路径的性能产生极大的影响。</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/distribution of path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/gradient magnitude per path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/total gradient magnitude per path length.png" width="200"><br></center><p>图(左)大部分的路径都流经了19到35个残差块。为了得到路径长度k的梯度幅度，作者们首先向网络输入了一批数据，然后任意采样了k个残差块。当反向传递梯度时，他们仅将采样的残差块通过权重层进行传递。图(中)表示随着路径长度的增加，梯度幅度会迅速下降。我们现在可以将每一路径长度与其期望的梯度大小相乘，看每一路径长度在训练中起到多大的作用，就像图(右)。</p><p>令人惊讶的是，大多分布都来自于9到18的路径长度，但它们都只包含少量的总路径（或者说ResNet是由大多数中度网络和一小部分浅度网络和深度网络组成的，说明虽然表面上ResNet网络很深，但是其实起实际作用的网络层数并没有很深。），如图(左)。这是一个非常有趣的发现，因为这暗示着<code>ResNet无法解决过长路径的梯度消失问题</code>，<strong>ResNet的成功实际上源自于它缩短了它的有效路径(effective path)的长度</strong>。</p><p> Stochastic depth通过在训练期间随机丢弃层来改善深度残留网络的训练。这表明并不是所有的层都是需要的，并且强调在深度（剩余）网络中存在大量的冗余。</p><hr><h4 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h4><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 3.png" style="zoom:40%"><br></center><br>Plain Network 主要是受 VGG 网络启发，主要采用<strong>3*3滤波器</strong>，遵循两个设计原则：1）对于相同输出特征图尺寸，卷积层有相同个数的滤波器，2）如果特征图尺寸缩小一半，滤波器个数加倍以保持每个层的计算复杂度。通过<strong>步长为2的卷积</strong>来进行降采样。一共<strong>34个权重层</strong>。<br>需要指出，我们这个网络<code>与VGG相比，滤波器要少，复杂度要小</code>。<br><br>Residual Network 主要是在 上述的 plain network上加入 shortcut connections。<strong>ResNet的结构使得网络具有与学习恒等映射的能力，同时也具有学习其他映射的能力。因此ResNet的结构要优于传统的卷积网络（plain networks）结构。</strong><br><br>#### Experiments<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 3.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 6.png" style="zoom:70%"><br></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Tensorboard_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Tensorboard-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Tensorboard-Morvan/</id>
    <published>2018-12-01T14:08:52.000Z</published>
    <updated>2018-12-01T14:15:06.483Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(tensorflow) ➜  Morvan_Tensorflow tensorboard --logdir logs</span><br><span class="line">TensorBoard 1.11.0 at http://MacBook-Pro:6006 (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure><ul><li>Chrome</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://0.0.0.0:6006</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/</id>
    <published>2018-12-01T13:18:30.000Z</published>
    <updated>2018-12-01T14:15:38.172Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><p>Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/plt/</a></p><h2 id="Matplotlib简介"><a href="#Matplotlib简介" class="headerlink" title="Matplotlib简介"></a>Matplotlib简介</h2><h3 id="Matplotlib-安装"><a href="#Matplotlib-安装" class="headerlink" title="Matplotlib 安装"></a>Matplotlib 安装</h3><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><h3 id="figure-图像"><a href="#figure-图像" class="headerlink" title="figure 图像"></a>figure 图像</h3><h3 id="设置坐标轴"><a href="#设置坐标轴" class="headerlink" title="设置坐标轴"></a>设置坐标轴</h3><h3 id="Legend图例"><a href="#Legend图例" class="headerlink" title="Legend图例"></a>Legend图例</h3><h3 id="Annotation标注"><a href="#Annotation标注" class="headerlink" title="Annotation标注"></a>Annotation标注</h3><h3 id="tick能见度"><a href="#tick能见度" class="headerlink" title="tick能见度"></a>tick能见度</h3><h2 id="画图种类"><a href="#画图种类" class="headerlink" title="画图种类"></a>画图种类</h2><h3 id="Scatter-散点图"><a href="#Scatter-散点图" class="headerlink" title="Scatter 散点图"></a>Scatter 散点图</h3><h3 id="Bar-柱状图"><a href="#Bar-柱状图" class="headerlink" title="Bar 柱状图"></a>Bar 柱状图</h3><h3 id="Contours-等高线图"><a href="#Contours-等高线图" class="headerlink" title="Contours 等高线图"></a>Contours 等高线图</h3><h3 id="Image-图片"><a href="#Image-图片" class="headerlink" title="Image 图片"></a>Image 图片</h3><h3 id="3D图片"><a href="#3D图片" class="headerlink" title="3D图片"></a>3D图片</h3><h2 id="多图合并显示"><a href="#多图合并显示" class="headerlink" title="多图合并显示"></a>多图合并显示</h2><h3 id="Subplot-多合一显示"><a href="#Subplot-多合一显示" class="headerlink" title="Subplot 多合一显示"></a>Subplot 多合一显示</h3><h3 id="Subplot-分格显示"><a href="#Subplot-分格显示" class="headerlink" title="Subplot 分格显示"></a>Subplot 分格显示</h3><h3 id="图中图"><a href="#图中图" class="headerlink" title="图中图"></a>图中图</h3><h3 id="次坐标轴"><a href="#次坐标轴" class="headerlink" title="次坐标轴"></a>次坐标轴</h3><h2 id="动画"><a href="#动画" class="headerlink" title="动画"></a>动画</h2><h3 id="Animation动画"><a href="#Animation动画" class="headerlink" title="Animation动画"></a>Animation动画</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
&lt;p&gt;Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>numpy&amp;pandas_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/</id>
    <published>2018-12-01T12:10:48.000Z</published>
    <updated>2018-12-01T14:16:13.563Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><a id="more"></a><hr><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/</a></p><h3 id="Numpy-和-Pandas-安装"><a href="#Numpy-和-Pandas-安装" class="headerlink" title="Numpy 和 Pandas 安装"></a>Numpy 和 Pandas 安装</h3><h4 id="numpy-安装"><a href="#numpy-安装" class="headerlink" title="numpy 安装"></a>numpy 安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install numpy</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install numpy</span></span><br></pre></td></tr></table></figure><h4 id="pandas安装"><a href="#pandas安装" class="headerlink" title="pandas安装"></a>pandas安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install pandas</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install pandas</span></span><br></pre></td></tr></table></figure><h3 id="Numpy属性"><a href="#Numpy属性" class="headerlink" title="Numpy属性"></a>Numpy属性</h3><ul><li><code>ndim</code>：维度</li><li><code>shape</code>：行数和列数</li><li><code>size</code>：元素个数</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#为了方便使用numpy 采用np简写</span></span><br><span class="line">array = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])  <span class="comment">#列表转化为矩阵</span></span><br><span class="line">print(array)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 2, 3],</span></span><br><span class="line"><span class="string">       [2, 3, 4]])</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">print(<span class="string">'number of dim:'</span>,array.ndim)  <span class="comment"># 维度</span></span><br><span class="line"><span class="comment"># number of dim: 2</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'shape :'</span>,array.shape)    <span class="comment"># 行数和列数</span></span><br><span class="line"><span class="comment"># shape : (2, 3)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'size:'</span>,array.size)   <span class="comment"># 元素个数</span></span><br><span class="line"><span class="comment"># size: 6</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-的创建array"><a href="#Numpy-的创建array" class="headerlink" title="Numpy 的创建array"></a>Numpy 的创建array</h3><ul><li>创建 array 有很多 <a href="https://docs.scipy.org/doc/numpy-dev/user/quickstart.html" target="_blank" rel="noopener">形式</a></li></ul><h4 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a><strong>关键字</strong></h4><ul><li><code>array</code>：创建数组</li><li><code>dtype</code>：指定数据类型</li><li><code>zeros</code>：创建数据全为0</li><li><code>ones</code>：创建数据全为1</li><li><code>empty</code>：创建数据接近0</li><li><code>arrange</code>：按指定范围创建数据</li><li><code>linspace</code>：创建线段</li></ul><h4 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>])  <span class="comment"># list 1d</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># [2 23 4]</span></span><br></pre></td></tr></table></figure><h4 id="指定数据-dtype"><a href="#指定数据-dtype" class="headerlink" title="指定数据 dtype"></a>指定数据 dtype</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int 64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int32</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float32</span></span><br></pre></td></tr></table></figure><h4 id="创建特定数据"><a href="#创建特定数据" class="headerlink" title="创建特定数据"></a>创建特定数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],[<span class="number">2</span>,<span class="number">32</span>,<span class="number">4</span>]])  <span class="comment"># 2d 矩阵 2行3列</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">[[ 2 23  4]</span></span><br><span class="line"><span class="string"> [ 2 32  4]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全零数组</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据全为0，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全一数组, 同时也能指定这些特定数据的 dtype:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.ones((<span class="number">3</span>,<span class="number">4</span>),dtype = np.int)   <span class="comment"># 数据为1，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全空数组, 其实每个值都是接近于零的数:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.empty((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据为empty，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  0.00000000e+000,   4.94065646e-324,   9.88131292e-324,   1.48219694e-323],</span></span><br><span class="line"><span class="string">       [  1.97626258e-323,   2.47032823e-323,   2.96439388e-323,   3.45845952e-323],</span></span><br><span class="line"><span class="string">       [  3.95252517e-323,   4.44659081e-323,   4.94065646e-323,   5.43472210e-323]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>arange</code> 创建连续数组:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>,<span class="number">20</span>,<span class="number">2</span>) <span class="comment"># 10-19 的数据，2步长</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([10, 12, 14, 16, 18])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>使用 <code>reshape</code> 改变数据的形状</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>,<span class="number">4</span>))    <span class="comment"># 3行4列，0到11</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">       [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">       [ 8,  9, 10, 11]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>linspace</code> 创建线段型数据:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>)    <span class="comment"># 开始端1，结束端10，且分割成20个数据，生成线段</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([  1.        ,   1.47368421,   1.94736842,   2.42105263,</span></span><br><span class="line"><span class="string">         2.89473684,   3.36842105,   3.84210526,   4.31578947,</span></span><br><span class="line"><span class="string">         4.78947368,   5.26315789,   5.73684211,   6.21052632,</span></span><br><span class="line"><span class="string">         6.68421053,   7.15789474,   7.63157895,   8.10526316,</span></span><br><span class="line"><span class="string">         8.57894737,   9.05263158,   9.52631579,  10.        ])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>同样也能进行 <code>reshape</code> 工作:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>).reshape((<span class="number">5</span>,<span class="number">4</span>)) <span class="comment"># 更改shape</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  1.        ,   1.47368421,   1.94736842,   2.42105263],</span></span><br><span class="line"><span class="string">       [  2.89473684,   3.36842105,   3.84210526,   4.31578947],</span></span><br><span class="line"><span class="string">       [  4.78947368,   5.26315789,   5.73684211,   6.21052632],</span></span><br><span class="line"><span class="string">       [  6.68421053,   7.15789474,   7.63157895,   8.10526316],</span></span><br><span class="line"><span class="string">       [  8.57894737,   9.05263158,   9.52631579,  10.        ]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-基础运算"><a href="#Numpy-基础运算" class="headerlink" title="Numpy 基础运算"></a>Numpy 基础运算</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.array([<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>])   <span class="comment"># array([10, 20, 30, 40])</span></span><br><span class="line">b=np.arange(<span class="number">4</span>) <span class="comment"># array([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line">c=a-b  <span class="comment"># array([10, 19, 28, 37])   矩阵的减法</span></span><br><span class="line">c=a+b   <span class="comment"># array([10, 21, 32, 43])矩阵的加法</span></span><br><span class="line">c=a*b   <span class="comment"># array([  0,  20,  60, 120])  矩阵的乘法</span></span><br><span class="line"></span><br><span class="line">c=b**<span class="number">2</span>  <span class="comment"># array([0, 1, 4, 9])  乘方</span></span><br><span class="line">c=<span class="number">10</span>*np.sin(a)  <span class="comment"># array([-5.44021111,  9.12945251, -9.88031624,  7.4511316 ]) 三角函数</span></span><br><span class="line">print(b&lt;<span class="number">3</span>)  <span class="comment"># array([ True,  True,  True, False], dtype=bool)  print()逻辑判断</span></span><br></pre></td></tr></table></figure><ul><li>对多行多维度的矩阵进行操作</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=np.array([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">b=np.arange(<span class="number">4</span>).reshape((<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[1, 1],</span></span><br><span class="line"><span class="comment">#       [0, 1]])</span></span><br><span class="line"></span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># array([[0, 1],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line"></span><br><span class="line">c_dot = np.dot(a,b)     <span class="comment"># 矩阵乘法，即对应行乘对应列得到相应元素</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line">c_dot_2 = a.dot(b)<span class="comment"># 矩阵乘法(另一写法)</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[ 0.94692159,  0.20821798,  0.35339414,  0.2805278 ],</span></span><br><span class="line"><span class="comment">#       [ 0.04836775,  0.04023552,  0.44091941,  0.21665268]])</span></span><br><span class="line">np.sum(a)   <span class="comment"># 4.4043622002745959   对矩阵中所有元素进行求和</span></span><br><span class="line">np.min(a)   <span class="comment"># 0.23651223533671784  对矩阵中所有元素寻找最小值</span></span><br><span class="line">np.max(a)   <span class="comment"># 0.90438450240606416  对矩阵中所有元素寻找最大值</span></span><br><span class="line"></span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(<span class="string">"a ="</span>,a)</span><br><span class="line"><span class="comment"># a = [[ 0.23651224  0.41900661  0.84869417  0.46456022]</span></span><br><span class="line"><span class="comment"># [ 0.60771087  0.9043845   0.36603285  0.55746074]]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"sum ="</span>,np.sum(a,axis=<span class="number">1</span>))   <span class="comment"># 当axis的值为1的时候，将会以行作为查找单元</span></span><br><span class="line"><span class="comment"># sum = [ 1.96877324  2.43558896]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"min ="</span>,np.min(a,axis=<span class="number">0</span>))   <span class="comment"># 当axis的值为0的时候，将会以列作为查找单元</span></span><br><span class="line"><span class="comment"># min = [ 0.23651224  0.41900661  0.36603285  0.46456022]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"max ="</span>,np.max(a,axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># max = [ 0.84869417  0.9043845 ]</span></span><br></pre></td></tr></table></figure><ul><li>对应元素的<code>索引</code>也是非常重要的</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">2</span>,<span class="number">14</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[ 2, 3, 4, 5]</span></span><br><span class="line"><span class="comment">#        [ 6, 7, 8, 9]</span></span><br><span class="line"><span class="comment">#        [10,11,12,13]])</span></span><br><span class="line">         </span><br><span class="line">print(np.argmin(A))    <span class="comment"># 0    求矩阵中最小元素的索引</span></span><br><span class="line">print(np.argmax(A))    <span class="comment"># 11   求矩阵中最大元素的索引</span></span><br><span class="line"></span><br><span class="line">print(np.mean(A))        <span class="comment"># 7.5  计算均值    </span></span><br><span class="line"><span class="comment"># print(A.mean())          # 7.5</span></span><br><span class="line">print(np.average(A))     <span class="comment"># 7.5</span></span><br><span class="line"></span><br><span class="line">print(A.median())       <span class="comment"># 7.5  求解中位数</span></span><br><span class="line"></span><br><span class="line">print(np.cumsum(A)) <span class="comment"># [2 5 9 14 20 27 35 44 54 65 77 90]   累加函数</span></span><br><span class="line"></span><br><span class="line">print(np.diff(A))    <span class="comment"># 累差运算</span></span><br><span class="line"><span class="comment"># [[1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]]</span></span><br><span class="line"></span><br><span class="line">print(np.nonzero(A))    <span class="comment"># 这个函数将所有非零元素的行与列坐标分割开，重构成两个分别关于行和列的矩阵。</span></span><br><span class="line"><span class="comment"># (array([0,0,0,0,1,1,1,1,2,2,2,2]),array([0,1,2,3,0,1,2,3,0,1,2,3]))</span></span><br><span class="line">B = np.array([[<span class="number">0</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">0</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">22</span>, <span class="number">0</span>, <span class="number">33</span>]])</span><br><span class="line">print(np.nonzero(B))<span class="comment">#遍历每一个元素，若其非0，则返回其行/列索引   第一(二)个array返回行(列)索引</span></span><br><span class="line"><span class="comment"># (array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([1, 2, 3, 0, 2, 3, 0, 1, 3]))</span></span><br></pre></td></tr></table></figure><ul><li>排序操作</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">14</span>,<span class="number">2</span>, <span class="number">-1</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[14, 13, 12, 11],</span></span><br><span class="line"><span class="comment">#       [10,  9,  8,  7],</span></span><br><span class="line"><span class="comment">#       [ 6,  5,  4,  3]])</span></span><br><span class="line"></span><br><span class="line">print(np.sort(A))    <span class="comment"># 仅针对每一行进行从小到大排序操作</span></span><br><span class="line"><span class="comment"># array([[11,12,13,14]</span></span><br><span class="line"><span class="comment">#        [ 7, 8, 9,10]</span></span><br><span class="line"><span class="comment">#        [ 3, 4, 5, 6]])</span></span><br></pre></td></tr></table></figure><ul><li>矩阵的转置有两种表示方法：</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(np.transpose(A))    </span><br><span class="line">print(A.T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br></pre></td></tr></table></figure><ul><li>在Numpy中具有<code>clip(Array,Array_min,Array_max)</code>函数：将Array中大于Array_max的元素转换成Array_max，将Array中小于Array_min的元素转换成Array_min</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(A)</span><br><span class="line"><span class="comment"># array([[14,13,12,11]</span></span><br><span class="line"><span class="comment">#        [10, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 4, 3]])</span></span><br><span class="line"></span><br><span class="line">print(np.clip(A,<span class="number">5</span>,<span class="number">9</span>))    </span><br><span class="line"><span class="comment"># array([[ 9, 9, 9, 9]</span></span><br><span class="line"><span class="comment">#        [ 9, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 5, 5]])</span></span><br></pre></td></tr></table></figure><h3 id="Numpy索引"><a href="#Numpy索引" class="headerlink" title="Numpy索引"></a>Numpy索引</h3><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Communication-Technology-Basics-Experiment</title>
    <link href="http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/"/>
    <id>http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/</id>
    <published>2018-12-01T06:43:44.788Z</published>
    <updated>2018-12-01T08:02:06.310Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】通信技术基础上机</p><a id="more"></a><h3 id="基带编码"><a href="#基带编码" class="headerlink" title="基带编码"></a>基带编码</h3><h4 id="example"><a href="#example" class="headerlink" title="example"></a>example</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>];</span><br><span class="line">num=<span class="number">0</span>;</span><br><span class="line">yn = xn;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span> xn(<span class="built_in">i</span>)==<span class="number">1</span></span><br><span class="line">        num = num+<span class="number">1</span>;</span><br><span class="line">        yn(<span class="built_in">i</span>) = yn(<span class="built_in">i</span>)+ num;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-1</span> <span class="number">8</span>]);grid on</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/example.jpg"><br></center><h4 id="AMI码"><a href="#AMI码" class="headerlink" title="AMI码"></a>AMI码</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=+<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                   <span class="comment">% 以上部分完成AMI码编码</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/AMI.jpg"><br></center><h4 id="HDB3"><a href="#HDB3" class="headerlink" title="HDB3"></a>HDB3</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line"><span class="comment">% xn = [1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1];</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>   </span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line"><span class="comment">% HDB3编码 </span></span><br><span class="line">num=<span class="number">0</span>;  <span class="comment">% 连零计数器初始化 </span></span><br><span class="line">yh=yn;  <span class="comment">% 输出初始化 </span></span><br><span class="line"><span class="built_in">sign</span>=<span class="number">0</span>; <span class="comment">% 极性标志初始化为0 </span></span><br><span class="line">nonzero=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(yn)    </span><br><span class="line">    <span class="keyword">if</span> yn(k)==<span class="number">0</span>        </span><br><span class="line">        num=num+<span class="number">1</span>;  <span class="comment">% 连“0”个数计数        </span></span><br><span class="line">        <span class="keyword">if</span> num==<span class="number">4</span>   <span class="comment">% 如果4连“0”          </span></span><br><span class="line">            num=<span class="number">0</span>;    <span class="comment">% 计数器清零 </span></span><br><span class="line">            yh(k)= nonzero;              <span class="comment">% 让0000的最后一个0改变为与前一个非零符号相同极性的符号          </span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> yh(k)==<span class="built_in">sign</span>     <span class="comment">% 如果当前V符号与前一个V符号的极性相同             </span></span><br><span class="line">                yh(k)=<span class="number">-1</span>*yh(k); <span class="comment">% 则让当前V符号极性反转,以满足V符号间相互极性反转要求             </span></span><br><span class="line">                yh(k<span class="number">-3</span>)=yh(k);  <span class="comment">% 添加B符号,与V符号同极性     </span></span><br><span class="line">                       </span><br><span class="line">                 yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn))=<span class="number">-1</span>*yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn));   <span class="comment">% 并让后面的非零符号从V符号开始再交替变化          </span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">          <span class="built_in">sign</span>=yh(k);          <span class="comment">% 记录前一个V符号的极性</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        num=<span class="number">0</span>;                <span class="comment">% 当前输入为“1”则连“0”计数器清零   </span></span><br><span class="line">        nonzero = yn(k);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                         <span class="comment">% 编码完成</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yh);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/HDB3.jpg"><br></center><h4 id="Manchester"><a href="#Manchester" class="headerlink" title="Manchester"></a>Manchester</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear all</span><br><span class="line">close all</span><br><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">t=<span class="number">0</span>:<span class="number">1</span>:<span class="number">2</span>*<span class="built_in">length</span>(xn)<span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span>(xn(<span class="built_in">i</span>)==<span class="number">1</span>)   <span class="comment">%manchester code "1"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">-1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span>           <span class="comment">%manchester code "0"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">stairs(t,yn);</span><br><span class="line">axis([<span class="number">0</span> length(yn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/Manchester.jpg"><br></center><h3 id="数字调制技术"><a href="#数字调制技术" class="headerlink" title="数字调制技术"></a>数字调制技术</h3><h4 id="DPSK"><a href="#DPSK" class="headerlink" title="DPSK"></a>DPSK</h4><p>参数设置Block Parameters <code>DPSK // DPSK_1(PPt)</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Bernoulli Binary Generator   </span><br><span class="line">- Source of initial seed: Parameter</span><br><span class="line">- Initial seed: 50</span><br><span class="line">- Output data type: single</span><br><span class="line"></span><br><span class="line">- Differential Encoder</span><br><span class="line">- Initial conditions: 0.05</span><br><span class="line"></span><br><span class="line">- Unipolar to Bipolar Converter</span><br><span class="line">- M-ary number:2</span><br><span class="line">- Output data type:Same as input</span><br><span class="line"></span><br><span class="line">- Sine Wave </span><br><span class="line">- Amplitude: 2  // 1</span><br><span class="line">- Frequency(rad/sec):4*2*pi // 40*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Analog Filter Design</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter order:8 // 4</span><br><span class="line">- Lower passband edge frequency (rad/s): 2*pi // 2*2*pi</span><br><span class="line">- Upper passband edge frequency (rad/s): 10*pi // 7*2*pi</span><br><span class="line"></span><br><span class="line">- Transport Delay</span><br><span class="line">- Time delay: 0.318*pi</span><br><span class="line"></span><br><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:4</span><br><span class="line">- Passband edge frequency (rad/s): 2*2*pi  // 3*2*pi</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0.3</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h4 id="2FSK"><a href="#2FSK" class="headerlink" title="2FSK"></a>2FSK</h4><p>参数设置Block Parameters    <code>(文件参数) //(PPT参数)</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 10*pi (与结果图Scope11一致) // 80</span><br><span class="line"></span><br><span class="line">- Analog Filter Design2</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 20*pi  // 20</span><br><span class="line"></span><br><span class="line">- Sine Wave3</span><br><span class="line">- Frequency(rad/sec):20*pi // 80*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Subtract</span><br><span class="line">- Icon shape:rectangular// round</span><br><span class="line">- List of signs:+-</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0 // 0.3(与结果图Scope15一致)</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h3 id="PCM-DM"><a href="#PCM-DM" class="headerlink" title="PCM_DM"></a>PCM_DM</h3><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear;</span><br><span class="line">t=<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>),plot(t,a);title(<span class="string">'Original signal'</span>);</span><br><span class="line"></span><br><span class="line">ts=<span class="number">0.05</span>;</span><br><span class="line">t=<span class="number">0</span>:ts:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),stem(t,a);title(<span class="string">'Sampling signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_u,aquan8_u,code8_u]=u_pcm1(a,<span class="number">8</span>);  </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">3</span>),stem(t,aquan8_u);</span><br><span class="line">title(<span class="string">'Uniformly quantized signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_A,aquan8_A,code8_A]=A_pcm1(a,<span class="number">8</span>);   axis([<span class="number">0</span> <span class="number">4</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">4</span>),stem(t,aquan8_A);</span><br><span class="line">title(<span class="string">'A-law quantized signal'</span>);</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/PCM_DM_example.jpg"><br></center><h5 id="u-pcm1"><a href="#u-pcm1" class="headerlink" title="u_pcm1"></a>u_pcm1</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">u_pcm1</span><span class="params">(a,n)</span> </span></span><br><span class="line">amax=max(a);</span><br><span class="line">amin=min(a);</span><br><span class="line">delta=(amax-amin)/n;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n+<span class="number">1</span></span><br><span class="line">    m(<span class="built_in">i</span>)=amin+(<span class="built_in">i</span><span class="number">-1</span>)*delta;</span><br><span class="line"><span class="keyword">end</span><span class="comment">%%量化间隔</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n</span><br><span class="line">    q(<span class="built_in">i</span>)=(m(<span class="built_in">i</span>)+m(<span class="built_in">i</span>+<span class="number">1</span>))/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span>    </span><br><span class="line"><span class="comment">%量化值的计算 </span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n  </span><br><span class="line">    index=<span class="built_in">find</span>((q(<span class="built_in">i</span>)-delta/<span class="number">2</span> &lt;= a) &amp; (a &lt;= q(<span class="built_in">i</span>)+delta/<span class="number">2</span>)); <span class="comment">%%找到处于某个量化间隔的所有抽样点</span></span><br><span class="line">    aq(index)=q(<span class="built_in">i</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(index));  <span class="comment">%%利用qi作为该量化间隔的抽样值的量化值</span></span><br><span class="line">    q_index(<span class="built_in">find</span>((aq==q(<span class="built_in">i</span>))))=(<span class="built_in">i</span><span class="number">-1</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(<span class="built_in">find</span>(aq==q(<span class="built_in">i</span>)))); <span class="comment">%%得到量化索引</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">% %PCM编码——二进制编码</span></span><br><span class="line">code=dec2bin(q_index);</span><br><span class="line"></span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(a)/norm(a-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h5 id="A-pcm1"><a href="#A-pcm1" class="headerlink" title="A_pcm1"></a>A_pcm1</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">A_pcm1</span><span class="params">(x,n)</span> </span></span><br><span class="line">A=<span class="number">87.6</span>;</span><br><span class="line">[amax,amin,y]=A_compress(x,A);</span><br><span class="line"></span><br><span class="line">[sqnr,y_q,code]=u_pcm1(y,n);</span><br><span class="line">aq=A_expand(y,A);</span><br><span class="line">aq=aq*(amax-amin)/<span class="number">2</span>;</span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(x)/norm(x-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h6 id="A-compress"><a href="#A-compress" class="headerlink" title="A_compress"></a>A_compress</h6><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[amax,amin,y]</span> = <span class="title">A_compress</span><span class="params">(x,A)</span></span></span><br><span class="line">amax=max(x);</span><br><span class="line">amin=min(x);</span><br><span class="line">x=<span class="number">2</span>*x/(amax-amin);</span><br><span class="line">y=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(x));</span><br><span class="line"><span class="comment">%%A律压缩</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(x(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/A </span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h6 id="A-expand"><a href="#A-expand" class="headerlink" title="A_expand"></a>A_expand</h6><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">x</span>=<span class="title">A_expand</span><span class="params">(y,A)</span></span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(y)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(y(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/(<span class="number">1</span>+<span class="built_in">log</span>(A)); </span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))/A;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>)).*<span class="built_in">exp</span>(<span class="built_in">abs</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))<span class="number">-1</span>)/A;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h4 id="DM1"><a href="#DM1" class="headerlink" title="DM1"></a>DM1</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"> <span class="comment">% ch6example13prog1.m</span></span><br><span class="line"> clc;clear all</span><br><span class="line">Ts=<span class="number">1e-3</span>;                                <span class="comment">%采样间隔</span></span><br><span class="line">t=<span class="number">0</span>:Ts:<span class="number">20</span>*<span class="number">1e-3</span>;                           <span class="comment">%仿真时间序列</span></span><br><span class="line">x=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">50</span>*t)+<span class="number">0.5</span>*<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">150</span>*t);   <span class="comment">%信号</span></span><br><span class="line">delta=<span class="number">0.7</span>;                              <span class="comment">%量化阶距</span></span><br><span class="line">D(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                       <span class="comment">%预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)                       </span><br><span class="line">    e(k)=x(k)-D(k);  <span class="comment">%误差信号</span></span><br><span class="line">    <span class="keyword">if</span> e(k)&gt;=<span class="number">0</span></span><br><span class="line">        e_q(k)=delta;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        e_q(k)=-delta;</span><br><span class="line">    <span class="keyword">end</span>                <span class="comment">%量化器输出</span></span><br><span class="line">    D(k+<span class="number">1</span>)=e_q(k)+D(k);                 <span class="comment">%预测器输出</span></span><br><span class="line">    codeout(k)=(e_q(k)&gt;<span class="number">0</span>);              <span class="comment">%编码输出</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);plot(t,x,<span class="string">'-o'</span>);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);hold on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs(t,codeout);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">                                        <span class="comment">%解码端</span></span><br><span class="line">Dr(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                      <span class="comment">%解码端预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)</span><br><span class="line">    <span class="keyword">if</span> codeout(k)==<span class="number">0</span></span><br><span class="line">        eq(k)=-delta;</span><br><span class="line">    <span class="keyword">else</span> eq(k)=delta;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    xr(k)=eq(k)+Dr(k);</span><br><span class="line">    Dr(k+<span class="number">1</span>)=xr(k);                      <span class="comment">%延迟器状态更新</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs(t,xr);hold on;    <span class="comment">%解码输出</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);plot(t,x);               <span class="comment">%原信号</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/DM1.jpg"><br></center><h3 id="差错控制"><a href="#差错控制" class="headerlink" title="差错控制"></a>差错控制</h3><h4 id="CRC16"><a href="#CRC16" class="headerlink" title="CRC16"></a>CRC16</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% CRC 编码主程序</span></span><br><span class="line">clear;clc;close all;</span><br><span class="line">uncode_sequence=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">sequence_length = <span class="built_in">length</span>(uncode_sequence);            <span class="comment">% 得到原始信号长度</span></span><br><span class="line">crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">crc_length=<span class="built_in">length</span>(crc_ccitt)<span class="number">-1</span>;</span><br><span class="line">add_bit = <span class="built_in">zeros</span>(<span class="number">1</span>,crc_length);                                 <span class="comment">% 添加冗余比特位</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence add_bit];            <span class="comment">% 初始化输出检错码序列</span></span><br><span class="line">remainder_bits = [uncode_sequence add_bit];                     <span class="comment">% 初始化余数数组</span></span><br><span class="line"><span class="keyword">for</span> k = <span class="number">1</span>:sequence_length                 <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">    add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,sequence_length-k); <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">    register_bits = [crc_ccitt add_zeros];  <span class="comment">% 构造除数数组</span></span><br><span class="line">    <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>        <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">        register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    remainder_bits = bitxor(register_bits,remainder_bits); <span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">register_bits = crc_ccitt;                        <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">remainder_bits(<span class="number">1</span>) = [];                 <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence remainder_bits]    <span class="comment">% 生成余数序列的冗余位以叠加到编码序列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%%CRC解码</span></span><br><span class="line">error=randint(<span class="number">1</span>,<span class="built_in">length</span>(crc_coded_sequence));<span class="comment">%%信道误码</span></span><br><span class="line"><span class="comment">% error=round(1*rand(1,length(crc_coded_sequence)));%%信道误码    %若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">crc_coded_sequence=bitxor(crc_coded_sequence,error);<span class="comment">%%接收码组 </span></span><br><span class="line">sequence_length = <span class="built_in">length</span>(crc_coded_sequence);         <span class="comment">% 得到编码的长度</span></span><br><span class="line">original_sequence = crc_coded_sequence;                  <span class="comment">% 初始化输出序列 </span></span><br><span class="line">        crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">        remainder_bits = crc_coded_sequence;           <span class="comment">% 初始化余数数组</span></span><br><span class="line">        cycle_length = sequence_length-<span class="built_in">length</span>(crc_ccitt)+<span class="number">1</span>;  <span class="comment">% 计算长除法的循环周期        </span></span><br><span class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:cycle_length            <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">            add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,cycle_length-k);       <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">            register_bits = [crc_ccitt add_zeros];        <span class="comment">% 构造除数数组</span></span><br><span class="line">            <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>     <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">                register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            remainder_bits = bitxor(register_bits,remainder_bits);<span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">            register_bits = crc_ccitt;            <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">            remainder_bits(<span class="number">1</span>) = [];      <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">if</span> sum(remainder_bits) == <span class="number">0</span>       <span class="comment">% 传输码元中没有发生个错误</span></span><br><span class="line">            original_sequence = crc_coded_sequence(<span class="number">1</span>:cycle_length)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            err = <span class="number">1</span>                             <span class="comment">% 码元传输发生错误</span></span><br><span class="line">        <span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">err =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>若注释掉”信道误码”和”接受码组”，Result：</strong></p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">original_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="汉明码"><a href="#汉明码" class="headerlink" title="汉明码"></a>汉明码</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clc;clear all;</span><br><span class="line">K=<span class="number">4</span>;</span><br><span class="line">N=<span class="number">7</span>;</span><br><span class="line">msg=randint(<span class="number">1</span>,K) <span class="comment">%%生成随机信息位   </span></span><br><span class="line"><span class="comment">% msg=round(1*rand(1,K)) %%生成随机信息位%若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">[H,G] = hammgen(N-K) <span class="comment">%%生成汉明码的生成矩阵和校验矩阵</span></span><br><span class="line">code=encode(msg,N,K,<span class="string">'linear/binary'</span>,G) <span class="comment">%%汉明码编码</span></span><br><span class="line">noise=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>];</span><br><span class="line">code_noise=bitxor(code,noise)</span><br><span class="line">rcv=decode(code_noise,N,K,<span class="string">'linear/binary'</span>,G)</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">msg =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">H =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">G =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code_noise =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">rcv =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">     </span><br><span class="line"># msg 与 rcv 保持一致即可</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】通信技术基础上机&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ADNI模态数据概念整理</title>
    <link href="http://yoursite.com/2018/11/30/ADNI%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2018/11/30/ADNI模态数据概念整理/</id>
    <published>2018-11-30T13:32:50.000Z</published>
    <updated>2018-11-30T13:57:42.874Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>最近需要了解ADNI（Alzheimer’s Disease Neuroimaging Initiative）数据集，刚在网站上注册和提交了<a href="https://ida.loni.usc.edu/services/Menu/IdaData.jsp?page=DATA&amp;subPage=AVAILABLE_DATA" target="_blank" rel="noopener">申请</a>（审核通过了才能下载数据集），审核时间大概是一周。暂时无法查看数据集内容，亦无法下载。无奈只好在再次回顾<a href="http://adni.loni.usc.edu/data-samples/data-types/" target="_blank" rel="noopener">ADNI Data Type</a> 相关说明。同时从同学处获取部分Nifti离线文件，并进行python读取文件数据。</p><h4 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h4><h5 id="Clinical-Data"><a href="#Clinical-Data" class="headerlink" title="Clinical Data"></a>Clinical Data</h5><p>ADNI临床数据集包括关于每个受试者的<code>临床信息</code>，包括招募，人口统计学，身体检查和认知评估数据。可以将整套临床数据作为逗号分隔值（CSV）文件批量下载。</p><p><img src="http://adni.loni.usc.edu/wp-content/uploads/2010/09/clinical-data-chart.png" style="zoom:60%"></p><ul><li><p>Demographics 人口统计学、Neurological Exam 神经系统检查、Screening Labs 筛选实验室 、Vital Signs 生命体征、Cognitive Assessments 认知评估、Biospecimen Collections 生物样本收集、 Medications 药物、Diagnostic Summary 诊断摘要、Lumbar Puncture 腰椎穿刺</p></li><li><p>Screening 筛选、Baseline 基线 、Month 3 、Month 6 、Month 12 、 Month 18 、Month 24 、Month36 、Month48 、Ongoing Annual Follow-up  当前进行的年度跟进</p></li></ul><h5 id="Gennetic-Data"><a href="#Gennetic-Data" class="headerlink" title="Gennetic Data"></a>Gennetic Data</h5><p>遗传因素在阿尔茨海默病中起重要作用。全基因组关联研究（<code>GWAS</code>）采用标记之间关联的测试，称为单核苷酸多态性（<code>SNP</code>）和感兴趣的表型。来自病例对照GWAS和其他类型的遗传关联研究的发现可以提供用于检查源自ADNI成像和其他生物标志物数据集的定量表型的目标。</p><p><code>APOE的4等位基因</code>是已知的AD最强大的遗传风险因素，如果拥有一个4等位基因的人患AD的风险增加了2- 3倍，那么如果有两个等位基因的人患AD的风险增加了12倍。</p><h5 id="MR-Image-Data"><a href="#MR-Image-Data" class="headerlink" title="MR Image Data"></a>MR Image Data</h5><p>MRI – <code>核磁共振成像</code>是根据有磁矩的原子核在磁场作用下，能产生能级间的跃迁的原理采用的技术。MRI对脑内低度星形胶质细胞瘤、神经节、神经胶质瘤、动静脉畸形和血肿等的诊断确认率极高。MRI能清楚地显示癫痫患者的脑萎缩，对脑实质和脑脊液的显示度极好。</p><p>原始，预处理和后处理图像文件，FMRI和DTI 这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/MRI.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>该项目将收集MRI（结构，扩散加权成像，灌注和静息状态序列）; 使用florbetapir F18（florbetapir）或florbetaben F18（florbetaben）的淀粉样蛋白PET; 18F-FDG-PET（FDG-PET）; CSF用于Aβ，tau，磷酸化tau（AKA磷酸化酶）和其他蛋白质; AV-1451 PET; 和遗传和尸检数据，以<code>确定这些生物标志物与基线临床状态和认知下降的关系</code>。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-47b425d8cdc1ff7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="PET-Image-Data"><a href="#PET-Image-Data" class="headerlink" title="PET Image Data"></a>PET Image Data</h5><p>正电子发射计算机断层扫描的大致方法是，将某种物质，一般是生物生命代谢中必须的物质，如：葡萄糖、蛋白质、核酸、脂肪酸，标记上短寿命的放射性核素（如18F，11C等），注入人体后，通过对于该物质在代谢中的聚集，来反映生命代谢活动的情况，从而达到诊断的目的。</p><p>其中：18F-FDG是指氟代脱氧葡萄糖，其完整的化学名称为2-氟-2-脱氧-D-葡萄糖，通常简称为FDG。葡萄糖是人体三大能源物质之一，将可以被PET探测并形成影像的的正电子核素18F标记在葡萄糖上。</p><p>原始，预处理和后处理图像文件，PIB（ADNI1），FDG（ADNI1 / GO / 2），FLORBETAPIR（ADNI GO / 2/3），FLORBETABEN（ADNI3）和TAU IMAGING（ADNI3）这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-1.png" alt="an overview of the PET data collected throughout the ADNI study" title="">                </div>                <div class="image-caption">an overview of the PET data collected throughout the ADNI study</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-Image-Data.png" alt="AVAILABLE IMAGE DATA" title="">                </div>                <div class="image-caption">AVAILABLE IMAGE DATA</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-508b820355abe639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="Biospecimen-Data"><a href="#Biospecimen-Data" class="headerlink" title="Biospecimen Data"></a>Biospecimen Data</h5><p>ADNI的目标之一是收集参与者的<code>血液</code>，<code>尿液</code>和<code>脑脊液（CSF）</code>等生物样本(Biospecimen Data)。鼓励有兴趣的调查员，无论是否与ADNI网站相关联，都可以申请使用这种有限的资源。但是，除非初步数据显示出明显优越的性能，否则不建议将ADNI样本用于技术开发或不同技术之间的比较。</p><p>此外，adni生物标记核心所执行的几项分析结果将在数据存档中提供如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Homocysteine</span><br><span class="line">- Species of isoprostanes</span><br><span class="line">- CSF tau, sAPPβ levels, BACE levels, and enzyme activity</span><br><span class="line">- Plasma Aβ 40 and Aβ 42</span><br><span class="line">- Other promising CSF and plasma based on ongoing multiplex immunoassay studies and mass - spectrometry MRM studies</span><br></pre></td></tr></table></figure><h4 id="python-读取nifti数据"><a href="#python-读取nifti数据" class="headerlink" title="python 读取nifti数据"></a>python 读取nifti数据</h4><ul><li>使用nifti数据 23.6 MB   </li></ul><figure><br>    <img src="/2018/11/30/ADNI模态数据概念整理/nii_example.png" style="zoom:80%"><br></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># show the nii_data.shape</span></span><br><span class="line">nii_file = <span class="string">"ADNI_011_S_0010_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20061208114538147_S8800_I32270.nii"</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line">img = np.squeeze(img)</span><br><span class="line">print(<span class="string">"img.shape"</span>,img.shape) <span class="comment"># img.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.shape"</span>,data.shape) <span class="comment"># data.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.affine.shape"</span>,data.affine.shape)  <span class="comment"># data.affine.shape (4, 4)</span></span><br><span class="line"><span class="comment"># print(data.header) #数据头信息  输出信息于Result列出</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取slice信息生成图像</span></span><br><span class="line"><span class="comment"># 把slice数据生成图片的方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span><span class="params">(slices)</span>:</span></span><br><span class="line"></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">1</span>, len(slices))</span><br><span class="line">    <span class="keyword">for</span> i, slice <span class="keyword">in</span> enumerate(slices):</span><br><span class="line">        axes[i].imshow(slice.T, cmap=<span class="string">"gray"</span>, origin=<span class="string">"lower"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取nifti文件中的slice数据</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取单张slice数据</span></span><br><span class="line">slice_0 = img[<span class="number">26</span>, :, :]</span><br><span class="line">slice_1 = img[:, <span class="number">30</span>, :]</span><br><span class="line">slice_2 = img[:, :, <span class="number">16</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成图表</span></span><br><span class="line">show_img([slice_0, slice_1, slice_2])</span><br><span class="line">plt.suptitle(<span class="string">"show slice image"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.affine.shape (<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">&lt;class 'nibabel.nifti1.Nifti1Header'&gt; object, endian='&gt;'</span><br><span class="line">sizeof_hdr      : <span class="number">348</span></span><br><span class="line">data_type       : <span class="string">b''</span></span><br><span class="line">db_name         : <span class="string">b'011_S_0010'</span></span><br><span class="line">extents         : <span class="number">0</span></span><br><span class="line">session_error   : <span class="number">0</span></span><br><span class="line">regular         : <span class="string">b'r'</span></span><br><span class="line">dim_info        : <span class="number">0</span></span><br><span class="line">dim             : [  <span class="number">3</span> <span class="number">192</span> <span class="number">192</span> <span class="number">160</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>]</span><br><span class="line">intent_p1       : <span class="number">0.0</span></span><br><span class="line">intent_p2       : <span class="number">0.0</span></span><br><span class="line">intent_p3       : <span class="number">0.0</span></span><br><span class="line">intent_code     : none</span><br><span class="line">datatype        : float32</span><br><span class="line">bitpix          : <span class="number">32</span></span><br><span class="line">slice_start     : <span class="number">0</span></span><br><span class="line">pixdim          : [<span class="number">1.</span>        <span class="number">1.2447063</span> <span class="number">1.2507237</span> <span class="number">1.2010667</span> <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span></span><br><span class="line"> <span class="number">1.</span>       ]</span><br><span class="line">vox_offset      : <span class="number">0.0</span></span><br><span class="line">scl_slope       : nan</span><br><span class="line">scl_inter       : nan</span><br><span class="line">slice_end       : <span class="number">0</span></span><br><span class="line">slice_code      : unknown</span><br><span class="line">xyzt_units      : <span class="number">2</span></span><br><span class="line">cal_max         : <span class="number">0.0</span></span><br><span class="line">cal_min         : <span class="number">0.0</span></span><br><span class="line">slice_duration  : <span class="number">0.0</span></span><br><span class="line">toffset         : <span class="number">0.0</span></span><br><span class="line">glmax           : <span class="number">1721</span></span><br><span class="line">glmin           : <span class="number">0</span></span><br><span class="line">descrip         : <span class="string">b'MPR; GradWarp; B1 Correction; N3; Scaled'</span></span><br><span class="line">aux_file        : <span class="string">b'none'</span></span><br><span class="line">qform_code      : scanner</span><br><span class="line">sform_code      : unknown</span><br><span class="line">quatern_b       : <span class="number">0.70710677</span></span><br><span class="line">quatern_c       : <span class="number">-1.0713779e-09</span></span><br><span class="line">quatern_d       : <span class="number">-0.70710677</span></span><br><span class="line">qoffset_x       : <span class="number">94.87749</span></span><br><span class="line">qoffset_y       : <span class="number">165.8339</span></span><br><span class="line">qoffset_z       : <span class="number">115.27711</span></span><br><span class="line">srow_x          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_y          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_z          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">intent_name     : <span class="string">b''</span></span><br><span class="line">magic           : <span class="string">b'n+1'</span></span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/11/30/ADNI模态数据概念整理/show" alt="show slice image" title="slice">                </div>                <div class="image-caption">slice</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>VGG_Introduction</title>
    <link href="http://yoursite.com/2018/11/30/VGG_Introduction/"/>
    <id>http://yoursite.com/2018/11/30/VGG_Introduction/</id>
    <published>2018-11-30T07:13:36.000Z</published>
    <updated>2018-11-30T09:12:26.958Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>论文出处：<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/41423739" target="_blank" rel="noopener">一文读懂VGG网络</a>\VGG模型论文译文<a href="https://zhuanlan.zhihu.com/p/34851133" target="_blank" rel="noopener">(上)</a><a href="https://zhuanlan.zhihu.com/p/35516173" target="_blank" rel="noopener">(下)</a></p><h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>VGG16相比AlexNet的一个改进是<strong>采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）</strong>。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p><p>简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p><p>比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 $3\times(3^2C^2)= 27C^2$，如果直接使用7x7卷积核，其参数总量为  $7^2C^2 = 49C^2$，这里 C 指的是输入和输出的通道数。很明显，$27C^2$小于$49C^2$，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</p><p><strong>这里解释一下为什么使用2个3x3卷积核可以来代替5*5卷积核：</strong></p><p>5x5卷积看做一个小的全连接网络在5x5区域滑动，我们可以先用一个3x3的卷积滤波器卷积，然后再用一个全连接层连接这个3x3卷积输出，这个全连接层我们也可以看做一个3x3卷积层。这样我们就可以用两个3x3卷积级联（叠加）起来代替一个 5x5卷积。</p><center><br>    <img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Mini-network replacing the 5x5 convolutions.jpg" alt="missing"><br>    <figcaption>Mini-network replacing the 5x5 convolutions</figcaption><br></center><h5 id="VGG优缺点"><a href="#VGG优缺点" class="headerlink" title="VGG优缺点"></a><strong>VGG优缺点</strong></h5><p><strong>VGG优点</strong></p><ul><li>VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</li><li>几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：</li><li>验证了通过不断加深网络结构可以提升性能。</li></ul><p><strong>VGG缺点</strong></p><ul><li>VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！</li></ul><p>PS：有的文章称：发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</p><p>注：很多pretrained的方法就是使用VGG的model（主要是16和19），VGG相对其他的方法，参数空间很大，最终的model有500多m，AlexNet只有200m，GoogLeNet更少，所以train一个vgg模型通常要花费更长的时间，所幸有公开的pretrained model让我们很方便的使用。</p><hr><p>以下是论文的详细介绍，深入了解细节，有助于对其进行实现。</p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>在本文中，我们研究了大规模图像识别任务下卷积网络<code>深度</code>对其<code>预测准确率</code>的影响。 我们的主要贡献是使用具有非常小的（<code>3×3</code>）卷积滤波器的架构对<code>深度不断递增</code>的网络进行全面评估，结果表明通过将权重层深度推到<code>16-19层</code>可以在现有技术配置下（使准确率）实现显著提升。</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在本文中，我们解决了ConvNet架构设计的另一个重要方面 - 它的深度。 为此，我们修复了架构的其他参数，并通过添加更多卷积层来稳定增加网络深度，由于在所有层中都使用了非常小的（3×3）卷积滤波器，这是可行的。</p><h4 id="卷积网络配置"><a href="#卷积网络配置" class="headerlink" title="卷积网络配置"></a>卷积网络配置</h4><h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5><p>在训练期间，我们ConvNets的输入是固定尺寸的224×224 RGB图像。我们所做的<code>唯一预处理</code>是从每个像素中减去在训练集上计算的RGB均值。图像通过一叠卷积层，我们使用了感受野非常小的卷积核：<code>3×3</code>（这是左/右，上/下，中心点概念可捕获的最小尺寸）。在<code>其中一种</code>配置中，我们还使用<code>1×1</code>卷积滤波器，这可以看作是输入通道的线性变换（随后是非线性）。卷积步长固定为1个像素；卷积层的空间填充是指使得在卷积操作后保留原空间的分辨率，比如使用3×3 卷积核，就填充<strong>1</strong>个像素。空间池化是由五个最大池化层完成的，每个池化层前面都会有若干个卷积层（并非所有的卷积层后都使用最大池化层）。 最大池化是以2×2像素窗口上执行，步幅为<strong>2</strong>。</p><p>一堆卷积层（在不同的体系结构中具有不同的深度）之后是<code>三个完全连接（FC）层</code>：前两个具有4096个通道，第三个执行1000路ILSVRC分类，因此包含1000个通道（一个 为每个类）。 最后一层是<strong>soft-max</strong>层。 全连接层的配置在所有网络中都是相同的。</p><p><code>所有隐藏层都配备了ReLU激活函数</code>。 我们注意到我们的网络（除了一个网络）都没有包含局部响应归一化层（LRN）标准化（Krizhevsky et al。，2012）。 如第4部分所示，<code>这种标准化不会提升ILSVRC数据集的性能</code>，但会导致内存消耗和计算时间的增加。 在使用的情况下，LRN层的参数是（Krizhevsky et al。，2012）的参数</p><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://pic2.zhimg.com/v2-7a0f9391fbdab0f5c3e8c61693ebe205_r.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>本文中评估的ConvNet配置在表1中列出，每列一个。 我们将以他们的名字（A-E）来提及。 所有的配置都遵循2.1节中提到的通用设计，并且仅在深度上有所不同：从网络A中的11个权重层（<code>8个卷积层和3个全连接层</code>）到网络E中的19个权重层（<code>16个卷积层和3个全连接层</code>）。卷积层的宽度（<code>通道数量</code>）相当小，从第一层的64开始，然后在<code>每个最大池层后增加1倍</code>，直到达到512。在表2中，我们报告了每个配置的参数数目。 尽管深度很大，但我们网络的权重数量不会超过那些深度较浅、但卷积核和感受野宽度更大的网络。</p><ul><li>VGG16包含了16个隐藏层（13个卷积层和3个全连接层），如上图中的D列所示</li><li>VGG19包含了19个隐藏层（16个卷积层和3个全连接层），如上图中的E列所示</li></ul><p>VGG网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的max pooling。</p><hr><h5 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h5><p>我们整体都使用了非常小的<code>3x3卷积核</code>配合<code>步幅1</code>。显而易见的是，用两层的3x3卷积层组合（中间不包含池化层）所得到的感受野相当于一层的5x5卷积层的感受野；而三层这样的卷积层组合所得到的感受野相当于一层的7x7卷积核的感受野。那么，如果我们用三层3x3的卷积层组合来代替一层7x7卷积层，我们会得到什么呢？首先，我们并入了三个ReLU激活函数，而不是一个，这使决策功能的分辨力更强。 其次，我们减少参数的数量：假设三层3×3卷积层相叠的输入和输出都具有C个通道，则该叠层参数化为$3\times(3^2C^2)= 27C^2$个权重; 同时，一个7×7 卷积层需要$7^2C^2 = 49C^2$ 参数，参数增加81％。 这可以被看作是在7×7卷积中实施正规化， 迫使他们通过3×3卷积核进行分解（两者之间注入非线性）。</p><p>纳入1×1卷积核（配置C，表1）是一种增加决策函数的非线性而不影响卷积层感受野的方法。</p><p>Goodfellow等人（2014）将深度ConvNets（11个权重层）应用于街道号识别任务，并表明增加深度能获得更好的性能。 </p><h4 id="分类框架"><a href="#分类框架" class="headerlink" title="分类框架"></a>分类框架</h4><p>在本节中，我们将介绍ConvNet培训和评估的分类细节。</p><h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><p>ConvNet的训练过程<strong>基本上</strong>参照Krizhevsky等人（2012）（除了从多尺度训练图像中采集输入裁剪图像，如后文所述）。也就是说，训练是通过使用<code>小批量梯度下降</code>（基于反向传播（LeCun et al。，1989））的动量优化多项逻辑回归目标来实现的。 批量大小设置为<strong>256</strong>，动量为<strong>0.9</strong>。 训练通过权值衰减（L2惩罚系数设置为 $5 · 10^{−4}$ ）和前两个完全连接层（dropout设置为<strong>0.5</strong>）的dropout正则化来调整。 学习率最初设置为$10^{−2}$  ，然后在验证集精度停止改进时再降低10倍。 总的来说，学习率<strong>一共降低了3次</strong>，并且在<strong>370K个迭代</strong>（74代）后停止了学习。 我们推测，尽管与（Krizhevsky et al.，2012）相比，网络的参数数量更多，网络深度也更大，但能用<code>更少的迭代次数</code>来实现收敛，由于：（a）更大深度和更小卷积核所带来的隐式正则化；（b）某些图层的预初始化。</p><p>网络权重的初始化很重要，因为由于深度网络中的梯度不稳定，初始化不好可能会导致学习停滞。 为了避免这个问题，我们从训练配置A（表1）开始，这个网络足够浅，可以随机初始化进行训练。 然后，当训练更深的体系结构时，我们使用了<code>网络A的权值来初始化了前四个卷积层和最后三个完全连接的层，（中间层随机初始化）</code>。 我们没有降低预初始化图层的学习速率，允许它们在学习期间改变。 对于随机初始化（如有），我们从具有零均值和 $10^{−2}$ 方差的正态分布采样权重。 偏差初始化为零。 值得注意的是，在提交论文后，我们发现<code>可以使用Glorot＆Bengio（2010）的随机初始化程序在没有预先训练的情况下初始化权重</code>。</p><p>为了获得224×224固定大小的 ConvNet输入图像，他们从<code>重新缩放</code>的训练图像中<code>随机裁剪</code>（每个SGD迭代每个图像裁剪一次）。 为了进一步<strong>增强训练集</strong>，被裁剪的图像经过<code>随机水平翻转</code>和<code>随机RGB颜色偏移处理</code>（Krizhevsky et al.，2012）。 下面将介绍训练图像缩放。</p><p><strong>训练图像尺寸。</strong> 设S(the smallest side)是<strong>等比例缩放</strong>的训练图像的最小边，ConvNet基于这些图像的裁剪作为输入（我们也称S为训练尺度）。 虽然裁剪大小固定为224×224，但原则上S可以取不小于224的任何值：对于<strong>S = 224</strong>，裁剪图将捕获整幅图像统计数据，完全跨越训练图像的最小边; 对于<strong>S&gt;&gt;224</strong>，裁剪图将对应于图像的一小部分，包含一个小物体或一个物体部分。</p><p>我们考虑设定训练尺度S的两种方法。第一种方法是<code>固定S</code>，这对应于<code>单尺度训练</code>（注意采样作物中的图像内容仍然可以表示多尺度图像统计）。 在我们的实验中，我们评估了以两个固定尺度训练的模型：S = 256（已被广泛用于现有技术（Krizhevsky等，2012; Zeiler＆Fergus，2013; Sermanet等，2014））和S = 384。给定一个ConvNet配置，我们首先使用<strong>S = 256</strong>来训练网络。为了加速<strong>S = 384</strong>网络的训练，它被初始化为具有S = 256的预训练权重，并且我们使用较小的学习率初始值为 $10^{−3}$ 。</p><p>设定S的第二种方法是<code>多尺度训练</code>，其中通过从特定范围<code>[Smin，Smax]</code>（我们使用<strong>Smin = 256</strong>和<strong>Smax = 512</strong>）<code>随机采样S来单独重新调整每个训练图像</code>。 由于图像中的物体可能具有不同的大小，因此在训练时考虑到这一点是有益的。 这也可以看作是通过<strong>缩放抖动来增强训练集</strong>，其中单个模型被训练以识别多种类别的物体。 出于速度的原因，我们通过对具有相同配置的单尺度模型的所有层进行微调来训练多尺度模型，并使用固定的<strong>S = 384</strong>进行预训练。</p><h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><p>在测试时，给定一个训练有素的ConvNet和一个输入图像，它按以下方式分类。首先，将其等比例缩放到预定义的最小边，表示为Q（我们也将其称为测试尺度）。我们注意到，Q不一定等于训练尺度S（如我们将在第4部分中所示，<code>对每个S使用几个Q值可获得性能改进</code>）。然后，网络以类似于（Sermanet等人，2014）的方式被密集地应用在重新缩放的测试图像上。也就是说，<code>完全连接的层首先被转换成卷积层</code>（第一个FC层转为<strong>7×7</strong>的卷积层，后两个FC层转为<strong>1×1</strong> 卷积层）。然后将所得的全卷积网络应用于整个（<u>未裁剪的</u>）图像。其结果是一个<strong>类别得分映射</strong>，其类别数等于任务的目标分类数，以及一个可变的空间分辨率，取决于输入图像的大小。最后，为了获得固定大小的图像类别分数的向量，类别得分映射会被<u>空间平均（加总池化）</u>。我们还通过<strong>水平翻转图像来增强测试集</strong>；对原始图像和翻转图像的softmax分类概率进行<code>平均</code>以获得图像的最终分数。</p><p>由于卷积边界条件不同，<code>多裁剪图像评估</code>与<code>密集评估</code>是互补的：将ConvNet应用于裁剪图像时，卷积后的特征映射用零填充，而在密集评估的情况下，同一裁切图像的填充天然地来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获更多的上下文信息。</p><h5 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h5><p>实现源自公开发布的<code>C ++ Caffe工具箱</code>（Jia，2013）（2013年12月推出），但包含许多重大修改，使得我们能在装有<code>多个GPU</code>的单系统中执行训练和评估，以及能够对<code>多种规模的全尺寸（未裁剪）图像</code>（如上所述）进行训练和评估。与使用单个GPU相比，我们概念更简单的方案在现成的<code>4 GPU系统上已经提供了3.75倍的加速</code>。在配备四个NVIDIA Titan Black GPU的系统上，根据架构的不同，训练一个网络需要<strong>2-3周</strong>的时间。</p><h4 id="分类实验"><a href="#分类实验" class="headerlink" title="分类实验"></a>分类实验</h4><p>该数据集包括1000种分类的图像，并且被分成三组：训练集（1.3M张图像），验证集（50K张图像）和测试集（100K张标签被去除的图像）。</p><h5 id="单尺度评估"><a href="#单尺度评估" class="headerlink" title="单尺度评估"></a>单尺度评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet performance at a single test scale.jpg"></p><ul><li>虽然额外的非线性确实有帮助（C比B好），但使用感受野范围不少的卷积核（D比C好）捕获空间上下文也很重要。</li><li>带有小型卷积核的深网优于具有更大卷积核的浅网。</li><li>通过尺度抖动来增强训练集确实有助于捕获多尺度图像统计信息。</li></ul><h5 id="多尺度评估"><a href="#多尺度评估" class="headerlink" title="多尺度评估"></a>多尺度评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet performance at a multiple test scale.jpg"></p><h5 id="多裁切图像评估"><a href="#多裁切图像评估" class="headerlink" title="多裁切图像评估"></a>多裁切图像评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet evaluation techniques comparison.jpg"> </p><ul><li>多裁切图像与密集评估，这两种方法确实是互补，因为它们的组合优于其中的每一种。</li></ul><h5 id="卷积网络融合"><a href="#卷积网络融合" class="headerlink" title="卷积网络融合"></a>卷积网络融合</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Multiple ConvNet fusion results.jpg"></p><h5 id="与当前最先进的技术相比较"><a href="#与当前最先进的技术相比较" class="headerlink" title="与当前最先进的技术相比较"></a>与当前最先进的技术相比较</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Comparison with the state of the art in ILSVRC classification.jpg"></p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>在这项工作中，我们评估了用于大规模图像分类的深层卷积网络（多达<code>19个权值层</code>）。 已经证明，<code>表示层的深度有利于分类准确性</code>，并且通过大幅增加网络深度便可以使用传统的ConvNet架构来实现ImageNet挑战数据集上的最新性能（LeCun等，1989; Krizhevsky等， 2012）。 在附录中，我们还展示了我们的模型能很好地<code>泛化应用</code>于其他的任务和数据集，不亚于甚至性能优于那些深度略浅、更复杂的识别流水线。 我们的结果再一次证实了视觉表示中<code>深度的重要性</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MachineLearningInAction_Code</title>
    <link href="http://yoursite.com/2018/11/26/MachineLearningInAction-Code/"/>
    <id>http://yoursite.com/2018/11/26/MachineLearningInAction-Code/</id>
    <published>2018-11-26T09:54:11.000Z</published>
    <updated>2018-11-27T11:23:20.893Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h3 id="Chapter13"><a href="#Chapter13" class="headerlink" title="Chapter13"></a><a href="http://ml.apachecn.org/mlia/pca/" target="_blank" rel="noopener">Chapter13</a></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># datArr = [map(float,line) for line in stringArr]   #only support python2.x</span></span><br><span class="line">datArr = [[float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line] <span class="keyword">for</span> line <span class="keyword">in</span> stringArr] <span class="comment">#support python3.x</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在shell里输入python指令so stupid !!  Please use IDE,example 'PyCharm' </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pca</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat = pca.loadDataSet(<span class="string">'testSet.txt'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; shape(lowDMat) # support python2.x</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">1</span>)   <span class="comment"># (1000, 1)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>) <span class="comment"># (1000, 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>) <span class="comment"># (1000, 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">... </span>...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制降维后的数据reconMat和原始数据dataMat</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fig = plt.figure()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax.scatter(dataMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], dataMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],marker=<span class="string">'^'</span>,s=<span class="number">90</span>)</span><br><span class="line">&lt;matplotlib.collections.PathCollection object at <span class="number">0x11a142160</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax.scatter(reconMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], reconMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],marker=<span class="string">'o'</span>,s=<span class="number">50</span>,c=<span class="string">'r'</span>)</span><br><span class="line">&lt;matplotlib.collections.PathCollection object at <span class="number">0x11a1424e0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat, reconMat = pca.pca(dataMat, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat</span><br><span class="line">matrix([[<span class="number">-2.51033597</span>,  <span class="number">0.15840394</span>],</span><br><span class="line">        [<span class="number">-2.86915379</span>,  <span class="number">0.5092619</span> ],</span><br><span class="line">        [ <span class="number">0.09741085</span>, <span class="number">-0.20728318</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">-0.50166225</span>, <span class="number">-0.62056456</span>],</span><br><span class="line">        [<span class="number">-0.05898712</span>, <span class="number">-0.02335614</span>],</span><br><span class="line">        [<span class="number">-0.18978714</span>, <span class="number">-1.37276015</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat</span><br><span class="line">matrix([[<span class="number">10.235186</span>, <span class="number">11.321997</span>],</span><br><span class="line">        [<span class="number">10.122339</span>, <span class="number">11.810993</span>],</span><br><span class="line">        [ <span class="number">9.190236</span>,  <span class="number">8.904943</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">9.854922</span>,  <span class="number">9.201393</span>],</span><br><span class="line">        [ <span class="number">9.11458</span> ,  <span class="number">9.134215</span>],</span><br><span class="line">        [<span class="number">10.334899</span>,  <span class="number">8.543604</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat</span><br><span class="line">matrix([[<span class="number">10.235186</span>, <span class="number">11.321997</span>],</span><br><span class="line">        [<span class="number">10.122339</span>, <span class="number">11.810993</span>],</span><br><span class="line">        [ <span class="number">9.190236</span>,  <span class="number">8.904943</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">9.854922</span>,  <span class="number">9.201393</span>],</span><br><span class="line">        [ <span class="number">9.11458</span> ,  <span class="number">9.134215</span>],</span><br><span class="line">        [<span class="number">10.334899</span>,  <span class="number">8.543604</span>]])</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有剔除任何特征，那么重构之后的数据reconMat会和原始的数据dataMat重合</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pca</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat = pca.replaceNanWithMean()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>meanVals = mean(dataMat, axis = <span class="number">0</span>)  <span class="comment"># np.mean(dataMat, axis = 0)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>meanRemoved = dataMat - meanVals</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>covMat = cov(meanRemoved, rowvar = <span class="number">0</span>) <span class="comment"># covMat = np.cov(meanRemoved, rowvar = 0)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eigVals,eigVects = linalg.eig(mat(covMat)) <span class="comment"># np.linalg.eig(np.mat(covMat))</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eigVals</span><br><span class="line">array([ <span class="number">5.34151979e+07</span>,  <span class="number">2.17466719e+07</span>,  <span class="number">8.24837662e+06</span>,  <span class="number">2.07388086e+06</span>,</span><br><span class="line">        <span class="number">1.31540439e+06</span>,  <span class="number">4.67693557e+05</span>,  <span class="number">2.90863555e+05</span>,  <span class="number">2.83668601e+05</span>,</span><br><span class="line">        <span class="number">2.37155830e+05</span>,  <span class="number">2.08513836e+05</span>,  <span class="number">1.96098849e+05</span>,  <span class="number">1.86856549e+05</span>,</span><br><span class="line">        <span class="number">1.52422354e+05</span>,  <span class="number">1.13215032e+05</span>,  <span class="number">1.08493848e+05</span>,  <span class="number">1.02849533e+05</span>,</span><br><span class="line">        <span class="number">1.00166164e+05</span>,  <span class="number">8.33473762e+04</span>,  <span class="number">8.15850591e+04</span>,  <span class="number">7.76560524e+04</span>,</span><br><span class="line">        <span class="number">6.66060410e+04</span>,  <span class="number">6.52620058e+04</span>,  <span class="number">5.96776503e+04</span>,  <span class="number">5.16269933e+04</span>,</span><br><span class="line">        <span class="number">5.03324580e+04</span>,  <span class="number">4.54661746e+04</span>,  <span class="number">4.41914029e+04</span>,  <span class="number">4.15532551e+04</span>,</span><br><span class="line">        <span class="number">3.55294040e+04</span>,  <span class="number">3.31436743e+04</span>,  <span class="number">2.67385181e+04</span>,  <span class="number">1.47123429e+04</span>,</span><br><span class="line">        <span class="number">1.44089194e+04</span>,  <span class="number">1.09321187e+04</span>,  <span class="number">1.04841308e+04</span>,  <span class="number">9.48876548e+03</span>,</span><br><span class="line">        <span class="number">8.34665462e+03</span>,  <span class="number">7.22765535e+03</span>,  <span class="number">5.34196392e+03</span>,  <span class="number">4.95614671e+03</span>,</span><br><span class="line">        <span class="number">4.23060022e+03</span>,  <span class="number">4.10673182e+03</span>,  <span class="number">3.41199406e+03</span>,  <span class="number">3.24193522e+03</span>,</span><br><span class="line">        <span class="number">2.74523635e+03</span>,  <span class="number">2.35027999e+03</span>,  <span class="number">2.16835314e+03</span>,  <span class="number">1.86414157e+03</span>,</span><br><span class="line">        <span class="number">1.76741826e+03</span>,  <span class="number">1.70492093e+03</span>,  <span class="number">1.66199683e+03</span>,  <span class="number">1.53948465e+03</span>,</span><br><span class="line">        <span class="number">1.33096008e+03</span>,  <span class="number">1.25591691e+03</span>,  <span class="number">1.15509389e+03</span>,  <span class="number">1.12410108e+03</span>,</span><br><span class="line">        <span class="number">1.03213798e+03</span>,  <span class="number">1.00972093e+03</span>,  <span class="number">9.50542179e+02</span>,  <span class="number">9.09791361e+02</span>,</span><br><span class="line">        <span class="number">8.32001551e+02</span>,  <span class="number">8.08898242e+02</span>,  <span class="number">7.37343627e+02</span>,  <span class="number">6.87596830e+02</span>,</span><br><span class="line">        <span class="number">5.64452104e+02</span>,  <span class="number">5.51812250e+02</span>,  <span class="number">5.37209115e+02</span>,  <span class="number">4.93029995e+02</span>,</span><br><span class="line">        <span class="number">4.13720573e+02</span>,  <span class="number">3.90222119e+02</span>,  <span class="number">3.37288784e+02</span>,  <span class="number">3.27558605e+02</span>,</span><br><span class="line">        <span class="number">3.08869553e+02</span>,  <span class="number">2.46285839e+02</span>,  <span class="number">2.28893093e+02</span>,  <span class="number">1.96447852e+02</span>,</span><br><span class="line">        <span class="number">1.75559820e+02</span>,  <span class="number">1.65795169e+02</span>,  <span class="number">1.56428052e+02</span>,  <span class="number">1.39671194e+02</span>,</span><br><span class="line">        <span class="number">1.28662864e+02</span>,  <span class="number">1.15624070e+02</span>,  <span class="number">1.10318239e+02</span>,  <span class="number">1.08663541e+02</span>,</span><br><span class="line">        <span class="number">1.00695416e+02</span>,  <span class="number">9.80687852e+01</span>,  <span class="number">8.34968275e+01</span>,  <span class="number">7.53025397e+01</span>,</span><br><span class="line">        <span class="number">6.89260158e+01</span>,  <span class="number">6.67786503e+01</span>,  <span class="number">6.09412873e+01</span>,  <span class="number">5.30974002e+01</span>,</span><br><span class="line">        <span class="number">4.71797825e+01</span>,  <span class="number">4.50701108e+01</span>,  <span class="number">4.41349593e+01</span>,  <span class="number">4.03313416e+01</span>,</span><br><span class="line">        <span class="number">3.95741636e+01</span>,  <span class="number">3.74000035e+01</span>,  <span class="number">3.44211326e+01</span>,  <span class="number">3.30031584e+01</span>,</span><br><span class="line">        <span class="number">3.03317756e+01</span>,  <span class="number">2.88994580e+01</span>,  <span class="number">2.76478754e+01</span>,  <span class="number">2.57708695e+01</span>,</span><br><span class="line">        <span class="number">2.44506430e+01</span>,  <span class="number">2.31640106e+01</span>,  <span class="number">2.26956957e+01</span>,  <span class="number">2.16925102e+01</span>,</span><br><span class="line">        <span class="number">2.10114869e+01</span>,  <span class="number">2.00984697e+01</span>,  <span class="number">1.86489543e+01</span>,  <span class="number">1.83733216e+01</span>,</span><br><span class="line">        <span class="number">1.72517802e+01</span>,  <span class="number">1.60481189e+01</span>,  <span class="number">1.54406997e+01</span>,  <span class="number">1.48356499e+01</span>,</span><br><span class="line">        <span class="number">1.44273357e+01</span>,  <span class="number">1.42318192e+01</span>,  <span class="number">1.35592064e+01</span>,  <span class="number">1.30696836e+01</span>,</span><br><span class="line">        <span class="number">1.28193512e+01</span>,  <span class="number">1.22093626e+01</span>,  <span class="number">1.15228376e+01</span>,  <span class="number">1.12141738e+01</span>,</span><br><span class="line">        <span class="number">1.02585936e+01</span>,  <span class="number">9.86906139e+00</span>,  <span class="number">9.58794460e+00</span>,  <span class="number">9.41686288e+00</span>,</span><br><span class="line">        <span class="number">9.20276340e+00</span>,  <span class="number">8.63791398e+00</span>,  <span class="number">8.20622561e+00</span>,  <span class="number">8.01020114e+00</span>,</span><br><span class="line">        <span class="number">7.53391290e+00</span>,  <span class="number">7.33168361e+00</span>,  <span class="number">7.09960245e+00</span>,  <span class="number">7.02149364e+00</span>,</span><br><span class="line">        <span class="number">6.76557324e+00</span>,  <span class="number">6.34504733e+00</span>,  <span class="number">6.01919292e+00</span>,  <span class="number">5.81680918e+00</span>,</span><br><span class="line">        <span class="number">5.44653788e+00</span>,  <span class="number">5.12338463e+00</span>,  <span class="number">4.79593185e+00</span>,  <span class="number">4.47851795e+00</span>,</span><br><span class="line">        <span class="number">4.50369987e+00</span>,  <span class="number">4.27479386e+00</span>,  <span class="number">3.89124198e+00</span>,  <span class="number">3.56466892e+00</span>,</span><br><span class="line">        <span class="number">3.32248982e+00</span>,  <span class="number">2.97665360e+00</span>,  <span class="number">2.61425544e+00</span>,  <span class="number">2.31802829e+00</span>,</span><br><span class="line">        <span class="number">2.17171124e+00</span>,  <span class="number">1.99239284e+00</span>,  <span class="number">1.96616566e+00</span>,  <span class="number">1.88149281e+00</span>,</span><br><span class="line">        <span class="number">1.79228288e+00</span>,  <span class="number">1.71378363e+00</span>,  <span class="number">1.68028783e+00</span>,  <span class="number">1.60686268e+00</span>,</span><br><span class="line">        <span class="number">1.47158244e+00</span>,  <span class="number">1.40656712e+00</span>,  <span class="number">1.37808906e+00</span>,  <span class="number">1.27967672e+00</span>,</span><br><span class="line">        <span class="number">1.22803716e+00</span>,  <span class="number">1.18531109e+00</span>,  <span class="number">9.38857180e-01</span>,  <span class="number">9.18222054e-01</span>,</span><br><span class="line">        <span class="number">8.26265393e-01</span>,  <span class="number">7.96585842e-01</span>,  <span class="number">7.74597255e-01</span>,  <span class="number">7.14002770e-01</span>,</span><br><span class="line">        <span class="number">6.79457797e-01</span>,  <span class="number">6.37928310e-01</span>,  <span class="number">6.24646758e-01</span>,  <span class="number">5.34605353e-01</span>,</span><br><span class="line">        <span class="number">4.60658687e-01</span>,  <span class="number">4.24265893e-01</span>,  <span class="number">4.08634622e-01</span>,  <span class="number">3.70321764e-01</span>,</span><br><span class="line">        <span class="number">3.67016386e-01</span>,  <span class="number">3.35858033e-01</span>,  <span class="number">3.29780397e-01</span>,  <span class="number">2.94348753e-01</span>,</span><br><span class="line">        <span class="number">2.84154176e-01</span>,  <span class="number">2.72703994e-01</span>,  <span class="number">2.63265991e-01</span>,  <span class="number">2.45227786e-01</span>,</span><br><span class="line">        <span class="number">2.25805135e-01</span>,  <span class="number">2.22331919e-01</span>,  <span class="number">2.13514673e-01</span>,  <span class="number">1.93961935e-01</span>,</span><br><span class="line">        <span class="number">1.91647269e-01</span>,  <span class="number">1.83668491e-01</span>,  <span class="number">1.82518017e-01</span>,  <span class="number">1.65310922e-01</span>,</span><br><span class="line">        <span class="number">1.57447909e-01</span>,  <span class="number">1.51263974e-01</span>,  <span class="number">1.39427297e-01</span>,  <span class="number">1.32638882e-01</span>,</span><br><span class="line">        <span class="number">1.28000027e-01</span>,  <span class="number">1.13559952e-01</span>,  <span class="number">1.12576237e-01</span>,  <span class="number">1.08809771e-01</span>,</span><br><span class="line">        <span class="number">1.07136355e-01</span>,  <span class="number">8.60839655e-02</span>,  <span class="number">8.50467792e-02</span>,  <span class="number">8.29254355e-02</span>,</span><br><span class="line">        <span class="number">7.03701660e-02</span>,  <span class="number">6.44475619e-02</span>,  <span class="number">6.09866327e-02</span>,  <span class="number">6.05709478e-02</span>,</span><br><span class="line">        <span class="number">5.93963958e-02</span>,  <span class="number">5.22163549e-02</span>,  <span class="number">4.92729703e-02</span>,  <span class="number">4.80022983e-02</span>,</span><br><span class="line">        <span class="number">4.51487439e-02</span>,  <span class="number">4.30180504e-02</span>,  <span class="number">4.13368324e-02</span>,  <span class="number">4.03281604e-02</span>,</span><br><span class="line">        <span class="number">3.91576587e-02</span>,  <span class="number">3.54198873e-02</span>,  <span class="number">3.31199510e-02</span>,  <span class="number">3.13547234e-02</span>,</span><br><span class="line">        <span class="number">3.07226509e-02</span>,  <span class="number">2.98354196e-02</span>,  <span class="number">2.81949091e-02</span>,  <span class="number">2.49158051e-02</span>,</span><br><span class="line">        <span class="number">2.36374781e-02</span>,  <span class="number">2.28360210e-02</span>,  <span class="number">2.19602047e-02</span>,  <span class="number">2.00166957e-02</span>,</span><br><span class="line">        <span class="number">1.86597535e-02</span>,  <span class="number">1.80415918e-02</span>,  <span class="number">1.72261012e-02</span>,  <span class="number">1.60703860e-02</span>,</span><br><span class="line">        <span class="number">1.49566735e-02</span>,  <span class="number">1.40165444e-02</span>,  <span class="number">1.31296856e-02</span>,  <span class="number">1.21358005e-02</span>,</span><br><span class="line">        <span class="number">1.07166503e-02</span>,  <span class="number">1.01045695e-02</span>,  <span class="number">9.76055340e-03</span>,  <span class="number">9.16740926e-03</span>,</span><br><span class="line">        <span class="number">8.78108857e-03</span>,  <span class="number">8.67465278e-03</span>,  <span class="number">8.30918514e-03</span>,  <span class="number">8.05104488e-03</span>,</span><br><span class="line">        <span class="number">7.56152126e-03</span>,  <span class="number">7.31508852e-03</span>,  <span class="number">7.26347037e-03</span>,  <span class="number">6.65728354e-03</span>,</span><br><span class="line">        <span class="number">6.50769617e-03</span>,  <span class="number">6.28009879e-03</span>,  <span class="number">6.19160730e-03</span>,  <span class="number">5.64130272e-03</span>,</span><br><span class="line">        <span class="number">5.30195373e-03</span>,  <span class="number">5.07453702e-03</span>,  <span class="number">4.47372286e-03</span>,  <span class="number">4.32543895e-03</span>,</span><br><span class="line">        <span class="number">4.22006582e-03</span>,  <span class="number">3.97065729e-03</span>,  <span class="number">3.75292740e-03</span>,  <span class="number">3.64861290e-03</span>,</span><br><span class="line">        <span class="number">3.38915810e-03</span>,  <span class="number">3.27965962e-03</span>,  <span class="number">3.06633825e-03</span>,  <span class="number">2.99206786e-03</span>,</span><br><span class="line">        <span class="number">2.83586784e-03</span>,  <span class="number">2.74987243e-03</span>,  <span class="number">2.31066313e-03</span>,  <span class="number">2.26782347e-03</span>,</span><br><span class="line">        <span class="number">1.82206662e-03</span>,  <span class="number">1.74955624e-03</span>,  <span class="number">1.69305161e-03</span>,  <span class="number">1.66624597e-03</span>,</span><br><span class="line">        <span class="number">1.55346749e-03</span>,  <span class="number">1.51278404e-03</span>,  <span class="number">1.47296800e-03</span>,  <span class="number">1.33617458e-03</span>,</span><br><span class="line">        <span class="number">1.30517592e-03</span>,  <span class="number">1.24056353e-03</span>,  <span class="number">1.19823961e-03</span>,  <span class="number">1.14381059e-03</span>,</span><br><span class="line">        <span class="number">1.13027458e-03</span>,  <span class="number">1.11081803e-03</span>,  <span class="number">1.08359152e-03</span>,  <span class="number">1.03517496e-03</span>,</span><br><span class="line">        <span class="number">1.00164593e-03</span>,  <span class="number">9.50024604e-04</span>,  <span class="number">8.94981182e-04</span>,  <span class="number">8.74363843e-04</span>,</span><br><span class="line">        <span class="number">7.98497545e-04</span>,  <span class="number">7.51612220e-04</span>,  <span class="number">6.63964302e-04</span>,  <span class="number">6.21097646e-04</span>,</span><br><span class="line">        <span class="number">6.18098604e-04</span>,  <span class="number">5.72611403e-04</span>,  <span class="number">5.57509231e-04</span>,  <span class="number">5.47002381e-04</span>,</span><br><span class="line">        <span class="number">5.27195077e-04</span>,  <span class="number">5.11487997e-04</span>,  <span class="number">4.87787872e-04</span>,  <span class="number">4.74249071e-04</span>,</span><br><span class="line">        <span class="number">4.52367689e-04</span>,  <span class="number">4.24431101e-04</span>,  <span class="number">4.19119024e-04</span>,  <span class="number">3.72489906e-04</span>,</span><br><span class="line">        <span class="number">3.38125455e-04</span>,  <span class="number">3.34002144e-04</span>,  <span class="number">2.97951371e-04</span>,  <span class="number">2.84845901e-04</span>,</span><br><span class="line">        <span class="number">2.79038288e-04</span>,  <span class="number">2.77054476e-04</span>,  <span class="number">2.67962797e-04</span>,  <span class="number">2.54815126e-04</span>,</span><br><span class="line">        <span class="number">2.29230595e-04</span>,  <span class="number">1.99245436e-04</span>,  <span class="number">1.90381389e-04</span>,  <span class="number">1.84497913e-04</span>,</span><br><span class="line">        <span class="number">1.77415682e-04</span>,  <span class="number">1.68160613e-04</span>,  <span class="number">1.63992031e-04</span>,  <span class="number">1.58025553e-04</span>,</span><br><span class="line">        <span class="number">1.54226003e-04</span>,  <span class="number">1.40079892e-04</span>,  <span class="number">1.46097434e-04</span>,  <span class="number">1.46890640e-04</span>,</span><br><span class="line">        <span class="number">1.35736724e-04</span>,  <span class="number">9.90265098e-05</span>,  <span class="number">1.04252870e-04</span>,  <span class="number">1.16752515e-04</span>,</span><br><span class="line">        <span class="number">1.14080847e-04</span>,  <span class="number">1.22704035e-04</span>,  <span class="number">9.66039062e-05</span>,  <span class="number">9.60766570e-05</span>,</span><br><span class="line">        <span class="number">9.16166335e-05</span>,  <span class="number">9.07003478e-05</span>,  <span class="number">8.60212633e-05</span>,  <span class="number">8.32654024e-05</span>,</span><br><span class="line">        <span class="number">7.70526077e-05</span>,  <span class="number">7.36470020e-05</span>,  <span class="number">7.24998305e-05</span>,  <span class="number">6.80209910e-05</span>,</span><br><span class="line">        <span class="number">6.68682698e-05</span>,  <span class="number">6.14500420e-05</span>,  <span class="number">5.99843174e-05</span>,  <span class="number">5.49918003e-05</span>,</span><br><span class="line">        <span class="number">5.24646955e-05</span>,  <span class="number">5.13403849e-05</span>,  <span class="number">5.02336264e-05</span>,  <span class="number">4.89288507e-05</span>,</span><br><span class="line">        <span class="number">4.51104475e-05</span>,  <span class="number">4.29823765e-05</span>,  <span class="number">4.18869715e-05</span>,  <span class="number">4.14341562e-05</span>,</span><br><span class="line">        <span class="number">3.94822843e-05</span>,  <span class="number">3.80307292e-05</span>,  <span class="number">3.57776535e-05</span>,  <span class="number">3.43901591e-05</span>,</span><br><span class="line">        <span class="number">2.98089203e-05</span>,  <span class="number">2.72388358e-05</span>,  <span class="number">2.42608885e-05</span>,  <span class="number">2.30962279e-05</span>,</span><br><span class="line">        <span class="number">2.27807559e-05</span>,  <span class="number">2.14440814e-05</span>,  <span class="number">1.96208174e-05</span>,  <span class="number">1.91217363e-05</span>,</span><br><span class="line">        <span class="number">1.88276186e-05</span>,  <span class="number">1.66549051e-05</span>,  <span class="number">1.46846459e-05</span>,  <span class="number">1.39779892e-05</span>,</span><br><span class="line">        <span class="number">1.43753346e-05</span>,  <span class="number">1.21760519e-05</span>,  <span class="number">1.20295835e-05</span>,  <span class="number">1.13426750e-05</span>,</span><br><span class="line">        <span class="number">1.09258905e-05</span>,  <span class="number">1.02782991e-05</span>,  <span class="number">1.01021808e-05</span>,  <span class="number">9.72678794e-06</span>,</span><br><span class="line">        <span class="number">9.64538296e-06</span>,  <span class="number">9.23630205e-06</span>,  <span class="number">8.93991858e-06</span>,  <span class="number">8.34247982e-06</span>,</span><br><span class="line">        <span class="number">7.36188590e-06</span>,  <span class="number">7.20354827e-06</span>,  <span class="number">6.69282813e-06</span>,  <span class="number">6.49477814e-06</span>,</span><br><span class="line">        <span class="number">4.45482134e-06</span>,  <span class="number">4.65422046e-06</span>,  <span class="number">5.09342483e-06</span>,  <span class="number">5.31392220e-06</span>,</span><br><span class="line">        <span class="number">5.67034892e-06</span>,  <span class="number">5.91044556e-06</span>,  <span class="number">6.00244889e-06</span>,  <span class="number">4.11265577e-06</span>,</span><br><span class="line">        <span class="number">3.77558985e-06</span>,  <span class="number">3.65202836e-06</span>,  <span class="number">3.48065950e-06</span>,  <span class="number">2.78847699e-06</span>,</span><br><span class="line">        <span class="number">2.66299628e-06</span>,  <span class="number">2.57492503e-06</span>,  <span class="number">2.39210233e-06</span>,  <span class="number">2.06298821e-06</span>,</span><br><span class="line">        <span class="number">2.00824521e-06</span>,  <span class="number">1.76373602e-06</span>,  <span class="number">1.58273269e-06</span>,  <span class="number">1.32211395e-06</span>,</span><br><span class="line">        <span class="number">1.49813697e-06</span>,  <span class="number">1.42489429e-06</span>,  <span class="number">1.44003524e-06</span>,  <span class="number">1.10002716e-06</span>,</span><br><span class="line">        <span class="number">9.01008863e-07</span>,  <span class="number">8.49881106e-07</span>,  <span class="number">7.62521870e-07</span>,  <span class="number">6.57641103e-07</span>,</span><br><span class="line">        <span class="number">5.85636641e-07</span>,  <span class="number">5.33937361e-07</span>,  <span class="number">4.16077215e-07</span>,  <span class="number">3.33765858e-07</span>,</span><br><span class="line">        <span class="number">2.95575265e-07</span>,  <span class="number">2.54744632e-07</span>,  <span class="number">2.20144574e-07</span>,  <span class="number">1.86314525e-07</span>,</span><br><span class="line">        <span class="number">1.77370967e-07</span>,  <span class="number">1.54794344e-07</span>,  <span class="number">1.47331687e-07</span>,  <span class="number">1.39738552e-07</span>,</span><br><span class="line">        <span class="number">1.04110968e-07</span>,  <span class="number">1.00786519e-07</span>,  <span class="number">9.38635094e-08</span>,  <span class="number">9.10853310e-08</span>,</span><br><span class="line">        <span class="number">8.71546325e-08</span>,  <span class="number">7.48338889e-08</span>,  <span class="number">6.06817435e-08</span>,  <span class="number">5.66479200e-08</span>,</span><br><span class="line">        <span class="number">5.24576913e-08</span>,  <span class="number">4.57020648e-08</span>,  <span class="number">2.89942624e-08</span>,  <span class="number">2.60449421e-08</span>,</span><br><span class="line">        <span class="number">2.10987990e-08</span>,  <span class="number">2.17618741e-08</span>,  <span class="number">1.75542294e-08</span>,  <span class="number">1.34637025e-08</span>,</span><br><span class="line">        <span class="number">1.27167435e-08</span>,  <span class="number">1.23258201e-08</span>,  <span class="number">9.86367963e-09</span>,  <span class="number">1.04987513e-08</span>,</span><br><span class="line">        <span class="number">8.49423161e-09</span>,  <span class="number">9.33428155e-09</span>,  <span class="number">7.42190962e-09</span>,  <span class="number">6.84633796e-09</span>,</span><br><span class="line">        <span class="number">6.46870806e-09</span>,  <span class="number">5.76455817e-09</span>,  <span class="number">5.01138098e-09</span>,  <span class="number">3.48686453e-09</span>,</span><br><span class="line">        <span class="number">2.91267177e-09</span>,  <span class="number">2.77880628e-09</span>,  <span class="number">1.73093438e-09</span>,  <span class="number">1.42391194e-09</span>,</span><br><span class="line">        <span class="number">9.24975774e-10</span>,  <span class="number">1.16454971e-09</span>,  <span class="number">6.95073614e-10</span>,  <span class="number">1.11815884e-09</span>,</span><br><span class="line">        <span class="number">1.80003518e-10</span>,  <span class="number">1.97062415e-10</span>,  <span class="number">2.61936054e-10</span>,  <span class="number">6.13219223e-10</span>,</span><br><span class="line">        <span class="number">5.27584239e-10</span>, <span class="number">-2.16417104e-15</span>,  <span class="number">2.10627686e-15</span>,  <span class="number">6.25652286e-16</span>,</span><br><span class="line">       <span class="number">-1.69155643e-17</span>,  <span class="number">5.08498479e-19</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>])</span><br><span class="line"><span class="comment"># 发现超过20％的特征值都是0，意味着这些特征都是其他特征的副本，也就是说它们可以通过其他特征来表示，而本身并没有提供额外的信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataMat.shape (1567, 590)</span></span><br><span class="line"><span class="comment"># meanVals.shape (1, 590)</span></span><br><span class="line"><span class="comment"># meanRemoved.shape (1567, 590)</span></span><br><span class="line"><span class="comment"># covMat.shape (590, 590)</span></span><br><span class="line"><span class="comment"># eigVects.shape (590, 590)</span></span><br><span class="line"><span class="comment"># eigVals.shape (590,)</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 半导体制造数据</span></span><br><span class="line">http://archive.ics.uci.edu/ml/machine-learning-databases/secom/</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>DeepLearningwithKeras_Code</title>
    <link href="http://yoursite.com/2018/11/26/DeepLearningwithKeras-Code/"/>
    <id>http://yoursite.com/2018/11/26/DeepLearningwithKeras-Code/</id>
    <published>2018-11-26T02:44:25.000Z</published>
    <updated>2018-11-29T07:23:56.248Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><ul><li><p>keras_CIFAR10_simple</p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_0.png" alt=""></p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_1.png" alt=""></p><center class="half"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_modleAccuracy.png" width="300"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_modleLoss.png" width="300"><br></center></li><li><p>keras_CIFAR10_V1</p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_run1.png" alt=""></p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_run2.png" alt=""></p><center class="half"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_Accuracy.png" width="300"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_Loss.png" width="300"><br></center></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MachineLearning_Environment configuration</title>
    <link href="http://yoursite.com/2018/11/25/MachineLearning_EnvironmentConfiguration/"/>
    <id>http://yoursite.com/2018/11/25/MachineLearning_EnvironmentConfiguration/</id>
    <published>2018-11-25T11:13:41.000Z</published>
    <updated>2018-12-27T10:51:31.518Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h4><p><a href="http://www.cnblogs.com/harvey888/p/5465452.html" target="_blank" rel="noopener">Anaconda多环境多版本python配置指导</a></p><ul><li>更换镜像（<a href="https://www.jianshu.com/p/d54546ab315e" target="_blank" rel="noopener">Mac下通过Anaconda安装Tensorflow</a>）</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加Anaconda的TUNA镜像</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置搜索时显示通道地址</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda config --<span class="built_in">set</span> show_channel_urls yes</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda install numpy   <span class="comment">#测试是否添加成功</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 之后会自动在用户根目录生成“.condarc”文件，可以在终端用 </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls -a </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令查看该文件，如果要删除镜像，直接删除“.condarc”文件即可： </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm .condarc</span></span><br></pre></td></tr></table></figure><ul><li>Mac <strong>Pycharm</strong>配置Anaconda环境</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Command + ,</span><br><span class="line">- Project → Project Interpreter </span><br><span class="line">- 齿轮 → Add → System Interpreter </span><br><span class="line">- 齿轮 → <span class="string">'/Users/Captain/anaconda3/python.app/Contents/MacOS/python'</span></span><br></pre></td></tr></table></figure><ul><li><p>shell 使用Anaconda的python</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> vim ~/.bash_profile</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Anaconda3</span></span><br><span class="line">export PATH=~/anaconda3/bin:$PATH  #若想使用系统自带的python版本，将此行注释即可</span><br></pre></td></tr></table></figure></li><li><p>Anaconda/env下 安装包路径</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/  <span class="comment">#keras</span></span></span><br></pre></td></tr></table></figure></li><li><p>anaconda_downgrade Failed</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">download low_version Anaconda</span><br></pre></td></tr></table></figure></li><li><p><a href="https://repo.anaconda.com/archive/" target="_blank" rel="noopener">Anaconda installer archive</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Anaconda2-5.3.0-MacOSX-x86_64.pkg  # 对应python3.6</span><br></pre></td></tr></table></figure></li><li><p><a href="https://blog.csdn.net/u011606714/article/details/77741324" target="_blank" rel="noopener">Anaconda_Jupyter</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> conda install ipykernel</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><a href="https://www.tensorflow.org/versions/r1.1/install/install_mac" target="_blank" rel="noopener">TensorFlow on MacOS</a></p><ul><li><p>暂不支持python3.7</p></li><li><p>查看TensorFlow版本</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tf.__version__</span><br><span class="line"><span class="string">'1.12.0'</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li><li><p>测试是否安装成功</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sess = tf.Session()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(sess.run(hello))</span><br><span class="line">Hello,TensorFlow!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- I tensorflow/core/platform/cpu_feature_guard.cc:<span class="number">140</span>] Your CPU supports instructions that this TensorFlow binary was <span class="keyword">not</span> compiled to use: AVX2 FMA</span><br></pre></td></tr></table></figure></li></ul><h4 id="Therno"><a href="#Therno" class="headerlink" title="Therno"></a>Therno</h4><ul><li><p>测试Therno</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> theano</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> theano.tensor <span class="keyword">as</span> T</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = T.dmatrix(<span class="string">'x'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="number">1</span>/(<span class="number">1</span>+T.exp(-x))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>logistic = theano.function([x],s)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>logistic([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">-1</span>,<span class="number">-2</span>]])</span><br><span class="line">array([[<span class="number">0.5</span>       , <span class="number">0.73105858</span>],</span><br><span class="line">       [<span class="number">0.26894142</span>, <span class="number">0.11920292</span>]])</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h4><ul><li><p>安装Keras</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install keras</span></span><br></pre></td></tr></table></figure></li><li><p>查看Keras版本号</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> keras</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(keras.__version__)</span><br><span class="line"><span class="number">2.2</span><span class="number">.4</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>切换Keras后端backend</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建或打开如下Keras配置文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ~/.keras/keras.json</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认配置如下：  (将backend字段的值改为theano或者tensorflow，即可切换到相应的后端)</span></span><br><span class="line">&#123; </span><br><span class="line">    "floatx": "float32",</span><br><span class="line">    "epsilon": 1e-07,</span><br><span class="line">    "backend": "tensorflow", # "backend": "theano"</span><br><span class="line">    "image_data_format": "channels_last"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>离线下载cifar数据集</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.通过源码\keras\datasets\cifar10.py可以看到文件下载地址:&apos;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz &apos;</span><br><span class="line">2.  通过源码keras\utils\data_utils.py可以看到下载后的文件保存至&apos;~/.keras/datasets/&quot;fname&quot;.tar.gz&apos;  (Anaconda 的env环境下的keras文件 保存路径亦如此)</span><br><span class="line"></span><br><span class="line">- 小结：</span><br><span class="line">手动下载数据集，然后移动到 ~\.keras\datasets目录下，并改名（包括后缀名）为cifar-10-batches-py.tar.gz，并且用到其他时依次类推。  注：&quot;改后缀名!!!&quot;</span><br></pre></td></tr></table></figure><ul><li>测试</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">print(y_train[:<span class="number">4</span>])</span><br></pre></td></tr></table></figure></li><li><p>downgrade Keras/upgrade keras</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> you can downgrade your keras with pip install keras==1.2.2 <span class="keyword">if</span> you don<span class="string">'t want to bother about keras 2 much. Otherwise, you have to write keras 2 go through the release notes and check the fresh API.</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install keras==1.2.2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> upgrade keras</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install --upgrade keras</span></span><br></pre></td></tr></table></figure></li><li><p>RunTime Error</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">- TypeError: softmax() got an unexpected keyword argument <span class="string">'axis'</span></span><br><span class="line"> - pip install --upgrade keras==<span class="number">2.1</span>.<span class="number">3</span></span><br><span class="line">     </span><br><span class="line">- <span class="string">'python matplotlib framework under macosx'</span></span><br><span class="line">ImportError: Python is not installed as a framework. The Mac OS X backend will not be able to <span class="keyword">function</span> correctly <span class="keyword">if</span> Python is not installed as a framework. See the Python documentation <span class="keyword">for</span> more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or <span class="keyword">try</span> one of the other backends. <span class="keyword">If</span> you are using (Ana)Conda please install python.app and replace the use of <span class="string">'python'</span> with <span class="string">'pythonw'</span>. See <span class="string">'Working with Matplotlib on OSX'</span> <span class="keyword">in</span> the Matplotlib FAQ <span class="keyword">for</span> more information.</span><br><span class="line">- Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg</span><br></pre></td></tr></table></figure></li></ul><h4 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h4><ul><li><p>下载速度慢</p><ul><li><p>临时使用： <code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple &#39;packageName&#39;</code></p></li><li><p>永久修改，一劳永逸：<br>Linux下，修改 ~/.pip/pip.conf (没有就创建一个文件夹及文件。文件夹要加“.”表示隐藏文件夹) 内容如下:</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure></li></ul></li><li><p>列出所有可升级的包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip list --outdate</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="Jupyter-notebook"><a href="#Jupyter-notebook" class="headerlink" title="Jupyter notebook"></a>Jupyter notebook</h4><ul><li><p>安装jupyter</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install jupyter</span></span><br></pre></td></tr></table></figure></li><li><p>运行jupyter</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jupyter notebook</span></span><br></pre></td></tr></table></figure></li><li><p>kernel 配置文件</p></li><li><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python -m ipykernel install --user</span></span><br><span class="line">Installed kernelspec python2 in /Users/Captain/Library/Jupyter/kernels/python2</span><br><span class="line"><span class="meta">$</span><span class="bash"> python3 -m ipykernel install --user</span></span><br><span class="line">Installed kernelspec python3 in /Users/Captain/Library/Jupyter/kernels/python3</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /Users/Captain/Library/Jupyter/kernels/python2/kernel.json</span></span><br><span class="line">&#123;</span><br><span class="line"> "display_name": "Python 2",</span><br><span class="line"> "language": "python",</span><br><span class="line"> "argv": [</span><br><span class="line">  "/Users/Captain/anaconda2/bin/python",</span><br><span class="line">  "-m",</span><br><span class="line">  "ipykernel_launcher",</span><br><span class="line">  "-f",</span><br><span class="line">  "&#123;connection_file&#125;"</span><br><span class="line"> ]</span><br><span class="line">&#125;%</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat /Users/Captain/Library/Jupyter/kernels/python3/kernel.json</span></span><br><span class="line">&#123;</span><br><span class="line"> "display_name": "Python 3",</span><br><span class="line"> "language": "python"</span><br><span class="line"> "argv": [</span><br><span class="line">  "/Library/Frameworks/Python.framework/Versions/3.6/bin/python3",</span><br><span class="line">  "-m",</span><br><span class="line">  "ipykernel_launcher",</span><br><span class="line">  "-f",</span><br><span class="line">  "&#123;connection_file&#125;"</span><br><span class="line"> ],</span><br><span class="line">&#125;%</span><br></pre></td></tr></table></figure></li><li><p>查看jupyter notebook内核列表</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jupyter kernelspec list</span></span><br><span class="line">Available kernels:</span><br><span class="line">  python2    /Users/Captain/Library/Jupyter/kernels/python2</span><br><span class="line">  python3    /Users/Captain/Library/Jupyter/kernels/python3</span><br></pre></td></tr></table></figure></li><li><p>安装或删除其他内核</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python kernel install --name python2   <span class="comment">#安装python2  </span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> jupyter kernelspec uninstall python2   <span class="comment">#删除python2</span></span></span><br></pre></td></tr></table></figure></li><li><p>查看使用的pyhton版本</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">print(sys.executable)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>DataMining_Review_Assignment</title>
    <link href="http://yoursite.com/2018/11/24/DataMining-Review-Assignment/"/>
    <id>http://yoursite.com/2018/11/24/DataMining-Review-Assignment/</id>
    <published>2018-11-24T06:40:05.000Z</published>
    <updated>2018-11-25T08:11:09.607Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>​    决策树是一种机器学习的方法。决策树的生成算法有ID3, C4.5和C5.0等。决策树是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果。决策树是一种十分常用的监督学习分类方法，监管学习就是给出一堆样本，每个样本都有一组属性和一个分类结果，也就是分类结果已知，那么通过学习这些样本得到一个决策树，这个决策树能够对新的数据给出正确的分类。</p><p>​    这里通过一个简单的例子来说明决策树的构成思路：给出如下的一组数据，一共有五个样本，每个样本有’不浮出水面是否可以生存’，’是否有脚蹼’属性，最后判断这些样本是否是鱼类。最后一列给出了人工分类结果。</p><table><thead><tr><th style="text-align:center">序号ID</th><th style="text-align:center">不浮出水面是否可以生存No Surfacing?</th><th style="text-align:center">是否有脚蹼Flippers？</th><th style="text-align:center">是否为鱼类Fish？</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td><td style="text-align:center">否  No</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">否  No</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">否  No</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td></tr></tbody></table><p>  <img src="/2018/11/24/DataMining-Review-Assignment/DecisionTree_exampleTree.png" alt="决策树范例"></p><h2 id="构建决策树"><a href="#构建决策树" class="headerlink" title="构建决策树"></a>构建决策树</h2><h3 id="决策树生成过程"><a href="#决策树生成过程" class="headerlink" title="决策树生成过程"></a>决策树生成过程</h3><ol><li><strong>特征选择</strong>：特征选择是指从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。</li><li><strong>决策树生成</strong>： 根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。 树结构来说，递归结构是最容易理解的方式。</li><li><strong>剪枝</strong>：决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合.剪枝技术有<code>预剪枝</code>和<code>后剪枝</code>两种.</li></ol><p>​    在非结束的条件下，首先选择出<code>合适的特征</code>，然后根据其分类。分类开始时，记录分类的特征到决策树中，然后在特征标签集中删除该特征，表示已经使用过该特征。<code>根据选中的特征将数据集分为若干个子数据集</code>，然后将子数据集作为参数<code>递归创建决策树</code>，最终生成一棵完整的决策树。</p><p>注：理想条件下，任何到达叶子节点的数据必然属于叶子结点的分类</p><h3 id="递归结束的条件"><a href="#递归结束的条件" class="headerlink" title="递归结束的条件"></a>递归结束的条件</h3><ul><li><p>每个分支下的所有实例都具有<code>相同的分类</code></p></li><li><p>程序遍历完所有划分数据集的<code>属性</code></p><p>遍历完全部属性，划分的数据有可能不全属于一个类，这个时候需要根据<strong>多数表决准则</strong>确定该子数据集的分类</p></li></ul><h3 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h3><ul><li>优点：决策树计算复杂度不高、便于使用、而且高效，决策树可处理具有不相关特征的数据、可很容易地构造出易于理解的规则，而规则通常易于解释和理解。</li><li>缺点：存在处理缺失数据时的困难、过度拟合以及忽略数据集中属性之间的相关性等问题。</li></ul><h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p><strong>特点</strong>：使用<code>信息增益</code>来选择特征，信息增益<code>大</code>的优先选择</p><p><strong>算法步骤</strong>：</p><p>1）初始化信息增益的阈值$ϵ$</p><p>2）判断样本是否为同一类输出$D_i$，如果是则返回单节点树$T$。标记类别为$D_i$</p><p>3）判断特征是否为空，如果是则返回单节点树🌲$T$，标记类别为样本中输出类别$D$实例数最多的类别</p><p>4）计算$A$中的各个特征（一共$n$个）对输出$D$的信息增益，选择信息增益最大的特征$A_g$</p><p>5）如果$A_g$的信息增益小于阈值$ϵ$，则返回单节点树🌲$T$，标记类别为样本中输出类别$D$实例数最多的类别</p><p>6）否则，按特征$A_g$的不同取值$A_{gi}$将对应的样本输出$D$分成不同的类别$D_i$。每个类别产生一个子节点。对应特征值为$A_{gi}$。返回增加了节点的树🌲$T$</p><p>7）对于所有的子节点，令$D=D_i$,$A=A−{A_g}$递归调用2-6步，得到子树🌲$T_i$并返回</p><p><strong>不足</strong>：</p><p>a）ID3没有考虑<code>连续特征</code>，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。</p><p>b）ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大（即<code>用信息增益作为标准容易偏向于取值较多的特征</code>）。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。如果校正这个问题呢？</p><p>c）ID3算法对于<code>缺失值</code>的情况没有做考虑</p><p>d) 没有考虑<code>过拟合</code>的问题</p><h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><p><strong>特点</strong>：采用<code>信息增益比</code>来选择特征，以减少信息增益容易选择特征值多的特征的问题</p><p><strong>算法思路</strong>：针对ID3算法的不足，加以改进</p><p>a）对于第一个问题，不能处理连续特征， C4.5的思路是将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为$a_1,a_2,…,a_m$,则C4.5取相邻两样本值的平均数，一共取得m-1个划分点，其中第i个划分点$T_i$表示为：$T_i=\frac{a_i+a_{i+1}}{2}$。对于这m-1个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。比如取到的增益最大的点为$a_t$，则小于$a_t$的值为$类别1$，大于$a_t$的值为$类别2$，这样我们就做到了连续特征的离散化。要注意的是，与离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。</p><p>b）对于第二个问题，信息增益作为标准容易偏向于取值较多的特征的问题。我们引入一个<code>信息增益比</code>的变量$I_R(D,A)$  (下文”相关概念”中有该变量的详细说明)。特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题。</p><p>c）对于第三个缺失值处理的问题，主要需要解决的是两个问题，一是在样本某些特征缺失的情况下<code>选择划分的属性</code>，二是选定了划分属性，对于在该属性上缺失特征的<code>样本处理</code>。</p><p>​    对于第一个子问题，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据$D_1$，另一部分是没有特征A的数据D2。然后对于没有缺失特征A的数据集$D_1$来和对应的A特征的各个特征值一起计算<code>加权重后的信息增益比</code>，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。</p><p>​    对于第二个子问题，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的<strong>权重</strong>按各个子节点样本的<strong>数量比例</strong>来分配。比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。</p><p>d）对于第4个问题，C4.5引入了正则化系数进行初步的剪枝。下文介绍CART算法时会详细讨论剪枝的思路。</p><p><strong>不足</strong>：</p><ul><li><p>由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。一般地，常采用”后剪枝加上交叉验证”选择最合适的决策树。</p></li><li><p>C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</p></li><li><p>C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</p></li><li><p>C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。</p></li></ul><h3 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h3><p><strong>特点</strong>：使用<code>基尼系数</code>来选择特征，简化模型（减少计算量）同时也不至于完全丢失熵模型的优点。</p><p><strong>对于连续特征和离散特征处理的改进</strong>：</p><ul><li>对于CART分类树<code>连续值</code>的处理问题，其思想和C4.5是相同的，都是将连续的特征离散化。唯一的区别在于在选择划分点时的度量方式不同，C4.5使用的是信息增益比，则CART分类树使用的是基尼系数。</li><li>对于CART分类树<code>离散值</code>的处理问题，采用的思路是不停的二分离散特征。如果某个特征A被选取建立决策树节点，它有A1,A2,A3三种类别，CART分类树会考虑把A分成${A_1}$和${A_2,A_3}$, ${A_2}$和${A_1,A_3}$,${A_3}$和${A_1,A_2}$三种情况，找到基尼系数最小的组合，比如${A_2}$和${A_1,A_3}$，然后建立二叉树节点，一个节点是$A2$对应的样本，另一个节点是${A1,A3}$对应的节点。同时，由于这次没有把特征A的取值完全分开，后面我们还有机会在子节点继续选择到特征A来划分A1和A3。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。</li></ul><p><strong>构建CART分类树的算法步骤</strong>：算法输入是训练集D，基尼系数的阈值，样本个数阈值；输出是决策树T；从根节点开始，用训练集递归的建立CART树。</p><p>1）对于当前节点的数据集为D，如果样本个数小于阈值或者没有特征，则返回决策子树，当前节点停止递归。</p><p>2）计算样本集D的基尼系数，如果基尼系数小于阈值，则返回决策树子树，当前节点停止递归。</p><p>3）计算当前节点现有的各个特征的各个特征值对数据集D的基尼系数，缺失值的处理和C4.5算法里描述的相同。</p><p>4）在计算出来的各个特征的各个特征值对数据集D的基尼系数中，选择基尼系数最小的特征A和对应的特征值a。根据这个最优特征和最优特征值，把数据集划分成两部分D1和D2，同时建立当前节点的左右节点，做节点的数据集D为D1，右节点的数据集D为D2.</p><p>5）对左右的子节点递归的调用1-4步，生成决策树。</p><p>对于生成的决策树做预测的时候，假如测试集里的样本A落到了某个叶子节点，而节点里有多个训练样本。则对于A的类别预测采用的是这个叶子节点里概率最大的类别（<strong>多数表决准则</strong>）。</p><p><strong>构建CART回归树算法</strong>：</p><p>​    CART回归树和CART分类树的建立算法大部分是类似的，所以这里我们只讨论CART回归树和CART分类树的建立算法不同的地方。</p><p>​    首先，我们要明白，什么是回归树，什么是分类树。两者的区别在于样本输出，如果样本输出是离散值，那么这是一颗分类树。如果果样本输出是连续值，那么那么这是一颗回归树。</p><p>​    除了概念的不同，CART回归树和CART分类树的建立和预测的区别主要有下面两点：</p><p>​    1)连续值的处理方法不同</p><p>​    2)决策树建立后做预测的方式不同。</p><p>​    对于连续值的处理，我们知道CART分类树采用的是用基尼系数的大小来度量特征的各个划分点的优劣情况。这比较适合分类模型，但是对于回归模型，我们使用了常见的<strong>和方差</strong>的度量方式，CART回归树的度量目标是，对于任意划分特征A，对应的任意划分点s两边划分成的数据集D1和D2，求出使D1和D2各自集合的<strong>均方差最小</strong>，同时D1和D2的<strong>均方差之和最小</strong>所对应的特征和特征值划分点。表达式为：<br>$$ \underbrace{min}_{A,s}\Bigg[\underbrace{min}_{c_1}\sum\limits_{x_i \in D_1(A,s)}(y_i - c_1)^2 + \underbrace{min}_{c_2}\sum\limits_{x_i \in D_2(A,s)}(y_i - c_2)^2\Bigg]$$ <br>其中，c1c1为D1数据集的样本输出均值，c2c2为D2数据集的样本输出均值。    </p><p>​    对于决策树建立后做预测的方式，上面讲到了CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来<code>预测输出结果</code>。</p><p>​    除了上面提到了以外，CART回归树和CART分类树的建立算法和预测没有什么区别。</p><h4 id="CART树算法的剪枝"><a href="#CART树算法的剪枝" class="headerlink" title="CART树算法的剪枝"></a>CART树算法的剪枝</h4><p>​    由于决策时算法很容易对训练集<code>过拟合</code>，而导致泛化能力差，为了解决这个问题，我们需要对CART树进行剪枝，即类似于线性回归的正则化，来增加决策树的泛化能力。但是，有很多的剪枝方法，我们应该这么选择呢？CART采用的办法是<code>后剪枝法</code>，即先生成决策树，然后产生所有可能的剪枝后的CART树，然后使用<code>交叉验证</code>来检验各种剪枝的效果，选择泛化能力最好的剪枝策略。</p><p>​    也就是说，CART树的剪枝算法可以概括为两步，第一步是从原始决策树生成<code>各种剪枝效果</code>的决策树，第二步是用交叉验证来检验剪枝后的预测能力，选择泛化预测能力最好的、剪枝后的树作为最终的CART树🌲。</p><p>​    首先我们看看剪枝的损失函数度量，在剪枝的过程中，对于任意的一刻子树$T$,其损失函数为：<br>$$ C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|$$ <br>其中，$α$为正则化参数，这和线性回归的正则化一样。$C(T_t)$为训练数据的预测误差，分类树是用基尼系数度量，回归树是均方差度量。$|T_t|$是子树T的叶子节点的数量。</p><p>​    当$α=0$时，即没有正则化，原始的生成的CART树即为最优子树。当$α=∞$时，即正则化强度达到最大，此时由原始的生成的CART树的根节点组成的单节点树为最优子树。当然，这是两种极端情况。一般来说，$α$越大，则剪枝剪的越厉害，生成的最优子树相比原生决策树就越偏小。对于固定的$α$，一定存在使损失函数$C_α(T)$最小的唯一子树。　　　　</p><p>​    看过剪枝的损失函数度量后，我们再来看看剪枝的思路，对于位于节点t的任意一颗子树$T_t$，如果没有剪枝，它的损失是<br>$$ C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|$$ <br>​    如果将其剪掉，仅仅保留根节点，则损失是<br>$$ C_{\alpha}(T) = C(T) + \alpha$$ <br>​    当$α=0$或者$α$很小时，$C_{\alpha}(T_t) &lt; C_{\alpha}(T)$ . 当$α$增大到一定的程度时，$C_{\alpha}(T_t) = C_{\alpha}(T)$ 。当$α$继续增大时不等式反向，也就是说，如果满足下式：$\alpha = \frac{C(T)-C(T_t)}{|T_t|-1}$，$T_t$和$T$有相同的损失函数，但是$T$节点更少，因此可以对子树$T_t$进行剪枝，也就是将它的子节点全部剪掉，变为一个叶子节点$T$。</p><p>​    最后我们看看CART树的交叉验证策略。上面我们讲到，可以计算出每个子树是否剪枝的阈值$α$，如果我们把所有的节点是否剪枝的值$α$都计算出来，然后分别针对不同的$α$所对应的剪枝后的最优子树做交叉验证。这样就可以选择一个最好的$α$，有了这个$α$，我们就可以用对应的最优子树作为最终结果。</p><p><strong>CART树的剪枝算法</strong>：</p><p>- 输入是CART树建立算法得到的原始决策树$T$</p><p>- 输出是最优决策子树$T_α$</p><p>1）初始化$α_{min}=∞$， 最优子树集合$ω={T}$。</p><p>2）从叶子节点开始自下而上计算各内部节点t的训练误差损失函数$C_α(T_t)$（回归树为均方差，分类树为基尼系数）, 叶子节点数$|T_t|$，以及正则化阈值$α=min{\frac{C(T)−C(T_t)}{|Tt|−1},α<em>{min}}$, 更新$α</em>{min}=α$</p><p>3) 得到所有节点的$α$值的集合M。</p><p>4）从M中选择最大的值$α_k$，自上而下的访问子树t的内部节点，如果$\frac{C(T)−C(T_t)}{|T_t|−1}≤α_k$时，进行剪枝。并决定叶节点t的值。如果是分类树，则是概率最高的类别，如果是回归树，则是所有样本输出的均值。这样得到$α_k$对应的最优子树$T_k$</p><p>5）最优子树集合$ω=ω∪T_k$， $M=M−{α_k}$。</p><p>6）如果M不为空，则回到步骤4。否则就已经得到了所有的可选最优子树集合$ω$.</p><p>7）采用交叉验证在$ω$选择最优子树$T_α$</p><p><strong>不足</strong>：</p><ul><li>无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1，这里不多介绍。</li><li>如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。</li></ul><h3 id="算法小结"><a href="#算法小结" class="headerlink" title="算法小结"></a>算法小结</h3><table><thead><tr><th>算法</th><th>支持模型</th><th>树结构</th><th>特征选择</th><th>连续值处理</th><th>缺失值处理</th><th>剪枝</th></tr></thead><tbody><tr><td>ID3</td><td>分类</td><td>多叉树</td><td>信息增益</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr><td>C4.5</td><td>分类</td><td>多叉树</td><td>信息增益比</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>CART</td><td>分类，回归</td><td>二叉树</td><td>基尼系数，均方差</td><td>支持</td><td>支持</td><td>支持</td></tr></tbody></table><h2 id="决策树相关概念"><a href="#决策树相关概念" class="headerlink" title="决策树相关概念"></a>决策树相关概念</h2><h3 id="信息熵-Entropy"><a href="#信息熵-Entropy" class="headerlink" title="信息熵 Entropy"></a>信息熵 Entropy</h3><ul><li><p>概念说明：熵表示混乱的程度，<strong>熵越大，越混乱</strong>，比如一杯浑浊水的熵就比一杯纯净的水熵大.</p></li><li><p>在信息论和概率统计中，设X是一个取有限个值的离散随机变量，其概率分布为：<br>$$   P(X=x_i)=p_i,i=1,2,3,..,n \tag{1}  $$ <br>则随机变量X的熵定义为：<br>$$   H(X)=-\sum _{i=1}^n p_i\log _2p_i\tag{2}  $$ <br>若$pi=0$，则规定$0log0=0$。需要说明的是，熵<code>只依赖于</code>$X$<code>的分布</code>，而不依赖于$X$的值.</p><ul><li><p>若$D:p_1=\frac{2}{5} \quad p_2=\frac{3}{5} $，则  $H(D)=-\left (-\frac {2}{5}\log _2 \frac {2}{5}-\frac {3}{5}\log _2\frac {3}{5}\right )=0.971$</p></li><li><p>推广：多个变量的联合熵，这里给出两个变量X和Y的<strong>联合熵</strong>表达式：<br>$$     H(X,Y) = -\sum\limits_{i=1}^{n}p(x_i,y_i)logp(x_i,y_i)    $$ </p></li></ul></li></ul><h3 id="条件熵-Conditional-Entropy"><a href="#条件熵-Conditional-Entropy" class="headerlink" title="条件熵 Conditional Entropy"></a>条件熵 Conditional Entropy</h3><ul><li><p>概念说明：条件熵 $H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性，定义为$X$给定条件下<code>Y</code>的条件概率分布的熵<code>对X的数学期望</code>。</p></li><li><p>条件熵的计算公式如下：<br>$$   H(Y|X)= -\sum\limits_{i=1}^{n}p(x_i,y_i)logp(y_i|x_i)=\sum _{i=1}^np(x_i)H(Y|X=x_i)\tag {3}  $$ <br>当熵和条件熵中的概率由<code>数据估计</code>得到时，所对应的熵与条件熵分别称为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</p></li></ul><h3 id="信息增益-Information-gain"><a href="#信息增益-Information-gain" class="headerlink" title="信息增益 Information gain"></a>信息增益 Information gain</h3><ul><li><p>概念说明：<strong>信息增益</strong>表示得知特征X的信息而使得类Y的信息的不确定性<code>减少的程度</code>。换一个角度解释一下，一杯浑浊的水$Y$，其熵为$H1$，现在将其中悬浮的一类物质$X$去除，这杯水的熵下降为$H2$，则物质$X$对于这杯水的信息增益就为$H1−H2$。</p></li><li><p>特征$X$对数据集$D$的信息增益记为$I(X,Y)$，计算公式如下：<br>$$   I(X,Y)=H(X)-H(X|Y) \tag {4}  $$ <br>其中$H(X|Y)$为特征X给定条件下$Y$的经验条件熵。</p></li><li><p>比较各个特征的信息增益，<code>选择信息增益最大的</code>作为分类的<code>最优特征</code>。</p><p><strong>ID3决策树在生成的过程中，根据信息增益来选择特征。</strong></p></li></ul><hr><p><strong>关系梳理</strong>：$H(X)$度量了X的不确定性，条件熵$H(X|Y)$度量了我们在知道$Y$以后$X$剩下的不确定性，$H(X)-H(X|Y)$为信息增益$I(X,Y)$</p><p><img src="/2018/11/24/DataMining-Review-Assignment/%E6%A6%82%E5%BF%B5%E5%9B%BE%E7%A4%BA.png" style="zoom:80%"></p><p>左边的椭圆代表$H(X)$,右边的椭圆代表$H(Y)$,中间重合的部分就是我们的互信息或者信息增益$I(X,Y)$, 左边的椭圆去掉重合部分就是$H(X|Y)$,右边的椭圆去掉重合部分就是$H(Y|X)$。两个椭圆的并就是$H(X,Y)$。</p><hr><h3 id="信息增益比-Information-gain-Ratio"><a href="#信息增益比-Information-gain-Ratio" class="headerlink" title="信息增益比 Information gain Ratio"></a>信息增益比 Information gain Ratio</h3><ul><li><p>引入目的：以信息增益作为划分训练数据集的特征，存在<code>偏向于选择取值较多</code>的特征的问题，使用<strong>信息增益比</strong>可以对这一问题进行校正。</p></li><li><p>概念说明：信息增益比是信息增益和特征熵的比值。</p></li><li><p>信息增益比计算公式如下：<br>$$   I_R(D,A)=\frac {I(A,D)}{H_A(D)} \tag {5}  $$ <br>其中$D$为样本特征输出的集合，$A$为样本特征，对于特征熵$H_A(D)$, 表达式如下：<br>$$   H_A(D)=-\sum _{i=1}^n\frac {|D_i|}{|D|}\log _2 \frac {|D_i|}{|D|}\tag {6}  $$ <br>特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题。</p></li><li><p>根据信息增益比，选择<code>数值最大的</code>作为分类的最优特征。</p><p><strong>C4.5决策树在生成的过程中，根据信息增益比来选择特征。</strong></p></li></ul><h3 id="基尼指数-GINI-index"><a href="#基尼指数-GINI-index" class="headerlink" title="基尼指数 GINI index"></a>基尼指数 GINI index</h3><ul><li><p>基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益(比)是相反的。</p></li><li><p>在分类问题中，假设有$K$个类别，第$k$个类别的概率为$p_k$, 则基尼系数的表达式为：<br>$$   Gini(p) = \sum\limits_{k=1}^{K}p_k(1-p_k) = 1- \sum\limits_{k=1}^{K}p_k^2  $$ <br>如果是<code>二类</code>分类问题，计算就更加简单了，如果属于第一个样本输出的概率是p，则基尼系数的表达式为：<br>$$   Gini(p) = 2p(1-p)  $$ <br>对于个给定的样本$D$,假设有$k$个类别, 第k个类别的数量为$C_k$,则样本$D$的基尼系数表达式为：<br>$$   Gini(D) = 1-\sum\limits_{k=1}^{K}(\frac{|C_k|}{|D|})^2  $$ <br>特别的，对于样本$D$,如果根据特征$A$的某个值$a$,把$D$分成$D_1$和$D_2$两部分，则在特征$A$的条件下，$D$的基尼系数表达式为：<br>$$   Gini(D,A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)  $$ <br>和熵模型的度量方式比，基尼系数对应的误差有多大呢？对于二类分类，基尼系数和熵之半的曲线如下：</p><p><img src="/2018/11/24/DataMining-Review-Assignment/GINIvsENTROPY.jpg" style="zoom:80%"></p><p>从上图可以看出，基尼系数和熵之半的曲线非常接近，仅仅在45度角附近误差稍大。因此，基尼系数可以做为熵模型的一个近似替代。而<strong>CART分类树算法就是使用的基尼系数来选择决策树的特征</strong>。同时，为了进一步简化，CART分类树算法每次仅仅对某个特征的值进行二分，而不是多分，这样CART分类树算法建立起来的是二叉树，而不是多叉树。这样一可以进一步简化基尼系数的计算，二可以建立一个更加优雅的二叉树模型。</p></li></ul><p>参考：<a href="https://blog.csdn.net/xuelabizp/article/details/50979469" target="_blank" rel="noopener">手把手生成决策树(dicision tree)</a>\决策树算法原理<a href="https://www.cnblogs.com/pinard/p/6050306.html" target="_blank" rel="noopener">(上)</a>、<a href="http://www.cnblogs.com/pinard/p/6053344.html" target="_blank" rel="noopener">(下)</a></p><p>阅读链接：<a href="">决策树(Decision Tree)：通俗易懂之介绍</a></p><h1 id="贝叶斯、SVM、ANN"><a href="#贝叶斯、SVM、ANN" class="headerlink" title="贝叶斯、SVM、ANN"></a>贝叶斯、SVM、ANN</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Arxiv_AD_with_Code</title>
    <link href="http://yoursite.com/2018/11/23/Arxiv_AD_with_Code/"/>
    <id>http://yoursite.com/2018/11/23/Arxiv_AD_with_Code/</id>
    <published>2018-11-23T14:04:50.000Z</published>
    <updated>2018-11-26T08:52:33.914Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="Alzheimer’s-Disease"><a href="#Alzheimer’s-Disease" class="headerlink" title="Alzheimer’s Disease"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease</a></h5><h5 id="Alzheimer’s-Disease-CNN"><a href="#Alzheimer’s-Disease-CNN" class="headerlink" title="Alzheimer’s Disease CNN"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+CNN&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease CNN</a></h5><ul><li><p><a href="https://arxiv.org/pdf/1808.02874.pdf" target="_blank" rel="noopener">Visualizing Convolutional Networks for MRI-based Diagnosis of Alzheimer’s Disease</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- We downloaded T1-weighted MPRAGE scans <span class="keyword">and</span> non- linearly registered all images to a <span class="number">1</span> mm isotropic ICBM template using <span class="string">'ANTs (http://stnava.github.io/ANTs/)'</span>, resulting <span class="keyword">in</span> volumes of <span class="number">193</span> × <span class="number">229</span> × <span class="number">193.</span></span><br><span class="line">- PyTorch implementations of all visualization methods will be made <span class="string">'available'</span> at http://github.com/jrieke/cnn-interpretability.</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1704.06033.pdf" target="_blank" rel="noopener">Predicting Cognitive Decline with Deep Learning of Brain Metabolism and Amyloid Imaging</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- This supervised learning are conducted by stochastic gradient descent (SGD) algorithm, the &apos;source code&apos; of which is distributed by MatConvNet (Version 1.0-beta 16).</span><br><span class="line">- Goodfellow IJ, Vinyals O, Saxe AM. Qualitatively characterizing neural network optimization problems. arXiv preprint arXiv:14126544 2014.</span><br><span class="line">-  Vedaldi A, Lenc K. MatConvNet: Convolutional neural networks for matlab. Proceedings of the 23rd Annual ACM Conference on Multimedia Conference; 2015: ACM: 689-692.</span><br></pre></td></tr></table></figure></li></ul><h5 id="Alzheimer’s-Disease-DeepLearning"><a href="#Alzheimer’s-Disease-DeepLearning" class="headerlink" title="Alzheimer’s Disease DeepLearning"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+Deep+Learning&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease DeepLearning</a></h5><ul><li><p><a href="https://arxiv.org/pdf/1807.10757.pdf" target="_blank" rel="noopener">A multi-contrast MRI approach to thalamus segmentation</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- The supervised learning <span class="keyword">and</span> convex segmentation steps of the algorithm were implemented <span class="keyword">in</span> MATLAB R2017b (The Mathworks Inc., Natick, MA, USA) <span class="keyword">and</span> are available at <span class="string">'https://github.com/veronicacorona/multicontrastSegmentation.git'</span>.</span><br><span class="line">- The dataset used <span class="keyword">in</span> this work <span class="keyword">and</span> the proposed supervised learning <span class="keyword">and</span> convex segmentation imple- mentations are available at <span class="string">'https://github.com/veronicacorona/multicontrastSegmentation.git'</span>.</span><br><span class="line">- Radio-frequency (RF) bias corrected [<span class="number">33</span>] T2∗-weighted magnitude images were affine co-registered to their corresponding bias-corrected MPRAGE volume using <span class="string">'ANTs (http://stnava.github.io/ ANTs/)'</span> [<span class="number">34</span>].</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1803.11550.pdf" target="_blank" rel="noopener">Multi-modal Disease Classification in Incomplete Datasets Using Geometric Matrix Completion</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Hyperparameters were optimized using Hyperopt(<span class="string">'http://hyperopt.github.io/hyperopt/'</span>), through nested cross-validation, targeting classification loss (binary cross-entropy) on a hold-out validation set (<span class="number">10</span>% <span class="keyword">in</span> each fold of training data).</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1801.00880.pdf" target="_blank" rel="noopener">Deep convolutional neural networks for segmenting 3D in vivo multiphoton images of vasculature in Alzheimer disease mouse models</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- DeepVess <span class="keyword">is</span> freely available at <span class="string">'https://github.com/mhaft/DeepVess'</span> <span class="keyword">and</span> can be used immediately by researchers who use MPM <span class="keyword">for</span> vasculature imaging. </span><br><span class="line">- We hope the availability of our open source code <span class="keyword">and</span> reported results will facilitate <span class="keyword">and</span> motivate the adoption of this method by researchers <span class="keyword">and</span> practitioners.</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1711.11117.pdf" target="_blank" rel="noopener">Towards Alzheimer’s Disease Classification through Transfer Learning</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Architecture models <span class="keyword">for</span> Tensor- Flow <span class="keyword">and</span> pre-trained weights were downloaded <span class="keyword">from</span> open source repositories of the models <span class="number">1</span>[<span class="string">'https://github.com/flyyufelix/cnn finetune'</span>].</span><br><span class="line">- For the Inception V4 model, stochastic gradient descent optimization <span class="keyword">with</span> a learning rate of <span class="number">0.0001</span> was used <span class="number">2</span>[Models, weights, dataset, <span class="keyword">and</span> code available at <span class="string">'https://github.com/ marciahon29/Ryerson MRP'</span>].</span><br><span class="line">- Keeping up <span class="keyword">with</span> the spirit of reproducible research, all our models, dataset, <span class="keyword">and</span> code can be accessed through the repository at: <span class="string">'https://github.com/marciahon29/Ryerson MRP'</span> .</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
