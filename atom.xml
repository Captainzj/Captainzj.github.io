<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Go Further</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-20T12:36:18.496Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>CaptainSE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Assignment_Implement_Note</title>
    <link href="http://yoursite.com/2018/11/20/Assignment-Implement-Note/"/>
    <id>http://yoursite.com/2018/11/20/Assignment-Implement-Note/</id>
    <published>2018-11-20T11:10:14.000Z</published>
    <updated>2018-11-20T12:36:18.496Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="SVM-梯度计算"><a href="#SVM-梯度计算" class="headerlink" title="SVM 梯度计算"></a>SVM 梯度计算<div id="SVM 梯度计算"></div></h5><p>$$<br>L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]<br>$$</p><p>$$ \left\{\begin{aligned}\nabla_{w_{y_i}} L_i = & -\left(\sum_{j \ne y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0)\right)x_i & j = y_i \\\nabla_{w_j} L_i = & 1(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i & j \ne y_i\end{aligned}\right.$$ <br>其中$\mathbb{1}$是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  dW = np.zeros(W.shape)  <span class="comment">#(3073, 10)</span></span><br><span class="line">  </span><br><span class="line">  num_classes = W.shape[<span class="number">1</span>] <span class="comment">#10</span></span><br><span class="line">  num_train = X.shape[<span class="number">0</span>]  <span class="comment">#500</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):  <span class="comment">#[0,500)</span></span><br><span class="line">    scores = X[i].dot(W)   <span class="comment">#矩阵乘法  (1,3073)*(3073,10)</span></span><br><span class="line">    correct_class_score = scores[y[i]] <span class="comment">#S_yi  该图像在正确标签上的得分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):</span><br><span class="line">      <span class="keyword">if</span> j == y[i]:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note: delta = 1  </span></span><br><span class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>: </span><br><span class="line">        loss += margin</span><br><span class="line">        dW[:, y[i]] -= X[i, :].T <span class="comment"># this is really a sum over j != y_i</span></span><br><span class="line">        dW[:, j] += X[i, :].T <span class="comment"># sums each contribution of the x_i's</span></span><br><span class="line">        </span><br><span class="line">  loss /= num_train</span><br><span class="line">  dW /= num_train</span><br><span class="line">  loss += <span class="number">0.5</span> *reg * np.sum(W * W) </span><br><span class="line">  dW += reg*W</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  dW = np.zeros(W.shape) <span class="comment"># dW.shape==(3073,500)</span></span><br><span class="line">  num_classes=W.shape[<span class="number">1</span>]</span><br><span class="line">  num_train=X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  scores=X.dot(W) <span class="comment">#(500,10) = (500,3073)*(3073,10)</span></span><br><span class="line">  scores_correct = scores[np.arange(num_train), y] <span class="comment">#(500,) scores_correct[i]=scores[i,y[i]]</span></span><br><span class="line">  scores_correct=np.reshape(scores_correct,(num_train,<span class="number">-1</span>))  <span class="comment">#(500,1) = (500,500*1/500)</span></span><br><span class="line">  margins=scores-scores_correct+<span class="number">1</span> <span class="comment">#delta=1  #scores.shape=(500,10)</span></span><br><span class="line">  margins=np.maximum(<span class="number">0</span>,margins)</span><br><span class="line">  margins[np.arange(num_train),y]=<span class="number">0</span></span><br><span class="line">  loss=np.sum(margins)/num_train</span><br><span class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># compute the gradient</span></span><br><span class="line">  margins[margins &gt; <span class="number">0</span>] = <span class="number">1</span>  <span class="comment">#margins中大于0的元素，数值赋为1;其余数值不变   shape==(500,10)</span></span><br><span class="line">  row_sum = np.sum(margins, axis=<span class="number">1</span>)                  <span class="comment"># 1 by N  (1行N列)</span></span><br><span class="line">  margins[np.arange(num_train), y] = -row_sum        <span class="comment">#margins[np.arange(num_train), y] 赋-row_sum前，值为0   shape==(500,)</span></span><br><span class="line">  <span class="comment">#print(margins)  ##necessary to understand</span></span><br><span class="line">  dW += np.dot(X.T, margins)/num_train + reg * W     <span class="comment"># D by C dW.shape==(3073，10) X.T.shape==(3073,500)  margins.shape==(500,10) </span></span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><ul><li>此处解释仅关注dW(即对权重的梯度计算) <code>np.dot(X.T, margins)</code>  </li></ul><p>$$ \underbrace{\underbrace{\begin{bmatrix}\overrightarrow{X_C}&\overrightarrow{X_D} &\overrightarrow{X_A}& \overrightarrow{X_B}\end{bmatrix}}_\text{可看作dW (D,C)}=\underbrace{\begin{bmatrix}\overrightarrow{X_c}&\overrightarrow{X_d}&\overrightarrow{X_a}&\overrightarrow{X_b}\end{bmatrix}}_\text{可看作X.T (D,N)}\underbrace{\begin{bmatrix}  1&1  &-3  &1 \\ 1 & 1 &  1&-3\\-3&  1&  1& 1\\  1&  -3&1  &1  \end{bmatrix}}_\text{可看作margins (N,C)}}_\text{svm_loss_vectorized dW计算过程}=\underbrace{\begin{bmatrix}   \overrightarrow{X_a}+\overrightarrow{X_b}-3\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}-3\overrightarrow{X_d} &-3\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}-3\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}   \end{bmatrix}}_\text{svm_loss_naive dW计算过程}$$ </p><p>$margins.shape==scores.shape$    $-row_sum=-3(代码中为-9) $</p><p>矩阵基本知识：<br>$$ (1)\begin{bmatrix}\overrightarrow{A}&\overrightarrow{B}  &\overrightarrow{C}  & \overrightarrow{D}\end{bmatrix}=\begin{bmatrix}\overrightarrow{a}&\overrightarrow{b}  &\overrightarrow{c}&\overrightarrow{d}\end{bmatrix}\begin{bmatrix} -3&  1&  1& 1\\  1&  -3&1  &1 \\  1&1  &-3  &1 \\ 1 & 1 &  1&-3 \end{bmatrix}=\begin{bmatrix} -3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  & \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}  \end{bmatrix}$$ <br>$$ (2)\begin{bmatrix}\overrightarrow{C}&\overrightarrow{D} &\overrightarrow{A}& \overrightarrow{B}\end{bmatrix}=\begin{bmatrix}\overrightarrow{c}&\overrightarrow{d}&\overrightarrow{a}&\overrightarrow{b}\end{bmatrix}\begin{bmatrix}  1&1  &-3  &1 \\ 1 & 1 &  1&-3\\-3&  1&  1& 1\\  1&  -3&1  &1  \end{bmatrix}=\begin{bmatrix}   \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d} &-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}   \end{bmatrix}$$ </p><p>$$ (3) \begin{bmatrix}\overrightarrow{A}\\\overrightarrow{B}\\\overrightarrow{C}\\\overrightarrow{D}\end{bmatrix}=\begin{bmatrix} -3&  1&  1& 1\\  1&  -3&1  &1 \\  1&1  &-3  &1 \\ 1 & 1 &  1&-3 \end{bmatrix}\begin{bmatrix}\overrightarrow{a}\\\overrightarrow{b}\\\overrightarrow{c}\\\overrightarrow{d}\end{bmatrix}=\begin{bmatrix}-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\ \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}  \end{bmatrix}$$ </p><p>$$ (4) \begin{bmatrix}\overrightarrow{C}\\\overrightarrow{D}\\\overrightarrow{A}\\\overrightarrow{B}\end{bmatrix}=\begin{bmatrix}   1&1  &-3  &1 \\ 1 & 1 &  1&-3 \\-3&  1&  1& 1\\  1&  -3&1  &1\end{bmatrix}\begin{bmatrix}\overrightarrow{c}\\\overrightarrow{d}\\\overrightarrow{a}\\\overrightarrow{b}\end{bmatrix}=\begin{bmatrix} \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}\\-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  \end{bmatrix}$$ </p><ul><li>$C = A B $ 等价于 $C^T = B^T    A^T$</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Assignment_Implement_Note</title>
    <link href="http://yoursite.com/2018/11/20/CS231n-Lecture-SVM/Assignment-Implement-Note/"/>
    <id>http://yoursite.com/2018/11/20/CS231n-Lecture-SVM/Assignment-Implement-Note/</id>
    <published>2018-11-20T11:10:14.000Z</published>
    <updated>2018-11-20T12:36:18.496Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="SVM-梯度计算"><a href="#SVM-梯度计算" class="headerlink" title="SVM 梯度计算"></a>SVM 梯度计算<div id="SVM 梯度计算"></div></h5><p>$$<br>L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]<br>$$</p><p>$$ \left\{\begin{aligned}\nabla_{w_{y_i}} L_i = & -\left(\sum_{j \ne y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0)\right)x_i & j = y_i \\\nabla_{w_j} L_i = & 1(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i & j \ne y_i\end{aligned}\right.$$ <br>其中$\mathbb{1}$是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  dW = np.zeros(W.shape)  <span class="comment">#(3073, 10)</span></span><br><span class="line">  </span><br><span class="line">  num_classes = W.shape[<span class="number">1</span>] <span class="comment">#10</span></span><br><span class="line">  num_train = X.shape[<span class="number">0</span>]  <span class="comment">#500</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):  <span class="comment">#[0,500)</span></span><br><span class="line">    scores = X[i].dot(W)   <span class="comment">#矩阵乘法  (1,3073)*(3073,10)</span></span><br><span class="line">    correct_class_score = scores[y[i]] <span class="comment">#S_yi  该图像在正确标签上的得分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):</span><br><span class="line">      <span class="keyword">if</span> j == y[i]:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note: delta = 1  </span></span><br><span class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>: </span><br><span class="line">        loss += margin</span><br><span class="line">        dW[:, y[i]] -= X[i, :].T <span class="comment"># this is really a sum over j != y_i</span></span><br><span class="line">        dW[:, j] += X[i, :].T <span class="comment"># sums each contribution of the x_i's</span></span><br><span class="line">        </span><br><span class="line">  loss /= num_train</span><br><span class="line">  dW /= num_train</span><br><span class="line">  loss += <span class="number">0.5</span> *reg * np.sum(W * W) </span><br><span class="line">  dW += reg*W</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  dW = np.zeros(W.shape) <span class="comment"># dW.shape==(3073,500)</span></span><br><span class="line">  num_classes=W.shape[<span class="number">1</span>]</span><br><span class="line">  num_train=X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  scores=X.dot(W) <span class="comment">#(500,10) = (500,3073)*(3073,10)</span></span><br><span class="line">  scores_correct = scores[np.arange(num_train), y] <span class="comment">#(500,) scores_correct[i]=scores[i,y[i]]</span></span><br><span class="line">  scores_correct=np.reshape(scores_correct,(num_train,<span class="number">-1</span>))  <span class="comment">#(500,1) = (500,500*1/500)</span></span><br><span class="line">  margins=scores-scores_correct+<span class="number">1</span> <span class="comment">#delta=1  #scores.shape=(500,10)</span></span><br><span class="line">  margins=np.maximum(<span class="number">0</span>,margins)</span><br><span class="line">  margins[np.arange(num_train),y]=<span class="number">0</span></span><br><span class="line">  loss=np.sum(margins)/num_train</span><br><span class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># compute the gradient</span></span><br><span class="line">  margins[margins &gt; <span class="number">0</span>] = <span class="number">1</span>  <span class="comment">#margins中大于0的元素，数值赋为1;其余数值不变   shape==(500,10)</span></span><br><span class="line">  row_sum = np.sum(margins, axis=<span class="number">1</span>)                  <span class="comment"># 1 by N  (1行N列)</span></span><br><span class="line">  margins[np.arange(num_train), y] = -row_sum        <span class="comment">#margins[np.arange(num_train), y] 赋-row_sum前，值为0   shape==(500,)</span></span><br><span class="line">  <span class="comment">#print(margins)  ##necessary to understand</span></span><br><span class="line">  dW += np.dot(X.T, margins)/num_train + reg * W     <span class="comment"># D by C dW.shape==(3073，10) X.T.shape==(3073,500)  margins.shape==(500,10) </span></span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><ul><li>此处解释仅关注dW(即对权重的梯度计算) <code>np.dot(X.T, margins)</code>  </li></ul><p>$$ \underbrace{\underbrace{\begin{bmatrix}\overrightarrow{X_C}&\overrightarrow{X_D} &\overrightarrow{X_A}& \overrightarrow{X_B}\end{bmatrix}}_\text{可看作dW (D,C)}=\underbrace{\begin{bmatrix}\overrightarrow{X_c}&\overrightarrow{X_d}&\overrightarrow{X_a}&\overrightarrow{X_b}\end{bmatrix}}_\text{可看作X.T (D,N)}\underbrace{\begin{bmatrix}  1&1  &-3  &1 \\ 1 & 1 &  1&-3\\-3&  1&  1& 1\\  1&  -3&1  &1  \end{bmatrix}}_\text{可看作margins (N,C)}}_\text{svm_loss_vectorized dW计算过程}=\underbrace{\begin{bmatrix}   \overrightarrow{X_a}+\overrightarrow{X_b}-3\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}-3\overrightarrow{X_d} &-3\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}-3\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}   \end{bmatrix}}_\text{svm_loss_naive dW计算过程}$$ </p><p>$margins.shape==scores.shape$    $-row_sum=-3(代码中为-9) $</p><p>矩阵基本知识：<br>$$ (1)\begin{bmatrix}\overrightarrow{A}&\overrightarrow{B}  &\overrightarrow{C}  & \overrightarrow{D}\end{bmatrix}=\begin{bmatrix}\overrightarrow{a}&\overrightarrow{b}  &\overrightarrow{c}&\overrightarrow{d}\end{bmatrix}\begin{bmatrix} -3&  1&  1& 1\\  1&  -3&1  &1 \\  1&1  &-3  &1 \\ 1 & 1 &  1&-3 \end{bmatrix}=\begin{bmatrix} -3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  & \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}  \end{bmatrix}$$ <br>$$ (2)\begin{bmatrix}\overrightarrow{C}&\overrightarrow{D} &\overrightarrow{A}& \overrightarrow{B}\end{bmatrix}=\begin{bmatrix}\overrightarrow{c}&\overrightarrow{d}&\overrightarrow{a}&\overrightarrow{b}\end{bmatrix}\begin{bmatrix}  1&1  &-3  &1 \\ 1 & 1 &  1&-3\\-3&  1&  1& 1\\  1&  -3&1  &1  \end{bmatrix}=\begin{bmatrix}   \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d} &-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}   \end{bmatrix}$$ </p><p>$$ (3) \begin{bmatrix}\overrightarrow{A}\\\overrightarrow{B}\\\overrightarrow{C}\\\overrightarrow{D}\end{bmatrix}=\begin{bmatrix} -3&  1&  1& 1\\  1&  -3&1  &1 \\  1&1  &-3  &1 \\ 1 & 1 &  1&-3 \end{bmatrix}\begin{bmatrix}\overrightarrow{a}\\\overrightarrow{b}\\\overrightarrow{c}\\\overrightarrow{d}\end{bmatrix}=\begin{bmatrix}-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\ \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}  \end{bmatrix}$$ </p><p>$$ (4) \begin{bmatrix}\overrightarrow{C}\\\overrightarrow{D}\\\overrightarrow{A}\\\overrightarrow{B}\end{bmatrix}=\begin{bmatrix}   1&1  &-3  &1 \\ 1 & 1 &  1&-3 \\-3&  1&  1& 1\\  1&  -3&1  &1\end{bmatrix}\begin{bmatrix}\overrightarrow{c}\\\overrightarrow{d}\\\overrightarrow{a}\\\overrightarrow{b}\end{bmatrix}=\begin{bmatrix} \overrightarrow{a}+\overrightarrow{b}-3\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-3\overrightarrow{d}\\-3\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-3\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  \end{bmatrix}$$ </p><ul><li>$C = A B $ 等价于 $C^T = B^T    A^T$</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>DataMining</title>
    <link href="http://yoursite.com/2018/11/20/dataMining/"/>
    <id>http://yoursite.com/2018/11/20/dataMining/</id>
    <published>2018-11-19T17:02:45.000Z</published>
    <updated>2018-11-19T17:03:01.313Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ADNI_Publications_digest</title>
    <link href="http://yoursite.com/2018/11/12/ADNI-Publications-digest/"/>
    <id>http://yoursite.com/2018/11/12/ADNI-Publications-digest/</id>
    <published>2018-11-12T06:16:06.000Z</published>
    <updated>2018-11-17T11:40:03.965Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>11</p><p><a href="http://adni.loni.usc.edu/adni-publications/Bayesian%20longitudinal%20low-rank%20regression%20models%20for%20imaging%20genetic%20data%20from%20longitudinal%20studies.pdf" target="_blank" rel="noopener">Bayesian longitudinal low-rank regression models for imaging genetic data from longitudinal studies</a><br>Z. H. Lu, Z. Khondker, J. G. Ibrahim, Y. Wang, H. Zhu and I. Alzheimer’s Disease Neuroimaging<br>Feature：开发了一个贝叶斯L2R2模型来确定纵向成像响应和协变量与成像遗传数据的关系</p><p>Result：我们应用L2R2模型来<strong>研究</strong>前10位单核苷酸多态性(SNPs)和前40位老年痴呆症相关基因的<strong>影响</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Structured%20and%20Sparse%20Canonical%20Correlation%20Analysis%20as%20a%20Brain-Wide%20Multi-Modal%20Data%20Fusion%20Approach.pdf" target="_blank" rel="noopener">Structured and Sparse Canonical Correlation Analysis as a Brain-Wide Multi-Modal Data Fusion Approach    </a><br>A. R. Mohammadi-Nejad, G. A. Hossein-Zadeh and H. Soltanian-Zadeh </p><p>Feature：提出了一种结构稀疏CCA (ssCCA)技术作为一种脑域多模态数据融合方法。</p><p>Result：ssCCA优于现有标准和正规化的基于CCA的融合方法。结果表明，所提出的无监督技术<strong>区分</strong>了AD患者的受试者过程与HC受试者之间的过渡模式。此外，我们还绘制了与AD患者相对于HC患者的解剖变化最相关的功能区域的脑图。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Normative%20morphometric%20data%20for%20cerebral%20cortical%20areas%20over%20the%20lifetime%20of%20the%20adult%20human%20brain.pdf" target="_blank" rel="noopener">Normative morphometric data for cerebral cortical areas over the lifetime of the adult human brain</a><br>O. Potvin, L. Dieumegarde, S. Duchesne and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：制定可以量化大脑异常的健康成人大脑皮层区域的<strong>规范数据</strong>，填补神经成像在此方面的不足。在健康成人的独立样本中验证了<strong>预测规范性数值</strong>的模型，显示了令人满意的验证R2。在轻度阿尔茨海默氏病和精神分裂症患者中，测量标准样本的偏差，并观察偏差的预期模式。</p><p><a href="http://adni.loni.usc.edu/adni-publications/High-resolution%20magnetic%20resonance%20imaging%20reveals%20nuclei%20of%20the%20human%20amygdala-%20manual%20segmentation%20to%20automatic%20atlas.pdf" target="_blank" rel="noopener">High-resolution magnetic resonance imaging reveals nuclei of the human amygdala: manual segmentation to automatic atlas</a><br>Z. M. Saygin, D. Kliemann, J. E. Iglesias, A. J. W. van der Kouwe, E. Boyd, M. Reuter, A. Stevens, K. Van Leemput, A. McKee, M. P. Frosch, B. Fischl, J. C. Augustinack and I. Alzheimer’s Disease Neuroimaging Feature：使用基于贝叶斯推理的atlas构建算法，使用高分辨率离体MRI数据<strong>自动分割</strong>可视化9个amygdala nuclei 的边界。提供了标准体内神经成像工具，能够自动将杏仁核划分成多个核，为神经成像研究人员提供探索人类杏仁核功能和连接的能力。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Independent%20value%20added%20by%20diffusion%20MRI%20for%20prediction%20of%20cognitive%20function%20in%20older%20adults.pdf" target="_blank" rel="noopener">Independent value added by diffusion MRI for prediction of cognitive function in older adults        </a><br>J. A. Scott, D. Tosun, M. N. Braskie, P. Maillard, P. M. Thompson, M. Weiner, C. DeCarli, O. T. Carmichael and Adni </p><p>Feature：<strong>预测老年人的认知功能</strong>. 确定通过扩散磁共振成像（dMRI）测量的白质微观结构能否提供关于认知障碍的老年人的基线水平或执行功能（EF）或记忆（MEM）变化的独立信息</p><p><a href="http://adni.loni.usc.edu/adni-publications/Opposing%20effects%20of%20progranulin%20deficiency%20on%20amyloid%20and%20tau%20pathologies%20via%20microglial%20TYROBP%20network.pdf" target="_blank" rel="noopener">Opposing effects of progranulin deficiency on amyloid and tau pathologies via microglial TYROBP network</a><br>H. Takahashi, Z. A. Klein, S. M. Bhagat, A. C. Kaufman, M. A. Kostylev, T. Ikezu, S. M. Strittmatter and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：探究缺乏颗粒体蛋白前体(PGRN)关于淀粉样蛋白和tau病理的<strong>反作用</strong>.揭示了GRN与AD的多维相互作用。PGRN缺乏会增加对Aβ的积累</p><p><a href="http://adni.loni.usc.edu/adni-publications/On%20the%20complexity%20of%20human%20neuroanatomy%20at%20the%20millimeter%20morphome%20scale-%20Developing%20codes%20and%20characterizing%20entropy%20indexed%20to%20spatial%20scale.pdf" target="_blank" rel="noopener">On the complexity of human neuroanatomy at the millimeter morphome scale: Developing codes and characterizing entropy indexed to spatial scale</a><br>D. J. Tward and M. I. Miller </p><p>Feature：我们通过使用来自阿尔茨海默病神经影像学计划的数据来训练多变量高斯先验模型，通过将它们与模板相关的微分变换来<strong>研究人脑中皮质下灰质结构的形状</strong>。这项工作代表了量化神经影像学研究可以提供疾病状态的信息量的第一步。</p><p><a href="http://adni.loni.usc.edu/adni-publications/jamaneurology_van_Maurik_2017_oi_170070.pdf" target="_blank" rel="noopener">Interpreting Biomarker Results in Individual Patients With Mild Cognitive Impairment in the Alzheimer’s Biomarkers in Daily Practice (ABIDE) Project</a><br>I. S. van Maurik, M. D. Zwan, B. M. Tijms, F. H. Bouwman, C. E. Teunissen, P. Scheltens, M. P. Wattjes, F. Barkhof, J. Berkhof, W. M. van der Flier and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：建立基于生物标志物的MCI患者未来<strong>AD痴呆预后模型</strong>。解释患有轻度认知障碍的个体患者的生物标志物结果，构建基于生物标记物的预测模型，帮助临床医生解释生物标记值并提供个性化的预测信息。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Generalized%20Scalar%20on%20Image%20Regression%20Models%20via%20Total%20Variation.pdf" target="_blank" rel="noopener">Generalized Scalar-on-Image Regression Models via Total Variation</a><br>X. Wang and H. Zhu </p><p>Feature：构建了一类基于总变差的广义标量图像回归模型(GSIRM-TV)，用于标量响应和存在标量协变量的<strong>成像预测器</strong>，可应用于从ADNI数据集获得的海马数据的分析。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Imaging-wide%20association%20study-%20Integrating%20imaging%20endophenotypes%20in%20GWAS.pdf" target="_blank" rel="noopener">Imaging-wide association study: Integrating imaging endophenotypes in GWAS</a><br>Z. Xu, C. Wu, W. Pan and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：提出了一种新的、强大的方法，称为全成像关联研究(image -wide association study, IWAS)，将成像内表型与GWAS相结合，以增强<strong>统计</strong>能力，并增强GWAS发现的生物学解释。所提出的IWAS是通用的，可以应用于其他的成像内表型，以及GWAS的个体水平或汇总关联数据。</p><p>12.</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20Novel%20Early%20Diagnosis%20System%20for%20Mild%20Cognitive%20Impairment%20Based%20on%20Local%20Region%20Analysis-%20A%20Pilot%20Study.pdf" target="_blank" rel="noopener">A Novel Early Diagnosis System for Mild Cognitive Impairment Based on Local Region Analysis: A Pilot Study</a><br>F. E. A. El-Gamal, M. M. Elmogy, M. Ghazal, A. Atwan, M. F. Casanova, G. N. Barnes, R. Keynton, A. S. El-Baz and A. Khalil </p><p>Feature：讨论了个性化MCI诊断系统，提出一种计算机辅助诊断（CAD）系统，其主要目标是提高<strong>诊断AD</strong>的准确性，特异性和敏感性</p><p><a href="http://adni.loni.usc.edu/adni-publications/Battaglini_et_al-2018-Human_Brain_Mapping.pdf" target="_blank" rel="noopener">SIENA-XL for improving the assessment of gray and white matter volume changes on brain MRI</a><br>M. Battaglini, M. Jenkinson, N. De Stefano and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：介绍了一种新的基于分段的纵向流水线SIENA-XL，可<strong>提高</strong>脑MRI上灰色和白色物质体积变化评估的<strong>精度</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Suresh_et_al-2018-Human_Brain_Mapping%20(1" target="_blank" rel="noopener">Factors influencing accuracy of cortical thickness in the diagnosis of Alzheimer’s disease</a>.pdf)<br>M. Belathur Suresh, B. Fischl, D. H. Salat and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：阐述影响诊断AD皮质厚度准确性的因素，有助于提高诊断<strong>分类</strong>的准确性</p><p>Result：通过检查一系列人口统计学，生物学和神经心理学数据来确定导致结构分类和临床诊断之间不匹配的因素，继发性病变（如WMH）影响与典型AD病理学重叠的区域的厚度值，从而影响分类的准确性。WMH体积增加，表明血管条件可能有助于皮质厚度测量的分类准确性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20spatio-temporal%20reference%20model%20of%20the%20aging%20brain.pdf" target="_blank" rel="noopener">A spatio-temporal reference model of the aging brain</a><br>W. Huizinga, D. H. J. Poot, M. W. Vernooij, G. V. Roshchupkin, E. E. Bron, M. A. Ikram, D. Rueckert, W. J. Niessen, S. Klein and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：开发由于正常衰老导致的大脑形态差异的时空模型，<strong>区分</strong>正常衰老和神经退行性疾病(AD)所产生的形态间<strong>差异</strong></p><p>Result：AD受试者和健康受试者之间的形态学差异可部分地通过加速衰老来解释</p><p><a href="http://adni.loni.usc.edu/adni-publications/Lee_et_al-2018-Statistics_in_Medicine.pdf" target="_blank" rel="noopener">Time-to-event data with time-varying biomarkers measured only at study entry, with applications to Alzheimer’s disease</a><br>C. Lee, R. A. Betensky and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：使用Cox回归模型对这些生物标记物轨迹关联到时间-事件将允许<strong>预测疾病进展</strong></p><p>Result：使用研究条目作为时间来源并将在研究进入时测量的时变协变量作为固定基线协变量进行处理，可以简化分析</p><p><a href="http://adni.loni.usc.edu/adni-publications/Cortical%20atrophy%20is%20associated%20with%20accelerate.pdf" target="_blank" rel="noopener">Cortical Atrophy is Associated with Accelerated Cognitive Decline in Mild Cognitive Impairment with Subsyndromal Depression</a><br>M. M. Gonzales, P. S. Insel, C. Nelson, D. Tosun, N. Mattsson, S. G. Mueller, Sacuiu, Bickford, W. Weiner and R. S. Mackin </p><p>Feature：<strong>研究</strong>轻度认知障碍（MCI）和慢性亚综合征性抑郁症（SSD）患者认知功能下降与皮质萎缩之间的<strong>关系</strong></p><p>Result：患有慢性SSD的个体可能代表MCI亚群，其非常容易受到加速认知衰退的影响，这种影响可能受额叶和前扣带萎缩的影响</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20Functional%20Varying-Coefficient%20Single%20Index.pdf" target="_blank" rel="noopener">A Functional Varying-Coefficient Single-Index Model for Functional Response Data</a><br>J. Li, C. Huang and H. Zhu </p><p>Feature：提出了一种新的功能变系数单指标模型（FVCSIM），可对一组感兴趣的协变量进行功能反应数据的回归分析，用于<strong>量化</strong>成像数据和感兴趣的临床变量之间的<strong>复杂关系</strong></p><p>Result：我们应用FVCSIM研究从阿尔茨海默病神经影像学倡议（ADNI）中获得的胼call体骨架上白质扩散的发展</p><p><a href="http://adni.loni.usc.edu/adni-publications/Gao_2016_PacSympBiocomput.pdf" target="_blank" rel="noopener">Adaptive Testing of SNP-Brain Functional Connectivity Association via a Modular Network Analysis</a><br>C. Gao, J. Kim and W. Pan </p><p>Feature：通过模块化网络分析自适应测试SNP-BRAIN功能连接关联，以识别脑功能网络中的模块结构</p><p>Result：我们将我们提出的方法应用于ADNI数据，以使用各种连通性测量来测试遗传变体与整个脑功能网络或其各种子组件之间的关联.发现了几个网络模块和APOE4基因变体之间联系的证据，APOE4基因变体是迄今为止阿尔茨海默病最重要的遗传风险因素.</p><p><a href="http://adni.loni.usc.edu/adni-publications/Biomarkers%20and%20Functional%20Decline%20in%20Prodromal.pdf" target="_blank" rel="noopener">Biomarkers and Functional Decline in Prodromal Alzheimer’s Disease.</a><br>C. Robb, C. Udeh-Momoh, S. Wagenpfeil, J. Schope, P. Alexopoulos, R. Perneczky and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：检测ADNI中生物标志物阳性和生物标志物阴性参与者之间的差异，以及这些差异是否代表了系统偏差</p><p>Result：基于ADNI的选择标准以及未来研究的设计，必须考虑生物标志物状态和疾病严重程度之间的潜在混淆，以确保前者(而非后者)是<strong>预测准确性</strong>的真正决定因素。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Ba_2017_Alzheimer&#39;s%20and%20dementia.pdf" target="_blank" rel="noopener">The prevalence and biomarkers’ characteristic of rapidly progressive Alzheimer’s disease from the Alzheimer’s Disease Neuroimaging Initiative database</a><br>M. Ba, X. Li, K. P. Ng, T. A. Pascoal, S. Mathotaarachchi, P. Rosa-Neto, S. Gauthier and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：探究快速进展性阿尔茨海默病(rpAD)的患病率和生物标志物特征，对<strong>识别</strong>临床高危rpAD具有预测价值</p><p>Result：发现rpAD通常存在于轻度AD中。脑代谢减退和p-tau/tau比值的降低可能在短期随访期间为rpAD提供潜在的临床差异值。</p><p>13</p><p><a href="http://adni.loni.usc.edu/adni-publications/Greenlaw_2016_arXiv.pdf" target="_blank" rel="noopener">A Bayesian Group Sparse Multi-Task Regression Model for Imaging Genetics</a><br>K. Greenlaw, E. Szefer, J. Graham, M. Lesperance, F. S. Nathoo and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：用于成像遗传学的贝叶斯群稀疏多任务回归模型，提供了可用于进行<strong>统计推断</strong>的技术，应用于神经影像学和遗传数据的分析，促使研究检查遗传变异对大脑结构的影响</p><p>Result：在将单核苷酸多态性与大脑影像学内表型联系起来时，将区间估计纳入单点估计之外的附加价值</p><p><a href="http://adni.loni.usc.edu/adni-publications/Li_2017_Alzheimer&#39;s%20and%20dementia%20A.D.A.M..pdf" target="_blank" rel="noopener">Age at injury is associated with the long-term cognitive outcome of traumatic brain injuries</a><br>W. Li, S. L. Risacher, T. W. McAllister, A. J. Saykin and A. s. D. N. Initiative </p><p>Feature：阐述 受伤年龄与创伤性脑损伤的长期认知结果有关 的回顾性调查报告</p><p><a href="http://adni.loni.usc.edu/adni-publications/Manning-2017-A%20Comparison%20of%20Accelerated%20and%20N.pdf" target="_blank" rel="noopener">A Comparison of Accelerated and Non-accelerated MRI Scans for Brain Volume and Boundary Shift Integral Measures of Volume Change: Evidence from the ADNI Dataset    </a><br>E. N. Manning, K. K. Leung, J. M. Nicholas, I. B. Malone, M. J. Cardoso, J. M. Schott, N. C. Fox, J. Barnes and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：评估加速MRI扫描代替非加速扫描是否影响对照组和轻度认知障碍和阿尔茨海默病患者的脑容量和萎缩率测量</p><p>Result：与非加速协议相比，使用加速扫描协议可以缩短采集时间，从而导致更少的扫描对由于运动伪影（可能影响BSI）而被排除在后续分析中，而不会显着改变绝对变化率或临床试验所需的样本量。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Autotaxin%20is%20Related%20to%20Metabolic%20Dysfunction.pdf" target="_blank" rel="noopener">Autotaxin is Related to Metabolic Dysfunction and Predicts Alzheimer’s Disease Outcomes</a><br>K. E. McLimans, A. A. Willette and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：自体分类素与代谢紊乱有关，可<strong>预测</strong>阿尔茨海默病的结果</p><p>Result： 自分泌运动因子水平在MCI和AD中显着升高，CSF自分泌运动因子可能是用于检查AD结果和风险的有用的代谢障碍生物标志物。</p><p>14</p><p><a href="http://adni.loni.usc.edu/adni-publications/Partovi-2017-Diagnostic%20performance%20of%20an%20auto.pdf" target="_blank" rel="noopener">Diagnostic performance of an automated analysis software for the diagnosis of Alzheimer’s dementia with 18F FDG PET        </a><br>S. Partovi, R. Yuh, S. Pirozzi, Z. Lu, S. Couturier, U. Grosse, M. D. Schluchter, A. Nelson, R. Jones, J. K. O’Donnell and P. Faulhaber </p><p>Feature：评估一种定量软件辅助方法的能力，以提高18F FDG PET对阿尔茨海默氏症的<strong>诊断准确性</strong></p><p>Result：基于定量体素的软件可能有助于经验丰富的18F FDG PET读者分析早发性AD</p><p><a href="http://adni.loni.usc.edu/adni-publications/Altered%20functional%20brain%20networks%20in%20amnestic%20mild%20cognitive%20impairment-%20a%20resting-state%20fMRI%20study.pdf" target="_blank" rel="noopener">Altered functional brain networks in amnestic mild cognitive impairment: a resting-state fMRI study</a><br>S. Cai, T. Chong, Y. Peng, W. Shen, J. Li, K. M. von Deneen and L. Huang </p><p>Feature：我们的目的是使用RS-fMRI技术探索aMCI患者中与记忆缺陷相关的异常静息状态网络RSN，用于研究aMCI的发病机制</p><p>Result：本研究的目的是探讨网络中这些roi之间的功能连通性，并探讨网络间的连通性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Application%20of%20Haralick%20texture%20features%20in%20brain%20[(18" target="_blank" rel="noopener">Application of Haralick texture features in brain (18)F-florbetapir positron emission tomography without reference region normalization        </a>F]-florbetapir%20positron%20emission%20tomography%20without%20reference%20region%20normalization.pdf)<br>D. L. Campbell, H. Kang and S. Shokouhi </p><p>Feature：Haralick特征可量化淀粉样蛋白PET放射性示踪剂摄取的空间特征，本研究的目的是计算不同诊断组中的几种HF并确定组间差异</p><p>Result：该技术可以改善AD药物试验中的受试者分层，并有助于纵向<strong>评估</strong>疾病进展和治疗效果，而没有与强度归一化相关的缺点</p><p><a href="http://adni.loni.usc.edu/adni-publications/Sparse%20shared%20structure%20based%20multi-task%20learning%20for%20MRI%20based%20Cognitive%20Performance%20prediction%20of%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Sparse shared structure based multi-task learning for MRI based Cognitive Performance prediction of Alzheimer’s disease        </a><br>P. Cao, X. Shan, D. Zhao, M. Huang and O. Zaiane </p><p>Feature：基于稀疏共享结构的多任务学习探索磁共振成像（MRI）和认知测量中存在的相关性</p><p>Result：证明了所提出的方法具有优于多种现有技术可比方法的优越性能，而且还<strong>识别</strong>与先验知识一致的认知相关MRI生物标志物</p><p><a href="http://adni.loni.usc.edu/adni-publications/Application%20of%20concordance%20probability%20estimate%20to%20predict%20conversion%20from%20mild%20cognitive%20impairment%20to%20Alzheimer%20s%20disease.pdf" target="_blank" rel="noopener">Application of concordance probability estimate to predict conversion from mild cognitive impairment to Alzheimer’s disease</a><br>X. Han, Y. Zhang, Y. Shao and A. s. D. N. Initiative </p><p>Feature：建立了Cox PH模型来<strong>预测</strong>从MCI到AD的转换，其中使用K指数评估预估准确性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Amyloidosis%20and%20neurodegeneration%20result%20in%20distinct%20structural%20connectivity%20patterns%20in%20mild%20cognitive%20impairment.pdf" target="_blank" rel="noopener">Amyloidosis and neurodegeneration result in distinct structural connectivity patterns in mild cognitive impairment</a><br>T. Jacquemont, F. De Vico Fallani, A. Bertrand, S. Epelbaum, A. Routier, B. Dubois, H. Hampel, S. Durrleman, O. Colliot and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：研究由淀粉样蛋白和神经变性生物标记物分层的MCI受试者亚组的结构连接体</p><p>Result：MCI亚组的连接组崩解模式在脑淀粉样蛋白和神经变性方面不同，展示了取决于生物标志物轮廓的网络改变的差异和相似之处</p><p><a href="http://adni.loni.usc.edu/adni-publications/Adaptive%20testing%20for%20multiple%20traits%20in%20a%20proportional%20odds%20model%20with%20applications%20to%20detect%20SNP-brain%20network%20associations.pdf" target="_blank" rel="noopener">Adaptive testing for multiple traits in a proportional odds model with applications to detect SNP-brain network associations        </a><br>J. Kim, W. Pan and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：提出一种在POM中结合检测SNP-brain网络的自适应关联测试模型，是一种灵活的统计检验来<strong>检测</strong>遗传由神经影像遗传学研究引起的多种性状的关联</p><p><a href="http://adni.loni.usc.edu/adni-publications/An%20Optimal%20Transportation%20based%20Univariate%20Neuroimaging%20Index.pdf" target="_blank" rel="noopener">An Optimal Transportation based Univariate Neuroimaging Index</a><br>L. Mi, W. Zhang, J. Zhang, Y. Fan, D. Goradia, K. Chen, E. M. Reiman, X. Gu and Y. Wang </p><p>Feature：一种基于单变量神经影像学指标的最优传输方法，用于数据集<strong>分类</strong></p><p>Result：在阿尔茨海默病患者和健康对照组之间的分类中，该方法在阿尔茨海默病疾病神经影像学倡议（ADNI）基线sMRI数据集上达到了82.30％的准确度，并且优于其他几个指数</p><p><a href="http://adni.loni.usc.edu/adni-publications/Predictive%20modelling%20using%20neuroimaging%20data%20in%20the%20presence%20of%20confounds.pdf" target="_blank" rel="noopener">Predictive modelling using neuroimaging data in the presence of confounds</a><br>A. Rao, J. M. Monteiro, J. Mourao-Miranda and I. Alzheimer’s Disease </p><p>Feature：讨论并评估了在神经影像学预测建模的背景下处理混杂的不同方法</p><p>Result：基线“仅图像”模型处理混淆时能给出更准确的<strong>预测</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Targeted%20metabolomics%20and%20medication%20classification%20data%20from%20participants%20in%20the%20ADNI1%20cohort.pdf" target="_blank" rel="noopener">Targeted metabolomics and medication classification data from participants in the ADNI1 cohort</a><br>L. St John-Williams, C. Blach, J. B. Toledo, D. M. Rotroff, S. Kim, K. Klavins, R. Baillie, X. Han, S. Mahmoudiandehkordi, J. Jack, T. J. Massaro, J. E. Lucas, G. Louie, A. A. Motsinger-Reif, S. L. Risacher, I. Alzheimer’s Disease Neuroimaging, C. Alzheimer’s Disease Metabolomics, A. J. Saykin, G. Kastenmuller, M. Arnold, T. Koal, M. A. Moseley, L. M. Mangravite, M. A. Peters, J. D. Tenenbaum, J. W. Thompson and R. Kaddurah-Daouk </p><p>Feature：我们提供了使用AbsoluteIDQ-p180平台从199名对照组、356名轻度认知障碍和175名ADNI1受试者的血清中生成的定量代谢组学<strong>数据</strong>，以及用于<strong>数据预处理</strong>和<strong>药物分类</strong>以进行混淆纠正的管道。</p><p>Result：帮助发现与疾病和进展相关的代谢失败以及AD中一系列重要生理过程的生物标志物</p><p>15</p><p>151<a href="http://adni.loni.usc.edu/adni-publications/Deep%20ensemble%20learning%20of%20sparse%20regression%20models%20for%20brain%20disease%20diagnosis.pdf" target="_blank" rel="noopener">Deep ensemble learning of sparse regression models for brain disease diagnosis</a><br>H. I. Suk, S. W. Lee, D. Shen and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：脑疾病诊断的稀疏回归模型的深度集成学习，用于阿尔茨海默病/轻度认知障碍的<strong>诊断和预测</strong>.关于脑成像分析的研究见证了机器学习技术在计算机辅助干预脑疾病诊断中的核心作用</p><p>152<a href="http://adni.loni.usc.edu/adni-publications/Ventricular%20and%20Periventricular%20Anomalies%20in%20the%20Aging%20and%20Cognitively%20Impaired%20Brain.pdf" target="_blank" rel="noopener">Ventricular and Periventricular Anomalies in the Aging and Cognitively Impaired Brain</a><br>K. L. Todd, T. Brighton, E. S. Norton, S. Schick, W. Elkins, O. Pletnikova, R. H. Fortinsky, J. C. Troncoso, P. J. Molfese, S. M. Resnick, J. C. Conover and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：老化和认知受损大脑的心室和心室周异常.基于MRI的纵向研究为LV体积分析的使用提供支持，结合FLAIR PVH分析，用于<strong>识别和监测</strong>认知障碍与衰老</p><p>Result：分析了纵向结构磁共振成像（MRI）和受试者匹配的液体衰减反转恢复（FLAIR）MRI和脑室周围生物样本，以便在时间上映射心室扩张和相关的脑室周围水肿和房室管膜丢失的进展。实验结果揭示了与正常脑老化和认知障碍相关的病理生理学结果，并表明多因素分析最适合预测和监测认知衰退。</p><p>153<a href="http://adni.loni.usc.edu/adni-publications/Val66Met%20Polymorphism%20in%20BDNF%20Has%20No%20Sexual%20and%20APOE%20%CE%B54%20Status-Based%20Dimorphic%20Effects%20on%20Susceptibility%20to%20Alzheimer%E2%80%99s%20Disease-%20Evidence%20From%20an%20Updated%20Meta-Analysis%20of%20Case%E2%80%93Control%20Studies%20and%20High-Throughput%20Genotyping%20Cohorts.pdf" target="_blank" rel="noopener">Val66Met Polymorphism in BDNF Has No Sexual and APOE ε4 Status-Based Dimorphic Effects on Susceptibility to Alzheimer’s Disease: Evidence From an Updated Meta-Analysis of Case–Control Studies and High-Throughput Genotyping Cohorts</a><br>Q. Zhao, Shen, Zhao, L. Si, S. Jiang, Y. Qiu and A. s. D. N. Initiative </p><p>Feature：本次元分析的目的是通过引入年龄，性别和APOE e4作为混杂因素来<strong>重新检验</strong>BDNF的Val66Met与AD之间的关联，验证Val66Met是否仅在女性大脑衍生神经营养因子(BDNF)多态性表达对阿尔茨海默病(AD)的易感性</p><p>154<a href="http://adni.loni.usc.edu/adni-publications/Zhu2017_Article_DiscriminativeSelf-representat.pdf" target="_blank" rel="noopener">Discriminative self-representation sparse regression for neuroimaging-based alzheimer’s disease diagnosis</a><br>X. Zhu, H. I. Suk, S. W. Lee and D. Shen </p><p>Feature：基于神经影像的阿尔茨海默病<strong>诊断</strong>的判别自我表征稀疏回归，所选特征用于训练支持向量机以进行<strong>分类</strong></p><p>155<a href="http://adni.loni.usc.edu/adni-publications/Ensemble%20of%20random%20forests%20One%20vs.%20Rest%20classifiers%20for%20MCI%20and%20AD%20prediction%20using%20ANOVA%20cortical%20and%20subcortical%20feature%20selection%20and%20partial%20least%20squares.pdf" target="_blank" rel="noopener">Ensemble of random forests One vs. Rest classifiers for MCI and AD prediction using ANOVA cortical and subcortical feature selection and partial least squares        </a><br>J. Ramirez, J. M. Gorriz, A. Ortiz, F. J. Martinez-Murcia, F. Segovia, D. Salas-Gonzalez, D. Castillo-Barnes, I. A. Illan, C. G. Puntonet and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：使用ANOVA皮层和皮质下特征选择和偏最小二乘法的随机森林与Rest分类的集成，用于MCI和AD<strong>预测</strong></p><p>156<a href="http://adni.loni.usc.edu/adni-publications/Luo_2016_BBI.pdf" target="_blank" rel="noopener">Affect of APOE on information processing speed in non-demented elderly population: a preliminary structural MRI study</a><br>X. Luo, Y. Jiaerken, X. Yu, P. Huang, T. Qiu, Y. Jia, J. Sun, J. Zhou, M. Zhang and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：我们通过测量白质高信号（WMH），皮质灰质体积（GMV）和厚度的叶状分布来<strong>探索APOE</strong>相关IPS(信息处理速度)改变的神经基质</p><p>Result：（1）ε4携带者的WMH体积大于对照组，特别是额叶和顶叶; （2）顶叶WMH体积与IPS相关，尤其是ε4携带者。</p><p>157<a href="http://adni.loni.usc.edu/adni-publications/Geifman_2017_Alzheimer&#39;s%20research%20therapy.pdf" target="_blank" rel="noopener">Evidence for benefit of statins to modify cognitive decline and risk in Alzheimer’s disease    </a><br>N. Geifman, R. D. Brinton, R. P. Kennedy, L. S. Schneider and A. J. Butte </p><p>Feature：通过分析综合临床试验和前瞻性观察研究的数据集，研究他汀类药物在AD中可能的保护和<strong>治疗</strong>作用</p><p>Result：他汀类药物的使用可能使所有AD患者受益，这些患者在ApoE4纯合子中具有潜在更大的治疗效果</p><p>158<a href="http://adni.loni.usc.edu/adni-publications/Espinosa-2017-Cognitive%20Composites%20Domain%20Scor.pdf" target="_blank" rel="noopener">Cognitive Composites Domain Scores Related to Neuroimaging Biomarkers within Probable-Amnestic Mild Cognitive Impairment-Storage Subtype.    </a><br>A. Espinosa, M. Alegret, P. Pesini, S. Valero, A. Lafuente, M. Buendia, I. San Jose, M. Ibarria, M. A. Tejero, J. Gimenez, S. Ruiz, I. Hernandez, F. Pujadas, P. Martinez-Lage, J. Munuera, J. Arbizu, L. Tarraga, S. B. Hendrix, A. Ruiz, J. T. Becker, S. M. Landau, O. Sotolongo-Grau, M. Sarasa, M. Boada, A. B. S. Group and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：这项研究的目的是在Pr-aMCI-storage亚型患者中<strong>发现</strong>与神经影像学生物标志物最相关的优化认知复合(CCs)域得分</p><p>Result：延迟回忆是与前驱AD诊断相关的神经成像生物标志物最佳相关的CC域得分。</p><p>159<a href="http://adni.loni.usc.edu/adni-publications/Fiford-2017-White%20matter%20hyperintensities%20are.pdf" target="_blank" rel="noopener">White matter hyperintensities are associated with disproportionate progressive hippocampal atrophy: ASSOCIATION OF WMH WITH HIPPOCAMPAL ATROPHY</a><br>C. M. Fiford, E. N. Manning, J. W. Bartlett, D. M. Cash, I. B. Malone, G. R. Ridgway, M. Lehmann, K. K. Leung, C. H. Sudre, S. Ourselin, G. J. Biessels, O. T. Carmichael, N. C. Fox, M. J. Cardoso, J. Barnes and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：本研究调查了白质高信号（WMH）体积，脑脊液（CSF），阿尔茨海默病（AD）病理学标志物与脑和海马体积减少之间的关系</p><p>Result：白质增强与不成比例的进行性海马萎缩有关。在未痴呆的老年人中，血管损伤和AD病理学的共同作用是导致海马萎缩的主要原因。</p><p>160<a href="http://adni.loni.usc.edu/adni-publications/Functional%20Reserve_Experience%20Participating%20in.pdf" target="_blank" rel="noopener">Functional Reserve: Experience Participating in Instrumental Activities of Daily Living is Associated with Gender and Functional Independence in Mild Cognitive Impairment.        </a><br>C. Berezuk, K. K. Zakzanis, J. Ramirez, A. C. Ruocco, J. D. Edwards, B. L. Callahan, S. E. Black and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：研究男性和女性在MCI中的功能障碍方面的差异，并确定性别差异是否与潜在的功能储备有关</p><p>Result：虽然效果很小，男性性别与大量MCI患者的功能能力差异显着相关。此外，这一男性缺点可部分解释为该队列中男性的IADL经历较低。具有更多IADL经验的个体可能会发展出更大的功能储备，这可能会延迟或减缓MCI的功能下降。</p><p>16 </p><p>161<a href="http://adni.loni.usc.edu/adni-publications/LeeSH_2016_AlzDem.pdf" target="_blank" rel="noopener">Predicting progression from mild cognitive impairment to Alzheimer’s disease using longitudinalcallosal atrophy    </a><br>S. Minhas, A. Khanum, F. Riaz, S. A. Khan and A. Alvi<br>Feature：使用纵向胼a体萎缩<strong>预测</strong>从轻度认知障碍到阿尔茨海默病的进展</p><p>162<a href="http://adni.loni.usc.edu/adni-publications/Glozman_2017_Journal%20of%20Alzheimer&#39;s%20disease.pdf" target="_blank" rel="noopener">Shape-Attributes of Brain Structures as Biomarkers for Alzheimer’s Disease    </a><br>T. Glozman, J. Solomon, F. Pestilli, L. Guibas and I. Alzheimer’s Disease Neuroimaging<br>Feature：我们描述了一种基于大脑结构形状差异的两种类型痴呆<strong>分类</strong>的全自动框架。我们的框架对于确定阿尔茨海默病的发病敏感，在对MCIc与NC进行分类时达到高达88.13％的准确性，优于以前的方法。</p><p>163<a href="http://adni.loni.usc.edu/adni-publications/Mayo_2016_neuroimage%20clinical.pdf" target="_blank" rel="noopener">Longitudinal changes in microstructural white matter metrics in Alzheimer’s disease    </a><br>C. D. Mayo, E. L. Mazerolle, L. Ritchie, J. D. Fisk, J. R. Gawryluk and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病微观结构白质指标的纵向变化，对白质显微结构的敏感性是研究AD生物标志物的一个很有前途的途径。有助于早期<strong>诊断</strong>AD的症状前生物标志物</p><p>164<a href="http://adni.loni.usc.edu/adni-publications/Groupwise%20envelope%20models%20for%20imaging%20genetic.pdf" target="_blank" rel="noopener">Groupwise Envelope Models for Imaging Genetic Analysis </a><br>Y. Park, Z. Su and H. Zhu<br>Feature：本文的目的是开发用于多元线性回归的分组包络模型，以建立多变量响应和协变量之间的关联。可以显着提高测试和估计的效率，该模型在有效估计中的有效性</p><p>165<a href="http://adni.loni.usc.edu/adni-publications/Tanpitukpongse_2017_American%20Journal%20of%20neuroradiology.pdf" target="_blank" rel="noopener">Predictive Utility of Marketed Volumetric Software Tools in Subjects at Risk for Alzheimer Disease: Do Regions Outside the Hippocampus Matter?    </a><br>T. P. Tanpitukpongse, M. A. Mazurowski, J. Ikhena and J. R. Petrella<br>Feature：我们的目的是评估在两个商业上可用的脑容量软件包中个体与联合区域容量的预后有效性，以<strong>预测</strong>轻度认知障碍患者转化为阿尔茨海默病。</p><p>Result：将这些工具与人口统计学和其他生物标志物测量相结合，将海马体积作为唯一的体积生物标志物是合理的</p><p>166<a href="http://adni.loni.usc.edu/adni-publications/Moradi_2016_Neuroimagie%20clinical.pdf" target="_blank" rel="noopener">Rey’s Auditory Verbal Learning Test scores can be predicted from whole brain MRI in Alzheimer’s disease    </a><br>Moradi E1, Hallikainen I2, Hänninen T3, Tohka J4; Alzheimer’s Disease Neuroimaging Initiative<br>Feature：目的是通过机器学习的方法，基于结构磁共振成像(MRI)数据来综合研究RAVLT评分可预测的程度，以及寻找评估RAVLT评分最重要的大脑区域。可以基于观察到的或估计的RAVLT评分来<strong>预测</strong>MCI受试者在3年内转化为AD，其准确性与基于MRI的生物标志物相当。</p><p>explanation：Rey的听觉言语学习测验（RAVLT）是一种强大的神经心理学工具，用于测试情景记忆，广泛用于痴呆症和痴呆前症状的认知评估。</p><p>167<a href="http://adni.loni.usc.edu/adni-publications/Nho_2015_BMC%20medical%20genomics.pdf" target="_blank" rel="noopener">Association analysis of rare variants near the APOE region with CSF and neuroimaging biomarkers of Alzheimer’s disease    </a><br>K. Nho, S. Kim, E. Horgusluoglu, S. L. Risacher, L. Shen, D. Kim, S. Lee, T. Foroud, L. M. Shaw and J. Q. Trojanowski<br>Feature：APOE区域附近<code>罕见变异</code>和阿尔茨海默病神经影像<code>生物标志物</code>的关联分析,说明下一代测序和定量内表型在<strong>评估</strong>稀有变异体中的作用，这些变异体可能有助于解释AD和其他复杂疾病中缺失的遗传性。</p><p>Result：在调整APOE基因型后，跨越APOE区域的基因内的罕见变异与LOAD相关的CSFAβ1-42和神经成像生物标志物显着相关。</p><p>168<a href="http://adni.loni.usc.edu/adni-publications/Ower2018_Article_TemporalAssociationPatternsAnd.pdf" target="_blank" rel="noopener">Temporal association patterns and dynamics of amyloid-beta and tau in Alzheimer’s disease    </a><br>A. K. Ower, C. Hadjichrysanthou, L. Gras, J. Goudsmit, R. M. Anderson, F. de Wolf and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病中淀粉样蛋白-b和tau的时间关联模式和动态.生物标志物轨迹有助于对<strong>疾病进展</strong>进行无偏见，客观的评估。定量轨迹可能在临床试验设计中有用，因为它们可以更详细地了解旨在延缓生物疾病发展的治疗方法的有效性。</p><p>169<a href="http://adni.loni.usc.edu/adni-publications/Freesurfer%20cortical%20normative%20data%20for%20adults%20using%20Desikan-Killiany-Tourville%20and%20ex%20vivo%20protocols.pdf" target="_blank" rel="noopener">Freesurfer cortical normative data for adults using Desikan-Killiany-Tourville and ex vivo protocols    </a><br>O. Potvin, L. Dieumegarde, S. Duchesne and A. s. D. N. Initiative<br>Feature：我们根据年龄，性别，估计的颅内体积（eTIV）开发了FreeSurfer形态学估计皮质测量的规范数据，这些规范允许人们测量偏离个体正常性的程度，同时考虑影响这些估计的因素。我们的目的是为Desikan-Killianny-Tourville（DKT）和基于体外的标记方案制定类似的<code>标准值</code>，并检查这三种图册之间的<code>差异</code></p><p>objective：1.为DKT和离体标记方案制定规范值 2.描述标记协议之间预测模型的差异  3.确定在病理人群中使用标准Z分数时，地图集的选择是否会产生实质性差异</p><p>170<a href="http://adni.loni.usc.edu/adni-publications/Presotto2017_Article_ValidationOf18FFDG-PETSingle-S.pdf" target="_blank" rel="noopener">Validation of (18)F-FDG-PET Single-Subject Optimized SPM Procedure with Different PET Scanners    </a><br>L. Presotto, T. Ballarini, S. P. Caminiti, V. Bettinardi, L. Gianolli and D. Perani </p><p>Feature：用不同的PET扫描仪<strong>验证</strong>18F-FDG-PET单一主题优化的SPM程序,使用基于SPM软件包的优化方法可大大提高<strong>诊断准确性</strong>。</p><p>17</p><p>171<a href="http://adni.loni.usc.edu/adni-publications/Comparison%20of%20Cortical%20and%20Subcortical%20Measurements%20in%20Normal%20Older%20Adults%20across%20Databases%20and%20Software%20Packages.pdf" target="_blank" rel="noopener">Comparison of Cortical and Subcortical Measurements in Normal Older Adults across Databases and Software Packages    </a><br>S. Rane, A. Plassard, B. A. Landman, D. O. Claassen and M. J. Donahue<br>Feature：跨数据库和软件包的正常老年人的皮质和皮层下测量的比较，评估使用不同软件包获得的皮质下体积之间的<code>协议</code>.这项工作提供了一个结合ADNI和PPMI的成像<strong>数据</strong>，以提高统计能力，以及询问不同病理，如阿尔茨海默氏症和帕金森病的常见机制。</p><p>172<a href="http://adni.loni.usc.edu/adni-publications/Li2017_Article_BrainExplorerForConnectomicAna.pdf" target="_blank" rel="noopener">Brain explorer for connectomic analysis    </a><br>H. Li, S. Fang, J. A. Contreras, J. D. West, S. L. Risacher, Y. Wang, O. Sporns, A. J. Saykin, J. Goni, L. Shen and I. Alzheimer’s Disease Neuroimaging<br>Feature：我们通过在相同解剖结构的背景下结合科学和信息可视化技术，为脑成像数据开发了一种新的集成<strong>可视化</strong>解决方案.通过视觉探索，这种集成的解决方案可以帮助识别具有高度相关的功能激活及其激活模式的大脑区域。视觉检测分化特征还可能发现基于图像的脑疾病表型生物标志物。</p><p>173<a href="http://adni.loni.usc.edu/adni-publications/Dynamic%20predictions%20in%20Bayesian%20functional%20joint%20models%20for%20longitudinal%20and%20time-to-event%20data-%20An%20application%20to%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Dynamic predictions in Bayesian functional joint models for longitudinal and time-to-event data: An application to Alzheimer’s disease    </a><br>K. Li and S. Luo  (重复181)</p><p>Feature：贝叶斯功能关节模型中纵向和时间到事件数据的<strong>动态预测</strong>：阿尔茨海默病的应用.基于所收集的信息准确<strong>预测</strong>痴呆症的时间有助于医生监测患者的疾病进展并做出早期知情的医疗决策。</p><p>method：我们首先提出了一个功能性联合模型，以考虑联合建模框架中纵向和生存子模型中的功能预测器。然后，我们基于其标量和功能测量，开发用于参数估计的贝叶斯方法和用于预测受试者的未来结果轨迹和痴呆风险的动态预测框架。</p><p>174<a href="http://adni.loni.usc.edu/adni-publications/Frequency%20Specific%20Effects%20of%20ApoE%20epsilon4%20Allele%20on%20Resting-State%20Networks%20in%20Nondemented%20Elders.pdf" target="_blank" rel="noopener">Frequency Specific Effects of ApoE epsilon4 Allele on Resting-State Networks in Nondemented Elders    </a><br>Y. Liang, Z. Li, J. Wei, C. Li, X. Zhang and A. s. D. N. Initiative （重复182）</p><p>Feature：ApoEε4等位基因对非痴呆老年人休息状态网络的频率特异性影响，便于在早期寻找敏感且可靠的生物标志物</p><p>Method：我们应用静息状态功能磁共振成像（fMRI）来检查载脂蛋白E（ApoE）ε4等位基因对默认模式网络（DMN）和显着网络（SN）的功能连接性的影响。</p><p>Result：结果表明，在研究RSN功能连通性时，静息状态信号具有<code>频率依赖性</code>效应(越来越多的研究人员认为功能连接可能是频率特异性的)。</p><p>175<a href="http://adni.loni.usc.edu/adni-publications/Multifactorial%20causal%20model%20of%20brain%20(dis" target="_blank" rel="noopener">Multifactorial causal model of brain (dis) organization and therapeutic intervention: Application to Alzheimer’s disease    </a>%20organization%20and%20therapeutic%20intervention-%20Application%20to%20Alzheimer%E2%80%99s%20disease.pdf)<br>Y. Iturria-Medina, F. M. Carbonell, R. C. Sotero, F. Chouinard-Decorte, A. C. Evans and A. s. D. N. Initiative<br>Feature：在此，我们提出了一个大脑(dis)组织和治疗干预的时空多因素因果模型(MCM)，该模型解释了<code>局部因果交互作用</code>、通过物理大脑网络传播的效应、认知改变和最佳治疗干预的<strong>识别</strong>。可以解释进行性神经障碍的病理演变和实施多种介入策略的影响.</p><p>176<a href="http://adni.loni.usc.edu/adni-publications/Analysis%20of%20longitudinal%20diffusion-weighted%20images%20in%20healthy%20and%20pathological%20aging-%20An%20ADNI%20study.pdf" target="_blank" rel="noopener">Analysis of longitudinal diffusion-weighted images in healthy and pathological aging: An ADNI study    </a><br>F. Kruggel, F. Masaki, A. Solodkin and I. Alzheimer’s Disease Neuroimaging<br>Feature：通过将线性模型与线性混合效应模型进行交换来扩展纵向成像数据的模型,我们的分类器为可获得的生物标志物提供了有前途的功能，可以<strong>预测</strong>转变为阿尔茨海默病的风险。</p><p>177<a href="http://adni.loni.usc.edu/adni-publications/Prediction%20and%20classification%20of%20Alzheimer%20disease%20based%20on%20quantification%20of%20MRI%20deformation.pdf" target="_blank" rel="noopener">Prediction and classification of Alzheimer disease based on quantification of MRI deformation    </a><br>X. Long, L. Chen, C. Jiang, L. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：基于MRI变形量化的阿尔茨海默病<strong>预测</strong>与<strong>分类</strong>.我们提出了一种机器学习方法，用于区分健康老年人AD或轻度认知障碍（MCI）患者，并通过计算和分析组间大脑的区域形态差异来预测MCI患者的AD转换</p><p>178<a href="http://adni.loni.usc.edu/adni-publications/Automatic_Alzheimers_Disease_Recognition_from_MRI.pdf" target="_blank" rel="noopener">Automatic Alzheimer’s Disease Recognition from MRI Data Using Deep Learning Method    </a><br>S. Luo, X. Li and J. Li<br>Feature：利用深度学习方法从MRI数据中自动<strong>识别</strong>阿尔茨海默病</p><p>Measure：它描述了一种基于3D脑MRI深度学习的自动AD识别算法。该算法使用卷积神经网络（CNN）来实现AD识别。它的独特之处在于，在AD识别中将大脑的三维拓扑视为一个整体，从而获得准确的识别。实验表明，该算法具有较高的AD识别准确度，灵敏度为1，特异度为0.93。</p><p>179<a href="http://adni.loni.usc.edu/adni-publications/Maggipinto_2017_Phys._Med._Biol._62_2361.pdf" target="_blank" rel="noopener">DTI measurements for Alzheimer’s classification    </a><br>T. Maggipinto, R. Bellotti, N. Amoroso, D. Diacono, G. Donvito, E. Lella, A. Monaco, M. Antonella Scelsi and S. Tangaro<br>Feature：DTI可以深入了解白质微观结构的完整性，并在早期阶段<strong>识别</strong>出受阿尔茨海默病（AD）影响的白质区域。我们测量了特征选择偏差对分类性能的显着影响，对采用了有偏见的特征选择策略的DTI进行<strong>评估</strong></p><p>180<a href="http://adni.loni.usc.edu/adni-publications/Learning%20non-linear%20patch%20embeddings%20with%20neural%20networks%20for%20label%20fusion.pdf" target="_blank" rel="noopener">Learning non-linear patch embeddings with neural networks for label fusion    </a><br>G. Sanroma, O. M. Benkarim, G. Piella, O. Camara, G. Wu, D. Shen, J. D. Gispert, J. L. Molinuevo, M. A. Gonzalez Ballester and I. Alzheimer’s Disease Neuroimaging （重复185）</p><p>Feature：我们提出了一个使用神经网络计算补丁嵌入的框架，以增加PBLF中基于相似性的加权投票的判别能力，能够适应在<code>大脑结构分割</code>中更广泛的解剖变异性</p><p>18</p><p>181<a href="http://adni.loni.usc.edu/adni-publications/Dynamic%20predictions%20in%20Bayesian%20functional%20joint%20models%20for%20longitudinal%20and%20time-to-event%20data-%20An%20application%20to%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Dynamic predictions in Bayesian functional joint models for longitudinal and time-to-event data: An application to Alzheimer’s disease    </a><br>K. Li and S. Luo     （重复）</p><p>182<a href="http://adni.loni.usc.edu/adni-publications/Frequency%20Specific%20Effects%20of%20ApoE%20epsilon4%20Allele%20on%20Resting-State%20Networks%20in%20Nondemented%20Elders.pdf" target="_blank" rel="noopener">Frequency Specific Effects of ApoE epsilon4 Allele on Resting-State Networks in Nondemented Elders    </a><br>Y. Liang, Z. Li, J. Wei, C. Li, X. Zhang and A. s. D. N. Initiative （重复）</p><p>183<a href="http://adni.loni.usc.edu/adni-publications/Ueki_et_al-2017-Genetic_Epidemiology.pdf" target="_blank" rel="noopener">Detecting genetic association through shortest paths in a bidirected graph    </a><br>M. Ueki, Y. Kawasaki, G. Tamiya and I. for Alzheimer’s Disease Neuroimaging<br>Feature：提出了一种用于在多元回归模型中<strong>检测</strong>具有显着但弱的边际关联的隐藏SNP的新方法。</p><p>Result：所提出的方法可以检测LD隐藏的敏感性SNP，这些SNP未通过边际关联检验或现有的多变量方法检测到。当应用于阿尔茨海默病神经影像学倡议（ADNI）的真实GWAS数据时，我们的方法检测到两组SNP：一组在含有载脂蛋白E（APOE）基因的区域，另一组在接近信号素5A的区域（SEMA5A）基因。</p><p>184<a href="http://adni.loni.usc.edu/adni-publications/Automatic%20labeling%20of%20MR%20brain%20images%20through%20extensible%20learning%20and%20atlas%20forests.pdf" target="_blank" rel="noopener">Automatic labeling of MR brain images through extensible learning and atlas forests    </a><br>L. Xu, H. Liu, E. Song, M. Yan, R. Jin and C. C. Hung<br>Feature：通过可扩展学习和阿特拉斯森林自动标记MR脑图像，基于Multiatlas的方法因其简单性和鲁棒性而广泛应用于<strong>MR脑图像分割</strong>，该方法提供了极好的准确性。</p><p>185<a href="http://adni.loni.usc.edu/adni-publications/Learning%20non-linear%20patch%20embeddings%20with%20neural%20networks%20for%20label%20fusion.pdf" target="_blank" rel="noopener">Learning non-linear patch embeddings with neural networks for label fusion    </a><br>G. Sanroma, O. M. Benkarim, G. Piella, O. Camara, G. Wu, D. Shen, J. D. Gispert, J. L. Molinuevo, M. A. Gonzalez Ballester and I. Alzheimer’s Disease Neuroimaging （重复）</p><p>186<a href="http://adni.loni.usc.edu/adni-publications/Risk%20factors%20for%20amyloid%20positivity%20in%20older%20people%20reporting%20significant%20memory%20concern.pdf" target="_blank" rel="noopener">Risk factors for amyloid positivity in older people reporting significant memory concern    </a><br>J. Zhang, W. Zhou, R. M. Cassidy, H. Su, Y. Su, X. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：本研究的目的是确定报告主观认知能力下降（SCD）患者脑内淀粉样蛋白积聚的风险因素。识别这些风险因素将有助于更好地<strong>识别</strong>应该接受神经影像学研究以确认斑块存在并开始干预的患者，以及加强对阿尔茨海默病发病机制的研究。</p><p>187<a href="http://adni.loni.usc.edu/adni-publications/Differential%20Regional%20Distribution%20of%20Juxtacor.pdf" target="_blank" rel="noopener">Differential Regional Distribution of Juxtacortical White Matter Signal Abnormalities in Aging and Alzheimer’s Disease    </a><br>E. R. Lindemer, D. N. Greve, B. Fischl, J. C. Augustinack, D. H. Salat and I. Alzheimer’s Disease Neuroimaging（重复193）<br>Feature：老年人和阿尔茨海默病患者皮质白质信号异常WMSA的微分区域分布.</p><p>Objective：观察AD患者大脑中WMSA的空间分布模式是否与认知健康老化者不同</p><p>Result：结果表明WMSA是AD发展的重要病理组成部分</p><p>188<a href="http://adni.loni.usc.edu/adni-publications/Huang_2017_Alzheimer&#39;s%20and%20dementia%20T%20RCI.pdf" target="_blank" rel="noopener">Power analysis to detect treatment effects in longitudinal clinical trials for Alzheimer’s disease    </a><br>Z. Huang, G. Muniz-Terrera and B. D. M. Tom （重复194）<br>Feature：功效分析，以检测阿尔茨海默病纵向临床试验中的治疗效果</p><p>Conclusion：在设计临床试验时考虑组分评分的多变量/联合分布而不是单个综合评分的分布可以导致功效的增加和样本量的减少，以便在早期AD的临床试验中<strong>检测治疗效果</strong>。</p><p>189<a href="http://adni.loni.usc.edu/adni-publications/Battista-2017-Optimizing%20Neuropsychological%20As.pdf" target="_blank" rel="noopener">Optimizing Neuropsychological Assessments for Cognitive, Behavioral, and Functional Impairment Classification: A Machine Learning Study</a><br>Battista P1, Salvatore C1, Castiglioni I1<br>Feature：对认知、行为和功能障碍分类的神经心理学评估进行优化:机器学习研究，有助于用于<strong>分类和诊断</strong>AD的临床措施</p><p>Objective：评估机器学习在量化神经心理学评估过程中的潜力，并优化甚至减少用于对AD患者进行分类的神经心理学测试的数量，同样在损伤的早期阶段。</p><p>190<a href="http://adni.loni.usc.edu/adni-publications/Cortical%20atrophy%20is%20associated%20with%20accelerate.pdf" target="_blank" rel="noopener">Cortical Atrophy is Associated with Accelerated Cognitive Decline in Mild Cognitive Impairment with Subsyndromal Depression    </a><br>M. M. Gonzales, P. S. Insel, C. Nelson, D. Tosun, N. Mattsson, S. G. Mueller, Sacuiu, Bickford, W. Weiner and R. S. Mackin </p><p>Feature：<strong>研究</strong>轻度认知障碍（MCI）和慢性亚综合征性抑郁症（SSD）患者认知功能下降与皮质萎缩之间的<strong>关系</strong></p><p>Result：患有慢性SSD的个体可能代表MCI亚群，其非常容易受到加速认知衰退的影响，这种影响可能受额叶和前扣带萎缩的影响</p><p>19</p><p>191 A comparison of accurate automatic hippocampal segmentation methods    </p><p>URL：<code>http://adni.loni.usc.edu/adni-publications/Zandifar)%202017_neuroimaging.pdf</code></p><p>A. Zandifar, V. Fonov, P. Coupe, J. Pruessner, D. L. Collins and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：准确自动海马分割方法的比较</p><p>Method：比较了四种完全自动化的海马分割方法，它们与手动分割的一致性以及它们在临床环境中用作AD生物标志物的能力</p><p>Result：我们的研究表明，基于非线性补丁的纠错分割方法是最准确的自动分割方法，与手动分割最符合（= 0.894）</p><p>192<a href="http://adni.loni.usc.edu/adni-publications/Regional%2018F-Fluorodeoxyglucose%20Hypometabolism.pdf" target="_blank" rel="noopener">Regional 18F-Fluorodeoxyglucose Hypometabolism is Associated with Higher Apathy Scores Over Time in Early Alzheimer Disease</a><br>J. R. Gatchel, J. Donovan, J. Locascio, J. A. Becker, M. Rentz, A. Sperling, A. Johnson, A. Marshall and A. s. D. N. Initiative<br>Feature：研究了<code>冷漠</code>与区域18F-氟脱氧葡萄糖（FDG）代谢在认知正常，轻度认知障碍和来自阿尔茨海默病神经影像学倡议数据库的AD痴呆受试者之间的关联。研究AD蛋白病在冷漠发病机制中的潜在作用。有助于制定<strong>预防</strong>和治疗AD的策略</p><p>193<a href="http://adni.loni.usc.edu/adni-publications/Differential%20Regional%20Distribution%20of%20Juxtacor.pdf" target="_blank" rel="noopener">Differential Regional Distribution of Juxtacortical White Matter Signal Abnormalities in Aging and Alzheimer’s Disease    </a><br>E. R. Lindemer, D. N. Greve, B. Fischl, J. C. Augustinack, D. H. Salat and I. Alzheimer’s Disease Neuroimaging<br>Feature：（重复187）</p><p>194<a href="http://adni.loni.usc.edu/adni-publications/Huang_2017_Alzheimer&#39;s%20and%20dementia%20T%20RCI.pdf" target="_blank" rel="noopener">Power analysis to detect treatment effects in longitudinal clinical trials for Alzheimer’s disease    </a><br>Z. Huang, G. Muniz-Terrera and B. D. M. Tom （重复188）</p><p>195<a href="http://adni.loni.usc.edu/adni-publications/Plasma%20neurofilament%20light%20chain%20levels%20in%20Alz.pdf" target="_blank" rel="noopener">Plasma neurofilament light chain levels in Alzheimer’s disease.    </a><br>W. Zhou, J. Zhang, F. Ye, G. Xu, H. Su, Y. Su, X. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病中的血浆神经丝轻链水平.检查了血浆NFL是否可能是AD的前驱和痴呆阶段的潜在生物标志物</p><p>Result：结果表明，血浆NFL水平可能不是诊断AD的前驱和痴呆阶段的有用生物标志物。</p><p>196<a href="http://adni.loni.usc.edu/adni-publications/Prediction%20of%20Conversion%20to%20Alzheimer_s%20Diseas.pdf" target="_blank" rel="noopener">Prediction of Conversion to Alzheimer’s Disease with Longitudinal Measures and Time-To-Event Data    </a><br>K. Li, W. Chan, R. S. Doody, J. Quinn, S. Luo and I. Alzheimer’s Disease Neuroimaging<br>Feature：通过纵向测量和事件发生时间数据<strong>预测</strong>阿尔茨海默病的转变</p><p>Objective：比较各种临床和生物标志物轨迹，以跟踪进展和预测从遗忘性轻度认知障碍到可能的AD的转换</p><p>Result：最强的预测因子是ADAS-Cog 13</p><p>Conclusion：除基线特征外，还可以通过纳入纵向变化信息来改善AD转换的预测。认知测量一直是重要的，并且通常比成像测量更强的<code>预测</code>因子。</p><p>197<a href="http://adni.loni.usc.edu/adni-publications/MRI-Based%20Classification%20Models%20in%20Prediction.pdf" target="_blank" rel="noopener">MRI-based classification models in prediction of mild cognitive impairment and dementia in late-life depression    </a><br>A. K. Lebedeva, E. Westman, T. Borza, M. K. Beyer, K. Engedal, D. Aarsland, G. Selbaek and A. K. Haberg<br>Feature：基于MRI的分类模型<code>预测</code>晚期抑郁症中的轻度认知障碍和痴呆</p><p>198<a href="http://adni.loni.usc.edu/adni-publications/Efficient%20Groupwise%20Registration%20for%20Brain%20MRI%20by%20Fast%20Initialization.pdf" target="_blank" rel="noopener">Efficient Groupwise Registration for Brain MRI by Fast Initialization    </a><br>P. Dong, X. Cao, J. Zhang, M. Kim, G. Wu and D. Shen<br>Feature：通过快速初始化测试<strong>图像的分组</strong>注册MRI，我们最终可以使用现有的分组注册方法来快速细化分组注册结果。与最先进的分组登记方法相比，ADNI数据集上的实验结果显示出显着提高的<code>计算效率</code>和竞争性配准精度。</p><p>199<a href="http://adni.loni.usc.edu/adni-publications/The%20interactive%20effect%20of%20demographic%20and%20clinical%20factors%20on%20hippocampal%20volume-%20A%20multicohort%20study%20on%201958%20cognitively%20normal%20individuals.pdf" target="_blank" rel="noopener">The interactive effect of demographic and clinical factors on hippocampal volume: A multicohort study on 1958 cognitively normal individuals    </a><br>D. Ferreira, O. Hansson, J. Barroso, Y. Molina, A. Machado, J. A. Hernandez-Cabrera, J. S. Muehlboeck, E. Stomrud, K. Nagga, O. Lindberg, D. Ames, G. Kalpouzos, L. Fratiglioni, L. Backman, C. Graff, P. Mecocci, B. Vellas, M. Tsolaki, I. Kloszewska, H. Soininen, S. Lovestone, H. Ahlstrom, L. Lind, E. M. Larsson, L. O. Wahlund, A. Simmons, E. Westman, f. t. A. s. D. N. I. the AddNeuroMed consortium, B. Australian Imaging and g. Lifestyle Study of Ageing research<br>Feature：人口统计学和临床因素对海马体积的交互影响：1958年认知正常个体的多项研究</p><p>200<a href="http://adni.loni.usc.edu/adni-publications/Left%20frontal%20cortex%20connectivity%20underlies%20cognitive%20reserve%20in%20prodromal%20Alzheimer%20disease.pdf" target="_blank" rel="noopener">Left frontal cortex connectivity underlies cognitive reserve in prodromal Alzheimer disease    </a><br>N. Franzmeier, M. Duering, M. Weiner, M. Dichgans, M. Ewers and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：检测阿尔茨海默病（AD）左侧额叶皮质（LFC）的更高全局功能连接是否与更多年的教育（代理认知储备[CR]）相关，并减轻AD相关氟脱氧葡萄糖之间的关联（ FDG）-PET hypome-formolism和情节记忆。</p><p>Conclusion：较高的gLFC连接性是CR的功能性基质，有助于在早期AD中出现FDG-PET代谢减退时相对良好地维持情景记忆。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="ADNI" scheme="http://yoursite.com/categories/ADNI/"/>
    
    
  </entry>
  
  <entry>
    <title>系统集成项目管理知识点</title>
    <link href="http://yoursite.com/2018/11/03/%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E8%BD%AF%E8%80%83/"/>
    <id>http://yoursite.com/2018/11/03/系统集成项目管理软考/</id>
    <published>2018-11-03T04:43:04.000Z</published>
    <updated>2018-11-10T10:45:49.816Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h1 id="项目管理类"><a href="#项目管理类" class="headerlink" title="项目管理类"></a>项目管理类</h1><h2 id="项目立项"><a href="#项目立项" class="headerlink" title="项目立项"></a>项目立项</h2><h3 id="项目可行性研究"><a href="#项目可行性研究" class="headerlink" title="项目可行性研究"></a>项目可行性研究</h3><ul><li><p>可行性研究的步骤</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 机会研究</span><br><span class="line">2. 初步可行性研究</span><br><span class="line">3. 详细可行性研究</span><br><span class="line">- 小型项目可以不进行详细可行性研究</span><br><span class="line">4. 项目论证</span><br><span class="line">5. 项目评估</span><br><span class="line">- 项目评估由第三方进行</span><br><span class="line">- 决策的主要依据</span><br><span class="line">6. 项目可行性研究报告的编写、提交和获得批准</span><br></pre></td></tr></table></figure></li><li><p>甲方立项管理(解决项目的组织战略符合性问题)的四个阶段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. 项目识别</span><br><span class="line">2. 项目论证</span><br><span class="line">- 项目社会影响评价</span><br><span class="line">- 项目环境影响评价</span><br><span class="line">- 项目国民经济评价</span><br><span class="line">- 项目财务评价</span><br><span class="line">3. 投标</span><br><span class="line">4. 签订合同</span><br></pre></td></tr></table></figure></li><li><p>承建方(乙方)的项目管理步骤</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1. 项目机会识别</span><br><span class="line">2. 项目论证</span><br><span class="line">- 技术可行性分析</span><br><span class="line">    - 项目风险分析</span><br><span class="line">    - 人力资源配置分析</span><br><span class="line">    - 项目财务分析</span><br><span class="line">    - 对其他投标者的相关情况分析</span><br><span class="line">    </span><br><span class="line">    - 有效防范风险</span><br><span class="line">3. 投标</span><br></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">项目识别--乙方</span><br><span class="line">项目评估 -- 主管</span><br></pre></td></tr></table></figure></li><li><p>项目建议书(又称立项申请，由项目建设单位编写，非承建单位)包括的核心内容</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 项目的必要性</span><br><span class="line">2. 项目的市场预测</span><br><span class="line">3. 产品方案或服务的市场预测</span><br><span class="line">4. 项目建设必须的条件</span><br><span class="line">- 本期项目建设方案</span><br></pre></td></tr></table></figure></li><li><p>供应商项目内部立项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">内容：</span><br><span class="line">1. 项目资源估算</span><br><span class="line">2. 项目资源分配</span><br><span class="line">3. 准备项目任务书</span><br><span class="line">4. 任命项目经理</span><br><span class="line"></span><br><span class="line">作用:</span><br><span class="line">1. 分配资源</span><br><span class="line">2. 确定项目绩效目标</span><br><span class="line">3. 提升效率</span><br></pre></td></tr></table></figure></li></ul><h3 id="项目生命周期"><a href="#项目生命周期" class="headerlink" title="项目生命周期"></a>项目生命周期</h3><ul><li>项目临时性：明确的开始和结束时间</li></ul><h2 id="项目整体管理"><a href="#项目整体管理" class="headerlink" title="项目整体管理"></a>项目整体管理</h2><h2 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a>项目范围管理</h2><ul><li><p>项目范围管理过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 范围计划</span><br><span class="line">2. 范围定义</span><br><span class="line">3. 创建WBS</span><br><span class="line">4. 范围确认</span><br><span class="line">5. 范围控制</span><br></pre></td></tr></table></figure></li></ul><h3 id="制定范围管理计划"><a href="#制定范围管理计划" class="headerlink" title="制定范围管理计划"></a>制定范围管理计划</h3><h3 id="定义项目范围"><a href="#定义项目范围" class="headerlink" title="定义项目范围"></a>定义项目范围</h3><ul><li><p>范围说明书的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 项目合理性(资源需求)</span><br><span class="line">2. 项目目标</span><br><span class="line">3. 项目可交付成果清单</span><br></pre></td></tr></table></figure></li><li><p>工作说明书SOW </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">工作说明书(任务书)是对项目所要提供交付的产品或服务的叙述性的描述</span><br><span class="line">- 业务需求</span><br><span class="line">- 产品范围描述</span><br><span class="line">- 战略计划</span><br><span class="line">项目范围说明书则通过明确项目应该完成的工作而确定了项目的范围</span><br></pre></td></tr></table></figure></li></ul><h3 id="创建WBS"><a href="#创建WBS" class="headerlink" title="创建WBS"></a>创建WBS</h3><ul><li><p>工作包：WBS是最底层的工作单元</p></li><li><p>工作分解步骤</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 识别</span><br><span class="line">2. 分解</span><br><span class="line">3. 确认</span><br><span class="line">4. 核实</span><br></pre></td></tr></table></figure></li><li><p>WBS分解方法(逐层向下分解,渐进明细的)</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 生命周期为第一层，可交付物为第二层</span><br><span class="line">- 生命周期:&quot;需求分析、方案设计、实施准备、测试和验收&quot;(瀑布模型)</span><br><span class="line">- 重要的交付物为第一层</span><br><span class="line">- 子项目为第一层，再分解子项目的WBS</span><br></pre></td></tr></table></figure></li><li><p>WBS的制定需要<code>所有</code>项目干系人的参与，需要包括<code>100％</code>的工作内容</p></li></ul><h3 id="范围确认"><a href="#范围确认" class="headerlink" title="范围确认"></a>范围确认</h3><ul><li><p>范围确认(又称范围核实)：<code>正式验收并接受</code>已完成的项目可交付物的过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一般步骤：</span><br><span class="line">1. 确定需要进行确认范围的时间</span><br><span class="line">2. 识别确认范围需要哪些投入</span><br><span class="line">3. 确定范围正式被接受的标准和要素</span><br><span class="line">4. 确定确认范围会议的组织步骤</span><br><span class="line">5. 组织确认范围会议</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- 范围确认的对象不仅包括范围说明书，还包括项目管理计划和所有交付物</span><br><span class="line">- 范围确认的参加人员是客户和所有项目干系人，不仅限于项目组和质量管理员</span><br><span class="line">- 范围确认贯穿项目始终</span><br><span class="line">- 系统的终验报告作为范围确认证据</span><br><span class="line">- 用于范围确认的项目管理计划的组成部分包括如下范围基准</span><br><span class="line">- 项目范围说明书 - WBS - WBS词典(WBS的详细说明)    </span><br><span class="line">- 进行范围确认活动时应邀请客户参加</span><br><span class="line"></span><br><span class="line">范围确认与质量控制不同：</span><br><span class="line">前者是有关工作结果的接受问题；而后者是有关工作正确与否的问题。质量控制一般在范围确认之前完成.</span><br></pre></td></tr></table></figure></li><li><p>范围确认采用的方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 检查(有时也称审查、产品审查、审计、巡查)</span><br><span class="line">- 测量、审查与确认</span><br><span class="line">- 群体决策技术</span><br><span class="line">-一致同意 -大多数原则(超过50％) -相对多数原则 -独裁</span><br></pre></td></tr></table></figure></li><li><p>何时关注</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- 实际完成项目时间比计划提前</span><br></pre></td></tr></table></figure></li></ul><h3 id="控制项目范围"><a href="#控制项目范围" class="headerlink" title="控制项目范围"></a>控制项目范围</h3><ul><li><p>范围控制是监控项目状态 (如项目的<code>工作范围状态</code>和<code>产品范围状态</code>)，也是<code>控制变更</code>的过程</p><ul><li>变更影响分析由<code>项目经理</code>负责</li></ul></li><li><p>变更管理中 变更初审的目的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 确认变更的必要性</span><br><span class="line">- 格式校验、完整性校验，确保评估所需信息准备充分</span><br><span class="line">- 在干系人间 就提出供评估的变更信息达成共识</span><br></pre></td></tr></table></figure></li><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">控制变更，推荐纠正措施  属于 监督和控制过程组</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a>项目进度管理</h2><h3 id="活动排序"><a href="#活动排序" class="headerlink" title="活动排序"></a>活动排序</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出：</span><br><span class="line">- 项目进度网络图</span><br></pre></td></tr></table></figure><h3 id="活动资源估算"><a href="#活动资源估算" class="headerlink" title="活动资源估算"></a>活动资源估算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">方法：</span><br><span class="line">- 专家判断</span><br><span class="line">- 多方案分析：自制或者购买的决策</span><br><span class="line">- 出版的估算数据</span><br><span class="line">- 项目管理软件</span><br><span class="line">- 自下而上估算</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">- 资源分解结构</span><br><span class="line">- 请求的变更</span><br><span class="line">- 资源日历</span><br></pre></td></tr></table></figure><h3 id="项目历时估算"><a href="#项目历时估算" class="headerlink" title="项目历时估算"></a>项目历时估算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 主要方法和技术包括：专家判断、类比估算、参数估算、三点估算、后备估算</span><br><span class="line">- 三点估算能评估时间与概率的关系，可以用于风险评估，属于定量分析</span><br></pre></td></tr></table></figure><h3 id="控制进度计划"><a href="#控制进度计划" class="headerlink" title="控制进度计划"></a>控制进度计划</h3><ul><li><p>制定进度计划时可采用的工具与技术</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 关键路径法</span><br><span class="line">- 资源平衡技术 </span><br><span class="line">- 资源平滑技术</span><br><span class="line">- 活动只在其自由浮动时间和总浮动时间内延迟，不改变关键路径</span><br></pre></td></tr></table></figure></li><li><p>常用的历时估算方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 类比估算(未掌握全部细节)</span><br><span class="line">- 参数估算</span><br><span class="line">- 三点估算</span><br><span class="line">- 后备估算</span><br></pre></td></tr></table></figure></li><li><p>后备分析：以    <code>应急时间</code>、<code>时间储备</code>、<code>缓冲时间</code>为名称 增加时间</p></li><li>控制点：即里程碑. 关键路径<code>不能</code>包括所有项目进度控制点</li><li>项目进度表：横道图(gantt chart)</li><li>进度网络分析技术中的一种方法是<code>关键链法（经常改变关键路径，结合了确定性与随机性，常考）</code>、<code>关键路线法(正向与反向分析)</code></li></ul><h3 id="控制项目进度"><a href="#控制项目进度" class="headerlink" title="控制项目进度"></a>控制项目进度</h3><ul><li><p>压缩工期</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 投入更多的资源以加速活动进程(赶工)</span><br><span class="line">- 指派经验更丰富的人去完成或帮助完成项目工作</span><br><span class="line">- 减小活动范围或降低活动要求</span><br><span class="line">- 通过改进方法或技术提高生产效率</span><br><span class="line">- 快速跟进(并行工作)</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a>项目成本管理</h2><h3 id="估算项目成本"><a href="#估算项目成本" class="headerlink" title="估算项目成本"></a>估算项目成本</h3><h3 id="制定项目预算"><a href="#制定项目预算" class="headerlink" title="制定项目预算"></a>制定项目预算</h3><ul><li><p>挣值分析是成本控制的工具</p></li><li><p>成本预算的工具</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 参数估算</span><br><span class="line">- 资金限制平衡</span><br><span class="line">- 准备金分析</span><br></pre></td></tr></table></figure></li><li><p>成本分类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 直接成本：差旅费、工资</span><br><span class="line">- 间接成本：企业管理费、税金、福利、保卫费</span><br></pre></td></tr></table></figure></li></ul><h3 id="控制项目成本"><a href="#控制项目成本" class="headerlink" title="控制项目成本"></a>控制项目成本</h3><h3 id="绩效评估"><a href="#绩效评估" class="headerlink" title="绩效评估"></a>绩效评估</h3><ul><li><p>项目绩效就是搜集项目<code>所有基准数据</code>并向项目干系人提供绩效信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">收集材料：</span><br><span class="line">- 被评价项目资料清单</span><br><span class="line">- 项目绩效预测</span><br><span class="line">- 调查问卷</span><br></pre></td></tr></table></figure></li><li><p>项目评估包括</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 盈利要求</span><br><span class="line">2. 客户满意度要求</span><br><span class="line">3. 后续项目指标要求</span><br><span class="line">4. 内部满意度要求</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a>项目质量管理</h2><h3 id="质量度量"><a href="#质量度量" class="headerlink" title="质量度量"></a>质量度量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 软件产品的使用质量的质量属性：有效性、生产率、安全性、满意度</span><br><span class="line">- 质量特性：功能性、可靠性、易用性、效率、维护性、可移植性</span><br><span class="line">- 质量属性：精确性、完整性、可靠性、及时性、经济性、可验证性、安全性</span><br><span class="line">- 可靠性：故障次数 可用性：故障恢复时间</span><br><span class="line">- CMMI(软件能力成熟度模型)的过程改进目标：1.保证产品或服务质量 2.项目时间控制 3.用最低的成本</span><br></pre></td></tr></table></figure><h2 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a>项目人力资源管理</h2><ul><li><p>编制人力资源计划</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- 工具技术</span><br><span class="line">- 组织结构图和职位描述</span><br><span class="line">- 人力资源模板(可加快编制速度)</span><br><span class="line">- 非正式的人际网络</span><br><span class="line">- 组织理论</span><br><span class="line"></span><br><span class="line">- 描述工具</span><br><span class="line">- 工作分解结构</span><br><span class="line">- 组织分解结构(OBS)</span><br><span class="line">- 资源分解结构(RBS)</span><br><span class="line"></span><br><span class="line">- 每个工具包只有一个明确的责任人</span><br></pre></td></tr></table></figure></li><li><p>组建项目团队</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 生命周期：形成、震荡、正规、发挥(表现)、终止  </span><br><span class="line">- 项目团队加入新成员时，重新进入形成期</span><br><span class="line">- 方式：培训、扩展训练、认可和奖励</span><br></pre></td></tr></table></figure></li><li><p>管理项目团队</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 马斯洛需要层次理论：生理、安全、社会(团建活动)、自尊</span><br><span class="line">- 赫兹伯格的双因素理论：保健因素和激励因素</span><br><span class="line">- X-Y理论：x假定人性本恶 y假定人性本善</span><br><span class="line"></span><br><span class="line">- 责任分配矩阵 直观</span><br><span class="line"></span><br><span class="line">- 团队建设内容：1.一般管理技能 2.培训 3.团队建设活动 4.基本原则 5.同地办公</span><br><span class="line">- 项目组织结构：项目经理权利从小到大依次是职能型、弱矩阵型、平衡矩阵型、强矩阵型、项目型</span><br></pre></td></tr></table></figure></li><li><p>项目管理知识域</p></li></ul><h2 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a>项目沟通管理</h2><ul><li>沟通管理计划</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">编制过程：</span><br><span class="line">1. 确定干系人的沟通信息需求</span><br><span class="line">2. 描述信息收集和文件归档的机构</span><br><span class="line">3. 发送信息和重要信息的格式</span><br><span class="line"></span><br><span class="line">- 冲突管理</span><br><span class="line"></span><br><span class="line">- 主要内容</span><br><span class="line">- 项目干系人沟通要求</span><br><span class="line">- 对要发布信息的描述</span><br><span class="line">- 信息接收的个人或组织</span><br><span class="line">- 信息传达所需的技术或方法</span><br><span class="line">- 沟通频率</span><br><span class="line">- 上报过程</span><br><span class="line">- 随项目的进展对沟通管理计划更新与细化方法</span><br><span class="line">- 通用词语表</span><br></pre></td></tr></table></figure><ul><li><p>发布信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 项目状态/评审会议的主要目的：</span><br><span class="line">- 介绍项目进展情况</span><br><span class="line">- 项目是否偏离进度计划</span><br><span class="line">- 说明造成进度偏离计划的原因和预防计划</span><br><span class="line">- 汇报在项目执行中发现的问题及潜在的问题</span><br><span class="line">- 应引起客户或项目负责人注意的事项</span><br><span class="line"></span><br><span class="line">- 沟通(与上司沟通、与下属沟通、水平沟通)</span><br></pre></td></tr></table></figure></li><li><p>管理干系人</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 主要目的：避免项目干系人在项目管理中的严重分歧，促进干系人对项目的理解和支持</span><br><span class="line">- 沟通过程管理的最终目标是保障干系人之间的有效沟通</span><br><span class="line">- 干系人分析贯穿项目的始终</span><br></pre></td></tr></table></figure></li><li><p>冲突处理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 解决冲突的范畴</span><br><span class="line">- 强制</span><br><span class="line">- 妥协</span><br><span class="line">- 撤退</span><br><span class="line">- 合作(得到大多数人都同意)</span><br><span class="line">- 问题解决(公开讨论，直至选择出一套最佳方案)</span><br><span class="line">- 求同存异 </span><br><span class="line">- 问题解决应该聚焦现在，而不是过去</span><br></pre></td></tr></table></figure></li><li><p>沟通方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 引导技术</span><br><span class="line">- 头脑风暴</span><br><span class="line">- 冲突处理</span><br><span class="line">- 问题解决</span><br><span class="line">- 会议管理</span><br><span class="line">- 控制沟通的技术和方法</span><br><span class="line">- 信息管理系统</span><br><span class="line">- 专家判断</span><br><span class="line">- 会议</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a>项目风险管理</h2><ul><li><p>风险识别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 输入：企业环境因素、组织过程资产、项目范围说明书、风险管理计划、项目管理计划</span><br><span class="line">- 输出：风险识别单</span><br><span class="line">- 方法：德尔菲技术(专家判断、大多数原则)、SWOT分析</span><br></pre></td></tr></table></figure></li><li><p>定性风险分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 工具和技术(概率)</span><br><span class="line">- 风险概率及影响评估</span><br><span class="line">- 概率及影响矩阵</span><br><span class="line">- 风险数据质量评估</span><br><span class="line">- 风险种类</span><br><span class="line">- 风险紧急度评估</span><br></pre></td></tr></table></figure></li><li><p>定量风险分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">工作成果：</span><br><span class="line">- 项目的概率分析</span><br><span class="line">- 实现成本和时间目标的概率</span><br><span class="line">- 量化风险优先级清单</span><br><span class="line">- 定量风险分析结果的趋势</span><br><span class="line"></span><br><span class="line">技术方法：</span><br><span class="line">- 表示技术：概率分布、专家判断、风险信息访谈</span><br><span class="line">- 建模技术：灵敏度分析、期望货币值分析、决策树分析、建模仿真</span><br></pre></td></tr></table></figure></li><li><p>制定风险应对计划</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 检查措施</span><br><span class="line">- 缺陷补救措施：对 在质量审查和审核过程中发现的缺陷 制定的修复和消除影响的措施</span><br><span class="line">- 预防措施：消除潜在不良影响，降低风险发生的可能性而需要的措施  (常考)</span><br><span class="line">- 纠正措施：消除 已发现的不合格的情况 所采取的措施</span><br></pre></td></tr></table></figure></li><li><p>监控项目风险</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 工具和技术</span><br><span class="line">- 风险再评估</span><br><span class="line">- 风险审计：检查并记录</span><br><span class="line">- 偏差和趋势分析</span><br><span class="line">- 技术绩效测量</span><br><span class="line">- 储备分析</span><br><span class="line">- 会议</span><br><span class="line"></span><br><span class="line">- 风险不能消除</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目采购和合同管理"><a href="#项目采购和合同管理" class="headerlink" title="项目采购和合同管理"></a>项目采购和合同管理</h2><ul><li><p>询价</p></li><li><p>招标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- 信息邀请书RFI(Request For Information)</span><br><span class="line">  投标邀请书IFB(Invitation for bid)</span><br><span class="line">  报价邀请书RFQ(Request For Quotation)</span><br><span class="line">  建议邀请书RFP(Request For Proposal)：征求潜在供应商建议的文件</span><br><span class="line"></span><br><span class="line">- 集成商在招标阶段的工作顺序</span><br><span class="line">1.研读招标公告</span><br><span class="line">2.编制投标文件</span><br><span class="line">3.提交投标文件</span><br><span class="line">4.参与开标过程</span><br><span class="line">- 合同价款应为中标者的投标价</span><br></pre></td></tr></table></figure></li><li><p>采购管理</p></li><li><p>合同管理</p></li><li><p>合同违约管理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 索赔的性质属于经济补偿，并非惩罚</span><br><span class="line">- 在索赔事项发生后28天后，向监理工程师提出索赔意向通知</span><br><span class="line">- 承建单位严重违约的，可部分或全部终止合同，并采取善后措施</span><br></pre></td></tr></table></figure></li><li><p>项目收尾</p></li></ul><h2 id="文档与配置管理"><a href="#文档与配置管理" class="headerlink" title="文档与配置管理"></a>文档与配置管理</h2><h2 id="需求管理"><a href="#需求管理" class="headerlink" title="需求管理"></a>需求管理</h2><h2 id="项目管理高级知识"><a href="#项目管理高级知识" class="headerlink" title="项目管理高级知识"></a>项目管理高级知识</h2><h3 id="大型及复杂项目管理"><a href="#大型及复杂项目管理" class="headerlink" title="大型及复杂项目管理"></a>大型及复杂项目管理</h3><h3 id="信息系统工程监理"><a href="#信息系统工程监理" class="headerlink" title="信息系统工程监理"></a>信息系统工程监理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- 信息系统工程监理遵循&quot;四控、三管、一协调&quot;</span><br><span class="line">- 四控</span><br><span class="line">- 质量控制</span><br><span class="line">- 进度控制</span><br><span class="line">- 投资控制</span><br><span class="line">- 变更控制</span><br><span class="line">- 三管</span><br><span class="line">    - 合同管理</span><br><span class="line">    - 信息管理</span><br><span class="line">    - 安全管理</span><br><span class="line">- 一协调</span><br><span class="line">- 在信息系统工程实施过程中协调有关单位及人员间的工作关系</span><br></pre></td></tr></table></figure><h1 id="信息系统类"><a href="#信息系统类" class="headerlink" title="信息系统类"></a>信息系统类</h1><h2 id="IT信息化知识"><a href="#IT信息化知识" class="headerlink" title="IT信息化知识"></a>IT信息化知识</h2><h3 id="企业信息化"><a href="#企业信息化" class="headerlink" title="企业信息化"></a>企业信息化</h3><ul><li><p>企业信息化结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 产品层</span><br><span class="line">- 作业层</span><br><span class="line">- 管理层</span><br><span class="line">- 决策层</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- CRM(客户关系管理)</span><br><span class="line">- 自动化的销售、客户服务和市场营销</span><br><span class="line">- 以客户为中心</span><br><span class="line">- ERP(企业资源计划)</span><br><span class="line">- 企业可以根据自身的情况灵活地选择和集成模块</span><br><span class="line">- SCM(供应链管理)</span><br><span class="line">- 把正确数量的商品在正确的时间配送到正确的地点的一套管理方法，有效控制各种信息流、资金流和物流</span><br><span class="line">- 最重要的评价指标：客户满意度</span><br></pre></td></tr></table></figure></li><li><p>客户数据</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 描述性数据：客户的基本信息</span><br><span class="line">- 促销性数据：企业为客户提供的产品和服务的历史数据(客服人员建议、广告数据等)</span><br><span class="line">- 交易性数据：客户对企业的回馈信息(历史购买记录、投诉数据、客户建议等)</span><br></pre></td></tr></table></figure></li><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- ssl通信协议用于保护电子商务交易中的敏感数据</span><br></pre></td></tr></table></figure></li></ul><h3 id="系统运维管理"><a href="#系统运维管理" class="headerlink" title="系统运维管理"></a>系统运维管理</h3><ul><li><p>IT运维管理内容</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1. 设备管理</span><br><span class="line">2. 应用服务</span><br><span class="line">3. 数据存储</span><br><span class="line">4. 业务</span><br><span class="line">5. 目录内容</span><br><span class="line">6. 资源资产</span><br><span class="line">7. 信息安全</span><br><span class="line">8. 日常活动</span><br><span class="line"></span><br><span class="line">- 对系统进行升级改造属于 开发 ，不属于运维</span><br><span class="line"></span><br><span class="line">系统运维分类：</span><br><span class="line">- 更正性维护</span><br><span class="line">- 适应性维护</span><br><span class="line">- 完善性维护</span><br><span class="line">- 预防性维护</span><br></pre></td></tr></table></figure></li><li><p>IT服务</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- 核心要素：人员(正确选人)、过程(正确做事)、技术(高效做事)和资源(保障做事)</span><br><span class="line">- 生命周期：</span><br><span class="line">- 规划设计</span><br><span class="line">- 部署实施</span><br><span class="line">- 服务运营</span><br><span class="line">- 持续改进</span><br><span class="line">- 监督管理</span><br></pre></td></tr></table></figure></li><li><p>一般公认信息系统审计准则：职业准则、ISACA公告、职业道德规范</p></li></ul><h3 id="系统集成企业资质"><a href="#系统集成企业资质" class="headerlink" title="系统集成企业资质"></a>系统集成企业资质</h3><ul><li><p>系统集成主要包括<code>设备系统集成</code>和<code>应用系统集成</code></p></li><li><p>我国信息系统服务管理的主要内容：计算机信息系统<code>集成单位</code>资质管理、信息系统<code>项目经理</code>资格管理、信息系统<code>工程监理单位</code>资质管理、信息系统<code>工程监理人员</code>资质管理</p></li><li><p>项目集成项目成功实施的保障：<code>管理</code>和<code>商务</code></p></li><li><p>资质企业要求</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">人才要求:</span><br><span class="line">一级：具有计算机信息系统集成项目经理人数不少于25人，其中高级项目经理人数不少于8名</span><br><span class="line">二级：具有计算机信息系统集成项目经理人数不少于18人，其中高级项目经理人数不少于4名</span><br><span class="line">三级：具有计算机信息系统集成项目经理人数不少于6人，其中高级项目经理人数不少于1名</span><br><span class="line">四级：具有计算机信息系统集成项目经理人数不少于2人</span><br><span class="line"></span><br><span class="line">收入比例要求：</span><br><span class="line">一级：近三年的系统集成收入总额占营业收入总额的比例不低于70％</span><br><span class="line">二级：近三年的系统集成收入总额占营业收入总额的比例不低于60％</span><br><span class="line">三级：近三年的系统集成收入总额占营业收入总额的比例不低于50％</span><br><span class="line"></span><br><span class="line">注册资金:</span><br><span class="line">一级：不少于5000万元</span><br><span class="line">二级：不少于3000万元</span><br><span class="line">三级：不少于500万元</span><br><span class="line">四级：不少于30万元</span><br></pre></td></tr></table></figure></li></ul><h3 id="云服务"><a href="#云服务" class="headerlink" title="云服务"></a>云服务</h3><ul><li><p>云计算的服务形式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- Iaas(基础设施即服务)：向用户提供计算机(物理机和虚拟机)、存储空间等基本计算资源</span><br><span class="line">- Paas(平台即服务)：将软件研发的平台作为一种服务(如数据库管理系统、Web应用系统)</span><br><span class="line">- SaaS(软件即服务)：用户租用基于Web的软件来管理企业经营活动</span><br></pre></td></tr></table></figure></li><li><p>混合云：将公有云(使用计算资源，解决访问量暴增的情况)与私有云(存放数据，安全)进行混合和匹配</p></li></ul><h3 id="移动互联网"><a href="#移动互联网" class="headerlink" title="移动互联网"></a>移动互联网</h3><ul><li><p>物流信息技术主要包括条码技术、RFID技术、EDI技术、GPS技术和GIS技术</p></li><li><p>物联网</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">从架构上分为：</span><br><span class="line">- 感知层：负责信息采集和物物之间信息传输</span><br><span class="line">- 网络层：对采集的数据进行编码认证和传输</span><br><span class="line">- 应用层：结合行业信息化需求</span><br></pre></td></tr></table></figure></li></ul><h3 id="商业智能BI"><a href="#商业智能BI" class="headerlink" title="商业智能BI"></a>商业智能BI</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- 基本体系结构：数据仓库、联机分析处理、数据挖掘</span><br><span class="line">- 主要功能</span><br><span class="line">- 数据仓库(数据存储和访问)</span><br><span class="line">- 数据ETL(数据的抽取、转换和加载)</span><br><span class="line">- 数据统计输出(统计报表的设计和展示)</span><br><span class="line">- 分析功能</span><br><span class="line">- 实现层次</span><br><span class="line">- 数据报表</span><br><span class="line">- 多维数据分析</span><br><span class="line">- 数据挖掘</span><br></pre></td></tr></table></figure><ul><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- 智能制造&quot;炼金术&quot;:信息物理系统CPS</span><br><span class="line">- 智能城市</span><br><span class="line">- 数据及服务支撑层(关键技术：SOA、海量数据汇聚与存储、数据融合与处理、智能挖掘分析、协同分析)</span><br><span class="line">- 中国制造2025 新一代信息技术产业</span><br><span class="line">- 集成电路及专用装备</span><br><span class="line">- 信息通信设备</span><br><span class="line">- 操作系统及工业软件</span><br></pre></td></tr></table></figure></li></ul><h2 id="信息系统基础"><a href="#信息系统基础" class="headerlink" title="信息系统基础"></a>信息系统基础</h2><h3 id="软件工程"><a href="#软件工程" class="headerlink" title="软件工程"></a>软件工程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">- 软件规模估算方法</span><br><span class="line">- 德尔菲法</span><br><span class="line">- 软件设计方法</span><br><span class="line">- V模型方法</span><br><span class="line">- 开发：需求分析 → 概要设计 → 详细设计 → 编码测试</span><br><span class="line">- 测试：验收测试 ← 系统测试 ← 集成测试 ← 单元测试</span><br><span class="line">- 原型法(反复修改来实现用户的最终系统需求)</span><br><span class="line">- 用例设计</span><br><span class="line">- 软件开发模型</span><br><span class="line">- 瀑布模型(适用于需求明确或很少变更单的项目,结构化分析与设计)</span><br><span class="line">- 螺旋模型(瀑布模型+快速原型模型)</span><br><span class="line">- 每次迭代的活动依次是 制定计划、风险分析、实施工程、客户评估</span><br><span class="line">- 软件文档的质量等级</span><br><span class="line">- 最低限度文档</span><br><span class="line">- 内部文档</span><br><span class="line">- 工作文档</span><br><span class="line">- 正式文档</span><br></pre></td></tr></table></figure><h3 id="ruan’jian"><a href="#ruan’jian" class="headerlink" title="ruan’jian"></a>ruan’jian</h3><h1 id="专题类"><a href="#专题类" class="headerlink" title="专题类"></a>专题类</h1><h2 id="计算题"><a href="#计算题" class="headerlink" title="计算题"></a>计算题</h2><ul><li><p>三点估算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 平均时间：(best + 4*average + worst)/6</span><br><span class="line">- 正态分布，期望值两边+-1个标准差的范围内，曲线下面积约占总面积的68％</span><br><span class="line">+-2个标准差的范围内，曲线下面积约占总面积的95％</span><br><span class="line">+-3个标准差的范围内，曲线下面积约占总面积的99％</span><br><span class="line">- 标准差 (最坏-最好)/6</span><br></pre></td></tr></table></figure></li><li><p>挣值估算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- PV:一切按计划 该时间点所需花费</span><br><span class="line">- EV:以实际进度为准 该时间段所完成的工作量 计划中所需花费 (按实际进度 计划本该花费)</span><br><span class="line">- AC:实际情况 进行到该时间点 的已支出花费</span><br><span class="line">- CV：EV-AC (计算费用偏差)</span><br><span class="line">- SV: EV-PV(计算进度偏差)</span><br><span class="line">- CPI：EV/AC (成本绩效)</span><br><span class="line">- SPI：EV/PV (进度绩效)</span><br><span class="line">- 完成尚需估算ETC </span><br><span class="line">- (非典型) ETC = BAC-EV</span><br><span class="line">- (典型) ETC = (BAC-EV)/CPI</span><br><span class="line">- 完工估计EAC=AC+ETC</span><br></pre></td></tr></table></figure></li><li><p>运筹统计</p></li><li><p>关键路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">历时最长的路径</span><br></pre></td></tr></table></figure></li><li><p>期望货币值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 预期收益EMV = 概率*期望</span><br><span class="line">- 常结合决策数分析</span><br></pre></td></tr></table></figure></li><li><p>投资回收期</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给你n年时间，你只需要pt年就收回成本了</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><ul><li><p>配置管理的目标：为了系统地控制配置变更，在系统的整个生命周期中维持配置的完整性和可综合性，而标识系统在不同时间点上配置的管理。</p></li><li><p>配置管理的主要活动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1. 制定配置管理计划</span><br><span class="line">2. 配置标识</span><br><span class="line">3. 配置控制</span><br><span class="line">4. 配置状态报告</span><br><span class="line">5. 配置审计</span><br><span class="line">-配置审计也称配置审核或配置评价，包括功能配置审计和物理配置审计，分别用以验证当前配置项的一致性和完整性。其 实施 主要是为了确保项目配置管理的有效性，体现项目配置的最根本要求---不允许出现任何混乱现象.</span><br><span class="line">   1. 变更申请</span><br><span class="line">   2. 变更评估</span><br><span class="line">   3. 通告评估结果</span><br><span class="line">   4. 变更实施</span><br><span class="line">   5. 变更验证与确认</span><br><span class="line">   6. 变更的发布</span><br><span class="line">   7. 基于配置库的变更控制</span><br><span class="line">6. 发布管理和交付</span><br></pre></td></tr></table></figure></li><li><p>配置库的分类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 开发库：也称动态库、程序员库或工作库</span><br><span class="line">- 受控库：也称主库，包含当前的基线加上对基线的变更</span><br><span class="line">- 产品库：也称静态库、发行库、软件仓库，包含已发布使用的各种基线的存档</span><br><span class="line"></span><br><span class="line">配置库应该区分开发库和受控库，否则处于已发布状态的项目是不可能被随意修改配置项的.</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置控制委员会-Configuration-Control-Board-CCB"><a href="#配置控制委员会-Configuration-Control-Board-CCB" class="headerlink" title="配置控制委员会(Configuration Control Board,CCB)"></a>配置控制委员会(Configuration Control Board,CCB)</h3><h3 id="配置管理员-Configuration-Management-Officer-CMO"><a href="#配置管理员-Configuration-Management-Officer-CMO" class="headerlink" title="配置管理员(Configuration Management Officer,CMO)"></a>配置管理员(Configuration Management Officer,CMO)</h3><ul><li>编写配置管理计划</li><li>建立和维护<code>配置管理系统</code></li><li>建立和维护<code>配置库</code></li><li>配置项识别</li><li>建立和管理<code>基线</code></li><li><code>版本管理</code>和配置控制</li><li>配置状态报告</li><li>配置审计</li><li>发布管理和交付</li><li>对项目成员进行<code>配置管理培训</code></li></ul><h2 id="合同管理"><a href="#合同管理" class="headerlink" title="合同管理"></a>合同管理</h2><h3 id="合同分类"><a href="#合同分类" class="headerlink" title="合同分类"></a>合同分类</h3><ul><li><p>按项目付款方式划分的合同分类</p><ol><li>总价合同：又称固定价格合同，是指在合同中确定一个完成项目的总价，承包人据此完成项目全部合同内容的合同。承包人(集成商)承担了需求变更等方面带来的风险。—-对甲方有利</li><li>成本补偿合同：甲方承担项目实际发生的一切费用，因此也承担了项目的全部风险。—-对甲方不利</li><li>工料合同： 成本补偿合同+总价合同  </li></ol></li><li><p>合同支付条款，应该规定以下3方面的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 支付货款的条件</span><br><span class="line">- 结算支付的方式</span><br><span class="line">- 拒付货款，发包方有权部分或全部拒付货款</span><br></pre></td></tr></table></figure></li></ul><h2 id="采购管理"><a href="#采购管理" class="headerlink" title="采购管理"></a>采购管理</h2><ol><li><p>编制采购管理计划</p><ul><li>按照自制/外购的判断因素进行评估</li><li>采购计划应提交公司高层领导审批</li></ul></li><li><p>实施采购</p><ul><li>不能以报价最低作为选择乙方的依据(进行充分调研，了解调研采购产品的市场价格，以及潜在供应商的资信情况)</li><li>选择标准 应对集成商的经验和业绩(资质和声誉) 做出要求</li><li>双方签订合同时应确定明确的需求(就产品的型号、质量进行约定，约定合同交付物必要的质量检验和付款条件的把控)</li></ul></li><li>控制采购<ul><li>有效管理合同的执行(遇到问题，不能推卸责任)</li></ul></li><li>结束采购</li></ol><h2 id="质量管理"><a href="#质量管理" class="headerlink" title="质量管理"></a>质量管理</h2><ul><li><p>质量管理的主要活动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 规划质量管理</span><br><span class="line">2. 实施质量保证</span><br><span class="line">3. 质量控制</span><br><span class="line"></span><br><span class="line">- 质量管理计划制定和实施过程中需要注意：</span><br><span class="line">- 明确质量管理相关各方职责</span><br><span class="line">- 质量管理计划应该由项目经理带领项目组一起完成，并应组织相关人员进行评审，最后需要有效执行</span><br><span class="line">- 明确质量保证(QA)人员的职责</span><br><span class="line">- 区分质量保证和质量控制</span><br></pre></td></tr></table></figure></li><li><p>QA的主要工作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 制定质量管理计划</span><br><span class="line">- 按照计划实施质量管理活动</span><br><span class="line">- 发现问题要记录和沟通直至问题解决</span><br><span class="line">- 定期提交质量报告</span><br><span class="line">- 为项目组人员提供质量方面的培训</span><br></pre></td></tr></table></figure></li><li><p>设计评审会议</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">应该由项目经理组织，QA也可以组织</span><br><span class="line">- 项目经理对整个项目负责(包括质量)，设计评审是保证质量的常见方式</span><br><span class="line">- QA如果有丰富的技术背景，也可以组织设计评审</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="软考" scheme="http://yoursite.com/tags/%E8%BD%AF%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>Note About NiftyNet_dev</title>
    <link href="http://yoursite.com/2018/10/29/Note-About-NiftyNet-dev/"/>
    <id>http://yoursite.com/2018/10/29/Note-About-NiftyNet-dev/</id>
    <published>2018-10-29T12:58:57.000Z</published>
    <updated>2018-11-05T06:33:30.347Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-4a7a634a40d3583a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><a href="http://niftynet.io" target="_blank" rel="noopener">NiftyNet</a>是一款开源的卷积神经网络平台，专门针对<code>医学图像处理分析</code>以及<code>医学影像指导治疗</code>,由<em>WEISS (Wellcome EPSRC Centre for Interventional and Surgical Sciences), CMIC ( Centre for Medical Image Computing),HIG(High-dimensional Imaging Group)</em>三家研究机构共同推出。</p><p>NiftyNet基于<code>Tensorflow</code>的开源卷积神经网络平台，这一模块化设计的开源平台包含了<code>可共享的网络</code>和<code>预训练模型</code>，在这些模块的帮助下我们可以方便<code>快速地搭建</code>针对医学图像处理的神经网络模型： </p><ul><li>利用内置工具使用<code>预训练模型</code>； </li><li>将<code>现有网络</code>应用于自有的数据上进行调整； </li><li>快速为特殊的图像分析问题<code>生成解决方案</code>原型；</li></ul><p>目前的NiftyNet支持医学图像分割和生成对抗网络，这是一个研究型平台、并不保证临床使用的稳定性和准确率，它具有以下一些功能方便医学图像处理的研究：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">·用户接口方便的修改个性化网络元件参数； </span><br><span class="line">·可共享网络和预训练模型； </span><br><span class="line">·支持2-D，2.5-D,3-D,4-D的数据输入； </span><br><span class="line">·支持多GPU的高效训练； </span><br><span class="line">·内置了当前前沿的神经网络包括HighRes3DNet, 3D U-net, V-net, DeepMedic等，可以方便的使用； </span><br><span class="line">·对医学图像分割的综合评价度量；</span><br></pre></td></tr></table></figure><p>NiftyNet支持：<strong>图像分割</strong>  　　<strong>图像分类（回归）</strong>  　　<strong>auto-encoder（图像模型表示）</strong>  　　<strong>GANs（图像生成）</strong> </p><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>平台描述：<a href="https://arxiv.org/abs/1709.03485" target="_blank" rel="noopener"><em>NiftyNet: a deep-learning platform for medical imaging</em></a> </p><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-070e7eee4154bdd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NiftyNet应用程序类通过连接四个组件封装了针对不同医学图像分析应用程序的标准分析管道:  </span><br><span class="line">Reader： 从文件中加载数据  </span><br><span class="line">Sampler： 为之后的处理生成合适的样本  </span><br><span class="line">Network： 处理输入  </span><br><span class="line">output handler： 包括在培训期间的损失和优化器，以及在推理和评估期间的聚合器  </span><br><span class="line">ApplicationDriver： 定义了跨所有应用程序的公共结构，并负责实例化数据分析管道并将计算分布到可用的计算资源</span><br></pre></td></tr></table></figure><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-a40efe8a422d9a6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="实现框架" title="">                </div>                <div class="image-caption">实现框架</div>            </figure><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><p>由于整个项目是基于Tensorflow，所以需要实现基于对应的版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu==1.3     //安装GPU版本</span><br><span class="line">pip install tensorflow==1.3  //安装CPU版本</span><br><span class="line">pip install niftynet//安装NiftyNet库，所以依赖可以自动完成安装</span><br></pre></td></tr></table></figure><p><a href="https://github.com/NifTK/NiftyNet" target="_blank" rel="noopener">代码</a>在PyCharm中运行源码的话，在对应脚本的解释器的配置中添加参数即可:</p><ol><li><p>下载模型  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python net_download.py highres3dnet_brain_parcellation_model_zoo</span><br></pre></td></tr></table></figure></li><li><p>分割</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python net_segment.py inference -c ~/niftynet/extensions/highres3dnet_brain_parcellation/highres3dnet_config_eval.ini</span><br></pre></td></tr></table></figure><ul><li>Run</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/python3.6 /Users/Captain/Desktop/NiftyNet-dev/net_segment.py inference -c ~/niftynet/extensions/highres3dnet_brain_parcellation/highres3dnet_config_eval.ini</span><br><span class="line"></span><br><span class="line">NiftyNet version f3378259018b927e8fc6b20b06c53ac3886ee3a9 (no suitable tags)</span><br><span class="line">[CUSTOM]</span><br><span class="line">-- num_classes: 160</span><br><span class="line">-- output_prob: False</span><br><span class="line">-- label_normalisation: False</span><br><span class="line">-- softmax: True</span><br><span class="line">-- min_sampling_ratio: 0</span><br><span class="line">-- compulsory_labels: (0, 1)</span><br><span class="line">-- rand_samples: 0</span><br><span class="line">-- min_numb_labels: 1</span><br><span class="line">-- proba_connect: True</span><br><span class="line">-- evaluation_units: foreground</span><br><span class="line">-- inferred: ()</span><br><span class="line">-- weight: ()</span><br><span class="line">-- sampler: ()</span><br><span class="line">-- label: ()</span><br><span class="line">-- image: (&apos;Modality0&apos;,)</span><br><span class="line">-- name: net_segment</span><br><span class="line">[CONFIG_FILE]</span><br><span class="line">-- path: /Users/Captain/niftynet/extensions/highres3dnet_brain_parcellation/highres3dnet_config_eval.ini</span><br><span class="line">[MODALITY0]</span><br><span class="line">-- csv_file: </span><br><span class="line">-- path_to_search: data/OASIS/</span><br><span class="line">-- filename_contains: (&apos;nii&apos;,)</span><br><span class="line">-- filename_not_contains: ()</span><br><span class="line">-- filename_removefromid: </span><br><span class="line">-- interp_order: 0</span><br><span class="line">-- loader: None</span><br><span class="line">-- pixdim: (1.0, 1.0, 1.0)</span><br><span class="line">-- axcodes: (&apos;R&apos;, &apos;A&apos;, &apos;S&apos;)</span><br><span class="line">-- spatial_window_size: (96, 96, 96)</span><br><span class="line">[SYSTEM]</span><br><span class="line">-- cuda_devices: &quot;&quot;</span><br><span class="line">-- num_threads: 2</span><br><span class="line">-- num_gpus: 1</span><br><span class="line">-- model_dir: /Users/Captain/niftynet/models/highres3dnet_brain_parcellation</span><br><span class="line">-- dataset_split_file: ./dataset_split.csv</span><br><span class="line">-- event_handler: (&apos;model_saver&apos;, &apos;model_restorer&apos;, &apos;sampler_threading&apos;, &apos;apply_gradients&apos;, &apos;output_interpreter&apos;, &apos;console_logger&apos;, &apos;tensorboard_logger&apos;)</span><br><span class="line">-- iteration_generator: iteration_generator</span><br><span class="line">-- action: inference</span><br><span class="line">[NETWORK]</span><br><span class="line">-- name: highres3dnet</span><br><span class="line">-- activation_function: relu</span><br><span class="line">-- batch_size: 1</span><br><span class="line">-- smaller_final_batch_mode: pad</span><br><span class="line">-- decay: 0.0</span><br><span class="line">-- reg_type: L2</span><br><span class="line">-- volume_padding_size: (10, 10, 10)</span><br><span class="line">-- volume_padding_mode: minimum</span><br><span class="line">-- window_sampling: uniform</span><br><span class="line">-- queue_length: 5</span><br><span class="line">-- multimod_foreground_type: and</span><br><span class="line">-- histogram_ref_file: databrain_std_hist_models_otsu.txt</span><br><span class="line">-- norm_type: percentile</span><br><span class="line">-- cutoff: (0.001, 0.999)</span><br><span class="line">-- foreground_type: mean_plus</span><br><span class="line">-- normalisation: True</span><br><span class="line">-- whitening: True</span><br><span class="line">-- normalise_foreground_only: True</span><br><span class="line">-- weight_initializer: he_normal</span><br><span class="line">-- bias_initializer: zeros</span><br><span class="line">-- keep_prob: 1.0</span><br><span class="line">-- weight_initializer_args: &#123;&#125;</span><br><span class="line">-- bias_initializer_args: &#123;&#125;</span><br><span class="line">[INFERENCE]</span><br><span class="line">-- spatial_window_size: (128, 128, 128)</span><br><span class="line">-- inference_iter: 33000</span><br><span class="line">-- dataset_to_infer: </span><br><span class="line">-- save_seg_dir: ./parcellation_output</span><br><span class="line">-- output_postfix: _niftynet_out</span><br><span class="line">-- output_interp_order: 0</span><br><span class="line">-- border: (2, 2, 2)</span><br><span class="line">INFO:niftynet: starting segmentation application</span><br><span class="line">INFO:niftynet: `csv_file = ` not found, writing to &quot;/Users/Captain/niftynet/models/highres3dnet_brain_parcellation/Modality0.csv&quot; instead.</span><br><span class="line">INFO:niftynet: Overwriting existing: &quot;/Users/Captain/niftynet/models/highres3dnet_brain_parcellation/Modality0.csv&quot;.</span><br><span class="line">INFO:niftynet: [Modality0] search file folders, writing csv file /Users/Captain/niftynet/models/highres3dnet_brain_parcellation/Modality0.csv</span><br><span class="line">INFO:niftynet: </span><br><span class="line"></span><br><span class="line">Number of subjects 1, input section names: [&apos;subject_id&apos;, &apos;Modality0&apos;]</span><br><span class="line">-- using all subjects (without data partitioning).</span><br><span class="line"></span><br><span class="line">INFO:niftynet: Image reader: loading 1 subjects from sections (&apos;Modality0&apos;,) as input [image]</span><br><span class="line">INFO:niftynet: normalisation histogram reference models ready for image:(&apos;Modality0&apos;,)</span><br><span class="line">2018-11-04 18:06:59.209921: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA</span><br><span class="line">INFO:niftynet: initialised window instance</span><br><span class="line">INFO:niftynet: initialised grid sampler &#123;&apos;image&apos;: (1, 128, 128, 128, 1, 1), &apos;image_location&apos;: (1, 7)&#125;</span><br><span class="line">INFO:niftynet: using HighRes3DNet</span><br><span class="line">INFO:niftynet: Initialising dataset from generator...</span><br><span class="line">INFO:niftynet: starting from iter 33000</span><br><span class="line">INFO:niftynet: Accessing /Users/Captain/niftynet/models/highres3dnet_brain_parcellation/models/model.ckpt-33000</span><br><span class="line">INFO:niftynet: Restoring parameters from /Users/Captain/niftynet/models/highres3dnet_brain_parcellation/models/model.ckpt-33000</span><br><span class="line">INFO:niftynet: grid sampling image sizes: &#123;&apos;image&apos;: (180, 276, 276, 1, 1)&#125;</span><br><span class="line">INFO:niftynet: grid sampling window sizes: &#123;&apos;image&apos;: (128, 128, 128, 1, 1)&#125;</span><br><span class="line">INFO:niftynet: yielding 27 locations from image</span><br><span class="line">INFO:niftynet: inference iter 0,  (398.539150s)</span><br><span class="line">INFO:niftynet: inference iter 1,  (313.655015s)</span><br><span class="line">INFO:niftynet: inference iter 2,  (297.785388s)</span><br><span class="line">INFO:niftynet: inference iter 3,  (2059.323541s)</span><br><span class="line">INFO:niftynet: inference iter 4,  (357.954505s)</span><br><span class="line">INFO:niftynet: inference iter 5,  (315.965626s)</span><br><span class="line">INFO:niftynet: inference iter 6,  (380.311502s)</span><br><span class="line">INFO:niftynet: inference iter 7,  (312.727651s)</span><br><span class="line">INFO:niftynet: inference iter 8,  (373.855815s)</span><br><span class="line">INFO:niftynet: inference iter 9,  (386.695381s)</span><br><span class="line">INFO:niftynet: inference iter 10,  (300.015597s)</span><br><span class="line">INFO:niftynet: inference iter 11,  (268.670928s)</span><br><span class="line">INFO:niftynet: inference iter 12,  (303.761694s)</span><br><span class="line">INFO:niftynet: inference iter 13,  (308.727933s)</span><br><span class="line">INFO:niftynet: inference iter 14,  (313.504975s)</span><br><span class="line">INFO:niftynet: inference iter 15,  (283.154703s)</span><br><span class="line">INFO:niftynet: inference iter 16,  (280.827804s)</span><br><span class="line">INFO:niftynet: inference iter 17,  (286.342750s)</span><br><span class="line">INFO:niftynet: inference iter 18,  (277.392094s)</span><br><span class="line">INFO:niftynet: inference iter 19,  (289.777673s)</span><br><span class="line">INFO:niftynet: inference iter 20,  (304.182126s)</span><br><span class="line">INFO:niftynet: inference iter 21,  (304.781269s)</span><br><span class="line">INFO:niftynet: inference iter 22,  (286.984278s)</span><br><span class="line">INFO:niftynet: inference iter 23,  (299.828858s)</span><br><span class="line">INFO:niftynet: inference iter 24,  (314.818588s)</span><br><span class="line">INFO:niftynet: inference iter 25,  (322.952987s)</span><br><span class="line">INFO:niftynet: inference iter 26,  (273.040366s)</span><br><span class="line">INFO:niftynet: inference iter 27,  (280.480217s)</span><br><span class="line">Saved /Users/Captain/niftynet/models/highres3dnet_brain_parcellation/parcellation_output/OAS1_0145_MR2_mpr_n4_anon_sbj_111_niftynet_out.nii.gz</span><br><span class="line">INFO:niftynet: stopping -- event handler: OutputInterpreter.</span><br><span class="line">INFO:niftynet: cleaning up...</span><br><span class="line">INFO:niftynet: stopping sampling threads</span><br><span class="line">INFO:niftynet: SegmentationApplication stopped (time in second 10501.22).</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br><span class="line">注：Mac pro A1502 运行了近三个小时</span><br></pre></td></tr></table></figure><ul><li><p>Run Problem</p><ul><li>Install packages failed</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- cv2</span><br><span class="line">  - pip3 install opencv-python</span><br><span class="line">- yaml</span><br><span class="line">  - pip3 install pyyaml</span><br></pre></td></tr></table></figure><ul><li>Others</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- The NiftyNetExamples server is not running</span><br><span class="line">- 直接从他处拷贝至~/niftynet</span><br></pre></td></tr></table></figure></li></ul></li></ol><p>执行结果：(运行完成会生成一个100__niftynet_out.nii文件，此文件可以用spm12和<a href="https://www.nitrc.org/frs/?group_id=152" target="_blank" rel="noopener">mriCron</a>打开)</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-6e7c93b7e9b69bac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><p><a href="http://niftynet.readthedocs.io/en/dev/" target="_blank" rel="noopener">文档</a>主要包括三个主要部分，分别是指引、资源和接口参考三个部分：</p><ul><li>Guide部分： 主要包括平台简介、安装指南和配置文件的设置；同时还有一个模型库可供用户选择合适的模型适配具体的问题；如果无法满足需求的情况下，它还提供了如何建立网络的教程，可以一步一步创建自己的新网络；</li><li>Resource部分： 这里包含了一系列资源，除了项目的网络还包括源码和源码镜像、以及模型库。同时还提供了Stack Overflow提问区域供用户交流；</li><li>API参考部分： 网络几大模块的说明，主要有application、contrib、engine、evaluation、io、layer、network和utilities等功能包供用户使用，每一个都有详尽的参数描述和使用指南；</li></ul><p>相关链接：</p><p><a href="https://pypi.org/project/NiftyNet/" target="_blank" rel="noopener">https://pypi.org/project/NiftyNet/</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="NiftyNet" scheme="http://yoursite.com/tags/NiftyNet/"/>
    
  </entry>
  
  <entry>
    <title>Note About Tensorflow</title>
    <link href="http://yoursite.com/2018/10/29/Note-About-Tensorflow/"/>
    <id>http://yoursite.com/2018/10/29/Note-About-Tensorflow/</id>
    <published>2018-10-29T12:47:37.000Z</published>
    <updated>2018-10-29T12:52:50.219Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Installing-TensorFlow-on-Mac-OS-X"><a href="#Installing-TensorFlow-on-Mac-OS-X" class="headerlink" title="Installing TensorFlow on Mac OS X"></a>Installing TensorFlow on Mac OS X</h2><p><strong>链接：<a href="https://www.tensorflow.org/versions/r1.1/install/install_mac" target="_blank" rel="noopener">在 macOS 上安装 TensorFlow</a></strong></p><p><strong>注意事项：</strong></p><ul><li><p>不支持python3.7</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">(tensorflow) ➜  NiftyNet-dev python</span><br><span class="line">Python 3.7.1 (default, Oct 23 2018, 14:07:42)</span><br><span class="line">[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt; import tensorflow as tf</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">  File "/Users/Captain/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/__init__.py", line 24, in &lt;module&gt;</span><br><span class="line">    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import</span><br><span class="line">  File "/Users/Captain/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/__init__.py", line 49, in &lt;module&gt;</span><br><span class="line">    from tensorflow.python import pywrap_tensorflow</span><br><span class="line">  File "/Users/Captain/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in &lt;module&gt;</span><br><span class="line">    from tensorflow.python.pywrap_tensorflow_internal import *</span><br><span class="line">  File "/Users/Captain/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 114</span><br><span class="line">    def TFE_ContextOptionsSetAsync(arg1, async):</span><br><span class="line">                                             ^</span><br><span class="line">SyntaxError: invalid syntax</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt;</span><br></pre></td></tr></table></figure></li><li><p><code>I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Python 3.6.3 (v3.6.3:2c5fed86e0, Oct  3 2017, 00:32:08)</span><br><span class="line">[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt; import tensorflow as tf</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt; hello = tf.constant('Hello, TensorFlow!')</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt; sess = tf.Session()</span><br><span class="line">2018-10-29 19:55:55.341316: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt; print(sess.run(hello))</span><br><span class="line">b'Hello, TensorFlow!'</span><br><span class="line"><span class="meta">&gt;</span>&gt;&gt;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Note_About_ADNI</title>
    <link href="http://yoursite.com/2018/10/28/Note-About-ADNI/"/>
    <id>http://yoursite.com/2018/10/28/Note-About-ADNI/</id>
    <published>2018-10-28T01:46:32.000Z</published>
    <updated>2018-11-19T11:07:28.731Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】ADNI 官网介绍笔记</p><a id="more"></a><h2 id="Welcome"><a href="#Welcome" class="headerlink" title="Welcome"></a>Welcome</h2><p>阿尔茨海默病神经影像学倡议（ADNI）将研究人员与研究数据联系起来，因为它们致力于确定阿尔茨海默病（AD）的进展。ADNI研究人员收集，验证和利用数据，包括<code>MRI</code>和<code>PET</code>图像，遗传学，认知测试，脑脊液和血液生物标志物作为疾病的<code>预测因子</code>。来自北美ADNI研究的研究资源和数据可通过本网站获得，包括阿尔茨海默病患者，轻度认知障碍受试者和老年人控制。 </p><p>欢迎来到<a href="http://adni.loni.usc.edu/" target="_blank" rel="noopener">网站</a>，其中添加了<code>ADNI3</code>的内容。该网站建立在<code>ADNI1</code>，<code>ADNI-GO</code>和<code>ADNI2</code>研究的基础上，旨在确定整个阿尔茨海默病的临床，认知，成像，遗传和生物化学生物标志物之间的关系。ADNI3将继续努力发现，优化，标准化和验证AD临床研究中使用的临床试验措施和生物标志物。</p><h2 id="ABOUT"><a href="#ABOUT" class="headerlink" title="ABOUT"></a>ABOUT</h2><p>ADNI研究的三个总体目标是：</p><ol><li>在尽可能早的阶段（痴呆前）检测AD，并确定用<code>生物标志物</code>跟踪疾病进展的方法。</li><li>通过在尽可能早的阶段应用新的诊断方法（此时干预可能最有效），<code>支持AD干预</code>，预防和治疗的进展。</li><li>持续管理ADNI的创新数据访问政策，该政策提供所有数据(<code>数据共享</code>)，而不是对世界上所有科学家进行禁运。</li></ol><h2 id="STUDY-DESIGN"><a href="#STUDY-DESIGN" class="headerlink" title="STUDY DESIGN"></a>STUDY DESIGN</h2><h3 id="关于BIOMARKERS"><a href="#关于BIOMARKERS" class="headerlink" title="关于BIOMARKERS"></a>关于BIOMARKERS</h3><p>生物标志物是生物状态的物质、测量或指标。在临床症状出现之前可能存在生物标志物。ADNI使用各种生物标志物来帮助预测阿尔茨海默病的发病。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2010/04/ADNI_clinicalDiseaseStage-V-EDIT.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>该图描绘了生物标志物作为AD的指标。曲线表明AD过程中五种生物标志物从正常到异常的变化（对痴呆的正常认知）</p><ol><li>在脑脊液中或通过淀粉样蛋白PET成像测量的<code>β-淀粉样蛋白</code>（Aβ）</li><li>由脑脊液中测量的<code>tau蛋白</code>表示的神经变性，或通过FDG-PET测量的突触<code>功能障碍</code></li><li><code>脑结构</code>萎缩，主要在内侧颞叶，通过结构MRI测量</li><li><code>记忆</code>丧失，通过认知测试来衡量</li><li><code>临床功能</code>，通过认知测试测量的一般认知下降表示。</li></ol><p>变化1-3表示可以在痴呆诊断之前观察到的生物标志物，而变化4-5是痴呆症诊断的经典指标。</p><h3 id="CLINICIAL-STUDY"><a href="#CLINICIAL-STUDY" class="headerlink" title="CLINICIAL STUDY"></a>CLINICIAL STUDY</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/10/clinical-data-chart.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><ul><li><p>CN：<code>正常衰老/认知正常</code>. CN参与者是ADNI研究中的对照受试者。他们没有表现出抑郁，轻度认知障碍或痴呆的迹象。</p></li><li><p>SMC 重要记忆关注 – 解决健康老年人对照组与MCI之间的差距</p></li><li><p>MCI： <code>轻度认知障碍</code>. MCI参与者日常活动基本上得到保留，其他认知领域没有显着的损伤水平，也没有痴呆症的迹象。使用Wechsler Memory Scale Logical Memory II确定MCI水平（早期或晚期）。</p><ul><li>EMCI：<code>早期</code>认知障碍.</li><li>LMCI：<code>晚期</code>认知障碍.</li></ul></li><li><p>AD：Alzheimer disease. 阿尔茨海默病</p></li></ul><h2 id="DATA-TYPES"><a href="#DATA-TYPES" class="headerlink" title="DATA TYPES"></a>DATA TYPES</h2><p>ADNI研究人员在参与研究期间从研究志愿者那里收集了几种类型的数据，使用一套标准的协议和程序来消除不一致性。此信息可通过<a href="https://ida.loni.usc.edu/login.jsp?project=ADNI" target="_blank" rel="noopener">LONI图像和数据存档（IDA）</a>免费提供给授权的调查员  。</p><h3 id="临床"><a href="#临床" class="headerlink" title="临床"></a>临床</h3><p>ADNI临床数据集包括关于每个受试者的临床信息，包括招募，人口统计学，身体检查和认知评估数据。可以将整套临床数据作为逗号分隔值（<code>CSV</code>）文件批量下载。</p><h3 id="遗传"><a href="#遗传" class="headerlink" title="遗传"></a>遗传</h3><p>遗传因素在阿尔茨海默病中起重要作用。全基因组关联研究（<code>GWAS</code>）采用标记之间关联的测试，称为单核苷酸多态性（<code>SNP</code>）和感兴趣的表型。来自病例对照GWAS和其他类型的遗传关联研究的发现可以提供用于检查源自ADNI成像和其他生物标志物数据集的定量表型的目标。</p><p><code>APOE的4等位基因</code>是已知的AD最强大的遗传风险因素，如果拥有一个4等位基因的人患AD的风险增加了2- 3倍，那么如果有两个等位基因的人患AD的风险增加了12倍。</p><h3 id="MRI图像"><a href="#MRI图像" class="headerlink" title="MRI图像"></a>MRI图像</h3><p>MRI – <code>核磁共振成像</code></p><p>原始，预处理和后处理图像文件，FMRI和DTI 这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/MRI.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>该项目将收集MRI（结构，扩散加权成像，灌注和静息状态序列）; 使用florbetapir F18（florbetapir）或florbetaben F18（florbetaben）的淀粉样蛋白PET; 18F-FDG-PET（FDG-PET）; CSF用于Aβ，tau，磷酸化tau（AKA磷酸化酶）和其他蛋白质; AV-1451 PET; 和遗传和尸检数据，以<code>确定这些生物标志物与基线临床状态和认知下降的关系</code>。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-47b425d8cdc1ff7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="PET图像"><a href="#PET图像" class="headerlink" title="PET图像"></a>PET图像</h3><p>PET – <code>正电子发射型计算机断层显像</code></p><p>原始，预处理和后处理图像文件，PIB（ADNI1），FDG（ADNI1 / GO / 2），FLORBETAPIR（ADNI GO / 2/3），FLORBETABEN（ADNI3）和TAU IMAGING（ADNI3）这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-1.png" alt="an overview of the PET data collected throughout the ADNI study" title="">                </div>                <div class="image-caption">an overview of the PET data collected throughout the ADNI study</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-Image-Data.png" alt="AVAILABLE IMAGE DATA" title="">                </div>                <div class="image-caption">AVAILABLE IMAGE DATA</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-508b820355abe639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="生物样本"><a href="#生物样本" class="headerlink" title="生物样本"></a>生物样本</h3><p>ADNI的目标之一是收集参与者的<code>血液</code>，<code>尿液</code>和<code>脑脊液（CSF）</code>等生物样本。鼓励有兴趣的调查员，无论是否与ADNI网站相关联，都可以申请使用这种有限的资源。但是，除非初步数据显示出明显优越的性能，否则不建议将ADNI样本用于技术开发或不同技术之间的比较。</p><h2 id="METHODS-AND-TOOLS"><a href="#METHODS-AND-TOOLS" class="headerlink" title="METHODS AND TOOLS"></a>METHODS AND TOOLS</h2><ul><li>生物标记分析</li><li>遗传数据方法</li><li>蛋白质组分析</li><li>MRI分析</li><li>PET分析</li><li>神经病学方法</li><li>RARC批准的研究</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】ADNI 官网介绍笔记&lt;/p&gt;
    
    </summary>
    
    
      <category term="ADNI" scheme="http://yoursite.com/tags/ADNI/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Convolutional_Neural_Networks</title>
    <link href="http://yoursite.com/2018/10/27/Lecture-Convolutional-Neural-Networks/"/>
    <id>http://yoursite.com/2018/10/27/Lecture-Convolutional-Neural-Networks/</id>
    <published>2018-10-27T10:18:13.000Z</published>
    <updated>2018-11-19T16:58:27.908Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h3 id="卷积神经网络（CNNs-ConvNets）"><a href="#卷积神经网络（CNNs-ConvNets）" class="headerlink" title="卷积神经网络（CNNs/ConvNets）"></a>卷积神经网络（CNNs/ConvNets）</h3><p>卷积神经网络和上一章讲的常规神经网络非常相似：</p><ul><li>它们都是由<code>神经元</code>组成,神经元中有具有学习能力的权重和偏差.每个神经元都得到一些<strong>输入数据</strong>,进行<strong>内积</strong>运算后再进行<strong>激活函数</strong>运算.</li><li>整个网络依旧是一个可导的评分函数：该函数的输入是原始的图像像素，输出是不同类别的评分.</li><li>在最后一层（往往是全连接层），网络依旧有一个损失函数（比如SVM或Softmax），并且在神经网络中我们实现的各种技巧和要点依旧适用于卷积神经网络.</li></ul><p>那么有哪些地方<code>变化</code>了呢？卷积神经网络的结构基于一个假设，即输入数据是图像，基于该假设，我们就向结构中添加了一些<code>特有的性质</code>.这些特有属性使得前向传播函数实现起来更高效，并且大幅度降低了网络中参数的数量.</p><h3 id="结构概述"><a href="#结构概述" class="headerlink" title="结构概述"></a>结构概述</h3><ul><li>回顾：常规神经网络.</li></ul><p>​    在上一章中，神经网络的输入是一个向量，然后在一系列的<code>隐层</code>中对它做变换.每个隐层都是由若干的神经元组成，每个神经元都与前一层中的所有神经元连接.但是在一个隐层中，神经元相互独立不进行任何连接.最后的全连接层被称为“<code>输出层</code>”，在分类问题中，它输出的值被看做是<code>不同类别的评分值</code>.</p><ul><li><p>常规神经网络对于大尺寸图像效果不尽人意.</p><p>在CIFAR-10中，图像的尺寸是32x32x3（宽高均为32像素，3个颜色通道），因此，对应的的常规神经网络的第一个隐层中，每一个单独的全连接神经元就有32x32x3=3072个权重.这个数量看起来还可以接受，但是很显然这个<code>全连接的结构不适用于更大尺寸的图像</code>.举例说来，一个尺寸为200x200x3的图像，会让神经元包含200x200x3=120,000个权重值.而网络中肯定不止一个神经元，那么参数的量就会快速增加！显而易见，这种<code>全连接方式效率低下，大量的参数也很快会导致网络过拟合</code>.</p></li><li><p>神经元的三维排列.</p><p>卷积神经网络针对输入全部是图像的情况，将结构调整得更加合理，获得了不小的优势.与常规神经网络不同，卷积神经网络的各层中的神经元是3维排列的：<strong>宽度</strong>、<strong>高度</strong>和<strong>深度</strong>（这里的<strong>深度</strong>指的是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度指的是网络的层数）.举个例子，CIFAR-10中的图像是作为卷积神经网络的输入，该数据体的维度是32x32x3（宽度，高度和深度）.我们将看到，层中的神经元将只与前一层中的<code>一小块区域</code>连接，而不是采取全连接方式.对于用来分类CIFAR-10中的图像的卷积网络，其最后的输出层的维度是1x1x10，因为在卷积神经网络结构的最后部分将会把<code>全尺寸的图像</code>压缩为<code>包含分类评分的一个向量</code>，向量是在深度方向排列的.</p></li></ul><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/CNN_图示.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>左边是一个3层的神经网络.右边是一个卷积神经网络，图例中网络将它的神经元都排列成3个维度（宽、高和深度）.<code>卷积神经网络的每一层</code>都将3D的输入数据变化为神经元3D的激活数据并输出.在这个例子中，红色的输入层装的是图像，所以它的宽度和高度就是图像的宽度和高度，它的深度是3（代表了红、绿、蓝3种颜色通道）.</p><hr><blockquote><p>卷积神经网络是由层组成的.每一层都有一个简单的API：用一些含或者不含参数的可导的函数，<code>将输入的3D数据变换为3D的输出数据</code>.</p></blockquote><h3 id="用来构建卷积神经网络的各种层"><a href="#用来构建卷积神经网络的各种层" class="headerlink" title="用来构建卷积神经网络的各种层"></a>用来构建卷积神经网络的各种层</h3><p>一个简单的卷积神经网络是<code>由各种层按照顺序排列组成</code>，网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层.卷积神经网络主要由三种类型的层构成：<strong>卷积(Convolutional)层</strong>，<strong>汇聚(Pooling)层</strong>和<strong>全连接(Full-Connected)层</strong>（全连接层和常规神经网络中的一样）.通过将这些层叠加起来，就可以构建一个完整的卷积神经网络.</p><p><em>网络结构例子：</em>这仅仅是个概述，下面会更详解的介绍细节.一个用于CIFAR-10图像数据分类的卷积神经网络的结构可以是<code>[输入层-卷积层-ReLU层-汇聚层-全连接层]</code>.细节如下：</p><ul><li>输入[32x32x3]存有图像的原始像素值，本例中图像宽高均为32，有3个颜色通道.</li><li>卷积层中，神经元与输入层中的一个<code>局部区域</code>相连，每个神经元都计算自己与输入层相连的小区域与自己权重的内积.卷积层会计算所有神经元的输出.如果我们使用12个滤波器（也叫作核），得到的输出数据体的维度就是[32x32x12].</li><li>ReLU层将会逐个元素地进行<code>激活函数</code>操作,比如使用以0为阈值的$max(0,x)$作为激活函数.该层对数据尺寸没有改变,还是[32x32x12].</li><li>汇聚层在在空间维度（宽度和高度）上进行<code>降采样（downsampling）</code>操作，数据尺寸变为[16x16x12].</li><li>全连接层将会<code>计算分类评分</code>，数据尺寸变为[1x1x10]，其中10个数字对应的就是CIFAR-10中10个类别的分类评分值.正如其名，全连接层与常规神经网络一样，其中每个神经元都与前一层中所有神经元相连接.</li></ul><p>由此看来，<code>卷积神经网络一层一层地将图像从原始像素值变换成最终的分类评分值</code>.其中有的层含有参数，有的没有.具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）.而ReLU层和汇聚层则是进行一个固定不变的函数操作.卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了.</p><p><strong>小结</strong>：</p><ul><li>简单案例中卷积神经网络的结构，就是一系列的层将输入数据变换为输出数据（比如分类评分）.</li><li>卷积神经网络结构中有几种不同类型的层（目前最流行的有卷积层、全连接层、ReLU层和汇聚层）.</li><li>每个层的输入是3D数据，然后使用一个可导的函数将其变换为3D的输出数据.</li><li>有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）.</li><li>有的层有额外的超参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）.</li></ul><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/激活输出例子.jpg" alt="卷积神经网络的激活输出例子" title="">                </div>                <div class="image-caption">卷积神经网络的激活输出例子</div>            </figure><p>左边的输入层存有原始图像像素，右边的输出层存有类别分类评分.在处理流程中的每个激活数据体是铺成一列来展示的.因为对3D数据作图比较困难，我们就把每个数据体切成层，然后铺成一列显示.最后一层装的是针对不同类别的分类得分，这里只显示了得分最高的5个评分值和对应的类别.完整的<a href="http://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/" target="_blank" rel="noopener">网页演示</a>在我们的课程主页.本例中的结构是一个小的VGG网络，VGG网络后面会有讨论.</p><hr><p>现在讲解不同的层，层的超参数和连接情况的细节.</p><h4 id="卷积层-Convolutional-Layer"><a href="#卷积层-Convolutional-Layer" class="headerlink" title="卷积层 Convolutional Layer"></a>卷积层 Convolutional Layer</h4><p>卷积层是构建卷积神经网络的核心层，它<code>产生了网络中大部分的计算量</code>.</p><p><strong>概述和直观介绍</strong>：首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么.卷积层的参数是有一些可学习的滤波器集合构成的.每个滤波器在空间上（宽度和高度）都比较小，但是<code>深度和输入数据一致</code>.举例来说，卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3（宽高都是5像素，深度是3是因为图像应为颜色通道，所以有3的深度）.在<code>前向传播</code>的时候，让每个滤波器都在输入数据的宽度和高度上<code>滑动</code>（更精确地说是卷积），然后计算整个滤波器和输入数据任一处的<code>内积</code>.当滤波器沿着输入数据的宽度和高度滑过后，会生成一个2维的激活图（activation map），激活图给出了在每个空间位置处滤波器的反应.直观地来说，<code>网络会让滤波器学习到当它看到某些类型的视觉特征时就激活</code>，具体的视觉特征可能是某些方位上的边界，或者在第一层上某些颜色的斑点，甚至可以是网络更高层上的蜂巢状或者车轮状图案.</p><p>在每个卷积层上，我们会有一整个集合的滤波器（比如12个），每个都会生成一个不同的二维激活图.将这些激活映射在深度方向上<code>层叠</code>起来就生成了输出数据.</p><p><strong>以大脑做比喻</strong>：如果你喜欢用大脑和生物神经元来做比喻，那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出，而该神经元<code>只观察输入数据中的一小部分</code>，并且和空间上左右两边的所有神经元<code>共享参数</code>（因为这些数字都是使用同一个滤波器得到的结果）.现在开始讨论神经元的连接，它们在空间中的排列，以及它们参数共享的模式.</p><p><strong>局部连接</strong>：在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的.相反，我们让每个神经元只与输入数据的一个<code>局部区域连接</code>.该连接的空间大小叫做神经元的<strong>感受野（receptive field）</strong>，它的尺寸是一个<code>超参数</code>（其实就是滤波器的空间尺寸）.在深度方向上，这个连接的大小总是和输入量的深度相等.需要再次强调的是，我们对待空间维度（宽和高）与深度维度是不同的：<code>连接在空间（宽高）上是局部的，但是在深度上总是和输入数据的深度一致</code>.</p><p><em>例1</em>：假设输入数据体尺寸为[32x32x3]（比如CIFAR-10的RGB图像），如果感受野（或滤波器尺寸）是5x5，那么卷积层中的每个神经元会有输入数据体中[5x5x3]区域的权重，共5x5x3=75个权重（还要加一个偏差参数）.注意这个连接在深度维度上的大小必须为3，和输入数据体的深度一致.</p><p><em>例2</em>：假设输入数据体的尺寸是[16x16x20]，感受野尺寸是3x3，那么卷积层中每个神经元和输入数据体就有3x3x20=180个连接.再次提示：在空间上连接是局部的（3x3），但是在深度上是和输入数据体一致的（20）.</p><p><img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/0.jpg" alt=""><strong>左边</strong>：红色的是输入数据体（比如CIFAR-10中的图像），蓝色的部分是第一个卷积层中的神经元.卷积层中的每个神经元都只是与输入数据体的一个局部在空间上相连，但是与输入数据体的所有深度维度全部相连（所有颜色通道）.在深度方向上有多个神经元（本例中5个），它们都接受输入数据的同一块区域（<code>感受野相同</code>）.至于深度列的讨论在下文中有.</p><p><strong>右边</strong>：神经网络章节中介绍的神经元保持不变，它们还是计算权重和输入的内积，然后进行激活函数运算，只是它们的连接被限制在一个局部空间.</p><hr><p><strong>空间排列</strong>：上文讲解了卷积层中每个神经元与输入数据体之间的连接方式，但是尚未讨论<code>输出数据体</code>中神经元的<code>数量</code>，以及它们的<code>排列方式</code>.3个超参数控制着输出数据体的尺寸：<strong>深度（depth），步长（stride）</strong>和<strong>零填充（zero-padding）</strong>.下面是对它们的讨论：</p><ol><li>首先，<code>输出数据体的深度是一个超参数：它和使用的滤波器的数量一致</code>，而每个滤波器在输入数据中寻找一些不同的东西.举例来说，如果第一个卷积层的输入是原始图像，那么在深度维度上的不同神经元将可能被不同方向的边界，或者是颜色斑点激活.我们将这些<code>沿着深度方向排列</code>、<code>感受野相同</code>的神经元集合称为<strong>深度列（depth column）</strong>，也有人使用纤维（fibre）来称呼它们.</li><li>其次，在滑动滤波器的时候，必须指定<strong>步长</strong>.当步长为1，滤波器每次移动1个像素.当步长为2（或者不常用的3，或者更多，这些在实际中很少使用），滤波器滑动时每次移动2个像素.这个操作会让输出数据体在空间上变小.</li><li>在下文可以看到，有时候将输入数据体用0在<code>边缘</code>处进行填充是很方便的.这个<strong>零填充（zero-padding）</strong>的尺寸是一个超参数.零填充有一个良好性质，即可以控制输出数据体的空间尺寸（最常用的是用来保持输入数据体在空间上的尺寸，这样输入和输出的宽高都相等）.</li></ol><p><code>输出数据体在空间上的尺寸</code>可以通过输入数据体尺寸（$W$），卷积层中神经元的感受野尺寸（$F$），步长（$S$）和零填充的数量（$P$）的函数来计算.（这里假设输入数组的空间形状是正方形，即高度和宽度相等）输出数据体的空间尺寸为<code>(W-F+2P)/S+1</code>.比如输入是7x7，滤波器是3x3，步长为1，填充为0，那么就能得到一个5x5的输出(其中$\frac{7-3+0}{1}+1=5$  ）.如果步长为2，输出就是3x3(其中 $\frac{7-3+0}{2}+1=3$ ).</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/1.jpg" alt="空间排列的图示" title="">                </div>                <div class="image-caption">空间排列的图示</div>            </figure><p>在本例中只有一个空间维度（x轴），神经元的感受野尺寸F=3，输入尺寸W=5，零填充P=1.</p><ul><li><p>左边：神经元使用的步长S=1，所以输出尺寸是(5-3+2)/1+1=5.</p></li><li><p>右边：神经元的步长S=2，则输出尺寸是(5-3+2)/2+1=3.</p></li><li><p>注意当步长S=3时是<code>无法使用</code>的，因为它无法整齐地穿过数据体.从等式上来说，因为(5-3+2)=4是不能被3整除的.</p></li></ul><p>本例中，神经元的权重是[1,0,-1]，显示在图的右上角，偏差值为0.这些权重是被所有黄色的神经元共享的.</p><hr><p><em>使用零填充</em>：在上面左边例子中，注意输入维度是5，输出维度也是5.之所以如此，是因为感受野是3并且使用了1的零填充.如果不使用零填充，则输出数据体的空间维度就只有3，因为这就是滤波器整齐滑过并覆盖原始数据需要的数目.一般说来，当步长$S=1$时，零填充的值是$P=(F-1)/2$，这样就能<code>保证输入和输出数据体有相同的空间尺寸</code>.</p><p><em>步长的限制</em>：注意这些空间排列的<code>超参数之间是相互限制的</code>.举例说来，当输入尺寸$W=10$，不使用零填充则$P=0$，滤波器尺寸$F=3$，这样步长$S=2$就行不通，因为$(W-F+2P)/S+1=(10-3+0)/2+1=4.5$，<code>结果不是整数，这就是说神经元不能整齐对称地滑过输入数据体</code>.因此，这些超参数的设定就被认为是无效的，一个卷积神经网络库可能会报出一个错误，或者修改零填充值来让设置合理，或者修改输入数据体尺寸来让设置合理，或者其他什么措施.在后面的卷积神经网络结构小节中，读者可以看到合理地设置网络的尺寸让所有的维度都能正常工作，这件事可是相当让人头痛的.而使用<code>零填充和遵守其他一些设计策略将会有效解决这个(空间尺寸计算结果不是整数，致使网络库报错)问题</code>.</p><p><em>真实案例</em>：<a href="http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener">Krizhevsky</a>构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3].在第一个卷积层，神经元使用的感受野尺寸$F=11$，步长$S=4$，不使用零填充$P=0$.因为(227-11)/4+1=55，卷积层的深度$K=96$，则卷积层的输出数据体尺寸为[55x55x96].  55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接.在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接，但是权重不同.有一个有趣的细节，在原论文中，说的输入图像尺寸是224x224，这是肯定错误的，因为(224-11)/4+1的结果不是整数.这件事在卷积神经网络的历史上让很多人迷惑，而这个错误到底是怎么发生的没人知道.我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充.</p><p><strong>参数共享</strong>：在卷积层中使用<code>参数共享是用来控制参数的数量</code>.就用上面的例子，在第一个卷积层就有55x55x96=290,400个神经元，每个有11x11x3=364个参数和1个偏差.将这些合起来就是290400x364=105,705,600个参数.单单第一层就有这么多参数，显然这个数目是非常大的.</p><p>作一个合理的假设：<code>如果一个特征在计算某个空间位置(x,y)的时候有用，那么它在计算另一个不同位置(x2,y2)的时候也有用</code>.基于这个假设，可以显著地减少参数数量.换言之，就是将深度维度上一个单独的2维切片看做<strong>深度切片（depth slice）</strong>，比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55].<code>在每个深度切片上的神经元都使用同样的权重和偏差</code>.在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）.在每个深度切片中的55x55个权重使用的都是同样的参数.在反向传播的时候，都要计算每个神经元对它的权重的梯度，但是需要把<code>同一个深度切片上的所有神经元对权重的梯度累加</code>，这样就得到了对<code>共享权重的梯度</code>.这样，<code>每个切片只更新一个权重集</code>.</p><p>注意，如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的<code>前向传播</code>在每个深度切片中可以看做是在计算神经元权重和输入数据体的<strong>卷积</strong>（这就是“卷积层”名字由来）.这也是为什么总是将这些权重集合称为<strong>滤波器（filter）</strong>（或<strong>卷积核（kernel）</strong>），因为它们和输入进行了卷积.</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/Krizhevsky等学习到的滤波器例子.jpg" alt="Krizhevsky等学习到的滤波器例子" title="">                </div>                <div class="image-caption">Krizhevsky等学习到的滤波器例子</div>            </figure><p>这96个滤波器(<code>权重集合</code>)的尺寸都是[11x11x3]，在一个深度切片中，每个滤波器都被55x55个神经元共享.注意参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为<code>图像结构具有平移不变性</code>.所以在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习去探测一个水平边界了.</p><hr><p>注意有时候参数共享假设可能没有意义，特别是当卷积神经网络的输入图像是一些<code>明确的中心结构</code>时候.这时候我们就应该期望<code>在图片的不同位置学习到完全不同的特征</code>.一个具体的例子就是输入图像是人脸，人脸一般都处于图片中心.你可能期望不同的特征，比如眼睛特征或者头发特征可能（也应该）会在图片的不同位置被学习.在这个例子中，通常就<code>放松参数共享的限制</code>，将层称为<strong>局部连接层</strong>（Locally-Connected Layer）.</p><p><strong>Numpy例子</strong>：为了让讨论更加的具体，我们用代码来展示上述思路.假设输入数据体是numpy数组<strong>X</strong>.那么：</p><ul><li>一个位于<strong>(x,y)</strong>的深度列（或纤维）将会是<strong>X[x,y,:]</strong>.</li><li>在深度为<strong>d</strong>处的深度切片，或激活图应该是<strong>X[:,:,d]</strong>.</li></ul><p><em>卷积层例子</em>：假设输入数据体<strong>X</strong>的尺寸<strong>X.shape:(11,11,4)</strong>，不使用零填充($P=0$)，滤波器的尺寸是$F=5$，步长$S=2$.那么输出数据体的空间尺寸就是(11-5)/2+1=4，即输出数据体的宽度和高度都是4.那么在输出数据体中的<code>激活映射</code>（称其为<strong>V</strong>）看起来就是下面这样（在这个例子中，只有部分元素被计算）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- V[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] = np.sum(X[:<span class="number">5</span>,:<span class="number">5</span>,:] * W0) + b0</span><br><span class="line">- V[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>] = np.sum(X[<span class="number">2</span>:<span class="number">7</span>,:<span class="number">5</span>,:] * W0) + b0</span><br><span class="line">- V[<span class="number">2</span>,<span class="number">0</span>,<span class="number">0</span>] = np.sum(X[<span class="number">4</span>:<span class="number">9</span>,:<span class="number">5</span>,:] * W0) + b0</span><br><span class="line">- V[<span class="number">3</span>,<span class="number">0</span>,<span class="number">0</span>] = np.sum(X[<span class="number">6</span>:<span class="number">11</span>,:<span class="number">5</span>,:] * W0) + b0</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在numpy中，<strong>*</strong>操作是进行数组间的<code>逐元素相乘</code>.权重向量<strong>W0</strong>是该神经元的权重，<strong>b0</strong>是其偏差.在这里，<strong>W0</strong>被假设尺寸是<strong>W0.shape: (5,5,4)</strong>，因为滤波器的宽高是5，输入数据量的深度是4.注意在每一个点，计算点积的方式和之前的常规神经网络是一样的.同时，计算内积的时候使用的是同一个权重和偏差（因为参数共享），在宽度方向的数字每次上升2（因为步长为2）.要构建输出数据体中的<code>第二张激活图</code>，代码应该是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- V[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>] = np.sum(X[:<span class="number">5</span>,:<span class="number">5</span>,:] * W1) + b1</span><br><span class="line">- V[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>] = np.sum(X[<span class="number">2</span>:<span class="number">7</span>,:<span class="number">5</span>,:] * W1) + b1</span><br><span class="line">- V[<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>] = np.sum(X[<span class="number">4</span>:<span class="number">9</span>,:<span class="number">5</span>,:] * W1) + b1</span><br><span class="line">- V[<span class="number">3</span>,<span class="number">0</span>,<span class="number">1</span>] = np.sum(X[<span class="number">6</span>:<span class="number">11</span>,:<span class="number">5</span>,:] * W1) + b1</span><br><span class="line">- V[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>] = np.sum(X[:<span class="number">5</span>,<span class="number">2</span>:<span class="number">7</span>,:] * W1) + b1 （在y方向上）</span><br><span class="line">- V[<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>] = np.sum(X[<span class="number">4</span>:<span class="number">9</span>,<span class="number">6</span>:<span class="number">11</span>,:] * W1) + b1 （或两个方向上同时）</span><br><span class="line">....</span><br></pre></td></tr></table></figure><p>我们访问的是<strong>V</strong>的深度维度上的第二层（即index1），因为是在计算第二个激活图，所以这次试用的参数集就是<strong>W1</strong>了.在上面的例子中，为了简洁,略去了卷积层对于输出数组<strong>V</strong>中其他部分的操作.还有，要记得这些卷积操作通常后面接的是ReLU层，<code>对激活图中的每个元素做激活函数运算，这里没有显示</code>.</p><p><strong>小结</strong>： 我们总结一下卷积层的性质：</p><ul><li>输入数据体的尺寸为$W_1\times H_1\times D_1$</li><li><p>4个超参数：</p><ul><li>滤波器的数量$K$</li><li>滤波器的空间尺寸$F$</li><li>步长$S$</li><li>零填充数量$P$</li></ul></li><li><p>输出数据体的尺寸为$W_2\times H_2\times D_2$ ，其中：</p><ul><li>$W_2=(W_1-F+2P)/S+1$   (W–width H–height)</li><li>$H_2=(H_1-F+2P)/S+1$ （宽度和高度的计算方法相同）</li><li>$D_2=K$</li></ul></li><li><p>由于参数共享，每个滤波器包含$F\cdot F\cdot D_1$个权重，卷积层一共有$F\cdot F\cdot D_1\cdot K$个权重和$K$个偏置. (k为滤波器的数目)</p></li><li>在输出数据体中，第$d$个深度切片（空间尺寸是$W_2\times H_2$），用第$d$个滤波器和输入数据进行有效卷积运算的结果（使用步长$S$），最后在加上第$d$个偏差.</li></ul><p>对这些超参数，常见的设置是$F=3$，$S=1$，$P=1$.同时设置这些超参数也有一些约定俗成的惯例和经验，可以在下面的卷积神经网络结构章节中查看.</p><p>卷积层演示：下面是一个卷积层的运行演示.因为3D数据难以可视化，所以所有的数据（输入数据体是蓝色，权重数据体是红色，输出数据体是绿色）都采取将深度切片按照列的方式排列展现.输入数据体的尺寸是$W_1=5,H_1=5,D_1=3$，卷积层参数$K=2,F=3,S=2,P=1$.就是说，有2个滤波器，滤波器的尺寸是$3\cdot 3$，它们的步长是2.因此，输出数据体的空间尺寸是(5-3+2)/2+1=3.注意输入数据体使用了零填充$P=1$，所以输入数据体外边缘一圈都是0.下面的例子在绿色的输出激活数据上循环演示，展示了其中每个元素都是先通过蓝色的输入数据和红色的滤波器逐元素相乘，然后求其总和，最后加上偏差得来.</p><hr><p><a href="/demo/Convolution demo.webarchive">Convolution demo.webarchive</a></p><hr><p><strong>用矩阵乘法实现</strong>：卷积运算本质上就是在滤波器和输入数据的局部区域间做<code>点积</code>.卷积层的常用实现方式就是利用这一点，将卷积层的前向传播变成一个巨大的矩阵乘法：</p><ol><li>输入图像的局部区域被<strong>im2col</strong>操作拉伸为列.比如，如果输入是[227x227x3]，要与尺寸为11x11x3的滤波器以步长为4进行卷积，就取输入中的[11x11x3]数据块，然后将其拉伸为长度为11x11x3=363的<strong>列向量</strong>.重复进行这一过程，因为步长为4，所以输出的宽高为(227-11)/4+1=55，所以得到im2col操作的输出矩阵<strong>X_col</strong>的尺寸是<code>[363x3025]</code>，其中每列是拉伸的感受野，共有55x55=3,025个.注意因为感受野之间有<strong>重叠</strong>，所以输入数据体中的数字在不同的列中可能有重复.</li><li>卷积层的权重也同样被拉伸成<strong>行</strong>.举例，如果有96个尺寸为[11x11x3]的滤波器，就生成一个矩阵<strong>W_row</strong>，尺寸为<code>[96x363]</code>.</li><li>现在卷积的结果和进行一个大矩阵乘<strong>np.dot(W_row, X_col)</strong>是等价的了，能得到每个滤波器和每个感受野间的点积.在我们的例子中，这个操作的输出是<code>[96x3025]</code>，给出了<code>每个滤波器在每个位置的点积输出</code>.</li><li>结果最后必须被重新变为合理的输出尺寸<code>[55x55x96]</code>.</li></ol><p>这个方法的缺点就是占用内存太多，因为在输入数据体中的某些值在<strong>X_col</strong>中被复制了多次.但是，其优点是矩阵乘法有非常多的高效实现方式，我们都可以使用（比如常用的<a href="http://link.zhihu.com/?target=http%3A//www.netlib.org/blas/" target="_blank" rel="noopener">BLAS</a> API）.还有，同样的<em>im2col</em>思路可以用在汇聚操作中.</p><p>反向传播：卷积操作的反向传播（同时对于数据和权重）还是一个卷积（但是是和空间上翻转的滤波器）.使用一个1维的例子比较容易演示.</p><p><strong>1x1卷积</strong>：一些论文中使用了1x1的卷积，这个方法最早是在论文<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1312.4400" target="_blank" rel="noopener">Network in Network</a>中出现.人们刚开始看见这个1x1卷积的时候比较困惑，尤其是那些具有信号处理专业背景的人.因为信号是2维的，所以1x1卷积就没有意义.但是，在卷积神经网络中不是这样，因为这里是对3个维度进行操作，滤波器和输入数据体的深度是一样的.比如，如果输入是[32x32x3]，那么1x1卷积就是在高效地进行3维点积（因为输入深度是3个通道）.</p><p><strong>扩张卷积</strong>：最近一个研究（<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.07122" target="_blank" rel="noopener">Fisher Yu和Vladlen Koltun的论文</a>）给卷积层引入了一个新的叫<em>扩张（dilation）</em>的超参数.到目前为止，我们只讨论了卷积层滤波器是连续的情况.但是，让滤波器中元素之间有间隙也是可以的，这就叫做扩张.举例，在某个维度上滤波器<strong>w</strong>的尺寸是3，那么计算输入<strong>x</strong>的方式是：<strong>w[0]*x[0] + w[1]*x[1] + w[2]*x[2]</strong>，此时扩张为0.如果扩张为1，那么计算为： <strong>w[0]*x[0] + w[1]*x[2] + w[2]*x[4]</strong>.换句话说，操作中存在1的间隙.在某些设置中，扩张卷积与正常卷积结合起来非常有用，因为在很少的层数内更快地汇集输入图片的大尺度特征.比如，如果上下重叠2个3x3的卷积层，那么第二个卷积层的神经元的感受野是输入数据体中5x5的区域（可以成这些神经元的<em>有效感受野</em>是5x5）.如果我们对卷积进行扩张，那么这个有效感受野就会迅速增长.</p><h4 id="汇聚层-Pooling-Layer"><a href="#汇聚层-Pooling-Layer" class="headerlink" title="汇聚层 Pooling Layer"></a>汇聚层 Pooling Layer</h4><p>通常，在连续的卷积层之间会<code>周期性</code>地插入一个汇聚层.它的作用是<code>逐渐降低数据体的空间尺寸</code>，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也能有效控制过拟合.汇聚层使用MAX操作，对输入数据体的每一个深度切片独立进行操作，改变它的空间尺寸.最常见的形式是汇聚层使用尺寸2x2的滤波器，以步长为2来对每个深度切片进行<code>降采样</code>，将其中75%的激活信息都丢掉.每个MAX操作是从4个数字中取最大值（也就是在深度切片中某个2x2的区域）.深度保持不变.汇聚层的一些公式：</p><ul><li>输入数据体尺寸$W_1\cdot H_1\cdot D_1$</li><li>有两个超参数：</li><li><ul><li>空间大小$F$</li><li>步长$S$</li></ul></li><li><p>输出数据体尺寸$W_2\cdot H_2\cdot D_2$，其中</p><ul><li>$ W_2=(W_1-F)/S+1$</li><li>$H_2=(H_1-F)/S+1$</li><li>$D_2=D_1$</li></ul></li><li><p>因为对输入进行的是固定函数计算，所以没有引入参数</p></li><li>在汇聚层中很少使用零填充</li></ul><p>在实践中，最大汇聚层通常只有两种形式：一种是$F=3,S=2$，也叫重叠汇聚（overlapping pooling），另一个更常用的是$F=2,S=2$.对更大感受野进行汇聚需要的汇聚尺寸也更大，而且往往对网络有破坏性.</p><p><strong>普通汇聚（General Pooling）</strong>：除了最大汇聚，汇聚单元还可以使用其他的函数，比如平均汇聚（average pooling）或L-2范式汇聚（L2-norm pooling）.平均汇聚历史上比较常用，但是现在已经很少使用了.因为实践证明，<code>最大汇聚的效果比平均汇聚要好</code>.</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/27/Lecture-Convolutional-Neural-Networks/2.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>汇聚层在输入数据体的每个深度切片上，独立地对其进行空间上的降采样.</p><ul><li>左边：本例中，输入数据体尺寸[224x224x64]被降采样到了[112x112x64]，采取的滤波器尺寸是2，步长为2，而深度不变((224-2+0)/2+1=112).</li><li>右边：最常用的降采样操作是取最大值，也就是<code>最大汇聚</code>，这里步长为2，每个取最大值操作是从4个数字中选取（即2x2的方块区域中）.</li></ul><hr><p><strong>反向传播：</strong>回顾一下反向传播的内容，其中$max(x,y)$函数的反向传播可以简单理解为将梯度只<code>沿最大的数回传</code>.因此，在向前传播经过汇聚层的时候，通常会把池中最大元素的<code>索引</code>记录下来（有时这个也叫作<strong>道岔（switches）</strong>），这样在反向传播的时候梯度的路由就很高效.</p><p><strong>不使用汇聚层</strong>：很多人不喜欢汇聚操作，认为可以不使用它.比如在<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.6806" target="_blank" rel="noopener">Striving for Simplicity: The All Convolutional Net</a>一文中，提出使用一种只有重复的卷积层组成的结构，抛弃汇聚层.通过在卷积层中使用<code>更大的步长来降低数据体的尺寸</code>.有发现认为，在训练一个良好的生成模型时，<code>弃用汇聚层</code>也是很重要的.比如变化自编码器（VAEs：variational autoencoders）和生成性对抗网络（GANs：generative adversarial networks）.现在看起来，未来的卷积网络结构中，可能会很少使用甚至不使用汇聚层.</p><h4 id="归一化层-Normalization-Layer"><a href="#归一化层-Normalization-Layer" class="headerlink" title="归一化层 Normalization Layer"></a>归一化层 Normalization Layer</h4><p>在卷积神经网络的结构中，提出了很多不同类型的归一化层，有时候是为了实现在生物大脑中观测到的抑制机制.但是这些层渐渐都不再流行，因为实践证明它们的效果即使存在，也是极其有限的.对于不同类型的归一化层，可以看看Alex Krizhevsky的关于<a href="http://link.zhihu.com/?target=https%3A//code.google.com/p/cuda-convnet/wiki/LayerParams%23Local_response_normalization_layer_%28same_map%29" target="_blank" rel="noopener">cuda-convnet library API</a>的讨论.</p><h4 id="全连接层-Full-Connected-Layer"><a href="#全连接层-Full-Connected-Layer" class="headerlink" title="全连接层 Full-Connected Layer"></a>全连接层 Full-Connected Layer</h4><p>在全连接层中，神经元对于前一层中的所有激活数据是全部连接的，这个常规神经网络中一样.它们的激活可以先用矩阵乘法，再加上偏差.更多细节请查看<em>神经网络</em>章节.</p><h4 id="将全连接层转化成卷积层"><a href="#将全连接层转化成卷积层" class="headerlink" title="将全连接层转化成卷积层"></a>将全连接层转化成卷积层</h4><p><u>全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数</u>.然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的.因此，将此两者<code>相互转化</code>是可能的：</p><ul><li>对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层.权重矩阵是一个巨大的矩阵，除了某些特定块（这是因为有局部连接），其余部分都是零.而在其中大部分块中，元素都是相等的（因为参数共享）.</li><li>相反，任何全连接层都可以被转化为卷积层.比如，一个$K=4096$的全连接层，输入数据体的尺寸是$7\times 7\times 512$，这个全连接层可以被等效地看做一个$F=7,P=0,S=1,K=4096$的卷积层.换句话说，就是<code>将滤波器的尺寸设置为和输入数据体的尺寸一致</code>了.因为只有一个单独的深度列覆盖并滑过输入数据体，所以输出将变成$1\times 1\times 4096$，这个结果就和使用初始的那个全连接层一样了.</li></ul><p><strong>全连接层转化为卷积层</strong>：在两种变换中，将全连接层转化为卷积层在实际运用中更加有用.假设一个卷积神经网络的输入是224x224x3的图像，一系列的卷积层和汇聚层将图像数据变为尺寸为7x7x512的激活数据体（在AlexNet中就是这样，通过使用5个汇聚层来对输入数据进行空间上的降采样，每次尺寸下降一半，所以最终空间尺寸为224/2/2/2/2/2=7）.从这里可以看到，AlexNet使用了两个尺寸为4096的全连接层，最后一个有1000个神经元的全连接层用于计算分类评分.我们可以<code>将这3个全连接层中的任意一个转化为卷积层</code>：</p><ul><li>针对第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为$F=7$，这样输出数据体就为[1x1x4096]了.</li><li>针对第二个全连接层，令其滤波器尺寸为$F=1$，这样输出数据体为[1x1x4096].</li><li>对最后一个全连接层也做类似的，令其$F=1$，最终输出为[1x1x1000]</li></ul><p>实际操作中，每次这样的变换都需要把全连接层的权重W重塑成卷积层的滤波器.那么这样的转化有什么作用呢？它在下面的情况下可以更高效：让卷积网络在一张更大的输入图片上滑动（即把一张更大的图片的不同区域都分别带入到卷积网络，得到每个区域的得分），得到多个输出，这样的转化可以让我们在单个向前传播的过程中完成上述的操作.</p><p>举个例子，如果我们想让224x224尺寸的浮窗，以步长为32在384x384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6x6个位置的类别得分.上述的把全连接层转换成卷积层的做法会更简便.如果224x224的输入图片<u>经过卷积层和汇聚层之后</u>得到了[7x7x512]的数组（因为途径5个汇聚层，尺寸变为224/2/2/2/2/2 = 7），那么，384x384的大图片直接经过同样的卷积层和汇聚层之后会得到[12x12x512]的数组（因为途径5个汇聚层，尺寸变为384/2/2/2/2/2 = 12）.然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出（因为(12 - 7)/1 + 1 = 6）.这个结果正是浮窗在原图经停的6x6个位置的得分！</p><blockquote><p>面对384x384的图像，让（含全连接层）的初始卷积神经网络以32像素的步长独立对图像中的224x224块进行<code>多次评价</code>，其效果和使用把全连接层变换为卷积层后的卷积神经网络进行<code>一次</code>前向传播是一样的.</p></blockquote><p>自然，相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为36次计算都在共享计算资源.这一技巧在实践中经常使用，<code>一次来获得更好的结果</code>.比如，通常将一张图像尺寸变得更大，然后使用<strong>变换后</strong>的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值.(多加思考)</p><p>最后，如果我们想用步长小于32的浮窗怎么办？用多次的向前传播就可以解决.比如我们想用步长为16的浮窗.那么先使用原图在转化后的卷积网络执行向前传播，然后分别沿宽度，沿高度，最后同时沿宽度和高度，把原始图片分别平移16个像素，然后把这些平移之后的图分别带入卷积网络.</p><ul><li><a href="http://link.zhihu.com/?target=https%3A//github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb" target="_blank" rel="noopener">Net Surgery</a>上一个使用Caffe演示如何在进行变换的IPython Note教程.</li></ul><h3 id="卷积神经网络的结构"><a href="#卷积神经网络的结构" class="headerlink" title="卷积神经网络的结构"></a>卷积神经网络的结构</h3><p>卷积神经网络通常是由三种层构成：卷积层，汇聚层（除非特别说明，一般就是最大值汇聚）和全连接层（简称FC）.ReLU激活函数也应该算是是一层，它逐元素地进行激活函数操作.在本节中将讨论在卷积神经网络中这些层通常是如何组合在一起的.</p><h4 id="层的排列规律"><a href="#层的排列规律" class="headerlink" title="层的排列规律"></a>层的排列规律</h4><p>卷积神经网络最常见的形式就是将一些卷积层和ReLU层放在一起，其后紧跟汇聚层，然后重复如此直到图像在空间上被缩小到一个足够小的尺寸，在某个地方过渡成全连接层也较为常见.最后的全连接层得到输出，比如分类评分等.换句话说，最常见的卷积神经网络结构如下：</p><p><strong>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</strong></p><p>其中<strong>*</strong>指的是重复次数，<strong>POOL?</strong>指的是一个可选的汇聚层.其中<strong>N &gt;=0</strong>,通常<strong>N&lt;=3</strong>,<strong>M&gt;=0</strong>,<strong>K&gt;=0</strong>,通常<strong>K&lt;3</strong>.例如，下面是一些常见的网络结构规律：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- INPUT -&gt; FC,实现一个线性分类器，此处N = M = K = 0.</span><br><span class="line">- INPUT -&gt; CONV -&gt; RELU -&gt; FC</span><br><span class="line">- INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; FC.此处在每个汇聚层前有一个卷积层.</span><br><span class="line">- INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC.此处每个汇聚层前有两个卷积层，这个思路适用于更大更深的网络，因为在执行具有破坏性的汇聚操作前，多重的卷积层可以从输入数据中学习到更多的复杂特征.</span><br></pre></td></tr></table></figure><p><code>几个小滤波器卷积层的组合比一个大滤波器卷积层好</code>：假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）.在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野.第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野.同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，也就是对输入数据体有7x7的视野.假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点.首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构<code>更能提取出深层的更好的特征</code>.其次，假设所有的数据有$C$个通道，那么单独的7x7卷积层将会包含$C\times (7\times 7\times C)=49C^2$个参数，而3个3x3的卷积层的组合仅有$3\times (C\times (3\times 3\times C))=27C^2$个参数.直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层.前者可以表达出输入数据中更多个强力特征，使用的参数也更少.<code>唯一的不足</code>是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存.</p><p>最新进展：传统的将层按照线性进行排列的方法已经受到了挑战，挑战来自谷歌的Inception结构和微软亚洲研究院的残差网络（Residual Net）结构.这两个网络（下文案例学习小节中有细节）的特征更加复杂，连接结构也不同.</p><h4 id="层的尺寸设置规律"><a href="#层的尺寸设置规律" class="headerlink" title="层的尺寸设置规律"></a>层的尺寸设置规律</h4><p>到现在为止，我们都没有提及卷积神经网络中每层的超参数的使用.现在先介绍设置结构尺寸的一般性规则，然后根据这些规则进行讨论：</p><p><strong>输入层</strong>（包含图像的）应该能被2整除很多次.常用数字包括32（比如CIFAR-10），64，96（比如STL-10）或224（比如ImageNet卷积神经网络），384和512.</p><p><strong>卷积层</strong>应该使用小尺寸滤波器（比如3x3或最多5x5），使用步长$S=1$.还有一点非常重要，就是对输入数据进行<code>零填充</code>，这样卷积层就不会改变输入数据在空间维度上的尺寸.比如，当$F=3$，那就使用$P=1$来保持输入尺寸.当$F=5,P=2$，一般对于任意$F$，当$P=(F-1)/2$的时候能保持输入尺寸.如果必须使用更大的滤波器尺寸（比如7x7之类），通常只用在第一个面对原始图像的卷积层上.</p><p><strong>汇聚层</strong>负责对输入数据的空间维度进行<code>降采样</code>.最常用的设置是用用2x2感受野（即$F=2$）的<code>最大值汇聚</code>，步长为2（$S=2$）.注意这一操作将会把输入数据中75%的激活数据丢弃（因为对宽度和高度都进行了2的降采样）.另一个不那么常用的设置是使用3x3的感受野，步长为2.最大值汇聚的感受野尺寸很少有超过3的，因为汇聚操作过于激烈，易造成数据信息丢失，这通常会导致算法性能变差.</p><p><em>减少尺寸设置的问题</em>：上文中展示的两种设置是很好的，因为所有的卷积层都能保持其输入数据的空间尺寸，汇聚层只负责对数据体从空间维度进行降采样.如果使用的步长大于1并且不对卷积层的输入数据使用零填充，那么就必须非常仔细地监督输入数据体通过整个卷积神经网络结构的过程，确认所有的步长和滤波器都尺寸互相吻合，卷积神经网络的结构美妙对称地联系在一起.</p><p><em>为什么在卷积层使用1的步长</em>？在实际应用中，更小的步长效果更好.上文也已经提过，步长为1可以让空间维度的降采样全部由汇聚层负责，卷积层只负责对输入数据体的深度进行变换.</p><p><em>为何使用零填充</em>？使用零填充除了前面提到的可以让卷积层的输出数据保持和输入数据在空间维度的不变，还可以提高算法性能.如果卷积层值进行卷积而不进行零填充，那么数据体的尺寸就会略微减小，那么图像边缘的信息就会过快地损失掉.</p><p><em>因为内存限制所做的妥协</em>：在某些案例（尤其是早期的卷积神经网络结构）中，基于前面的各种规则，内存的使用量迅速飙升.例如，使用64个尺寸为3x3的滤波器对224x224x3的图像进行卷积，零填充为1，得到的激活数据体尺寸是[224x224x64].这个数量就是一千万的激活数据，或者就是72MB的内存（每张图就是这么多，激活函数和梯度都是）.因为GPU通常因为内存导致性能瓶颈，所以做出一些妥协是必须的.在实践中，人们<code>倾向于在网络的第一个卷积层做出妥协</code>.例如，可以妥协可能是在第一个卷积层使用步长为2，尺寸为7x7的滤波器（比如在ZFnet中）.在AlexNet中，滤波器的尺寸的11x11，步长为4.</p><h4 id="案例学习（LeNet-AlexNet-ZFNet-GoogLeNet-VGGNet）"><a href="#案例学习（LeNet-AlexNet-ZFNet-GoogLeNet-VGGNet）" class="headerlink" title="案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）"></a>案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）</h4><p>下面是卷积神经网络领域中比较有名的几种结构：</p><ul><li><strong>LeNet</strong>： 第一个成功的卷积神经网络应用，是Yann LeCun在上世纪90年代实现的.当然，最著名还是被应用在识别数字和邮政编码等的<a href="http://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="noopener">LeNet</a>结构.</li><li><strong>AlexNet</strong>：<a href="http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener">AlexNet</a>卷积神经网络在计算机视觉领域中受到欢迎，它由Alex Krizhevsky，Ilya Sutskever和Geoff Hinton实现.AlexNet在2012年的<a href="http://link.zhihu.com/?target=http%3A//www.image-net.org/challenges/LSVRC/2014/" target="_blank" rel="noopener">ImageNet ILSVRC 竞赛</a>中夺冠，性能远远超出第二名（16%的top5错误率，第二名是26%的top5错误率）.这个网络的结构和LeNet非常类似，但是更深更大，并且使用了层叠的卷积层来获取特征（之前通常是只用一个卷积层并且在其后马上跟着一个汇聚层）.</li><li><strong>ZF Net</strong>：Matthew Zeiler和Rob Fergus发明的网络在ILSVRC 2013比赛中夺冠，它被称为 <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1311.2901" target="_blank" rel="noopener">ZFNet</a>（Zeiler &amp; Fergus Net的简称）.它通过修改结构中的超参数来实现对AlexNet的改良，具体说来就是增加了中间卷积层的尺寸，让第一层的步长和滤波器尺寸更小.</li><li><strong>GoogLeNet</strong>：ILSVRC 2014的胜利者是谷歌的<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szeged等</a>实现的卷积神经网络.它主要的贡献就是实现了一个<em>奠基模块</em>，它能够显著地减少网络中参数的数量（AlexNet中有60M，该网络中只有4M）.还有，这个论文中没有使用卷积神经网络顶部使用全连接层，而是使用了一个平均汇聚，把大量不是很重要的参数都去除掉了.GooLeNet还有几种改进的版本，最新的一个是<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1602.07261" target="_blank" rel="noopener">Inception-v4</a>.</li><li><strong>VGGNet</strong>：ILSVRC 2014的第二名是Karen Simonyan和 Andrew Zisserman实现的卷积神经网络，现在称其为<a href="http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/" target="_blank" rel="noopener">VGGNet</a>.它主要的贡献是<code>展示出网络的深度是算法优良性能的关键部分</code>.他们最好的网络包含了16个卷积/全连接层.网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的汇聚.他们的<a href="http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/" target="_blank" rel="noopener">预训练模型</a>是可以在网络上获得并在Caffe中使用的.VGGNet不好的一点是它耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）.其中绝大多数的参数都是来自于第一个全连接层.后来发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量.</li><li><strong>ResNet</strong>：<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1512.03385" target="_blank" rel="noopener">残差网络</a>（Residual Network）是ILSVRC2015的胜利者，由何恺明等实现.它使用了特殊的<em>跳跃链接</em>，大量使用了<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03167" target="_blank" rel="noopener">批量归一化</a>（batch normalization）.这个结构同样在最后没有使用全连接层.读者可以查看何恺明的的演讲（<a href="http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks" target="_blank" rel="noopener">视频</a>，<a href="http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks" target="_blank" rel="noopener">PPT</a>），以及一些使用Torch重现网络的<a href="http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks" target="_blank" rel="noopener">实验</a>.ResNet当前最好的卷积神经网络模型（2016年五月）.何开明等最近的工作是对原始结构做一些优化，可以看论文<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a>，2016年3月发表.</li></ul><p><strong>VGGNet的细节：</strong>我们进一步对<a href="http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/" target="_blank" rel="noopener">VGGNet</a>的细节进行分析学习.整个VGGNet中的卷积层都是以步长为1进行3x3的卷积，使用了1的零填充，汇聚层都是以步长为2进行了2x2的最大值汇聚.可以写出处理过程中每一步数据体尺寸的变化，然后对数据尺寸和整体权重的数量进行查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864</span><br><span class="line">POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456</span><br><span class="line">POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824</span><br><span class="line">POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216</span><br><span class="line">FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000</span><br><span class="line"></span><br><span class="line">TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)</span><br><span class="line">TOTAL params: 138M parameters</span><br></pre></td></tr></table></figure><p>注意，大部分的内存和计算时间都被前面的卷积层占用，大部分的参数都用在后面的全连接层，这在卷积神经网络中是比较常见的.在这个例子中，全部参数有140M，但第一个全连接层就包含了100M的参数.</p><h4 id="计算上的考量"><a href="#计算上的考量" class="headerlink" title="计算上的考量"></a>计算上的考量</h4><p>在构建卷积神经网络结构时，最大的瓶颈是<code>内存瓶颈</code>.大部分现代GPU的内存是3/4/6GB，最好的GPU大约有12GB的内存.要注意三种内存占用来源：</p><ul><li>来自中间数据体尺寸：卷积神经网络中的每一层中都有激活数据体的原始数值，以及损失函数对它们的梯度（和激活数据体尺寸一致）.通常，大部分激活数据都是在网络中靠前的层中（比如第一个卷积层）.在训练时，这些数据需要放在内存中，因为反向传播的时候还会用到.但是在测试时可以聪明点：让网络在测试运行时候每层都只存储当前的激活数据，然后丢弃前面层的激活数据，这样就能减少巨大的激活数据量.</li><li>来自参数尺寸：即整个网络的参数的数量，在反向传播时它们的梯度值，以及使用momentum、Adagrad或RMSProp等方法进行最优化时的每一步计算缓存.因此，存储参数向量的内存通常需要在参数向量的容量基础上乘以3或者更多.</li><li>卷积神经网络实现还有各种零散的内存占用，比如成批的训练数据，扩充的数据等等.</li></ul><p>一旦对于所有这些数值的数量有了一个大略估计（包含激活数据，梯度和各种杂项），数量应该转化为以GB为计量单位.把这个值乘以4，得到原始的字节数（因为每个浮点数占用4个字节，如果是双精度浮点数那就是占用8个字节），然后多次除以1024分别得到占用内存的KB，MB，最后是GB计量.如果你的网络工作得不好，一个常用的方法是<code>降低批尺寸（batch size）</code>，因为绝大多数的内存都是被激活数据消耗掉了.</p><p>参考链接：<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">ConvNet notes</a>/<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" target="_blank" rel="noopener">卷积神经网络笔记</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Neural Networks Part 3</title>
    <link href="http://yoursite.com/2018/10/24/Lecture-Neural-Networks-Part-3/"/>
    <id>http://yoursite.com/2018/10/24/Lecture-Neural-Networks-Part-3/</id>
    <published>2018-10-24T07:07:12.000Z</published>
    <updated>2018-11-19T10:34:04.987Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>在前面章节中，我们讨论了神经网络的静态部分：如何创建网络的连接、数据和损失函数。本节将致力于讲解神经网络的动态部分，即神经网络<code>学习参数</code>和搜索<code>最优超参数</code>的过程。</p><h2 id="梯度检查"><a href="#梯度检查" class="headerlink" title="梯度检查"></a>梯度检查</h2><p>理论上将进行梯度检查很简单，就是简单地把解析梯度和数值计算梯度进行比较.</p><p><strong>使用中心化公式</strong>  在使用有限差值近似来计算数值梯度的时候，$\frac{df(x)}{dx}=\frac{f(x+h)-f(x-h)}{2h}$(use instead) 效果较好</p><ul><li><p><strong>使用相对误差来比较</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 相对误差&gt;1e-2：通常就意味着梯度可能出错。</span><br><span class="line">- 1e-2&gt;相对误差&gt;1e-4：要对这个值感到不舒服才行。</span><br><span class="line">- 1e-4&gt;相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高。</span><br><span class="line">- 1e-7或者更小：好结果，可以高兴一把了。</span><br><span class="line"></span><br><span class="line">要知道的是网络的深度越深，相对误差就越高。所以如果你是在对一个10层网络的输入数据做梯度检查，那么1e-2的相对误差值可能就OK了，因为误差一直在累积。相反，如果一个可微函数的相对误差值是1e-2，那么通常说明梯度实现不正确。</span><br></pre></td></tr></table></figure></li><li><p><strong>使用双精度</strong></p><p>一个常见的错误是使用单精度浮点数来进行梯度检查。这样会导致即使梯度实现正确，相对误差值也会很高（比如1e-2）。在我的经验而言，出现过使用单精度浮点数时相对误差为1e-2，换成双精度浮点数时就降低为1e-8的情况。</p></li><li><p><strong>目标函数的不可导点（kinks）</strong></p><p>不可导点是指目标函数不可导的部分，由ReLU（$max(0,x)$）等函数，或SVM损失，Maxout神经元等引入。考虑当$x=-1e6$时，对ReLU函数进行梯度检查。因为$x&lt;0$，所以解析梯度在该点的梯度为0。然而，在这里数值梯度会突然计算出一个非零的梯度值，因为$f(x+h)$可能越过了不可导点(例如：如果$h&gt;1e-6$)，导致了一个非零的结果。实际上这种情况很常见。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意，在计算损失的过程中是可以知道不可导点有没有被越过的。在具有max(x,y)形式的函数中持续跟踪所有“赢家”的身份，就可以实现这一点。其实就是看在前向传播时，到底x和y谁更大。如果在计算f(x+h)和f(x-h)的时候，至少有一个“赢家”的身份变了，那就说明不可导点被越过了，数值梯度会不准确。</span><br><span class="line"></span><br><span class="line">解决上面的不可导点问题的一个办法是使用更少的数据点。如果你的梯度检查对2-3个数据点都有效，那么基本上对整个批量数据进行梯度检查也是没问题的。所以使用很少量的数据点，能让梯度检查更迅速高效。</span><br></pre></td></tr></table></figure></li><li><p><strong>不要让正则化吞没数据。</strong></p><p>推荐先关掉正则化对数据损失做单独检查，然后对正则化做单独检查。对于正则化的单独检查可以是修改代码，去掉其中数据损失的部分，也可以提高正则化强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了。</p></li><li><p><strong>记得关闭随机失活（dropout）和数据扩张（augmentation）</strong></p><p>在进行梯度检查时，记得关闭网络中任何不确定的效果的操作，比如随机失活，随机数据扩展等。</p></li><li><p><strong>检查少量的维度。</strong></p><p>在实际中，梯度可以有上百万的参数，在这种情况下只能检查其中一些维度然后假设其他维度是正确的。<strong>注意</strong>：确认在所有不同的参数中都抽取一部分来梯度检查。</p></li></ul><h2 id="合理性（Sanity）检查"><a href="#合理性（Sanity）检查" class="headerlink" title="合理性（Sanity）检查"></a>合理性（Sanity）检查</h2><ul><li><p><strong>寻找特定情况的正确损失值</strong></p><p>在使用小参数进行初始化时，<code>确保得到的损失值与期望一致</code>。最好先单独检查数据损失（让正则化强度为0）。例如，对于一个跑CIFAR-10的Softmax分类器，一般期望它的初始损失值是2.302，这是因为初始时预计每个类别的概率是0.1（因为有10个类别），然后Softmax损失值正确分类的负对数概率：-ln(0.1)=2.302。</p></li><li><p><strong>提高正则化强度时导致损失值变大</strong></p></li><li><p><strong>对小数据子集过拟合</strong></p><p>在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），然后<code>确保能到达0的损失值</code>。进行这个实验的时候，最好让正则化强度为0，不然它会阻止得到0的损失。</p></li></ul><h2 id="检查学习过程"><a href="#检查学习过程" class="headerlink" title="检查学习过程"></a>检查学习过程</h2><p>在训练神经网络的时候，应该跟踪多个重要数值。这些数值输出的图表是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，从而知道<code>如何修改超参数以获得更高效的学习过程</code>。</p><p>在下面的图表中，x轴通常都是表示<strong>周期（epochs）</strong>单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）。相较于迭代次数（iterations），一般<code>更倾向跟踪周期</code>，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>训练期间第一个要跟踪的数值就是损失值，它在前向传播时对每个独立的批数据进行计算。</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/24/Lecture-Neural-Networks-Part-3/check_learning_loss.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><strong>左图</strong>展示了不同的学习率的效果。过低的学习率导致算法的改善是线性的。高一些的学习率会看起来呈几何指数下降，更高的学习率会让损失值很快下降，但是接着就停在一个不好的损失值上（绿线）。这是因为最优化的“能量”太大，参数在混沌中随机震荡，不能最优化到一个很好的点上。<strong>右图</strong>显示了一个典型的随时间变化的损失函数值，在CIFAR-10数据集上面训练了一个小的网络，这个损失函数值曲线看起来比较合理（虽然可能学习率有点小，但是很难说），而且指出了批数据的数量可能有点太小（因为损失值的噪音很大）。</p><hr><h3 id="训练集与验证集准确率"><a href="#训练集与验证集准确率" class="headerlink" title="训练集与验证集准确率"></a>训练集与验证集准确率</h3><p>在训练分类器的时候，需要跟踪的第二重要的数值是验证集和训练集的准确率。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/24/Lecture-Neural-Networks-Part-3/check_learning_accuracy.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>在训练集准确率和验证集准确率中间的空隙指明了<code>模型过拟合</code>的程度。在图中，蓝色的验证集曲线显示相较于训练集，验证集的准确率低了很多，这就说明模型有很强的过拟合。遇到这种情况，就应该增大正则化强度（更强的L2权重惩罚，更多的随机失活等）或收集更多的数据。另一种可能就是验证集曲线和训练集曲线如影随形，这种情况说明你的模型容量还不够大：应该通过增加参数数量让模型容量更大些。</p><h3 id="权重：更新比例"><a href="#权重：更新比例" class="headerlink" title="权重：更新比例"></a>权重：更新比例</h3><p>最后一个应该跟踪的量是权重中<code>更新</code>值的数量和全部值的数量之间的比例。需要对每个参数集的更新比例进行单独的计算和跟踪。一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设参数向量为W，其梯度向量为dW</span></span><br><span class="line">param_scale = np.linalg.norm(W.ravel())</span><br><span class="line">update = -learning_rate*dW <span class="comment"># 简单SGD更新</span></span><br><span class="line">update_scale = np.linalg.norm(update.ravel())</span><br><span class="line">W += update <span class="comment"># 实际更新</span></span><br><span class="line"><span class="keyword">print</span> update_scale / param_scale <span class="comment"># 要得到1e-3左右</span></span><br></pre></td></tr></table></figure><h3 id="每层的激活数据与梯度分布"><a href="#每层的激活数据与梯度分布" class="headerlink" title="每层的激活数据与梯度分布"></a>每层的激活数据与梯度分布</h3><h4 id="第一层可视化"><a href="#第一层可视化" class="headerlink" title="第一层可视化"></a>第一层可视化</h4><p>如果数据是图像像素数据，那么把第一层特征可视化会有帮助：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/24/Lecture-Neural-Networks-Part-3/第一层可视化.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>将神经网络第一层的权重可视化的例子。<br>左图中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低.<br>右图的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好.</p><h2 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h2><p>一旦能使用反向传播计算解析梯度，梯度就能被用来进行参数更新了。进行参数更新有好几种方法，接下来都会进行讨论。</p><h3 id="一阶（随机梯度下降）方法，动量方法，Nesterov动量方法"><a href="#一阶（随机梯度下降）方法，动量方法，Nesterov动量方法" class="headerlink" title="一阶（随机梯度下降）方法，动量方法，Nesterov动量方法"></a>一阶（随机梯度下降）方法，动量方法，Nesterov动量方法</h3><ul><li><p><strong>普通更新</strong>. 最简单的更新形式是沿着负梯度方向改变参数（因为梯度指向的是上升方向，但是我们通常希望最小化损失函数）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通更新</span></span><br><span class="line">x += - learning_rate * dx</span><br></pre></td></tr></table></figure><p>其中learning_rate是一个超参数，它是一个固定的常量。当在整个数据集上进行计算时，只要学习率足够低，总是能在损失函数上得到非负的进展。</p></li><li><p><strong>动量（Momentum）更新</strong></p><p>这样最优化过程可以看做是模拟参数向量（即质点）在地形上滚动的过程。在普通版本中，梯度直接影响位置。而在这个版本的更新中，物理观点建议梯度只是影响速度，然后速度再影响位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动量更新</span></span><br><span class="line">v = mu * v - learning_rate * dx <span class="comment"># 与速度融合</span></span><br><span class="line">x += v <span class="comment"># 与位置融合</span></span><br></pre></td></tr></table></figure><p>在这里引入了一个初始化为0的变量<strong>v</strong>和一个超参数<strong>mu</strong>。说得不恰当一点，这个变量（mu）在最优化的过程中被看做<em>动量</em>（一般值设为0.9），但其物理意义与摩擦系数更一致。这个变量有效地抑制了速度，降低了系统的动能，不然质点在山底永远不会停下来。通过交叉验证，这个参数通常设为[0.5,0.9,0.95,0.99]中的一个。和学习率随着时间退火（下文有讨论）类似，动量随时间变化的设置有时能略微改善最优化的效果，其中动量在学习过程的后阶段会上升。一个<code>典型的设置</code>是刚开始将动量设为0.5而在后面的多个周期（epoch）中慢慢提升到0.99。</p><blockquote><p>通过动量更新，参数向量会在任何有持续梯度的方向上增加速度。</p></blockquote></li><li><p><strong>Nesterov动量</strong>与普通动量有些许不同，最近变得比较流行。在理论上对于凸函数它能得到更好的收敛，在实践中也确实比标准动量表现更好一些。</p><p>Nesterov动量的核心思路是，当参数向量位于某个位置<strong>x</strong>时，观察上面的动量更新公式可以发现，动量部分（忽视带梯度的第二个部分）会通过<strong>mu * v</strong>稍微改变参数向量。因此，如果要计算梯度，那么可以将未来的近似位置<strong>x + mu * v</strong>看做是“向前看”，这个点在我们一会儿要停止的位置附近。因此，相比“旧”位置<strong>x</strong>的梯度，<code>计算x + mu \* v的梯度</code>会更有意义。</p><p><img src="/2018/10/24/Lecture-Neural-Networks-Part-3/Nesterov动量.jpg" alt="Nesterov动量"></p><p>既然我们知道动量将会把我们带到绿色箭头指向的点，我们就不要在原点（红色点）那里计算梯度了。使用Nesterov动量，我们就在这个“向前看”的地方计算梯度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_ahead = x + mu * v<span class="comment"># 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)</span></span><br><span class="line">v = mu * v - learning_rate * dx_ahead</span><br><span class="line">x += v</span><br></pre></td></tr></table></figure><p>然而在实践中，人们更喜欢和普通SGD或上面的动量方法一样简单的表达式。通过对<strong>x_ahead = x + mu * v</strong>使用变量变换进行改写是可以做到的，然后用<strong>x_ahead</strong>而不是<strong>x</strong>来表示上面的更新。也就是说，<code>实际存储的参数向量总是向前一步的那个版本</code>。<strong>x_ahead</strong>的公式（将其重新命名为<strong>x</strong>）就变成了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v_prev = v <span class="comment"># 存储备份</span></span><br><span class="line">v = mu * v - learning_rate * dx <span class="comment"># 速度更新保持不变</span></span><br><span class="line">x += -mu * v_prev + (<span class="number">1</span> + mu) * v <span class="comment"># 位置更新变了形式</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="学习率退火"><a href="#学习率退火" class="headerlink" title="学习率退火"></a>学习率退火</h3><p>在训练深度网络的时候，让学习率随着时间退火通常是有帮助的。通常，实现学习率退火有3种方式：</p><ul><li><strong>随步数衰减</strong>：每进行几个周期就根据一些因素降低学习率。典型的值是每过5个周期就将学习率减少一半，或者每20个周期减少到之前的0.1。这些数值的设定是严重依赖具体问题和模型的选择的。在实践中可能看见这么一种经验做法：使用一个固定的学习率来进行训练的同时观察验证集错误率，每当验证集错误率停止下降，就乘以一个常数（比如0.5）来降低学习率。</li><li><strong>指数衰减</strong>。数学公式是$\alpha=\alpha_0e^{-kt}$，其中$\alpha_0,k$是超参数，t是迭代次数（也可以使用周期作为单位）。</li><li><strong>1/t衰减</strong>的数学公式是$\alpha=\alpha_0/(1+kt)$，其中$\alpha_0,k$是超参数，t是迭代次数。</li></ul><p>在实践中，我们发现<code>随步数衰减的随机失活（dropout）更受欢迎</code>，因为它使用的超参数（衰减系数和以周期为时间单位的步数）比k更有解释性。最后，如果你有足够的计算资源，可以让衰减更加缓慢一些，让训练时间更长些。</p><h3 id="二阶方法"><a href="#二阶方法" class="headerlink" title="二阶方法"></a>二阶方法</h3><p>在深度网络背景下，第二类常用的最优化方法是基于牛顿法的，其迭代如下：$\displaystyle x\leftarrow x-[Hf(x)]^{-1}\nabla f(x)$</p><h3 id="逐参数适应学习率方法（Adagrad，RMSProp）"><a href="#逐参数适应学习率方法（Adagrad，RMSProp）" class="headerlink" title="逐参数适应学习率方法（Adagrad，RMSProp）"></a>逐参数适应学习率方法（Adagrad，RMSProp）</h3><p>前面讨论的所有方法都是对学习率进行全局地操作，并且对所有的参数都是一样的。学习率调参是很耗费计算资源的过程，所以很多工作投入到发明能够<code>适应性地对学习率调参</code>的方法，<code>甚至</code>是逐个参数适应学习率调参。</p><ul><li><p><strong>Adagrad</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设有梯度和参数向量x</span></span><br><span class="line">cache += dx**<span class="number">2</span></span><br><span class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</span><br></pre></td></tr></table></figure></li><li><p><strong>RMSprop</strong></p><p>用一种很简单的方式修改了Adagrad方法，让它不那么激进，单调地降低了学习率。具体说来，就是它使用了一个梯度平方的滑动平均：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cache =  decay_rate * cache + (<span class="number">1</span> - decay_rate) * dx**<span class="number">2</span></span><br><span class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</span><br></pre></td></tr></table></figure></li><li><p><strong>Adam</strong></p><p>看起来像是RMSProp的动量版</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = beta1*m + (<span class="number">1</span>-beta1)*dx</span><br><span class="line">v = beta2*v + (<span class="number">1</span>-beta2)*(dx**<span class="number">2</span>)</span><br><span class="line">x += - learning_rate * m / (np.sqrt(v) + eps)</span><br></pre></td></tr></table></figure></li></ul><hr><p><center class="half"><br>    &lt;img src=./Lecture-Neural-Networks-Part-3/opt0.gif width=”300”/&gt;<br>    &lt;img src=./Lecture-Neural-Networks-Part-3/opt.gif width=”300”/&gt;<br></center><br>​    上面的动画可以帮助你理解学习的动态过程。</p><ul><li><p><strong>左边</strong>是一个损失函数的等高线图，上面跑的是不同的最优化算法。</p><ul><li>基于动量的方法出现了射偏了的情况，使得最优化过程看起来像是一个球滚下山的样子。</li></ul></li><li><p><strong>右边</strong>展示了一个马鞍状的最优化地形，其中对于不同维度它的曲率不同（一个维度下降另一个维度上升）。</p><ul><li>SGD很难突破对称性，一直卡在顶部。</li><li>RMSProp之类的方法能够看到马鞍方向有很低的梯度。因为在RMSProp更新方法中的分母项，算法提高了在该方向的有效学习率，使得RMSProp能够继续前进。</li></ul></li></ul><hr><h2 id="超参数调优"><a href="#超参数调优" class="headerlink" title="超参数调优"></a>超参数调优</h2><p>训练一个神经网络会遇到很多超参数设置。神经网络最常用的设置有：</p><ul><li>初始学习率</li><li>学习率衰减方式（例如一个衰减常量）</li><li>正则化强度（L2惩罚，随机失活强度）</li></ul><p>调参要点和技巧：</p><ul><li><p><strong>实现</strong>  </p><p>更大的神经网络需要更长的时间去训练，所以调参可能需要几天甚至几周。记住这一点很重要，因为这会影响你设计代码的思路。</p></li><li><p><strong>比起交叉验证最好使用一个验证集</strong></p><p>在大多数情况下，一个尺寸合理的验证集可以让代码更简单，不需要用几个数据集来交叉验证。</p></li><li><p><strong>超参数范围</strong></p><p>在对数尺度上进行超参数搜索。例如，一个典型的学习率应该看起来是这样：<strong>learning_rate = 10 \</strong> uniform(-6, 1)**。也就是说，我们从标准分布中随机生成了一个数字，然后让它成为10的阶数。对于正则化强度，可以采用同样的策略。直观地说，这是因为学习率和正则化强度都对于训练的动态进程有乘的效果。</p></li><li><p><strong>随机搜索优于网格搜索</strong></p><p><img src="/2018/10/24/Lecture-Neural-Networks-Part-3/随机搜索优于网格搜索.jpg" alt=""></p><p>通常，有些超参数比其余的更重要，通过随机搜索，而不是网格化的搜索，可以让你更精确地发现那些比较重要的超参数的好数值。</p></li><li><p><strong>对于边界上的最优值要小心</strong></p><p>这种情况一般发生在你在一个不好的范围内搜索超参数（比如学习率）的时候.一旦我们得到一个比较好的值，一定要确认你的值不是出于这个范围的边界上，不然你可能错过更好的其他搜索范围。</p></li><li><p><strong>从粗到细地分阶段搜索</strong></p><p>先进行初略范围搜索，然后根据好的结果出现的地方，缩小范围进行搜索。</p></li><li><p><strong>贝叶斯超参数最优化</strong></p><p>主要是研究在超参数空间中更高效的导航算法。其核心的思路是在不同超参数设置下查看算法性能时，要在探索和使用中进行合理的权衡。</p></li></ul><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><h3 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h3><p>在实践的时候，有一个总是能提升神经网络几个百分点准确率的办法，就是在训练的时候训练几个独立的模型，然后在测试的时候平均它们预测结果。集成的模型数量增加，算法的结果也单调提升（但提升效果越来越少）。还有模型之间的差异度越大，提升效果可能越好。进行集成有以下几种方法：</p><ul><li><strong>同一个模型，不同的初始化</strong>。使用交叉验证来得到最好的超参数，然后用最好的参数来训练不同初始化条件的模型。这种方法的风险在于多样性只来自于不同的初始化条件。</li><li><strong>在交叉验证中发现最好的模型</strong>。使用交叉验证来得到最好的超参数，然后取其中最好的几个（比如10个）模型来进行集成。这样就提高了集成的多样性，但风险在于可能会包含不够理想的模型。在实际操作中，这样操作起来比较简单，在交叉验证后就不需要额外的训练了。</li><li><strong>一个模型设置多个记录点</strong>。如果训练非常耗时，那就在不同的训练时间对网络留下记录点（比如每个周期结束），然后用它们来进行模型集成。很显然，这样做多样性不足，但是在实践中效果还是不错的，这种方法的优势是代价比较小。</li><li><strong>在训练的时候跑参数的平均值</strong>。和上面一点相关的，还有一个也能得到1-2个百分点的提升的小代价方法，这个方法就是在训练过程中，如果损失值相较于前一次权重出现指数下降时，就在内存中对网络的权重进行一个备份。这样你就对前几次循环中的网络状态进行了平均。你会发现这个“平滑”过的版本的权重总是能得到更少的误差。直观的理解就是目标函数是一个碗状的，你的网络在这个周围跳跃，所以对它们平均一下，就更可能跳到中心去。</li></ul><p>模型集成的一个劣势就是在测试数据的时候会花费更多时间。最近Geoff Hinton在“<a href="http://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DEK61htlw8hY" target="_blank" rel="noopener">Dark Knowledge</a>”上的工作很有启发：其思路是通过将集成似然估计纳入到修改的目标函数中，从一个好的集成中抽出一个单独模型。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>训练一个神经网络需要：</p><ul><li>利用小批量数据对实现进行<code>梯度检查</code>，还要注意各种错误.</li><li>进行<code>合理性检查</code>，确认初始损失值是合理的，在小数据集上能得到100%的准确率.</li><li>在训练时，<code>跟踪</code>损失函数值，训练集和验证集准确率，如果愿意，还可以跟踪更新的参数量相对于总参数量的比例（一般在1e-3左右），然后如果是对于卷积神经网络，可以将第一层的权重可视化.</li><li>推荐的两个<code>更新</code>方法是SGD+Nesterov动量方法，或者Adam方法.</li><li>随着训练进行<code>学习率衰减</code>。比如，在固定多少个周期后让学习率减半，或者当验证集准确率下降的时候.</li><li>使用<code>随机搜索</code>（不要用网格搜索）来搜索最优的超参数。分阶段<code>从粗</code>（比较宽的超参数范围训练1-5个周期）<code>到细</code>（窄范围训练很多个周期）地来搜索.</li><li>进行<code>模型集成</code>来获得额外的性能提高.</li></ul><p>参考链接：<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Nets notes 3</a>、神经网络笔记3<a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" target="_blank" rel="noopener">（上）</a><a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" target="_blank" rel="noopener">（下）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Neural Networks Part 2</title>
    <link href="http://yoursite.com/2018/10/22/Lecture-Neural-Networks-Part-2/"/>
    <id>http://yoursite.com/2018/10/22/Lecture-Neural-Networks-Part-2/</id>
    <published>2018-10-22T08:27:27.000Z</published>
    <updated>2018-11-19T07:01:32.821Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="设置数据和模型"><a href="#设置数据和模型" class="headerlink" title="设置数据和模型"></a>设置数据和模型</h2><p>具体来说，神经网络就是进行了一系列的线性映射与非线性激活函数交织的运算。</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ul><li><p><strong>均值减法（Mean subtraction）</strong>是预处理最常用的形式。</p></li><li><p><strong>归一化（Normalization）</strong>是指将数据的所有维度都归一化，使其数值范围都近似相等。</p><ul><li>零中心化（zero-centered）+ 每个维度都除以其标准差</li><li>对每个维度都做归一化，使得每个维度的最大和最小值是1和-1</li></ul></li></ul><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-df918c8372752302.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>一般数据预处理流程：</p><p>左边：原始的2维输入数据。</p><p>中间：在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。</p><p>右边：每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。</p><hr><ul><li><strong>PCA和白化（Whitening）</strong>是另一种预处理形式。在这种处理中，先对数据进行<code>零中心化</code>处理，然后计算<code>协方差</code>矩阵，它展示了数据中的相关性结构</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-f7389c2994251ec6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>PCA/白化。<strong>左边</strong>是二维的原始数据。<strong>中间</strong>：经过PCA操作的数据。可以看出数据首先是零中心的，然后变换到了数据<code>协方差</code>矩阵的基准轴上。这样就对数据进行了解相关（协方差矩阵变成对角阵）。<strong>右边</strong>：每个维度都被特征值调整数值范围，将数据协方差矩阵变为单位矩阵。从几何上看，就是对数据在各个方向上拉伸压缩，使之变成服从<code>高斯分布</code>的一个数据点分布。</p><hr><p><strong>强调：</strong> 任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。即<strong>应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值</strong></p><h3 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h3><p><strong>错误：全零初始化.</strong> 如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头。</p><p><strong>小随机数初始化</strong>权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来<em>打破对称性</em>。<strong>W = 0.01 * np.random.randn(D,H)</strong></p><p><strong>使用1/sqrt(n)校准方差</strong>：<strong>w = np.random.randn(n) / sqrt(n)</strong>(其中<strong>n</strong>是输入数据的数量)这样就保证了网络中所有神经元起始时有近似同样的输出分布。实践经验证明，这样做可以提高收敛的速度.</p><p><a href="https://link.zhihu.com/?target=http%3A//arxiv-web3.library.cornell.edu/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>文中给出了一种针对ReLU神经元的特殊初始化，并给出结论：网络中神经元的方差应该是$2.0/n$。代码为<strong>w = np.random.randn(n) * sqrt(2.0/n)</strong>。这个形式是神经网络算法使用ReLU神经元时的当前最佳推荐。</p><p><strong>稀疏初始化（Sparse initialization）</strong>另一个处理非标定方差的方法是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都同下一层固定数目的神经元随机连接（其权重数值由一个小的高斯分布生成）。一个比较典型的连接数目是10个。</p><p><strong>偏置（biases）的初始化。</strong>通常将偏置初始化为0，这是因为随机小数值权重矩阵已经打破了对称性。</p><h3 id="批量归一化（Batch-Normalization）"><a href="#批量归一化（Batch-Normalization）" class="headerlink" title="批量归一化（Batch Normalization）"></a>批量归一化（Batch Normalization）</h3><p>在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。</p><h3 id="正则化（L2-L1-Maxnorm-Dropout）"><a href="#正则化（L2-L1-Maxnorm-Dropout）" class="headerlink" title="正则化（L2/L1/Maxnorm/Dropout）"></a>正则化（L2/L1/Maxnorm/Dropout）</h3><p>正则化：<code>防止过拟合</code></p><p><strong>L2正则化</strong>可能是最常用的正则化(Regularization)方法.可以通过<code>惩罚</code>目标函数中所有参数的平方将其实现。即对于网络中的每个权重$w$，向目标函数中增加一个$\frac{1}{2}\lambda w^2$，其中$\lambda$是正则化强度。L2正则化可以直观理解为它对于<u>大数值的权重向量进行严厉惩罚</u>，倾向于更加分散的权重向量。</p><p><strong>L1正则化</strong>是另一个相对常用的正则化方法。对于每个$w$我们都向目标函数增加一个$\lambda|w|$。在实践中，如果不是特别关注某些明确的特征选择，一般说来L2正则化都会比L1正则化效果好。</p><p><strong>最大范式约束（Max norm constraints）</strong>是给每个神经元中权重向量的量级<code>设定上限</code>，并使用投影梯度下降来确保这一约束。在实践中，与之对应的是参数更新方式不变，然后要求神经元中的权重向量$\overrightarrow{w}$必须满足$||\overrightarrow{w}||_2&lt;c$这一条件，一般$c$值为3或者4。即使在学习率设置过高的时候，网络中也不会出现数值“爆炸”，这是因为它的参数更新始终是被限制着的。</p><p><strong>随机失活（Dropout）</strong>是一个简单又<code>极其有效</code>的正则化方法。与L1正则化，L2正则化和最大范式约束等方法互为补充。在训练的时候，随机失活的实现方法是让神经元以超参数$p$的概率被激活或者被设置为0。</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://cs231n.github.io/assets/nn2/dropout.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>在训练过程中，随机失活可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相互独立的，因为它们都共享参数）。在测试过程中不使用随机失活，可以理解为是对数量巨大的子网络们做了模型集成（model ensemble），以此来计算出一个平均的预测。</p><hr><p>实际更倾向使用<strong>反向随机失活（inverted dropout）</strong>，它是在训练时就进行数值范围调整，从而让前向传播在测试时保持不变。这样做还有一个好处，无论你决定是否使用随机失活，预测方法的代码可以保持不变。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>我们已经讨论过损失函数的正则化损失部分，它可以看做是对模型复杂程度的某种惩罚。损失函数的第二个部分是<em>数据损失</em>，它是一个有监督学习问题，用于衡量分类算法的预测结果（即分类评分）和真实标签结果之间的一致性。数据损失是对所有样本的数据损失求平均。也就是说，$L=\frac{1}{N}\sum_iL_i$中，$N$是训练集数据的样本数。</p><ul><li><p><strong>分类问题</strong> 在该问题中，假设有一个装满样本的数据集，每个样本都有一个唯一的正确标签（是固定分类标签之一）.</p><ul><li>最常见的损失函数就是SVM.$\displaystyle L_i=\sum_{j\not=y_i}max(0,f_j-f_{y_i}+1)$<ul><li>平方折叶损失（即使用$ max(0,f_j-f_{y_i}+1)^2$）算法的结果会更好</li></ul></li><li>第二个常用的损失函数是Softmax分类器.   它使用交叉熵损失：$\displaystyle L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})$</li></ul></li><li><p><strong>属性（Attribute）分类</strong> 若每个样本的标签$y_i$是一个二值向量，每个样本可能有，也可能没有某个属性，而且属性之间并不相互排斥，此时应为每个属性创建一个独立的二分类的分类器。$\displaystyle L_i=\sum_jmax(0,1-y_{ij}f_j)$</p></li><li><p><strong>回归问题</strong>是预测实数的值的问题.</p><ul><li>L2范式 $L_i=||f-y_i||^2_2$</li><li>L1范式则是要将每个维度上的绝对值加起来：$L_i=||f-y_i||_1=\sum_j|f_j-(y_i)_j|$</li></ul><blockquote><p>当面对一个回归任务，首先考虑是不是必须这样。一般而言，尽量把你的输出变成二分类，然后对它们进行分类，从而变成一个分类问题。</p></blockquote></li><li><p><strong>结构化预测（structured prediction）</strong>结构化损失是指标签可以是任意的结构，例如图表、树或者其他复杂物体的情况。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>推荐的预处理操作是对数据的每个特征都进行零中心化，然后将其数值范围都归一化到[-1,1]范围之内。</li><li>使用标准差为$\sqrt{2/n}$的高斯分布来初始化权重，其中$n$是输入的神经元数。例如用numpy可以写作：<strong>w = np.random.randn(n) * sqrt(2.0/n)</strong>。</li><li>使用L2正则化和随机失活的倒置版本。</li><li>使用批量归一化。</li><li>讨论了在实践中可能要面对的不同任务，以及每个任务对应的常用损失函数。</li></ul><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" target="_blank" rel="noopener">神经网络笔记 2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Neural Networks Part 1</title>
    <link href="http://yoursite.com/2018/10/22/Lecture-Neural-Networks-Part-1/"/>
    <id>http://yoursite.com/2018/10/22/Lecture-Neural-Networks-Part-1/</id>
    <published>2018-10-22T05:25:48.000Z</published>
    <updated>2018-11-19T06:36:21.399Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="单个神经元建模"><a href="#单个神经元建模" class="headerlink" title="单个神经元建模"></a>单个神经元建模</h2><h3 id="生物动机和连接"><a href="#生物动机和连接" class="headerlink" title="生物动机和连接"></a>生物动机和连接</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-6f0bc09c687d2934.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>将神经元的激活率建模为<strong>激活函数（activation function）f</strong>，它表达了轴突上激活信号的频率.激活函数，非线性函数，”扭曲”得分函数.</p><p>由于历史原因，激活函数常常选择使用<strong>sigmoid函数</strong>$\sigma$，该函数输入实数值（求和后的信号强度），然后将输入值压缩到0-1之间。</p><h3 id="作为线性分类器的单个神经元"><a href="#作为线性分类器的单个神经元" class="headerlink" title="作为线性分类器的单个神经元"></a>作为线性分类器的单个神经元</h3><p>一个单独的神经元可以用来实现一个二分类分类器，比如二分类的Softmax或者SVM分类器。</p><h3 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h3><p><img src="https://upload-images.jianshu.io/upload_images/5267500-a9e31b332db38761.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><p>左边是Sigmoid非线性函数，将实数压缩到[0,1]之间。右边是tanh函数，将实数压缩到[-1,1]。 </p><p><strong>Sigmoid：</strong>$\sigma(x)=\frac{1}{1+e^{-x}}$ </p><ul><li><em>Sigmoid函数饱和使梯度消失</em></li><li><em>Sigmoid函数的输出不是零中心的</em></li></ul><p><strong>Tanh：</strong>$tanh(x)=2\sigma(2x)-1$  （tanh神经元是一个简单放大的sigmoid神经元）</p><ul><li>Tanh也存在饱和问题</li><li>Tanh的输出是零中心的</li></ul><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-c3bc267ea5b658fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><strong>ReLU</strong>(校正线性单元：Rectified Linear Unit)激活函数: $f(x)=max(0,x)$</p><ul><li>ReLU对于随机梯度下降的收敛有巨大的加速作用</li><li>ReLU单元比较脆弱并且可能“死掉”.通过合理设置学习率，这种情况的发生概率会降低<ul><li>Leaky ReLU是为解决“ReLU死亡”问题的尝试</li><li><strong>Maxout：</strong>$max(w^T_1x+b_1,w^T_2x+b_2)$  Maxout是对ReLU和leaky ReLU的<code>一般化归纳</code>.</li></ul></li></ul><hr><p>在同一个网络中混合使用不同类型的神经元是非常少见的.</p><h2 id="神经网络结构"><a href="#神经网络结构" class="headerlink" title="神经网络结构"></a>神经网络结构</h2><h3 id="层组织"><a href="#层组织" class="headerlink" title="层组织"></a>层组织</h3><p><strong>将神经网络算法以神经元的形式图形化</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-d7ec4d232e0994af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><ul><li><p>左边是一个2层神经网络，隐层由4个神经元（也可称为单元（unit））组成，输出层由2个神经元组成，输入层是3个神经元。该网络有4+2=6个神经元（输入层不算），[3x4]+[4x2]=20个权重，还有4+2=6个偏置，共26个可学习的参数。</p></li><li><p>右边是一个3层神经网络，两个含4个神经元的隐层。该网络有4+4+1=9个神经元，[3x4]+[4x4]+[4x1]=32个权重，4+4+1=9个偏置，共41个可学习的参数。</p></li></ul><p>注意：<strong>全连接层（fully-connected layer）</strong>。全连接层中的神经元与其前后两层的神经元是完全成对连接的，但是在同一个全连接层内的神经元之间没有连接.上面两个神经网络的图例，都使用的全连接层.</p><hr><h3 id="前向传播计算例子"><a href="#前向传播计算例子" class="headerlink" title="前向传播计算例子"></a>前向传播计算例子</h3><p>完整的3层神经网络的前向传播就是简单的3次矩阵乘法，其中交织着激活函数的应用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个3层神经网络的前向传播:</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: <span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-x)) <span class="comment"># 激活函数(用的sigmoid)</span></span><br><span class="line">x = np.random.randn(<span class="number">3</span>, <span class="number">1</span>) <span class="comment"># 含3个数字的随机输入向量(3x1)</span></span><br><span class="line">h1 = f(np.dot(W1, x) + b1) <span class="comment"># 计算第一个隐层的激活数据(4x1)</span></span><br><span class="line">h2 = f(np.dot(W2, h1) + b2) <span class="comment"># 计算第二个隐层的激活数据(4x1)</span></span><br><span class="line">out = np.dot(W3, h2) + b3 <span class="comment"># 神经元输出(1x1)</span></span><br></pre></td></tr></table></figure><blockquote><p>全连接层的前向传播一般就是先进行一个矩阵乘法，然后加上偏置并运用激活函数。</p></blockquote><h3 id="表达能力"><a href="#表达能力" class="headerlink" title="表达能力"></a>表达能力</h3><p>神经网络可以近似任何连续函数。</p><p>虽然在理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的，但是就实践经验而言，深度网络效果比单层网络好(设置的网络深度也应适度而行)。</p><h3 id="设置层的数量和尺寸"><a href="#设置层的数量和尺寸" class="headerlink" title="设置层的数量和尺寸"></a>设置层的数量和尺寸</h3><p>注意：不应该因为害怕出现过拟合而使用小网络。相反，应该进尽可能使用大网络，然后使用正则化技巧来控制过拟合。</p><h2 id="小节"><a href="#小节" class="headerlink" title="小节"></a>小节</h2><ul><li>介绍了生物神经元的粗略模型；</li><li>讨论了几种不同类型的激活函数，其中ReLU是最佳推荐；</li><li>介绍了<strong>神经网络</strong>，神经元通过<strong>全连接层</strong>连接，层间神经元两两相连，但是层内神经元不连接；</li><li>理解了分层的结构能够让神经网络高效地进行矩阵乘法和激活函数运算；</li><li>理解了神经网络是一个<strong>通用函数近似器</strong>，但是该性质与其广泛使用无太大关系。之所以使用神经网络，是因为它们对于实际问题中的函数的公式能够某种程度上做出“正确”假设。</li><li>讨论了更大网络总是更好的这一事实。然而更大容量的模型一定要和更强的正则化（比如更高的权重衰减）配合，否则它们就会过拟合。在后续章节中我们讲学习更多正则化的方法，尤其是dropout。</li></ul><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" target="_blank" rel="noopener">神经网络笔记1 上</a>、<a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit" target="_blank" rel="noopener">神经网络笔记1 下</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture-backpropagation</title>
    <link href="http://yoursite.com/2018/10/22/Lecture-backpropagation/"/>
    <id>http://yoursite.com/2018/10/22/Lecture-backpropagation/</id>
    <published>2018-10-22T02:54:04.000Z</published>
    <updated>2018-11-19T04:04:02.675Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本节将帮助读者对<strong>反向传播</strong>形成直观而专业的理解。反向传播是利用<code>链式法则</code>递归计算表达式的梯度的方法。</p><h2 id="简单表达式和理解梯度"><a href="#简单表达式和理解梯度" class="headerlink" title="简单表达式和理解梯度"></a>简单表达式和理解梯度</h2><p>函数关于每个变量的导数指明了整个表达式对于该变量的<code>敏感程度</code>.</p><h2 id="复合表达式，链式法则，反向传播"><a href="#复合表达式，链式法则，反向传播" class="headerlink" title="复合表达式，链式法则，反向传播"></a>复合表达式，链式法则，反向传播</h2><p><strong>链式法则</strong>指出将这些梯度表达式链接起来的正确方式是相乘，比如$\frac{\partial f}{\partial x} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial x}$。在实际操作中，这只是简单地将两个梯度数值相乘.</p><hr><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-0c9de63f20983077.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置输入值</span></span><br><span class="line">x = <span class="number">-2</span>; y = <span class="number">5</span>; z = <span class="number">-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">q = x + y <span class="comment"># q becomes 3</span></span><br><span class="line">f = q * z <span class="comment"># f becomes -12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行反向传播:</span></span><br><span class="line"><span class="comment"># 首先回传到 f = q * z</span></span><br><span class="line">dfdz = q <span class="comment"># df/dz = q, 所以关于z的梯度是3   (f = 3*z)</span></span><br><span class="line">dfdq = z <span class="comment"># df/dq = z, 所以关于q的梯度是-4  (f = -4*q)</span></span><br><span class="line"><span class="comment"># 现在回传到q = x + y</span></span><br><span class="line">dfdx = <span class="number">1.0</span> * dfdq <span class="comment"># dq/dx = 1. (q = x+5)这里的乘法是因为链式法则 </span></span><br><span class="line">dfdy = <span class="number">1.0</span> * dfdq <span class="comment"># dq/dy = 1. (q = -2+y)</span></span><br></pre></td></tr></table></figure><p>上图 $f(x,y,z)=(x+y)*z$ 的真实值计算线路展示了计算的视觉化过程。<strong>前向传播</strong>从输入计算到输出（绿色），<strong>反向传播</strong>从尾部开始，根据链式法则递归地向前计算梯度（显示为红色），一直到网络的输入端。可以认为，梯度是从计算链路中回流。</p><hr><h2 id="直观理解反向传播"><a href="#直观理解反向传播" class="headerlink" title="直观理解反向传播"></a>直观理解反向传播</h2><p>这里对于每个输入的乘法操作是基于链式法则的。该操作让一个相对独立的门单元变成复杂计算线路中不可或缺的一部分，这个复杂计算线路可以是神经网络等。</p><p>反向传播可以看做是门单元之间在通过梯度信号相互通信，只要让它们的输入<code>沿着梯度方向变化</code>，无论它们自己的输出值在何种程度上升或降低，都是为了让整个网络的<code>输出值更高</code>.</p><p>任何可微分的函数都可以看做门。可以根据需要将一个函数分拆成多个简单门(计算反向传播就简单了)；也可以将多个门组合成一个门从而可以进行简化(让代码量更少，效率更高).</p><h2 id="模块：Sigmoid例子"><a href="#模块：Sigmoid例子" class="headerlink" title="模块：Sigmoid例子"></a>模块：Sigmoid例子</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-83b12b83edf6b42b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>$$ f(w,x) = \frac{1}{1+e^{-(w_0x_0 + w_1x_1 + w_2)}}$$ </p><p>使用sigmoid激活函数的2维神经元的例子。输入是[x0, x1]，可学习的权重是[w0, w1, w2]。一会儿会看见，这个神经元对输入数据做点积运算，然后其激活数据被sigmoid函数挤压到0到1之间。<br>$$ \sigma(x) = \frac{1}{1+e^{-x}} \\\\\rightarrow \hspace{0.3in} \frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = \left( \frac{1 + e^{-x} - 1}{1 + e^{-x}} \right) \left( \frac{1}{1+e^{-x}} \right) = \left( 1 - \sigma(x) \right) \sigma(x)$$ <br>和之前的计算流程比起来，现在的计算使用一个单独的简单表达式即可。因此，在实际的应用中将这些操作装进一个单独的门单元中将会非常有用。</p><h2 id="反向传播实践：分段计算"><a href="#反向传播实践：分段计算" class="headerlink" title="反向传播实践：分段计算"></a>反向传播实践：分段计算</h2><p>$$ f(x,y) = \frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}$$ </p><p>构建前向传播的代码模式：(对<code>前向传播</code>变量进行缓存)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">3</span> <span class="comment"># 例子数值</span></span><br><span class="line">y = <span class="number">-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">sigy = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-y)) <span class="comment"># 分子中的sigmoid         #(1)</span></span><br><span class="line">num = x + sigy <span class="comment"># 分子                                    #(2)</span></span><br><span class="line">sigx = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-x)) <span class="comment"># 分母中的sigmoid         #(3)</span></span><br><span class="line">xpy = x + y                                              <span class="comment">#(4)</span></span><br><span class="line">xpysqr = xpy**<span class="number">2</span>                                          <span class="comment">#(5)</span></span><br><span class="line">den = sigx + xpysqr <span class="comment"># 分母                                #(6)</span></span><br><span class="line">invden = <span class="number">1.0</span> / den                                       <span class="comment">#(7)</span></span><br><span class="line">f = num * invden <span class="comment"># 搞定！                                 #(8)</span></span><br></pre></td></tr></table></figure><p>(1) $sigy=\sigma(y)=\frac{1}{1+e^{-y}}$    (2) $num = x + sigy =x+\sigma(y)$  (3) $sigx=\sigma(x)=\frac{1}{1+e^{-x}}$ (4) $xpy =x+y$  </p><p>(5) $xpysqr = xpy**2=(x+y)^2$  (6) $den = sigx + xpysqr=\sigma(x)+(x+y)^2$ </p><p>(7) $invden=1/{den}=\frac{1}{\sigma(x)+(x+y)^2}$  (8) $f=num/invden=\frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}$</p><p><code>反向传播</code>的代码模式：(<strong>在不同分支的梯度要相加</strong>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回传 f = num * invden</span></span><br><span class="line">dnum = invden <span class="comment"># 分子的梯度:分母                                         #(8)</span></span><br><span class="line">dinvden = num <span class="comment"># 分母的梯度:分子                                         #(8)</span></span><br><span class="line"><span class="comment"># 回传 invden = 1.0 / den </span></span><br><span class="line">dden = (<span class="number">-1.0</span> / (den**<span class="number">2</span>)) * dinvden                                <span class="comment">#(7)</span></span><br><span class="line"><span class="comment"># 回传 den = sigx + xpysqr</span></span><br><span class="line">dsigx = (<span class="number">1</span>) * dden                                                <span class="comment">#(6)</span></span><br><span class="line">dxpysqr = (<span class="number">1</span>) * dden                                              <span class="comment">#(6)</span></span><br><span class="line"><span class="comment"># 回传 xpysqr = xpy**2</span></span><br><span class="line">dxpy = (<span class="number">2</span> * xpy) * dxpysqr                                        <span class="comment">#(5)</span></span><br><span class="line"><span class="comment"># 回传 xpy = x + y</span></span><br><span class="line">dx = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line">dy = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line"><span class="comment"># 回传 sigx = 1.0 / (1 + math.exp(-x))</span></span><br><span class="line">dx += ((<span class="number">1</span> - sigx) * sigx) * dsigx <span class="comment"># Notice += !! See notes below  #(3)</span></span><br><span class="line"><span class="comment"># 回传 num = x + sigy</span></span><br><span class="line">dx += (<span class="number">1</span>) * dnum                                                  <span class="comment">#(2)</span></span><br><span class="line">dsigy = (<span class="number">1</span>) * dnum                                                <span class="comment">#(2)</span></span><br><span class="line"><span class="comment"># 回传 sigy = 1.0 / (1 + math.exp(-y))</span></span><br><span class="line">dy += ((<span class="number">1</span> - sigy) * sigy) * dsigy                                 <span class="comment">#(1)</span></span><br><span class="line"><span class="comment"># 完成! 嗷~~</span></span><br></pre></td></tr></table></figure><h2 id="回传流中的模式"><a href="#回传流中的模式" class="headerlink" title="回传流中的模式"></a>回传流中的模式</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-ec4f09b059f37c5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>一个展示反向传播的例子.</p><ul><li><code>加法操作</code>将(反向传来的)梯度相等地分发给它的输入.</li><li><code>取最大操作</code>将梯度路由给更大的输入.</li><li><code>乘法操作</code>拿取输入激活数据，对它们进行交换，然后乘以梯度.</li></ul><h2 id="用户向量化操作的梯度"><a href="#用户向量化操作的梯度" class="headerlink" title="用户向量化操作的梯度"></a>用户向量化操作的梯度</h2><p><strong>矩阵相乘的梯度</strong>：可能最有技巧的操作是矩阵相乘（也适用于矩阵和向量，向量和向量相乘）的乘法操作：(<em>分析维度</em>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">W = np.random.randn(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">X = np.random.randn(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">D = W.dot(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们得到了D的梯度</span></span><br><span class="line">dD = np.random.randn(*D.shape) <span class="comment"># 和D一样的尺寸</span></span><br><span class="line">dW = dD.dot(X.T) <span class="comment">#.T就是对矩阵进行转置</span></span><br><span class="line">dX = W.T.dot(dD)</span><br></pre></td></tr></table></figure><p><strong>使用小而具体的例子</strong>：有些读者可能觉得向量化操作的梯度计算比较困难，建议是写出一个很小很明确的向量化例子，在纸上演算梯度，然后对其一般化，得到一个高效的向量化操作形式。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>对梯度的含义有了<code>直观理解</code>，知道了梯度是如何在网络中<code>反向传播</code>的，知道了它们是如何与网络的不同部分通信并控制其升高或者降低，并使得<code>最终输出值更高</code>的。</li><li>讨论了<strong>分段计算</strong>在反向传播的实现中的重要性。应该将函数分成不同的模块，这样<code>计算局部梯度相对容易</code>，然后基于链式法则将其“链”起来。重要的是，不需要把这些表达式写在纸上然后演算它的完整求导公式，因为实际上并不需要关于输入变量的梯度的数学公式。只需要将表达式<code>分</code>成不同的可以求导的模块（模块可以是矩阵向量的乘法操作，或者取最大值操作，或者加法操作等），然后在反向传播中<code>一步一步地计算梯度</code>。</li></ul><p>在下节课中，将会开始定义神经网络，而反向传播使我们能高效计算神经网络各个节点<code>关于损失函数的梯度</code>。换句话说，我们现在已经准备好训练神经网络了，本课程最困难的部分已经过去了！ConvNets相比只是向前走了一小步。</p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" target="_blank" rel="noopener">反向传播笔记</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Optimization</title>
    <link href="http://yoursite.com/2018/10/20/CS231n-Lecture-Optimization/"/>
    <id>http://yoursite.com/2018/10/20/CS231n-Lecture-Optimization/</id>
    <published>2018-10-20T09:18:06.000Z</published>
    <updated>2018-11-19T03:18:09.964Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="课程链接参考"><a href="#课程链接参考" class="headerlink" title="课程链接参考"></a>课程链接参考</h4><p>课程笔记：<a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="noopener">Optimization: Stochastic Gradient Descent</a></p><p>笔记翻译：<a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit" target="_blank" rel="noopener">最优化笔记（上）</a>、<a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit" target="_blank" rel="noopener">最优化笔记（下）</a></p><h4 id="损失函数可视化"><a href="#损失函数可视化" class="headerlink" title="损失函数可视化"></a>损失函数可视化</h4><h5 id="损失函数的分段线性结构"><a href="#损失函数的分段线性结构" class="headerlink" title="损失函数的分段线性结构"></a>损失函数的分段线性结构</h5><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://cs231n.github.io/assets/svmbowl.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>从一个维度方向上对数据损失值的展示。x轴方向就是一个权重，y轴就是损失值。数据损失是多个部分组合而成。其中每个部分要么是某个权重的<code>独立部分</code>，要么是该权重的线性函数与0阈值的比较。</p><h4 id="最优化-Optimization"><a href="#最优化-Optimization" class="headerlink" title="最优化 Optimization"></a>最优化 Optimization</h4><ul><li><code>最优化的目标就是找到能够最小化损失函数值的W</code></li></ul><h5 id="策略-1：一个差劲的初始方案：随机搜索"><a href="#策略-1：一个差劲的初始方案：随机搜索" class="headerlink" title="策略#1：一个差劲的初始方案：随机搜索"></a>策略#1：一个差劲的初始方案：随机搜索</h5><p>既然确认参数集<strong>W</strong>的好坏蛮简单的，那第一个想到的（差劲）方法，就是可以<code>随机尝试</code>很多不同的权重，然后看其中哪个最好。</p><p><strong>核心思路：迭代优化</strong>。我们的策略是从随机权重开始，然后迭代取优，从而获得更低的损失值。</p><h5 id="策略-2：随机本地搜索"><a href="#策略-2：随机本地搜索" class="headerlink" title="策略#2：随机本地搜索"></a><strong>策略#2：随机本地搜索</strong></h5><p>第一个策略可以看做是每走一步都尝试几个随机方向，如果某个方向是向山下的，就向该方向走一步。这次我们从一个随机$W$开始，然后生成一个<code>随机的扰动</code>$\delta W$ ，只有当$W+\delta W$的损失值变低，我们才会更新。</p><p>评价： 较策略一准确率更高些，但依然不够高，且过于浪费计算资源</p><h5 id="策略-3：跟随梯度"><a href="#策略-3：跟随梯度" class="headerlink" title="策略#3：跟随梯度"></a><strong>策略#3：跟随梯度</strong></h5><p>前两个策略中，我们是尝试在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以<code>直接计算出最好的方向</code>，这就是从数学上计算出最陡峭的方向。在蒙眼徒步者的比喻中，这个方法就好比是感受我们脚下山体的倾斜程度，然后向着<code>最陡峭</code>的下降方向下山。这个方向就是损失函数的<strong>梯度（gradient）</strong>.注：梯度就是在每个维度上偏导数所形成的向量。</p><h4 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h4><ol><li>缓慢的<code>近似</code>方法（<strong>数值梯度法numerical gradient</strong>），实现相对简单，但耗费计算资源太多</li><li><strong>分析梯度法analytic gradient</strong> 计算迅速，结果<code>精确</code>，但是实现时容易出错，且需要使用微分</li></ol><p>在实际操作时常常将<code>分析梯度法</code>的结果和<code>数值梯度法</code>的结果作比较，以此来<code>检查</code>其实现的正确性，这个步骤叫做<strong>梯度检查</strong></p><h5 id="利用有限差值计算梯度"><a href="#利用有限差值计算梯度" class="headerlink" title="利用有限差值计算梯度"></a><strong>利用有限差值计算梯度</strong></h5><p><strong>实践考量</strong>：实际中用<strong>中心差值公式（centered difference formula）</strong>$[f(x+h)-f(x-h)]/2h$效果较好</p><p><strong>步长的影响</strong>：梯度指明了函数在哪个方向是变化率最大的，但是没有指明在这个方向上应该走多远。小步长下降稳定但进度慢，大步长进展快但是风险更大。采取大步长可能导致错过最优点，让损失值上升。步长（后面会称其为<strong>学习率</strong>）将会是我们在调参中最重要的超参数之一。</p><p><strong>效率问题</strong>：这个策略不适合大规模数据，我们需要更好的策略。</p><h5 id="微分分析计算梯度"><a href="#微分分析计算梯度" class="headerlink" title="微分分析计算梯度"></a><strong>微分分析计算梯度</strong></h5><p>一旦将梯度的公式微分出来，代码实现公式并用于梯度更新就比较顺畅了.</p><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>现在可以计算损失函数的梯度了，程序重复地计算梯度然后<code>更新参数</code>，这一过程称为<em>梯度下降</em>.</p><p>核心思想不变，那就是我们一直跟着梯度走，直到结果不再变化。</p><h5 id="小批量数据梯度下降（Mini-batch-gradient-descent）"><a href="#小批量数据梯度下降（Mini-batch-gradient-descent）" class="headerlink" title="小批量数据梯度下降（Mini-batch gradient descent）"></a><strong>小批量数据梯度下降（Mini-batch gradient descent）</strong></h5><p>小批量数据的梯度就是对整个数据集梯度的一个近似。因此，在实践中通过计算小批量数据的梯度可以实现<code>更快</code>地收敛，并以此来进行更频繁的参数更新。(提高计算效率)</p><p>小批量数据的大小是一个超参数，但是一般并不需要通过交叉验证来调参。它一般由存储器的限制来决定的，或者干脆设置为同样大小，比如32，64，128等。</p><h5 id="随机梯度下降（Stochastic-Gradient-Descent-简称SGD）"><a href="#随机梯度下降（Stochastic-Gradient-Descent-简称SGD）" class="headerlink" title="随机梯度下降（Stochastic Gradient Descent 简称SGD）"></a><strong>随机梯度下降</strong>（Stochastic Gradient Descent 简称SGD）</h5><p>小批量数据策略有个极端情况，那就是每个批量中只有1个数据样本，这种策略被称为<strong>随机梯度下降（Stochastic Gradient Descent 简称SGD）</strong>。这种策略在实际情况中相对少见，因为向量化操作的代码一次计算100个数据 比100次计算1个数据要高效很多。</p><p>你有时会听到人们使用SGD来<code>指代</code>小批量数据梯度下降（或者用MGD来指代小批量数据梯度下降，而BGD来指代则相对少见）。</p><h5 id="提取图片特征（Image-Features）"><a href="#提取图片特征（Image-Features）" class="headerlink" title="提取图片特征（Image Features）"></a>提取图片特征（Image Features）</h5><ul><li><p>颜色直方图（Color Histogram）</p><p><img src="https://github.com/HusterHope/blogimage/raw/master/CS231n3-9.png" alt=""></p></li><li><p>定向梯度直方图（Histogram of Oriented Gradient）</p><p><img src="https://github.com/HusterHope/blogimage/raw/master/CS231n3-10.png" alt=""></p></li></ul><ul><li><p>词袋模型（Bag of Words）</p><p><img src="https://github.com/HusterHope/blogimage/raw/master/CS231n3-11.png" alt=""></p></li></ul><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://cs231n.github.io/assets/dataflow.jpeg" alt="Summary of the information flow" title="">                </div>                <div class="image-caption">Summary of the information flow</div>            </figure><p>最优化的目标就是找到能够最小化损失函数值的<strong>W</strong>.数据集中的(x,y)是给定的.<code>权重</code>从一个随机数字开始，且可以改变。在前向传播时，评分函数计算出类别的<code>分类评分</code>并存储在向量<strong>f</strong>中。<code>损失函数</code>包含两个部分：<u>数据损失</u>和<u>正则化损失</u>。其中，数据损失计算的是分类评分f和实际标签y之间的差异，<code>正则化损失只是一个关于权重的函数</code>。在梯度下降过程中，我们计算<code>权重的梯度</code>（如果愿意的话，也可以计算<code>数据上的梯度</code>），然后使用它们来实现参数的更新。</p><hr><ul><li>将<code>损失函数</code>比作了一个<strong>高维度的最优化地形</strong>，并尝试到达它的最底部。最优化的工作过程可以看做一个蒙着眼睛的徒步者希望摸索着走到山的底部。在例子中，可见SVM的损失函数是分段线性的，并且是碗状的。</li><li>提出了迭代优化的思想，从一个随机的权重开始，然后一步步地让损失值变小，直到最小。</li><li>函数的<strong>梯度</strong>给出了该函数最陡峭的上升方向。介绍了利用有限的差值来近似计算梯度的方法，该方法实现简单但是效率较低（有限差值就是<em>h</em>，用来计算数值梯度）。</li><li>参数更新需要有技巧地设置<strong>步长</strong>。也叫学习率。如果步长太小，进度稳定但是缓慢，如果步长太大，进度快但是可能有风险。</li><li>讨论权衡了数值梯度法和分析梯度法。数值梯度法计算简单，但结果只是近似且耗费计算资源。分析梯度法计算准确迅速但是实现容易出错，而且需要对梯度公式进行推导的数学基本功。因此，在实际中使用分析梯度法，然后使用<strong>梯度检查</strong>来检查其实现正确与否，其本质就是将分析梯度法的结果与数值梯度法的计算结果对比。</li><li>介绍了<strong>梯度下降</strong>算法，它在循环中迭代地计算梯度并更新参数。</li></ul><p>这节课的核心内容是：理解并能计算损失函数<strong>关于权重的梯度</strong>，是设计、训练和理解神经网络的核心能力。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Lecture_Linear_classification</title>
    <link href="http://yoursite.com/2018/10/18/CS231n-Lecture-SVM/"/>
    <id>http://yoursite.com/2018/10/18/CS231n-Lecture-SVM/</id>
    <published>2018-10-18T12:01:32.000Z</published>
    <updated>2018-11-20T12:54:28.283Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h3 id="课程链接"><a href="#课程链接" class="headerlink" title="课程链接"></a>课程链接</h3><ul><li><p><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">Linear classification: Support Vector Machine, Softmax</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/20918580" target="_blank" rel="noopener">线性分类笔记(上)</a>/<a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" target="_blank" rel="noopener">线性分类笔记(中)</a>/<a href="https://zhuanlan.zhihu.com/p/21102293" target="_blank" rel="noopener">线性分类笔记(下)</a></p></li></ul><h3 id="线性分类器"><a href="#线性分类器" class="headerlink" title="线性分类器"></a>线性分类器</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-a17e4ca30a831bd0.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>图像空间的示意图,其中每个图像是一个点,且有3个分类器.以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低.   <a href="http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/" target="_blank" rel="noopener">Interactive web demo</a></p><hr><h3 id="评分函数-Score-function"><a href="#评分函数-Score-function" class="headerlink" title="评分函数 Score function"></a>评分函数 Score function</h3><h4 id="线性映射"><a href="#线性映射" class="headerlink" title="线性映射"></a>线性映射</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-1bd42914c6f44015.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>$$ f(x_i,W,b)=Wx_i+b$$ </p><ul><li>W(Weights 权重) : [K*D] (W的每一行对应一个分类的模板(“原型”)) <code>如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转.</code><br> x_i(输入数据) : [D*1]     </li><li>b(bias vector 偏差向量) : [K*1] <code>允许分类器对应的直线平移.如果没有偏差,无论权重如何,在x_i=0时分类分值始终为0.这样所有分类器的线都不得不穿过原点.</code></li></ul><ol><li>该函数的输出值为对应各类别的score</li><li>我们的目的就是找到最优化的参数W、b,即为每一个分类找到最好的模板.</li><li>评分函数在正确的分类的位置应当得到最高的评分（score）</li></ol><h4 id="偏差和权重的合并Bias-trick"><a href="#偏差和权重的合并Bias-trick" class="headerlink" title="偏差和权重的合并Bias trick"></a>偏差和权重的合并Bias trick</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://cs231n.github.io/assets/wb.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>$$ f(x_i,W,b)=Wx_i+b\rightarrow f(x_i,W) = Wx_i$$ </p><p>其中，W[K*D]→W[K*(D+1)], x_i[D,1] → x_i[(D+1),1]</p><hr><h4 id="将线性分类器看作模板匹配"><a href="#将线性分类器看作模板匹配" class="headerlink" title="将线性分类器看作模板匹配"></a>将线性分类器看作模板匹配</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-5e1fbbb3ebc2d9c4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Interpretation of linear classifiers as template matching" title="">                </div>                <div class="image-caption">Interpretation of linear classifiers as template matching</div>            </figure><p>W的每一行为对应一个分类的模板(“原型”).注意，船的模板如期望的那样有很多蓝色像素。如果图像是一艘船行驶在大海上，那么这个模板利用内积计算图像将给出很高的分数。</p><hr><h4 id="图像数据预处理-Image-data-preprocessing"><a href="#图像数据预处理-Image-data-preprocessing" class="headerlink" title="图像数据预处理 Image data preprocessing"></a>图像数据预处理 Image data preprocessing</h4><ul><li><p>对于输入的特征做归一化（normalization）处理</p><ul><li><p>对每个特征减去平均值来<strong>中心化</strong>数据</p></li><li><p>归一. 区间变为[-1,1]</p></li></ul></li></ul><hr><h3 id="损失函数-Loss-function"><a href="#损失函数-Loss-function" class="headerlink" title="损失函数 Loss function"></a>损失函数 Loss function</h3><p>我们将使用损失函数（Loss Function）（有时也叫代价函数Cost Function或目标函数Objective）来衡量我们对结果的<strong>不满意程度</strong>。直观地讲，当评分函数输出结果与真实结果之间<strong>差异</strong>越大，损失函数输出越大，反之越小。，对<code>训练集中数据做出准确分类预测</code>和<code>让损失值最小化</code>这两件事是等价的。</p><hr><h4 id="多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss"><a href="#多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss" class="headerlink" title="多类支持向量机损失 Multiclass Support Vector Machine Loss"></a>多类支持向量机损失 Multiclass Support Vector Machine Loss</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://cs231n.github.io/assets/margin.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><a href="http://leohope.com/%E5%81%9A%E7%AC%94%E8%AE%B0/2017/08/22/CS231n-3/" target="_blank" rel="noopener">SVM的损失函数</a>想要SVM在正确分类上的得分始终比不正确分类上的得分高,且至少高出一个边界值delta.如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-69a890113e7bf295.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Hinge Loss" title="">                </div>                <div class="image-caption">Hinge Loss</div>            </figure>针对第i个数据的多类SVM的损失函数定义：<br>$$ L_i=\sum_{j\not=y_i}max(0,s_j-s_{y_i}+\Delta)$$ <h5 id="Data-Loss"><a href="#Data-Loss" class="headerlink" title="Data Loss"></a><strong>Data Loss</strong></h5><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/18/CS231n-Lecture-SVM/loss_i.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://github.com/HusterHope/blogimage/raw/master/CS231n3-3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>$$ L =  { \frac{1}{N} \sum_i L_i }$$ </p><h5 id="正则化-Regularization"><a href="#正则化-Regularization" class="headerlink" title="正则化 Regularization"></a><strong>正则化 Regularization</strong></h5><p><strong>防止过拟合</strong>：向损失函数增加一个<strong>正则化惩罚（regularization penalty） R(W)</strong>部分，使其不能完全匹配训练集.<br>最常用的正则化惩罚是L2范式，L2范式通过<code>对所有参数进行逐元素的平方惩罚</code>来<strong>抑制大数值的权重</strong>.对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响.<br>$$<br>R(W) = \sum_k\sum_l W_{k,l}^2<br>$$</p><p>需要注意的是，和权重不同，偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常<code>只</code>对权重$W$正则化，而不正则化偏差$b$。因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当$W=0$的特殊情况下，才能得到损失值为0</p><h5 id="完整的多类SVM损失函数"><a href="#完整的多类SVM损失函数" class="headerlink" title="完整的多类SVM损失函数"></a>完整的多类SVM损失函数</h5><p>$$ L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \frac{\lambda}{2} R(W) }_\text{regularization loss} \\\\$$ </p><p>将其展开完整公式是：<br>$$ L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \frac{\lambda}{2} \sum_k\sum_l W_{k,l}^2$$ </p><p>对于每一个输入数据$x_i$都有一个L值</p><h5 id="设置超参-Delta-和λ"><a href="#设置超参-Delta-和λ" class="headerlink" title="设置超参$\Delta$和λ"></a>设置超参$\Delta$和λ</h5><p>超参数$\Delta$和λ失函数中的数据损失和正则化损失之间的权衡。理解这一点的关键是要知道，权重<strong>W</strong>的大小对于分类分值有直接影响（当然对他们的差异也有直接影响）：当我们将<strong>W</strong>中值缩小，分类分值之间的差异也变小，反之亦然。因此，不同分类分值之间的边界的具体值（比如$\Delta$=1或$\Delta$=100).从某些角度来看是没意义的，因为<code>权重自己就可以控制差异变大和缩小</code>。也就是说，真正的权衡是我们允许权重能够变大到何种程度（通过<code>正则化强度λ</code>来控制）</p><h5 id="SVM-梯度计算"><a href="#SVM-梯度计算" class="headerlink" title="SVM 梯度计算"></a>SVM 梯度计算</h5><p>$$ L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]$$ </p><p>$$ \left\{\begin{aligned}\nabla_{w_{y_i}} L_i = & -\left(\sum_{j \ne y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0)\right)x_i & j = y_i \\\nabla_{w_j} L_i = & 1(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i & j \ne y_i\end{aligned}\right.$$ <br>其中$\mathbb{1}$是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。(<a href="./../Assignment-Implement-Note.html">代码实现中对dW的解释</a>)</p><hr><h4 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h4><p>与SVM不同，Softmax的输出（归一化的分类概率）更加直观，并且<code>从概率上可以解释</code>。在Softmax分类器中，函数映射$f(x_i;W)=Wx_i$保持不变，但将这些评分值视为每个分类的<code>未归一化</code>的对数概率，并且将<em>折叶损失（hinge loss）</em>替换为<strong>交叉熵损失</strong>（<strong>cross-entropy loss）</strong></p><p>公式如下：$\displaystyle Li=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})$ 或等价于 $L_i=-f_{y_i}+log(\sum_je^{f_j})$</p><h5 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h5><p>函数$f_j(z)=\frac{e^{z_j}}{\sum_ke^{z_k}}$被称作<strong>softmax 函数</strong>.函数对输入向量z(score值)进行压缩，输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1.<br>$$<br>P(y_i|x_i,W)=\frac{e^{f_{y_i}}}{\sum_je^{f_j}}<br>$$<br>可以解释为是给定图像数据$x_i$，以$W$为参数，分配给正确分类标签$y_i$的<strong>归一化概率</strong>。从概率论的角度来理解，我们就是在<code>最小化正确分类的负对数概率</code>(令正确分类的概率尽趋近于1，即令错误分类的概率均趋近于0)，这可以看做是在进行<em>最大似然估计</em>（MLE）。</p><h5 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h5><p>在“真实”分布(未知)$p$和估计分布(样本分布)$q$之间的<strong>交叉熵</strong>定义： $\displaystyle H(p,q)=-\sum_xp(x) logq(x)$</p><p>交叉熵损失函数“想要”<strong>预测分布的所有概率密度都在正确分类</strong>上,让预测分布与真实分布保持一致。Softmax分类器所做的就是<code>最小化</code>在<code>估计分类概率</code>（就是上面的$e^{f_{y_i}}/\sum_je^{f_j}$）和<code>“真实”分布</code>之间的<code>交叉熵</code>，在这个解释中，“真实”分布就是所有概率密度都分布在正确的类别上（比如：$p=[0,…1,…,0]$中在$y_i$的位置就有一个单独的1）</p><hr><h4 id="SVM和Softmax的比较"><a href="#SVM和Softmax的比较" class="headerlink" title="SVM和Softmax的比较"></a>SVM和Softmax的比较</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/18/CS231n-Lecture-SVM/SVMvsSoftmax.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量<strong>f</strong>（本节中是通过矩阵乘来实现）。不同之处在于对<strong>f</strong>中分值的解释：</p><p>SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。SVM的最终的损失值是1.58。</p><p>Softmax分类器将这些数值看做是每个分类没有归一化的<strong>对数概率</strong>，鼓励正确分类的归一化的对数概率变高，其余的变低。Softmax的最终的损失值是0.452。但要注意<code>SVM和Softmax的最终损失值(1.58和0.452)两个数值没有可比性</code>。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。</p><hr><p><strong>Softmax分类器为每个分类提供了“可能性”</strong>：可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，softmax分类器算出来的概率最好是看成一种对于分类正确性的置信水平。</p><hr><p><strong>在实际使用中，SVM和Softmax经常是相似的</strong>：通常说来，两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。</p><p>SVM更加“局部目标化（local objective）”.<code>SVM对于数字个体的细节是不关心的</code>：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM($\Delta$=1)来说没什么不同，只要满足超过边界值等于1，那么损失值就等于0。SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。</p><p>softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。</p><hr><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>定义了从图像像素映射到不同类别的分类评分的评分函数。在本节中，评分函数是一个基于权重<strong>W</strong>和偏差<strong>b</strong>的线性函数。</li><li>与kNN分类器不同，<strong>参数方法</strong>的优势在于一旦通过训练学习到了参数，就可以将训练数据丢弃了。同时该方法对于新的测试数据的预测非常快，因为只需要与权重<strong>W</strong>进行一个矩阵乘法运算。</li><li>介绍了偏差技巧，让我们能够将偏差向量和权重矩阵合二为一，然后就可以只跟踪一个矩阵。</li><li>定义了损失函数（介绍了SVM和Softmax线性分类器最常用的2个损失函数）。损失函数能够衡量给出的参数集与训练集数据真实类别情况之间的一致性。在损失函数的定义中可以看到，对训练集数据做出良好预测与得到一个足够低的损失值这两件事是等价的。</li></ul><p>现在我们知道了如何基于参数，将数据集中的图像映射成为分类的评分，也知道了两种不同的损失函数，它们都能用来衡量算法分类预测的质量。但是，如何高效地得到能够使损失值最小的参数呢？这个求得最优参数的过程被称为<a href="https://captainzj.github.io/2018/10/20/CS231n-Lecture-Optimization/" target="_blank" rel="noopener">最优化</a>.</p><p>参考：<a href="https://blog.csdn.net/bury_/article/details/76081639" target="_blank" rel="noopener">cs231n assignment1 svm</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>Concept_Note</title>
    <link href="http://yoursite.com/2018/10/18/Concept-Note/"/>
    <id>http://yoursite.com/2018/10/18/Concept-Note/</id>
    <published>2018-10-18T08:48:07.000Z</published>
    <updated>2018-11-19T06:33:59.970Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><ul><li><a href="https://blog.csdn.net/tangyudi/article/details/80124771" target="_blank" rel="noopener">score function</a>:<ul><li>得分函数的目的：我们要做的就是对于一个给定的输入，比如一张小猫的图片，通过一系列复杂的变换（中间的过程咱们暂且当做一个黑盒子）能得到这个输入对应于每个类别的得分数值.</li></ul></li><li><p><a href="http://leohope.com/%E5%81%9A%E7%AC%94%E8%AE%B0/2017/08/22/CS231n-3/" target="_blank" rel="noopener">Loss Fuction</a>:</p><ul><li>量化我们对训练结果的满意程度，换句话说，是衡量分类器的错误程度</li></ul></li><li><p>正则化</p><ul><li>正则化项即惩罚函数，该项对模型向量进行“惩罚”，从而避免单纯最小二乘问题的过拟合问题。</li></ul></li></ul><p><strong>激活函数（activation function）f</strong>：非线性函数，”扭曲”得分函数.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_Assignment_note</title>
    <link href="http://yoursite.com/2018/10/17/CS231n-Assignment-note/"/>
    <id>http://yoursite.com/2018/10/17/CS231n-Assignment-note/</id>
    <published>2018-10-17T12:57:13.000Z</published>
    <updated>2018-11-18T13:47:05.365Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><a href="https://blog.csdn.net/zhangxb35/article/details/55223825" target="_blank" rel="noopener">cs231n 课程作业 Assignment 1</a></p><p><a href="https://blog.csdn.net/zhangxb35/article/details/69568456" target="_blank" rel="noopener">cs231n 课程作业 Assignment 2</a></p><p><a href="https://blog.csdn.net/zhangxb35/article/details/70859075" target="_blank" rel="noopener">cs231n 课程作业 Assignment 3</a></p><p>可参考:</p><p><a href="https://www.jianshu.com/u/0ee5409b18bf" target="_blank" rel="noopener">https://www.jianshu.com/u/0ee5409b18bf</a></p><p><a href="standford-cs231n-assignment1">standford-cs231n-assignment1</a></p><h4 id="Assignment1"><a href="#Assignment1" class="headerlink" title="Assignment1"></a>Assignment1</h4><h4 id="Assignment2"><a href="#Assignment2" class="headerlink" title="Assignment2"></a>Assignment2</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- layers.py</span><br><span class="line">spatial_groupnorm_forward</span><br><span class="line">spatial_groupnorm_backward</span><br><span class="line">layernorm_forward</span><br><span class="line">layernorm_backward</span><br></pre></td></tr></table></figure><p><strong>Python Error: no module named ‘past’</strong></p><p>由于目前普遍使用的是python3版本，其中已经移除 xrange 这一操作（具体来说是与range合并了）。但是在作业的实例代码中考虑python2和python3版本的兼容，仍然使用了xrange操作。于是对于python3版本用户来说就需要重新引入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> past.builtins <span class="keyword">import</span> xrange</span><br></pre></td></tr></table></figure><p>但是在运行的时候就遇到了no module named ‘past’问题，原因是没有安装past库</p><p>但是这里比较坑的一点就是安装past库使用的代码竟然是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install future</span><br></pre></td></tr></table></figure><p>竟然是future！！！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Assignment_1_KNN</title>
    <link href="http://yoursite.com/2018/10/17/CS231n-Assignment-1-KNN/"/>
    <id>http://yoursite.com/2018/10/17/CS231n-Assignment-1-KNN/</id>
    <published>2018-10-17T09:39:40.000Z</published>
    <updated>2018-11-17T12:51:18.950Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】8 min 2043 words<br>【阅读内容】……</p><a id="more"></a><ul><li><p><a href="https://github.com/Captainzj/CS231n_Assignment/blob/master/assignment1/Presentation/knn.pdf" target="_blank" rel="noopener">效果演示</a></p></li><li><p><a href="https://github.com/Captainzj/CS231n_Assignment/tree/master/assignment1/cs231n/classifiers" target="_blank" rel="noopener">代码实现部分</a></p></li><li><p>计算test样本与training样本的L2距离.<br>L2距离的定义：$$ L_2(I_1,I_2) = \sqrt{{\sum_p{(I_1^p - I_2^p)^2}}} $$</p></li></ul><p>@card{</p><ol><li><code>Open cs231n/classifiers/k_nearest_neighbor.py and implement compute_distances_two_loops.</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_two_loops</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(num_train):</span><br><span class="line"></span><br><span class="line">        <span class="comment">#####################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></span><br><span class="line">        <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></span><br><span class="line">        <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></span><br><span class="line">        <span class="comment"># not use a loop over dimension.                                    #</span></span><br><span class="line">        <span class="comment">#####################################################################</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="comment">### X - X_test.shape == (500,3072)  X_train.shape = (5000,3072)</span></span><br><span class="line">        <span class="comment"># dists[i][j] = np.sqrt(np.sum((X[i]-self.X_train[j])**2))    </span></span><br><span class="line">        dists[i][j] = np.sqrt(np.sum(np.square(X[i,:] - self.X_train[j,:])))</span><br><span class="line">        <span class="comment">#####################################################################</span></span><br><span class="line">        <span class="comment">#                       END OF YOUR CODE                            #</span></span><br><span class="line">        <span class="comment">#####################################################################</span></span><br><span class="line">    <span class="keyword">return</span> dists  <span class="comment">#dists.shape = (500, 5000)</span></span><br></pre></td></tr></table></figure></li></ol><p>}</p><p>@card{</p><ol start="2"><li><code>Now lets speed up distance matrix computation by using partial vectorization with one loop. Implement the function compute_distances_one_loop</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_one_loop</span><span class="params">(self, X)</span>:</span></span><br><span class="line">  num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">  num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">  dists = np.zeros((num_test, num_train))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test):</span><br><span class="line">    <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></span><br><span class="line">    <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></span><br><span class="line">    <span class="comment"># points, and store the result in dists[i, :].                        #</span></span><br><span class="line">    <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># dists[i] = np.sqrt(np.sum((self.X_train - X[i]) ** 2, 1))</span></span><br><span class="line">    dists[i] = np.sqrt(np.sum(np.square(self.X_train - X[i]), axis=<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="comment">#                         END OF YOUR CODE                            #</span></span><br><span class="line">    <span class="comment">#######################################################################</span></span><br><span class="line">  <span class="keyword">return</span> dists  <span class="comment"># dists.shape = (500, 5000)</span></span><br></pre></td></tr></table></figure><p>}</p><p>@card{</p><ol start="3"><li><code>Now implement the fully vectorized version inside compute_distances_no_loops</code> <a href="https://blog.csdn.net/zhyh1435589631/article/details/54236643/#2234-computedistancesnoloops" target="_blank" rel="noopener">数学说明</a></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_no_loops</span><span class="params">(self, X)</span>:</span></span><br><span class="line"></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train)) </span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">    <span class="comment"># Compute the l2 distance between all test points and all training      #</span></span><br><span class="line">    <span class="comment"># points without using any explicit loops, and store the result in      #</span></span><br><span class="line">    <span class="comment"># dists.                                                                #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># You should implement this function using only basic array operations; #</span></span><br><span class="line">    <span class="comment"># in particular you should not use functions from scipy.                #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span></span><br><span class="line">    <span class="comment">#       and two broadcast sums.                                         #</span></span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    dists += np.sum(self.X_train ** <span class="number">2</span>, axis=<span class="number">1</span>).reshape(<span class="number">1</span>, num_train)</span><br><span class="line">    dists += np.sum(X ** <span class="number">2</span>, axis=<span class="number">1</span>).reshape(num_test, <span class="number">1</span>) <span class="comment"># reshape for broadcasting</span></span><br><span class="line">    dists -= <span class="number">2</span> * np.dot(X, self.X_train.T)</span><br><span class="line">    dists = np.sqrt(dists)</span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment">#                         END OF YOUR CODE                              #</span></span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="keyword">return</span> dists<span class="comment"># dists.shape = (500, 5000)</span></span><br></pre></td></tr></table></figure><p>}</p><p>@card{</p><ol start="4"><li><code>Now implement the function predict_labels</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_labels</span><span class="params">(self, dists, k=<span class="number">1</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    num_test = dists.shape[<span class="number">0</span>]</span><br><span class="line">    y_pred = np.zeros(num_test)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test):</span><br><span class="line">      <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></span><br><span class="line">      <span class="comment"># the ith test point.</span></span><br><span class="line">      closest_y = []</span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">      <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></span><br><span class="line">      <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></span><br><span class="line">      <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></span><br><span class="line">      <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># sorted_index = np.argsort(dists[i])</span></span><br><span class="line">      <span class="comment"># closest_y = self.y_train[sorted_index[:k]]</span></span><br><span class="line"></span><br><span class="line">      closest_y = self.y_train[np.argsort(dists[i])[:k]]</span><br><span class="line"></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">      <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></span><br><span class="line">      <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></span><br><span class="line">      <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></span><br><span class="line">      <span class="comment"># label.                                                                #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line">      y_pred[i] = np.bincount(closest_y).argmax()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># timeLabel = sorted([(np.sum(np.array(closest_y) == y_), y_) for y_ in set(closest_y)])[-1]</span></span><br><span class="line">      <span class="comment"># y_pred[i] = timeLabel[1]</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># appear_times = &#123;&#125;</span></span><br><span class="line">      <span class="comment"># for label in closest_y:</span></span><br><span class="line">      <span class="comment">#   if label in appear_times:</span></span><br><span class="line">      <span class="comment">#     appear_times[label] += 1</span></span><br><span class="line">      <span class="comment">#   else:</span></span><br><span class="line">      <span class="comment">#     appear_times[label] = 0</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># # find most commen label</span></span><br><span class="line">      <span class="comment"># y_pred[i] = max(appear_times, key=lambda x: appear_times[x])</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment">#                           END OF YOUR CODE                            # </span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure><p>}</p><p>@card{</p><ol start="5"><li><p><code>We will now determine the best value of this hyperparameter with cross-validation.</code><br>使用cross validation的方法，来选择hyper-parameter超参数k的值.<br>cross validation的原理是，将training样本集分成n份（如下图中的例子，是5份），每一份叫做一个fold，然后依次迭代这n个fold，将其作为validation集合，其余的n-1个fold一起作为training集合，然后进行训练并计算准确率。<br>选择一组候选k值，依次迭代执行上面描述的过程，最终根据准确率，进行评估选择最合适的k值.</p><p><img src="https://upload-images.jianshu.io/upload_images/5267500-c13d6a6b322baa1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">num_folds = <span class="number">5</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></span><br><span class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></span><br><span class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></span><br><span class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># Your code</span></span><br><span class="line">X_train_folds = np.array_split(X_train, num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train, num_folds)</span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment">#                                 END OF YOUR CODE                             #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></span><br><span class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></span><br><span class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></span><br><span class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></span><br><span class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></span><br><span class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></span><br><span class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></span><br><span class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># Your code</span></span><br><span class="line"><span class="keyword">for</span> k_candi <span class="keyword">in</span> k_choices:</span><br><span class="line">    k_to_accuracies[k_candi] = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_folds):</span><br><span class="line">        X_test_hy = X_train_folds[i]</span><br><span class="line">        y_test_hy = y_train_folds[i]</span><br><span class="line">        </span><br><span class="line">        X_train_hy = np.vstack(X_train_folds[<span class="number">0</span>:i]+X_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">        y_train_hy = np.hstack(y_train_folds[<span class="number">0</span>:i]+y_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         x_trai = np.array(X_train_folds[:f] + X_train_folds[f+1:])</span></span><br><span class="line"><span class="comment">#         y_trai = np.array(Y_train_folds[:f] + Y_train_folds[f+1:])</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#         x_trai = x_trai.reshape(-1, x_trai.shape[2])</span></span><br><span class="line"><span class="comment">#         y_trai = y_trai.reshape(-1)</span></span><br><span class="line">        </span><br><span class="line">        classifier.train(X_train_hy, y_train_hy)</span><br><span class="line">        dists_hy = classifier.compute_distances_no_loops(X_test_hy)</span><br><span class="line">        y_test_pred_hy = classifier.predict_labels(dists_hy, k=k_candi)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the fraction of correctly predicted examples</span></span><br><span class="line">        num_correct_hy = np.sum(y_test_pred_hy == y_test_hy)</span><br><span class="line">        accuracy_hy = float(num_correct_hy) / len(y_test_hy)</span><br><span class="line">        k_to_accuracies[k_candi].append(accuracy_hy)</span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment">#                                 END OF YOUR CODE                             #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"></span><br><span class="line">print(k_to_accuracies)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the computed accuracies</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> sorted(k_to_accuracies):</span><br><span class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</span><br><span class="line">        print(<span class="string">'k = %d, accuracy = %f'</span> % (k, accuracy))</span><br></pre></td></tr></table></figure><p>}</p><p>@card{</p><h5 id="numpy-matplotlib-部分函数说明"><a href="#numpy-matplotlib-部分函数说明" class="headerlink" title="numpy/matplotlib 部分函数说明"></a>numpy/matplotlib 部分函数说明</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> numpy.flatnonzero():  输入一个矩阵，返回了其中非零元素的位置</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> numpy.random.choice(a, size=<span class="keyword">None</span>, replace=<span class="keyword">True</span>, p=<span class="keyword">None</span>)</span><br><span class="line">  - a: If an ndarray, a random sample <span class="keyword">is</span> generated <span class="keyword">from</span> its elements. </span><br><span class="line">       If an int, the random sample <span class="keyword">is</span> generated <span class="keyword">as</span> <span class="keyword">if</span> a was np.arange(n) </span><br><span class="line">  - size : int <span class="keyword">or</span> tuple of ints, optional</span><br><span class="line">  - replace : boolean, optional </span><br><span class="line">    If you want only unique samples then this should be false.</span><br><span class="line">  - p : <span class="number">1</span>-D array-like, optional </span><br><span class="line">   The probabilities associated <span class="keyword">with</span> each entry <span class="keyword">in</span> a. If <span class="keyword">not</span> given the sample assumes a uniform distribution over all entries <span class="keyword">in</span> a.</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> matplotlib.pyplot.subplot(X,X,X)：</span><br><span class="line">  - 前两个数表示子图组成的矩阵的行列数，比如有<span class="number">6</span>个子图，排列成<span class="number">3</span>行<span class="number">2</span>列，那就是subplot(<span class="number">3</span>,<span class="number">2</span>,X)。最后一个数表示要画第X个图了。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> matplotlib.pyplot.imshow(X,interpolation=<span class="string">'none'</span>,cmap=<span class="keyword">None</span>)</span><br><span class="line">  - X: 要绘制的图像或数组.</span><br><span class="line">  - interpolation 插值方式 [<span class="keyword">None</span>, <span class="string">'none'</span>, <span class="string">'nearest'</span>, <span class="string">'bilinear'</span>, <span class="string">'bicubic'</span>, <span class="string">'spline16'</span>,</span><br><span class="line">           <span class="string">'spline36'</span>, <span class="string">'hanning'</span>, <span class="string">'hamming'</span>, <span class="string">'hermite'</span>, <span class="string">'kaiser'</span>, <span class="string">'quadric'</span>,</span><br><span class="line">           <span class="string">'catrom'</span>, <span class="string">'gaussian'</span>, <span class="string">'bessel'</span>, <span class="string">'mitchell'</span>, <span class="string">'sinc'</span>, <span class="string">'lanczos'</span>]</span><br><span class="line">  - cmap: 颜色图谱（colormap), 默认绘制为RGB(A)颜色空间.</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> numpy.reshape(a, newshape, order=<span class="string">'C'</span>)</span><br><span class="line">  - 注：给出一个m*n的矩阵，如果newshape给的参数是（x, <span class="number">-1</span>）,那么函数会自动判别newshape为（x, m*n/x）,这里的x一定要能被m*n整除！</span><br><span class="line"></span><br><span class="line"><span class="number">6.</span> numpy.argsort()：输出排好序的元素下标, a[np.argsort(a)]的结果才是最终排好序的结果.</span><br><span class="line"></span><br><span class="line"><span class="number">7.</span> numpy.binicount(x, weight = <span class="keyword">None</span>, minlength = <span class="keyword">None</span>) </span><br><span class="line">    &gt;&gt;&gt; x = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">7</span>])</span><br><span class="line">    &gt;&gt;&gt; np.bincount(x)</span><br><span class="line">        array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">8.</span> x_norm=np.linalg.norm(x, ord=<span class="keyword">None</span>, axis=<span class="keyword">None</span>, keepdims=<span class="keyword">False</span>)  </span><br><span class="line">  - linalg=linear（线性）+algebra（代数），norm则表示范数</span><br><span class="line">  - x: 表示矩阵（也可以是一维）</span><br><span class="line">  - ord：范数类型</span><br><span class="line">    - ord=<span class="number">1</span>：列和的最大值</span><br><span class="line">    - ord=<span class="number">2</span>：|λE-ATA|=<span class="number">0</span>，求特征值，然后求最大特征值的算术平方根</span><br><span class="line">    - ord=np.inf：行和的最大值</span><br><span class="line">  - axis：处理类型</span><br><span class="line">    - axis=<span class="number">1</span>表示按行向量处理，求多个行向量的范数</span><br><span class="line">    - axis=<span class="number">0</span>表示按列向量处理，求多个列向量的范数</span><br><span class="line">    - axis=<span class="keyword">None</span>表示矩阵范数</span><br><span class="line">  - keepding：是否保持矩阵的二维特性</span><br><span class="line">    - <span class="keyword">True</span>表示保持矩阵的二维特性，<span class="keyword">False</span>相反</span><br><span class="line"></span><br><span class="line"><span class="number">9.</span>  np.dot(A, B)：对于二维矩阵，计算真正意义上的矩阵乘积，同线性代数中矩阵乘法的定义.</span><br><span class="line"></span><br><span class="line"><span class="number">10.</span> sum(a, axis=<span class="keyword">None</span>, dtype=<span class="keyword">None</span>, out=<span class="keyword">None</span>, keepdims=&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">_globals</span>.<span class="title">_NoValue</span>'&gt;)</span></span><br><span class="line"><span class="class">  - <span class="title">axis</span> :</span></span><br><span class="line">    - axis = <span class="keyword">None</span>: 对所有元素求和</span><br><span class="line">    - axis = <span class="number">0</span>: 对所有在同一列的元素求和</span><br><span class="line">    - axis = <span class="number">1</span>: 对所有在同一行的元素求和</span><br><span class="line"></span><br><span class="line"><span class="number">11.</span> np.vstack(tup): 沿着竖直方向将矩阵堆叠起来</span><br><span class="line">  - Note: the arrays must have the same shape along all but the first axis. 除开第一维外，被堆叠的矩阵各维度要一致.</span><br><span class="line"></span><br><span class="line"><span class="number">12.</span> np.hstack(tup):沿着水平方向将数组堆叠起来</span><br><span class="line"></span><br><span class="line"><span class="number">13.</span> plt.scatter(X, Y)： 散点图 (x,y)即坐标</span><br><span class="line"></span><br><span class="line"><span class="number">14.</span> np.random.randn(d0,d1,…,dn)</span><br><span class="line">   - randn函数返回一个或一组样本，具有标准正态分布。</span><br><span class="line">   - d表示维度</span><br><span class="line">   - 返回值为指定维度的array</span><br></pre></td></tr></table></figure><p>}</p><p>@card{</p><h5 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h5><p>即使经过调优，knn算法的准确率也不足30%，可以知道knn算法并不适合用于图像分类学习任务.</p><p>}</p><p>@card{</p><p>参考：</p><ul><li><p><a href="https://blog.csdn.net/zhyh1435589631/article/details/54236643" target="_blank" rel="noopener">【实验小结】cs231n assignment1 knn 部分</a></p></li><li><p><a href="https://blog.csdn.net/zhangxb35/article/details/55223825" target="_blank" rel="noopener">cs231n 课程作业 Assignment 1</a>、<a href="https://xyiyy.github.io/2017/02/27/standford-cs231n-assignment1/" target="_blank" rel="noopener">standford-cs231n-assignment1</a></p></li></ul><p>}</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】8 min 2043 words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
      <category term="Assignment" scheme="http://yoursite.com/tags/Assignment/"/>
    
  </entry>
  
  <entry>
    <title>Assignment_1_SVM</title>
    <link href="http://yoursite.com/2018/10/17/CS231n-Assignment-1-SVM/"/>
    <id>http://yoursite.com/2018/10/17/CS231n-Assignment-1-SVM/</id>
    <published>2018-10-17T09:39:40.000Z</published>
    <updated>2018-11-17T14:16:57.142Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】8 min 2043 words<br>【阅读内容】……</p><a id="more"></a><ul><li><p><a href="https://github.com/Captainzj/CS231n_Assignment/blob/master/assignment1/svm.ipynb" target="_blank" rel="noopener">效果演示</a></p></li><li><p><a href="https://github.com/Captainzj/CS231n_Assignment/blob/master/assignment1/cs231n/classifiers/linear_svm.py" target="_blank" rel="noopener">代码实现部分</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】8 min 2043 words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="MachineLearning" scheme="http://yoursite.com/categories/MachineLearning/"/>
    
    
      <category term="CS231n" scheme="http://yoursite.com/tags/CS231n/"/>
    
      <category term="Assignment" scheme="http://yoursite.com/tags/Assignment/"/>
    
  </entry>
  
  <entry>
    <title>Python_Note</title>
    <link href="http://yoursite.com/2018/10/04/Python-Note/"/>
    <id>http://yoursite.com/2018/10/04/Python-Note/</id>
    <published>2018-10-04T05:28:48.000Z</published>
    <updated>2018-10-06T06:25:05.122Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h5><ul><li><p>字符串是一个sequence</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">word = <span class="string">'hello'</span></span><br><span class="line"><span class="keyword">for</span> letter <span class="keyword">in</span> word:</span><br><span class="line">    print(letter)</span><br></pre></td></tr></table></figure></li></ul><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><ul><li>python函数参数传递可以理解为就是变量传值操作</li></ul><h4 id="enumerate-使用"><a href="#enumerate-使用" class="headerlink" title="enumerate()使用"></a>enumerate()使用</h4><ul><li>如果对一个列表，既要遍历索引又要遍历元素时，首先可以这样写：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="string">"这"</span>, <span class="string">"是"</span>, <span class="string">"一个"</span>, <span class="string">"测试"</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range (len(list1)):</span><br><span class="line">    <span class="keyword">print</span> i ,list1[i]<span class="number">123</span></span><br></pre></td></tr></table></figure><ul><li>上述方法有些累赘，利用enumerate()会更加直接和优美：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="string">"这"</span>, <span class="string">"是"</span>, <span class="string">"一个"</span>, <span class="string">"测试"</span>]</span><br><span class="line"><span class="keyword">for</span> index, item <span class="keyword">in</span> enumerate(list1):</span><br><span class="line">    <span class="keyword">print</span> index, item</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">0</span> 这</span><br><span class="line"><span class="number">1</span> 是</span><br><span class="line"><span class="number">2</span> 一个</span><br><span class="line"><span class="number">3</span> 测试<span class="number">12345678</span></span><br></pre></td></tr></table></figure><ul><li>enumerate还可以接收第二个参数，用于指定索引起始值，如：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="string">"这"</span>, <span class="string">"是"</span>, <span class="string">"一个"</span>, <span class="string">"测试"</span>]</span><br><span class="line"><span class="keyword">for</span> index, item <span class="keyword">in</span> enumerate(list1, <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">print</span> index, item</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">1</span> 这</span><br><span class="line"><span class="number">2</span> 是</span><br><span class="line"><span class="number">3</span> 一个</span><br><span class="line"><span class="number">4</span> 测试</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
