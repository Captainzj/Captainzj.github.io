<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Go Further</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-23T08:15:31.966Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>CaptainSE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PyTorch中文网_归档</title>
    <link href="http://yoursite.com/2019/01/22/PyTorch%E4%B8%AD%E6%96%87%E7%BD%91-%E5%BD%92%E6%A1%A3/"/>
    <id>http://yoursite.com/2019/01/22/PyTorch中文网-归档/</id>
    <published>2019-01-22T15:54:53.000Z</published>
    <updated>2019-01-23T08:15:31.966Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="PyTorch-版本"><a href="#PyTorch-版本" class="headerlink" title="PyTorch 版本"></a>PyTorch 版本</h4><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-first-time-user/" target="_blank" rel="noopener">Pytorch 初体验（一个优雅的框架）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/why-ai-and-machine-learning-researchers-are-beginning-to-embrace-pytorch/" target="_blank" rel="noopener">为什么机器学习研究者都投入了 PyTorch 的怀抱？</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-chinese-doc/" target="_blank" rel="noopener">PyTorch 中文文档发布</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-0-2/" target="_blank" rel="noopener">PyTorch 推出0.2版本：加入分布式机器学习功能</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-0-3-0-release/" target="_blank" rel="noopener">PyTorch 0.3.0 发布，性能大幅提升，支持 Cuda 9，修复众多 bugs</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-0-4-0-migration-guide/" target="_blank" rel="noopener">PyTorch 0.4.0 迁移指南</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-0-4-1-release/" target="_blank" rel="noopener">PyTorch 0.4.1 发布</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-1-0/" target="_blank" rel="noopener">PyTorch 1.0 正式版发布（包含更新的安装命令）</a></strong></li></ul><h4 id="PyTorch-教程"><a href="#PyTorch-教程" class="headerlink" title="PyTorch 教程"></a>PyTorch 教程</h4><h5 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-yolov2/" target="_blank" rel="noopener">PyTorch 实现 YOLOv2</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/yolo3-in-pytorch-1/" target="_blank" rel="noopener">从头开始用 PyTorch 实现 YOLO (v3) 教程（一）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/yolo3-in-pytorch-2/" target="_blank" rel="noopener">从头开始用 PyTorch 实现 YOLO (v3) 教程（二）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/yolo3-in-pytorch-3/" target="_blank" rel="noopener">从头开始用 PyTorch 实现 YOLO (v3) 教程（三）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/yolo3-in-pytorch-4/" target="_blank" rel="noopener">从头开始用 PyTorch 实现 YOLO (v3) 教程（四）</a></strong></li></ul><h5 id="Flask系列"><a href="#Flask系列" class="headerlink" title="Flask系列"></a>Flask系列</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/use-flask-to-build-pytorch-server/" target="_blank" rel="noopener">利用 Flask 搭建 PyTorch 深度学习服务</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/fastai-tutorial-1-installation/" target="_blank" rel="noopener">fastai 系列教程（一）- 安装</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/fastai-tutorial-2-overview-mnist/" target="_blank" rel="noopener">fastai 系列教程（二）- 快速入门 MNIST 示例</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/fastai-tutorial-3-cifar10/" target="_blank" rel="noopener">fastai 系列教程（三）- CIFAR10 示例</a></strong></li></ul><h5 id="源码浅析"><a href="#源码浅析" class="headerlink" title="源码浅析"></a>源码浅析</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/how-to-read-pytorch-source-code/" target="_blank" rel="noopener">如何有效地阅读 PyTorch 的源代码？</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-code-reading-network/" target="_blank" rel="noopener">Pytorch 源码与运行原理浅析 - 网络篇</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-python-layer/" target="_blank" rel="noopener">PyTorch 源码分析：Python 层</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-codes-1/" target="_blank" rel="noopener">PyTorch 源码浅析（一）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-codes-2/" target="_blank" rel="noopener">PyTorch 源码浅析（二）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-codes-3/" target="_blank" rel="noopener">PyTorch 源码浅析（三）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-source-codes-4/" target="_blank" rel="noopener">PyTorch 源码浅析（四）</a></strong></li></ul><h5 id="10分钟快速入门"><a href="#10分钟快速入门" class="headerlink" title="10分钟快速入门"></a>10分钟快速入门</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-0/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (0) - 基础</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-1/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (1) - 线性回归</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-2/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (2) - 逻辑回归</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-3/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (3) - 神经网络</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-4/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (4) - CNN</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-5/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (5) - RNN</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-6/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (6) - LSTM for MNIST</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-7/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (7) - Word Embedding</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-8/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (8) - Word Prediction</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-9/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (9) - LSTM 词性判断</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-10/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (10) - GAN</a></strong></li></ul><h5 id="PyTorch-入门"><a href="#PyTorch-入门" class="headerlink" title="PyTorch 入门"></a>PyTorch 入门</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-60-minuites/" target="_blank" rel="noopener">PyTorch深度学习：60分钟入门</a></strong></li></ul><h5 id="PyTorch-学习笔记"><a href="#PyTorch-学习笔记" class="headerlink" title="PyTorch 学习笔记"></a>PyTorch 学习笔记</h5><ul><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note1-what-is-pytorch/" target="_blank" rel="noopener">PyTorch 学习笔记（一）：什么是 PyTorch</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note2-gradient/" target="_blank" rel="noopener">PyTorch 学习笔记（二）：关于Gradient</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note3-autograd/" target="_blank" rel="noopener">PyTorch 学习笔记（三）：自动求导</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note4-input-data-pipeline/" target="_blank" rel="noopener">PyTorch 学习笔记（四）：自定义 Dataset 和输入流</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note5-save-and-restore-models/" target="_blank" rel="noopener">PyTorch 学习笔记（五）：存储和恢复模型并查看参数</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-note6-pytorch-hook-and-pytorch-backward/" target="_blank" rel="noopener">PyTorch 学习笔记（六）：PyTorch hook 和关于 PyTorch backward 过程的理解</a></strong></li></ul><h5 id="PyTorch-细节详解"><a href="#PyTorch-细节详解" class="headerlink" title="PyTorch 细节详解"></a>PyTorch 细节详解</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-how-to-write-your-own-module/" target="_blank" rel="noopener">PyTorch 如何自定义 Module</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-learning-rate-decay/" target="_blank" rel="noopener">如何在 PyTorch 中设定学习率衰减（learning rate decay）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/" target="_blank" rel="noopener">什么情况下应该设置 cudnn.benchmark = True？</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-backward/" target="_blank" rel="noopener">PyTorch 中 backward() 详解</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-custom-dataset-examples/" target="_blank" rel="noopener">PyTorch 中自定义数据集的读取方法小结</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-tensor-broadcasting/" target="_blank" rel="noopener">PyTorch 中 Tensor Broadcasting 详解</a></strong></li></ul><h5 id="莫烦-PyTorch"><a href="#莫烦-PyTorch" class="headerlink" title="莫烦 PyTorch"></a>莫烦 PyTorch</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/1-1-why-pytorch/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 1.1 - Why PyTorch?</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/1-2-install-pytorch/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 1.2 - 安装 PyTorch</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/2-1-torch-vs-numpy/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 2.1 - Torch vs Numpy</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/2-2-variable/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 2.2 - 变量 (Variable)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/2-3-activation/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 2.3 - 激励函数 (Activation)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-1-regression/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 3.1 - 关系拟合 (回归 Regression)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-2-classification/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 3.2 - 区分类型 (分类 Classification)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-3-sequential-cnn-model/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 3.3 - 快速搭建回归神经网络</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-4-save-and-restore-model/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 3.4 - 保存和恢复模型</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-5-data-loader/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程] 3.5 - 数据读取 (Data Loader)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/3-6-optimizer/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]3.6 - 优化器 (Optimizer)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-1-cnn/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.1 - CNN 卷积神经网络</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-2-rnn-for-classification/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.2 - RNN 循环神经网络 (分类 Classification)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-3-rnn-for-regression/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.3 - RNN 循环神经网络 (回归 Regression)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-4-autoencoder/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.4 - AutoEncoder (自编码/非监督学习)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-5-dqn-reinforcement-learning/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.5 - DQN 强化学习 (Reinforcement Learning)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/4-6-gan-generative-adversarial-nets/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]4.6 - GAN (Generative Adversarial Nets 生成对抗网络)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/5-1-why-dynamic/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]5.1 - 为什么 Torch 是动态的</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/5-2-gpu-in-pytorch/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]5.2 - GPU 加速运算</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/5-3-dropout-to-prevent-overfitting/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]5.3 - Dropout 防止过拟合</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/5-4-batch-normalization/" target="_blank" rel="noopener">[莫烦 PyTorch 系列教程]5.4 - Batch Normalization 批标准化</a></strong></li></ul><h5 id="PyTorch-工具"><a href="#PyTorch-工具" class="headerlink" title="PyTorch 工具"></a>PyTorch 工具</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/using-visdom-for-visualization-in-pytorch/" target="_blank" rel="noopener">使用 Visdom 在 PyTorch 中进行可视化</a></strong></li><li style="list-style: none"><input type="checkbox" checked> <strong><a href="https://www.pytorchtutorial.com/pytorch-visdom/" target="_blank" rel="noopener">PyTorch 可视化工具 Visdom 介绍</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-tensorboardx/" target="_blank" rel="noopener">PyTorch 使用 TensorboardX 进行网络可视化</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-docker/" target="_blank" rel="noopener">PyTorch 的 Docker 镜像</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-ignite/" target="_blank" rel="noopener">PyTorch 的高抽象库 Ignite 简介</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/distiller-compress-pytorch-model/" target="_blank" rel="noopener">用 Distiller 压缩 PyTorch 模型</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-to-caffe/" target="_blank" rel="noopener">PyTorch 到 Caffe 的模型转换工具</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/graphpipe-deploy-pytorch-using-tensorflow/" target="_blank" rel="noopener">GraphPipe：在 TensorFlow 部署 PyTorch 模型</a></strong></li></ul><h5 id="教学课程"><a href="#教学课程" class="headerlink" title="教学课程"></a>教学课程</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/cs230-pytorch/" target="_blank" rel="noopener">吴恩达斯坦福 CS230 深度学习课程（含PyTorch部分）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/hongkong-pytorch-in-four-days/" target="_blank" rel="noopener">香港科技大学 PyTorch 四日速成教程</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/deep-learning-with-pytorch-video/" target="_blank" rel="noopener">爱可可老师推荐的 PyTorch 深度学习视频教程下载 [无需梯子]</a></strong></li></ul><h5 id="论文复现"><a href="#论文复现" class="headerlink" title="论文复现"></a>论文复现</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-wavenet/" target="_blank" rel="noopener">PyTorch 实现 Wavenet</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-dqn/" target="_blank" rel="noopener">PyTorch DQN（深度Q网络）示例</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-feature-pyramid-networks/" target="_blank" rel="noopener">PyTorch 实现特征金字塔网络 Feature Pyramid Network (FPN)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-mask-rcnn/" target="_blank" rel="noopener">PyTorch 实现 Mask-RCNN</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/deepdream-pytorch/" target="_blank" rel="noopener">DeepDream 的 PyTorch 实现</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-sequence-model-and-lstm-networks/" target="_blank" rel="noopener">PyTorch 实现序列模型和基于LSTM的循环神经网络</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-improved-training-of-wasserstein-gans-wgan-gp/" target="_blank" rel="noopener">PyTorch 实现论文 “Improved Training of Wasserstein GANs” (WGAN-GP)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-lrgan/" target="_blank" rel="noopener">PyTorch 实现 LR-GAN</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-policy-gradient/" target="_blank" rel="noopener">PyTorch 实现各种 Policy Gradient 算法 (REINFORCE, NPG, TRPO, PPO)</a></strong></li></ul><h5 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-sample-gan/" target="_blank" rel="noopener">用 PyTorch 实现一个基本 GAN 网络学习正态分布</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-installation-commands/" target="_blank" rel="noopener">PyTorch 官方安装命令合集</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-for-numpy-users/" target="_blank" rel="noopener">面向 Numpy 用户的 PyTorch 速查表</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/aws-ami-pytorch/" target="_blank" rel="noopener">AWS 深度学习 AMI 现在支持 PyTorch 部署</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/50-lines-of-codes-for-gan/" target="_blank" rel="noopener">50行代码实现GAN（PyTorch）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/use-pytorch-on-mac-with-egpu-nvidia-titan-xp/" target="_blank" rel="noopener">在 Mac OS 上搭配外置 eGPU (NVIDIA Titan XP) 安装和使用 PyTorch</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-large-batches-multi-gpu-and-distributed-training/" target="_blank" rel="noopener">PyTorch 大批量数据在单个或多个 GPU 训练指南</a></strong></li></ul><h4 id="PyTorch-项目"><a href="#PyTorch-项目" class="headerlink" title="PyTorch 项目"></a>PyTorch 项目</h4><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/ios-neural-style-transfer-using-pytorch-and-coreml/" target="_blank" rel="noopener">在 iOS 上用 PyTorch 和 CoreML 实现图像风格迁移 (Neural Style Transfer)</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/augmentations-faster-than-torchvision/" target="_blank" rel="noopener">用 OpenCV 实现比 Torchvision 更快的图像增广（Augmentations）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/cvpr-ntire-2018-image-super-resolution/" target="_blank" rel="noopener">CVPR NTIRE 2018 超分辨比赛第一名 作者开源 PyTorch 实现</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/github-nlp-with-pytorch/" target="_blank" rel="noopener">Github 上 Star 过千的 NLP 相关项目</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-retinanet/" target="_blank" rel="noopener">PyTorch 实现 RetinaNet 目标检测</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-opennmt/" target="_blank" rel="noopener">用 PyTorch 实现 OpenNMT 翻译系统</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-1-0-ssd/" target="_blank" rel="noopener">用 PyTorch 1.0 实现快速高效的 SSD，提供预训练模型</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-1-0-faster-r-cnn-mask-r-cnn/" target="_blank" rel="noopener">官方 PyTorch 1.0 实现 Faster R-CNN 和 Mask R-CNN</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-image-dehazing/" target="_blank" rel="noopener">PyTorch 实现 AOD-Net 图片去雾</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/nn_tools/" target="_blank" rel="noopener">NN-Tools：神经网络工具集（转换/构建/分析器）</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/everybody-dance-now/" target="_blank" rel="noopener">人人皆为舞王 - Everybody Dance Now 的 PyTorch 实现</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/kaggle-pytorch-starter-kit/" target="_blank" rel="noopener">Kaggle 比赛的 PyTorch Starter Kit</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/batch-norm-fusion-pytorch/" target="_blank" rel="noopener">模型推理加速方法 Batch Norm Fusion 的 PyTorch 实现，可提速 30%</a></strong></li></ul><h5 id="PyTorch-应用"><a href="#PyTorch-应用" class="headerlink" title="PyTorch 应用"></a>PyTorch 应用</h5><ul><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-rnn-for-name-classification/" target="_blank" rel="noopener">PyTorch 实现循环神经网络判断人名属于哪个国家的常用名</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-one-shot-learning/" target="_blank" rel="noopener">PyTorch 实现孪生网络识别面部相似度</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-cnn-image-classification/" target="_blank" rel="noopener">PyTorch 实战：使用卷积神经网络对照片进行分类</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-rnn-name-classification/" target="_blank" rel="noopener">Pytorch实战：使用 RNN 对姓名进行分类</a></strong></li><li style="list-style: none"><input type="checkbox"> <strong><a href="https://www.pytorchtutorial.com/pytorch-style-transfer/" target="_blank" rel="noopener">PyTorch 实现风格迁移 (style transfer)</a></strong></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>10分钟快速入门 PyTorch</title>
    <link href="http://yoursite.com/2019/01/22/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-PyTorch/"/>
    <id>http://yoursite.com/2019/01/22/10分钟快速入门-PyTorch/</id>
    <published>2019-01-22T15:43:52.000Z</published>
    <updated>2019-01-22T16:43:09.535Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Catalogue"><a href="#Catalogue" class="headerlink" title="Catalogue"></a>Catalogue</h2><p><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-0/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (0) - 基础</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-1/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (1) - 线性回归</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-2/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (2) - 逻辑回归</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-3/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (3) - 神经网络</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-4/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (4) - CNN</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-5/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (5) - RNN</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-6/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (6) - LSTM for MNIST</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-7/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (7) - Word Embedding</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-8/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (8) - Word Prediction</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-9/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (9) - LSTM 词性判断</a></strong><br><strong><a href="https://www.pytorchtutorial.com/10-minute-pytorch-10/" target="_blank" rel="noopener">10分钟快速入门 PyTorch (10) - GAN</a></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch 学习笔记</title>
    <link href="http://yoursite.com/2019/01/22/PyTorch-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/01/22/PyTorch-学习笔记/</id>
    <published>2019-01-22T07:44:19.000Z</published>
    <updated>2019-01-23T08:14:44.528Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Catalogue"><a href="#Catalogue" class="headerlink" title="Catalogue"></a>Catalogue</h2><p><strong><a href="https://www.pytorchtutorial.com/pytorch-note1-what-is-pytorch/" target="_blank" rel="noopener">PyTorch 学习笔记（一）：什么是 PyTorch</a></strong><br><strong><a href="https://www.pytorchtutorial.com/pytorch-note2-gradient/" target="_blank" rel="noopener">PyTorch 学习笔记（二）：关于Gradient</a></strong><br><strong><a href="https://www.pytorchtutorial.com/pytorch-note3-autograd/" target="_blank" rel="noopener">PyTorch 学习笔记（三）：自动求导</a></strong><br><strong><a href="https://www.pytorchtutorial.com/pytorch-note4-input-data-pipeline/" target="_blank" rel="noopener">PyTorch 学习笔记（四）：自定义 Dataset 和输入流</a></strong><br><strong><a href="https://www.pytorchtutorial.com/pytorch-note5-save-and-restore-models/" target="_blank" rel="noopener">PyTorch 学习笔记（五）：存储和恢复模型并查看参数</a></strong><br><strong><a href="https://www.pytorchtutorial.com/pytorch-note6-pytorch-hook-and-pytorch-backward/" target="_blank" rel="noopener">PyTorch 学习笔记（六）：PyTorch hook 和关于 PyTorch backward 过程的理解</a></strong></p><h2 id="PyTorch-学习笔记（一）"><a href="#PyTorch-学习笔记（一）" class="headerlink" title="PyTorch 学习笔记（一）"></a>PyTorch 学习笔记（一）</h2><h3 id="如何保存参数"><a href="#如何保存参数" class="headerlink" title="如何保存参数"></a>如何保存参数</h3><p>pytorch中有两种变量类型，一个是Tensor，一个是Variable.</p><blockquote><p><code>Tensor</code>： 就像ndarray一样,一维Tensor叫Vector，二维Tensor叫Matrix，三维及以上称为Tensor<br><code>Variable</code>：是Tensor的一个<code>wrapper</code>，不仅保存了值，而且保存了这个值的creator，需要BP的网络都是Variable参与运算</p></blockquote><h3 id="neural-networks"><a href="#neural-networks" class="headerlink" title="neural networks"></a>neural networks</h3><p>使用torch.nn包中的工具来构建神经网络 需要以下几步：</p><ol><li>定义神经网络的权重,搭建网络结构</li><li>遍历整个数据集进行训练</li><li>将数据输入神经网络</li><li>计算loss</li><li>计算网络权重的梯度</li><li>更新网络权重<ul><li>weight = weight + learning_rate * gradient</li></ul></li></ol><h2 id="PyTorch-学习笔记（二）"><a href="#PyTorch-学习笔记（二）" class="headerlink" title="PyTorch 学习笔记（二）"></a>PyTorch 学习笔记（二）</h2><h3 id="torch-autograd"><a href="#torch-autograd" class="headerlink" title="torch.autograd"></a>torch.autograd</h3><blockquote><p>torch.autograd包可以使模型参数自动计算在优化过程中需要用到的梯度值，降低了实现后向传播代码的复杂度</p></blockquote><ol><li>w1 = Variable(…, requires_grad = True)</li><li>loss.backward() #让模型根据计算图自动计算每个节点的梯度值并根据需求进行保留</li><li>w1.grad.data.zero_() #将grad置零</li></ol><h3 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h3><blockquote><p>如果每个参数的更新都要<code>w1.data.sub_(learning_rate*w1.grad.data)</code> (等价于<code>w1.data -= learning_rate * w1.grad.data</code>)，那就比较头疼了。还好，pytorch为我们提供了torch.optim包，这个包可以简化我们更新参数的操作。</p></blockquote><ol><li>optimzer = torch.optim.Adam(models.parameters(), lr = learning_rate)</li><li>optimzer.step()</li></ol><h3 id="关于-backward"><a href="#关于-backward" class="headerlink" title="关于 backward()"></a>关于 backward()</h3><blockquote><p><a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener">torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None)</a></p></blockquote><p><strong>Parameters:</strong> </p><ul><li><strong>retain_graph</strong> (bool, optional) – If <code>False</code>, the graph used to compute the grad will be <em>freed</em>. Note that in nearly all cases setting this option to <code>True</code> is <em>not needed</em> and often can be worked around in a much more efficient way. Defaults to the value of <code>create_graph</code>.</li></ul><h2 id="PyTorch-学习笔记（三）"><a href="#PyTorch-学习笔记（三）" class="headerlink" title="PyTorch 学习笔记（三）"></a>PyTorch 学习笔记（三）</h2><h3 id="Backward过程中排除子图"><a href="#Backward过程中排除子图" class="headerlink" title="Backward过程中排除子图"></a>Backward过程中排除子图</h3><p>pytorch的BP过程是由一个函数决定的，loss.backward()， 可以看到backward()函数里并没有传要求谁的梯度。那么我们可以大胆猜测，在BP的过程中，pytorch是<code>将所有影响loss的Variable都求了一次梯度</code>。但是有时候，我们并不想求所有Variable的梯度(浪费计算资源)。那就要<code>考虑如何在Backward过程中排除子图</code>（ie.排除没必要的梯度计算）。<br>如何BP过程中排除子图？ Variable的两个参数（<code>requires_grad</code>和<code>volatile挥发性</code>）</p><ul><li><p>requires_grad = False</p><ul><li><p>变量的requires_grad标记的运算就相当于or</p><pre><code>x (x.requires_grad=False) + y (y.requires_grad=False) -&gt;&gt; a (a.requires_grad=False)a (a.requires_grad=False) + z (z.requires_grad=True) -&gt;&gt; b (b.requires_grad=True)</code></pre></li></ul></li><li><p>volatile = True</p><ul><li><p>变量的volatile标记的运算也相当于or</p><pre><code>k (k.volatile=False) + m (m.volatile=False) -&gt;&gt; n (n.volatile=False)k (k.volatile=False) + j (j.volatile=True) -&gt;&gt; o (o.volatile=True)</code></pre></li></ul></li></ul><p>注意：<code>volatile=True相当于requires_grad=False</code>。但是在纯推断模式的时候，只要是输入volatile=True，那么输出Variable的volatile必为True。这就比使用requires_grad=False方便(???)多了。    </p><h2 id="PyTorch-学习笔记（四）"><a href="#PyTorch-学习笔记（四）" class="headerlink" title="PyTorch 学习笔记（四）"></a>PyTorch 学习笔记（四）</h2><h3 id="什么是Datasets"><a href="#什么是Datasets" class="headerlink" title="什么是Datasets"></a>什么是Datasets</h3><p>在输入流水线中，我们看到准备数据的代码是这么写的<code>data = datasets.CIFAR10(“./data/”, transform=transform, train=True, download=True)</code>。datasets.CIFAR10就是一个Datasets<code>子类</code>，data是这个类的一个<code>实例</code>。</p><h3 id="为什么要定义Datasets"><a href="#为什么要定义Datasets" class="headerlink" title="为什么要定义Datasets"></a>为什么要定义Datasets</h3><p>PyTorch提供了一个工具函数torch.utils.data.DataLoader。通过这个类，我们在准备mini-batch的时候可以<code>多线程并行处理</code>，这样可以加快准备数据的速度。Datasets就是构建这个类的实例的<code>参数</code>之一。</p><h3 id="如何自定义Datasets"><a href="#如何自定义Datasets" class="headerlink" title="如何自定义Datasets"></a>如何自定义Datasets</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(data.Dataset)</span>:</span><span class="comment">#需要继承data.Dataset</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line">        <span class="comment"># 1. Initialize file path or list of file names.</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line">        <span class="comment"># 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).</span></span><br><span class="line">        <span class="comment"># 2. Preprocess the data (e.g. torchvision.Transform).</span></span><br><span class="line">        <span class="comment"># 3. Return a data pair (e.g. image and label).</span></span><br><span class="line">        <span class="comment">#这里需要注意的是，第一步：read one data，是一个data</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># You should change 0 to the total size of your dataset.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h2 id="PyTorch-学习笔记（五）"><a href="#PyTorch-学习笔记（五）" class="headerlink" title="PyTorch 学习笔记（五）"></a>PyTorch 学习笔记（五）</h2><p>在模型完成训练后，我们需要将训练好的模型保存为一个文件供测试使用，或者因为一些原因我们需要继续之前的状态训练之前保存的模型，<a href="https://captainzj.github.io/2018/12/28/Pytorch-Save-Load-Model/" target="_blank" rel="noopener">那么如何在PyTorch中保存和恢复模型呢？</a></p><h2 id="PyTorch-学习笔记（六）"><a href="#PyTorch-学习笔记（六）" class="headerlink" title="PyTorch 学习笔记（六）"></a>PyTorch 学习笔记（六）</h2><h3 id="Variable-的-hook"><a href="#Variable-的-hook" class="headerlink" title="Variable 的 hook"></a>Variable 的 hook</h3><p><code>register_hook(hook)</code> 注册一个backward钩子: <code>每次gradients被计算的时候</code>，这个hook都被调用.hook不应该修改它的输入，但是它可以<code>返回一个替代当前梯度的新梯度</code>.这个函数返回一个 句柄(handle).它有一个方法 <code>handle.remove()</code>，可以用这个方法将hook从module移除.</p><p>Example:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v = Variable(torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]), requires_grad=<span class="keyword">True</span>)</span><br><span class="line">h = v.register_hook(<span class="keyword">lambda</span> grad: grad * <span class="number">2</span>)  <span class="comment"># double the gradient</span></span><br><span class="line">v.backward(torch.Tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="comment">#先计算原始梯度，再进hook，获得一个新梯度。</span></span><br><span class="line">print(v.grad.data)</span><br><span class="line">h.remove()  <span class="comment"># removes the hook</span></span><br></pre></td></tr></table></figure></p><p>out:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">3</span>]</span><br></pre></td></tr></table></figure></p><h3 id="nn-Module的hook"><a href="#nn-Module的hook" class="headerlink" title="nn.Module的hook"></a>nn.Module的hook</h3><p><code>register_forward_hook(hook)</code>在module上注册一个forward hook: 这里要注意的是，<code>hook 只能注册到 Module 上</code>，即，仅仅是简单的 op 包装的 Module，而不是我们继承 Module时写的那个类，我们继承 Module写的类叫做 Container。<code>每次调用forward()计算输出的时候</code>，这个hook就会被调用。</p><p>Example:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">for_hook</span><span class="params">(module, input, output)</span>:</span></span><br><span class="line">    print(module,<span class="string">"1"</span>)</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> input:</span><br><span class="line">        print(<span class="string">"input val:"</span>,val)</span><br><span class="line">    <span class="keyword">for</span> out_val <span class="keyword">in</span> output:</span><br><span class="line">        print(<span class="string">"output val:"</span>, out_val)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line">x = Variable(torch.FloatTensor([<span class="number">1</span>]), requires_grad=<span class="keyword">True</span>)</span><br><span class="line">handle = model.register_forward_hook(for_hook)  <span class="comment"># register_forward_hook</span></span><br><span class="line">print(<span class="string">"hello"</span>)</span><br><span class="line">print(<span class="string">"model(x)"</span>,model(x))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">当我们执行model(x)的时候，底层干了以下几件事：</span></span><br><span class="line"><span class="string">- 调用 forward 方法计算结果</span></span><br><span class="line"><span class="string">- 判断有没有注册 forward_hook，有的话，就将 forward 的输入及结果作为hook的实参。然后让hook自己干一些不可告人的事情。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">handle.remove() <span class="comment">#  句柄(handle)有一个方法 handle.remove()，可以用这个方法将hook从module移除.</span></span><br></pre></td></tr></table></figure></p><p>out:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hello</span><br><span class="line">Model() <span class="number">1</span></span><br><span class="line">input val: tensor([<span class="number">1.</span>], requires_grad=<span class="keyword">True</span>)</span><br><span class="line">output val: tensor(<span class="number">2.</span>, grad_fn=&lt;SelectBackward&gt;)</span><br><span class="line">model(x) tensor([<span class="number">2.</span>], grad_fn=&lt;AddBackward&gt;)</span><br></pre></td></tr></table></figure></p><p>Explain:</p><ul><li>register_forward_hook<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_forward_hook</span><span class="params">(self, hook)</span>:</span></span><br><span class="line"></span><br><span class="line">       handle = hooks.RemovableHandle(self._forward_hooks)</span><br><span class="line">       self._forward_hooks[handle.id] = hook</span><br><span class="line">       <span class="keyword">return</span> handle</span><br></pre></td></tr></table></figure></li></ul><p>这个方法的作用是<code>在此module上注册一个hook</code>，函数中第一句就没必要在意了，主要看第二句，是把注册的hook保存在_forward_hooks字典里。</p><ul><li>nn.Module 的<strong>call</strong>方法(仅保留需要关注的部分)</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, *input, **kwargs)</span>:</span></span><br><span class="line">   result = self.forward(*input, **kwargs)</span><br><span class="line">   <span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_hooks.values():</span><br><span class="line">       <span class="comment">#将注册的hook拿出来用</span></span><br><span class="line">       hook_result = hook(self, input, result)</span><br><span class="line">   ...</span><br><span class="line">   <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="register-backward-hook"><a href="#register-backward-hook" class="headerlink" title="register_backward_hook"></a>register_backward_hook</h3><p>在module上注册一个backward hook。此方法目前只能用在Module上，不能用在Container上，当Module的forward函数中只有一个Function的时候，称为Module，如果Module包含其它Module，称之为Container。<code>每次计算module的inputs的梯度的时候</code>，这个hook会被调用。<br>注：Module的register_backward_hook的行为在未来的几个版本可能会改变</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>torchvision.models.md</title>
    <link href="http://yoursite.com/2019/01/16/torchvision-models/"/>
    <id>http://yoursite.com/2019/01/16/torchvision-models/</id>
    <published>2019-01-16T06:41:27.000Z</published>
    <updated>2019-01-16T08:09:46.652Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><a href="https://pytorch.org/docs/stable/torchvision/models.html" target="_blank" rel="noopener">torchvision.models — PyTorch master documentation</a></p><p>The models subpackage contains definitions for the following model architectures:</p><ul><li><p><a href="https://arxiv.org/abs/1404.5997" target="_blank" rel="noopener">AlexNet</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/alexnet.png" alt="alexnet" title="">                </div>                <div class="image-caption">alexnet</div>            </figure></li><li><p><a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">VGG</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/vgg.png" alt="vgg" title="">                </div>                <div class="image-caption">vgg</div>            </figure></li><li><p><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">ResNet</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/ResNet_Structure.png" alt="ResNet_Structure" title="">                </div>                <div class="image-caption">ResNet_Structure</div>            </figure></li><li><p><a href="https://arxiv.org/abs/1602.07360" target="_blank" rel="noopener">SqueezeNet</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/squeezenet.png" alt="squeezenet" title="">                </div>                <div class="image-caption">squeezenet</div>            </figure></li><li><p><a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">DenseNet</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/DenseNet_Structure.png" alt="DenseNet_Structure" title="">                </div>                <div class="image-caption">DenseNet_Structure</div>            </figure></li><li><p><a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Inception v3</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/01/16/torchvision-models/Inception.png" alt="Inception" title="">                </div>                <div class="image-caption">Inception</div>            </figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Pokémon_Model</title>
    <link href="http://yoursite.com/2019/01/09/Pokemon-Model/"/>
    <id>http://yoursite.com/2019/01/09/Pokemon-Model/</id>
    <published>2019-01-09T13:27:32.000Z</published>
    <updated>2019-01-10T08:57:38.852Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>Tutorial：</p><p><a href="https://zhuanlan.zhihu.com/p/25868154" target="_blank" rel="noopener">看图判断口袋妖怪属性，学会用卷积神经网络分类</a></p><p>Model Source：</p><p><a href="https://veekun.com/dex/downloads" target="_blank" rel="noopener">veekun</a></p><p><a href="http://www.element3ds.com/thread-93669-1-1.html" target="_blank" rel="noopener">《口袋妖怪XY》全套3D模型</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="Have_Fun" scheme="http://yoursite.com/categories/Have-Fun/"/>
    
    
  </entry>
  
  <entry>
    <title>数据分析与挖掘Exam</title>
    <link href="http://yoursite.com/2019/01/06/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%8C%96%E6%8E%98Exam/"/>
    <id>http://yoursite.com/2019/01/06/数据分析与挖掘Exam/</id>
    <published>2019-01-06T10:56:52.000Z</published>
    <updated>2019-01-08T13:55:42.778Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【内容描述】<a href="https://captainzj.github.io/2019/01/06/数据分析与挖掘/" target="_blank" rel="noopener">《数据分析与挖掘》</a>之后篇</p><a id="more"></a><h2 id="Exam"><a href="#Exam" class="headerlink" title="Exam"></a>Exam</h2><table><thead><tr><th style="text-align:center">题型</th><th style="text-align:center">题量（道）</th><th style="text-align:center">分值（分）</th><th style="text-align:center">总计（分）</th></tr></thead><tbody><tr><td style="text-align:center">选择题</td><td style="text-align:center">10</td><td style="text-align:center">2</td><td style="text-align:center">20</td></tr><tr><td style="text-align:center">计算题</td><td style="text-align:center">3</td><td style="text-align:center">10</td><td style="text-align:center">30</td></tr><tr><td style="text-align:center">简答题</td><td style="text-align:center">4</td><td style="text-align:center">5</td><td style="text-align:center">20</td></tr><tr><td style="text-align:center">论述题</td><td style="text-align:center">2</td><td style="text-align:center">15</td><td style="text-align:center">30</td></tr></tbody></table><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>What is datamining </p><p>从数据中发现知识</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> 统计分析  +     分析报告      -&gt;&gt;     数据挖掘</span><br><span class="line">(数据统计) + (协同过滤关联分析) -&gt;&gt; (找寻事物的隐含规律)</span><br><span class="line"> (描述性)  +   (预测性概率)    -&gt;&gt;     (规范性)</span><br><span class="line"> </span><br><span class="line">- 分析报告一般是整个事件发生结束以后的总结（描述性）。</span><br><span class="line">- 统计分析能利用大量的历史样本来预测整个事件总体未来的走向（预测性概率）。</span><br><span class="line">- 数据挖掘则透过事件的表象发现隐藏在背后的蛛丝马迹，从而找到潜伏的规律以及看似无关事物之间背后的联系，用此来洞察未来（规范性）。</span><br></pre></td></tr></table></figure></li><li><p>What is machine learning</p><p> 计算机程序基于数据自动地学习识别复杂的模式，并作出智能的决断。 允许程序可以根据提供的数据进行自动的学习，它可以使你的程序变得更”聪明”。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- 监督学习 (分类)</span><br><span class="line">- 无监督学习 (聚类)</span><br><span class="line">- 半监督学习: 在学习模型时，它使用标记(学习模型)和未标记(改进类边界)的实例。</span><br><span class="line">- 主动学习: 通过主动地从用户获取知识来提高模型质量</span><br></pre></td></tr></table></figure></li><li><p>What is artificial intelligence </p><p>在计算机科学的基础上，综合信息论、心理学、生理学、语言学、逻辑学和数学等知识，制造能<code>模拟人类智能行为</code>的计算机系统的边缘学科。</p></li></ul><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">计算公式</span><br></pre></td></tr></table></figure><h4 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Relational records'</span>  关系记录</span><br><span class="line">  - Relational tables, highly structured 关系表，高度结构化</span><br><span class="line">* <span class="string">'Data matrix'</span>, e.g., numerical matrix, crosstabs 数据矩阵，例如数值矩阵，交叉表</span><br><span class="line">* <span class="string">'Transaction data'</span> 交易数据</span><br><span class="line">* <span class="string">'Document data'</span>: Term-frequency vector (matrix) of text documents</span><br><span class="line">  文档数据：文本文档的术语 - 频率向量（矩阵）</span><br><span class="line">* <span class="string">'Transportation network'</span> 交通网络</span><br><span class="line">* <span class="string">'World Wide Web'</span> 万维网</span><br><span class="line">* <span class="string">'Molecular Structures'</span> 分子结构</span><br><span class="line">* <span class="string">'Social or information networks'</span> 社交或信息网络</span><br></pre></td></tr></table></figure><ul><li><p><strong>Attribute Types</strong> </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Nominal'</span>: categories, states, <span class="keyword">or</span> “names of things” <span class="comment"># 标称属性</span></span><br><span class="line">* <span class="string">'Binary'</span> : Nominal attribute <span class="keyword">with</span> only <span class="number">2</span> states (<span class="number">0</span> <span class="keyword">and</span> <span class="number">1</span>)<span class="comment"># 二元属性:仅有2个状态（0和1）的标称属性</span></span><br><span class="line">* <span class="string">'Ordinal'</span>  <span class="comment"># 序数属性</span></span><br><span class="line">- Values have a meaningful order (ranking) but magnitude between successive values <span class="keyword">is</span> <span class="keyword">not</span> known</span><br><span class="line">  值具有有意义的顺序（排名），但连续值之间的大小未知</span><br><span class="line">* <span class="string">'Numeric'</span> <span class="comment"># 数值属性</span></span><br><span class="line"> - `Interval`: Measured on a scale of equal-sized units 间隔: 按相同大小的单位测量</span><br><span class="line">- `Ratio` 比率(倍数)</span><br><span class="line">   We can speak of values <span class="keyword">as</span> being an order of magnitude larger than the unit of measurement (<span class="number">10</span> K˚ <span class="keyword">is</span> twice <span class="keyword">as</span> high <span class="keyword">as</span> <span class="number">5</span> K˚).</span><br><span class="line">   我们可以说价值比测量单位大一个数量级（<span class="number">10</span>K˚是<span class="number">5</span>K˚的两倍）</span><br><span class="line">* <span class="string">'Discrete Attribute'</span>  <span class="comment"># 离散属性</span></span><br><span class="line">- Sometimes, represented <span class="keyword">as</span> integer variables 有时，表示为`整数变量`</span><br><span class="line">- Note: Binary attributes are a special case of discrete attributes </span><br><span class="line">  注意：二进制属性是离散属性的特例</span><br><span class="line">* <span class="string">'Continuous Attribute'</span>  <span class="comment"># 连续属性</span></span><br><span class="line">- Practically, real values can only be measured <span class="keyword">and</span> represented using a finite number of digits</span><br><span class="line">  实际上，只能使用有限数字来测量和表示实际值</span><br><span class="line">- Continuous attributes are typically represented <span class="keyword">as</span> floating-point variables</span><br><span class="line">  连续属性通常表示为`浮点变量`</span><br></pre></td></tr></table></figure></li></ul><h4 id="Data-statistics"><a href="#Data-statistics" class="headerlink" title="Data statistics"></a>Data statistics</h4><ul><li><strong>Motivation</strong>: To better understand the data: central tendency, variation and spread</li></ul><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/DataStatistical.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/SimilarityDissimilarityAndProximity.png" width="600"><br></center><h3 id="Data-preprocessing"><a href="#Data-preprocessing" class="headerlink" title="Data preprocessing"></a>Data preprocessing</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">常用方法  缺失值 处理方法</span><br></pre></td></tr></table></figure><center><br><img src="/2019/01/06/数据分析与挖掘Exam/dataPreprocess_mainTask.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/DataQualityIssues.png" width="600"><br></center><h4 id="Data-cleaning"><a href="#Data-cleaning" class="headerlink" title="Data cleaning"></a>Data cleaning</h4><ul><li>Handle <code>missing data</code>(Incomplete), smooth <code>noisy data</code>,identify or remove <code>outliers</code>, and resolve <code>inconsistencies</code> 处理丢失的数据，平滑噪声数据，识别或删除异常值，并解决不一致问题</li></ul><h5 id="How-to-Handle-Missing-Data"><a href="#How-to-Handle-Missing-Data" class="headerlink" title="How to Handle Missing Data?"></a>How to Handle Missing Data?</h5><ul><li>Data is not always available:  many tuples have <code>no recorded value</code> for several attributes</li></ul><blockquote><p> 1.忽略元组  2.手动填充  3. 自动（以”unknown”/“均值”/“最可能的值’’）填充</p></blockquote><h5 id="How-to-Handle-Noisy-Data"><a href="#How-to-Handle-Noisy-Data" class="headerlink" title="How to Handle Noisy Data?"></a>How to Handle Noisy Data?</h5><ul><li>Noise: random <code>error or variance</code> in a measured variable</li></ul><blockquote><p>1.binning平滑  2.回归(拟合平滑) 3.聚类（无监督,检查并删除异常点） 4.半监督（检测可疑值并由人查验）</p></blockquote><h4 id="Data-integrating"><a href="#Data-integrating" class="headerlink" title="Data integrating"></a>Data integrating</h4><ul><li>Integration of multiple databases, data cubes, or files 集成多个数据库，数据立方体或文件</li></ul><blockquote><p>1.数据集成 2.模式集成 3.实体识别 4.检测和解决数据值的冲突</p></blockquote><h5 id="Handling-Redundancy-in-Data-Integration"><a href="#Handling-Redundancy-in-Data-Integration" class="headerlink" title="Handling Redundancy in Data Integration"></a>Handling Redundancy in Data Integration</h5><blockquote><p>1.冗余原因（对象标识不同、派生数据）2.检测手段（相关性和协方差分析）3.仔细整合</p></blockquote><h4 id="Data-transforming"><a href="#Data-transforming" class="headerlink" title="Data transforming"></a>Data transforming</h4><ul><li>A function that maps the entire set of values of a given attribute to a new set of replacement values s.t. each old value can be identified with one of the new values  一种函数，它将给定属性的整个值集映射到一组新的替换值 使得 可以使用其中一个新值标识每个旧值</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Methods</span><br><span class="line">  - <span class="string">'Smoothing'</span>: Remove noise <span class="keyword">from</span> data <span class="comment"># 平滑</span></span><br><span class="line">  - <span class="string">'Attribute/feature construction'</span>  <span class="comment"># 属性/特征构建</span></span><br><span class="line">    - New attributes constructed <span class="keyword">from</span> the given ones</span><br><span class="line">  - <span class="string">'Aggregation'</span>: Summarization, data cube construction  <span class="comment"># 聚合</span></span><br><span class="line">  - <span class="string">'Normalization'</span>: Scaled to fall within a smaller, specified range  <span class="comment"># 归一化</span></span><br><span class="line">    - min-max normalization</span><br><span class="line">    - z-score normalization</span><br><span class="line">    - normalization by decimal scaling</span><br><span class="line">  - <span class="string">'Discretization'</span>: Concept hierarchy climbing <span class="comment"># 离散化</span></span><br></pre></td></tr></table></figure><h4 id="Data-Reduction"><a href="#Data-Reduction" class="headerlink" title="Data Reduction"></a>Data Reduction</h4><ul><li><p>Obtain a reduced representation of the data set  获得数据集的缩减表示</p><ul><li>much smaller in volume but yet produces almost the same analytical results 体积小得多，但产生几乎相同的分析结果</li></ul></li><li><p><strong>Methods for data reduction</strong></p></li><li><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># data reduction </span></span><br><span class="line">- <span class="string">'Regression and Log-Linear Models'</span>  （Parametric methods）</span><br><span class="line">- <span class="string">'Histograms, clustering, sampling'</span>  （Non-parametric methods）</span><br><span class="line">&gt; sampling: 选择具有代表性的子集；简单随机、放回、不放回、分层抽样</span><br><span class="line">- <span class="string">'Data cube aggregation'</span> 数据立方体聚合</span><br><span class="line">- <span class="string">'Data Compression'</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Some typical dimensionality methods</span></span><br><span class="line">* Principal Component Analysis (<span class="string">'PCA'</span>) </span><br><span class="line">* Supervised <span class="keyword">and</span> nonlinear techniques</span><br><span class="line">- <span class="string">'Feature subset selection'</span> 找寻合适子集(仅收集与分析任务相关的属性)</span><br><span class="line">- <span class="string">'Feature creation'</span></span><br><span class="line">- `Attribute extraction`  高维映射至低维(降维)</span><br><span class="line">- `Attribute construction`</span><br></pre></td></tr></table></figure></li></ul><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/06/数据分析与挖掘Exam/Summary_datapreprocessing.png" width="600"><br></center><h2 id="classification"><a href="#classification" class="headerlink" title="classification"></a>classification</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">构建模型 应用模型(预测) 描述过程</span><br></pre></td></tr></table></figure><ul><li><p>What is classification?</p><p>根据训练集和类标签（分类属性中的值）构建模型，并将其用于分析新数据，预测其标签。</p><ul><li><p>Supervised learning</p><p><strong>监督学习</strong>是机器学习任务的一种。它<code>从有标记的训练数据中推导出预测标签</code>。有标记的训练数据是指每个训练实例都包括输入和期望的输出。一句话：<strong>给定数据，预测标签</strong>。(分类、回归)</p><ul><li><strong>无监督学习</strong>是机器学习任务的一种。它<code>从无标记的训练数据中推断结论</code>。最典型的无监督学习就是聚类分析，它可以在探索性数据分析阶段用于发现隐藏的模式或者对数据进行分组。一句话：<strong>给定数据，寻找隐藏的结构</strong>。</li></ul></li></ul></li><li><p>Steps</p><ol><li><p>模型构建：根据数据集特征构建合适的分类模型，并使用训练集样本进行模型训练</p></li><li><p>模型验证与测试：将已知的测试样品<code>标签</code>与模型使用测试集所得的<code>分类结果</code>进行比较，而后使用验证集改进模型准确率</p></li><li><p>模型部署：如果准确度可接受，便可使用此模型分类新数据</p></li></ol></li></ul><h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><blockquote><p>1.决策树：基于规则   2.贝叶斯：基于概率  3.ANN: 机器学习最优化 </p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">算法 思路 优缺点</span><br><span class="line">考 朴素贝叶斯</span><br><span class="line">解释 svm ann 大概了解DeepLearning 理论描述</span><br></pre></td></tr></table></figure><h4 id="Decision-tree-ID3-C4-5-CART"><a href="#Decision-tree-ID3-C4-5-CART" class="headerlink" title="Decision tree-ID3,C4.5,CART"></a>Decision tree-ID3,C4.5,CART</h4><ul><li><p>Algorithm Step</p><p>树以自上而下，递归，分而治之的方式构建</p><ul><li>一开始，所有的训练样例都是根源</li><li><strong>样例基于被选定的属性递归地划分</strong>(在每个节点上，基于<code>该节点上的训练示例</code>以及<code>启发式或统计度量（例如，信息增益）</code>来<code>选择属性</code>。)</li></ul><p>停止条件</p><ul><li>给定节点的所有样本都属于<code>同一个类</code></li><li>没有<code>剩余属性</code>可用于进一步分区</li><li>没有<code>剩余样例</code></li></ul></li><li><p>Basic Concepts</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">- Entropy 信息熵:  表征混乱程度 </span><br><span class="line">- Conditional Entropy条件熵: 在已知随机变量X的条件下随机变量Y的不确定性(概率)</span><br><span class="line">- Mutual Information互信息/Information gain信息增益: 得知特征X的信息而使得类Y的信息的不确定性减少的程度(越大越好) -&gt;&gt; 'ID3决策树'</span><br><span class="line">- Gain Ratio信息增益比: 解决使用信息增益存在偏向于选择取值较多的特征的问题(越大越好) -&gt;&gt; 'C4.5决策树' </span><br><span class="line">- GINI index基尼指数： 表征不纯度(越小越好)  -&gt;&gt;  'CART分类树'</span><br></pre></td></tr></table></figure></li><li><p>决策树算法比较</p><p>| 算法 |  支持模型  | 树结构 |     特征选择     | 连续值处理 | 缺失值处理 |  剪枝  |<br>| :–: | :——–: | :—-: | :————–: | :——–: | :——–: | :—-: |<br>| ID3  |    分类    | 多叉树 |     信息增益     |   不支持   |   不支持   | 不支持 |<br>| C4.5 |    分类    | 多叉树 |    信息增益比    |    支持    |    支持    |  支持  |<br>| CART | 分类，回归 | 二叉树 | 基尼系数，均方差 |    支持    |    支持    |  支持  |</p></li></ul><h4 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h4><ul><li>Define: Find a linear/non-linear hyperplane (decision boundary) that will separate the data</li><li>Optimize：希望所有的点都离超平面远 -&gt;  可以让离超平面比较近的点尽可能的远离超平面</li><li>kernel核函数：将数据从低维空间映射到高维空间</li></ul><h4 id="Bayes"><a href="#Bayes" class="headerlink" title="Bayes"></a>Bayes</h4><ul><li><p><strong>贝叶斯定理：</strong> $P(H|X)=\frac{P(X|H)P(H)}{P(X)}$</p></li><li><p>Naïve Bayesian Classifier</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Advantages</span></span><br><span class="line"> Easy to implement  易于实现</span><br><span class="line"> Good results obtained <span class="keyword">in</span> most of the cases 大多数情况下获得了良好的结果</span><br><span class="line"><span class="comment"># Disadvantages</span></span><br><span class="line"> Assumption: class conditional independence, therefore loss of accuracy类条件独立-&gt;准确率缺失</span><br><span class="line"> Practically, dependencies exist among variables</span><br><span class="line">  实际上，变量之间存在<span class="string">'依赖'</span>关系</span><br><span class="line"> E.g., hospitals: patients: Profile: age, family history, etc. Symptoms: fever, cough etc., Disease: lung cancer, diabetes,etc.</span><br><span class="line"> Dependencies among these cannot be modeled by Naïve Bayesian Classifier</span><br><span class="line">      这些依赖关系不能用朴素贝叶斯分类器建模</span><br><span class="line"><span class="comment"># How to deal with these dependencies? Bayesian Belief Networks</span></span><br><span class="line">  如何处理这些依赖关系？贝叶斯置信网络</span><br></pre></td></tr></table></figure></li></ul><h4 id="ANN"><a href="#ANN" class="headerlink" title="ANN"></a>ANN</h4><ul><li><p>受生物神经元的启发，将<strong>多输入单输出</strong>的信息处理单元作为人工神经网络中的一个神经元。人工神经网络的基本结构如下：输入层(输入层的神经元数目对应于训练集数据的属性数目)、隐藏层、输出层(输出层的神经元数目对应于网络预测的分类数目)</p></li><li><p>Backpropagation</p><blockquote><p>Backpropagate the error (by updating weights and biases)</p></blockquote></li><li><h5 id="DeepLearning"><a href="#DeepLearning" class="headerlink" title="DeepLearning"></a>DeepLearning</h5><blockquote><p>通过更深的layers，自动提取特征（构建特征空间），以达到更”深层次”的学习效果</p></blockquote></li></ul><h3 id="Model-evaluation-and-selection"><a href="#Model-evaluation-and-selection" class="headerlink" title="Model evaluation and selection"></a>Model evaluation and selection</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">混淆矩阵 准确率 错误率 等等指标 交叉验证</span><br></pre></td></tr></table></figure><h4 id="Confusion-matrix-and-criteria"><a href="#Confusion-matrix-and-criteria" class="headerlink" title="Confusion matrix and criteria"></a>Confusion matrix and criteria</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/ConfusionMatrix.png" width="600"><br></center><ul><li><p><strong>Issues Affecting Model Selection</strong></p><blockquote><p>1.准确性 2.速度 3.鲁棒性 4.可伸缩性 5.可解释性 6.其他措施，例如规则的好处，例如决策树大小或分类规则的紧凑性</p></blockquote></li></ul><h4 id="Cross-evaluation"><a href="#Cross-evaluation" class="headerlink" title="Cross-evaluation"></a>Cross-evaluation</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Cross-validation (k-fold, where k = 10 is most popular)</span></span><br><span class="line">- 随机将数据划分为k个互斥的子集，每个子集的大小大致相等</span><br><span class="line">- 在第i次迭代中，使用Di作为测试集，使用其他作为训练集</span><br><span class="line">- 留一个：k折叠，其中k = <span class="string">'#'</span> 元组的数量，对于小尺寸数据</span><br><span class="line">- *分层交叉验证*：折叠是分层的，因此每个折叠中的类分布与初始数据中的类别分布大致相同</span><br></pre></td></tr></table></figure><h3 id="Ensemble-methods"><a href="#Ensemble-methods" class="headerlink" title="Ensemble methods"></a>Ensemble methods</h3><ul><li>使用模型组合来提高准确性</li></ul><h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><ul><li>Bagging: 使用训练集的子集训练每个模型，并且并行学习模型</li></ul><h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h4><blockquote><p>（Bagging）投票得分    -&gt;  （Boosting）加权得分</p></blockquote><ul><li>Boosting：训练每个新模型实例以强调先前模型错误分类的训练实例，以及按顺序学习的模型</li></ul><h4 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h4><blockquote><p>Avariation of bagging for decision trees 对<strong>决策树的bagging</strong>的’变异’</p></blockquote><h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/06/数据分析与挖掘Exam/classification_summary1.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/classification_summary2.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/classification_summary3.png" width="600"><br></center><h2 id="Frequent-patterns"><a href="#Frequent-patterns" class="headerlink" title="Frequent patterns"></a>Frequent patterns</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">频繁模式</span><br><span class="line">频繁子图 不考 hhhhh</span><br><span class="line">关联规则重点掌握</span><br><span class="line">必须明白 apriori fp-growth </span><br><span class="line">k -&gt; k+1</span><br></pre></td></tr></table></figure><ul><li><p>What is a frequent pattern </p><p>频繁模式是数据集中频繁出现(满足最小支持度)的项集、序列或子结构。</p><ul><li><p>Association rule </p><p>关联规则就是有关联的规则，形式是这样定义的：<em>两个不相交的非空集合X、Y，如果有X–&gt;Y，就说X–&gt;Y是一条关联规则</em>。</p></li></ul></li></ul><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><h4 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a>Apriori</h4><ul><li><p>Apriori定律</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 如果一个集合是频繁项集，则它的所有<span class="string">'子集'</span>都是频繁项集。</span><br><span class="line"><span class="number">2.</span> 如果一个集合不是频繁项集，则它的所有<span class="string">'超集'</span>都不是频繁项集。</span><br></pre></td></tr></table></figure></li><li><p>Step</p><center><br><img src="/2019/01/06/数据分析与挖掘Exam/AprioriExample.png" width="600"><br></center></li></ul><h4 id="FP-growth"><a href="#FP-growth" class="headerlink" title="FP-growth"></a>FP-growth</h4><p>FpGrowth算法通过构造一个树结构来压缩数据记录，使得挖掘频繁项集只需要<strong>扫描两次数据记录</strong>，而且该算法不需要生成候选集合，所以效率会比较高。</p><ul><li><p><strong>Method</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> For each frequent item, construct its conditional pattern-base, <span class="keyword">and</span> then its conditional FP-tree</span><br><span class="line">  对于每个频繁项，<span class="string">'构造其条件模式库'</span>，然后<span class="string">'构造其条件FP树'</span></span><br><span class="line"> Repeat the process on <span class="string">'each'</span> newly created conditional FP-tree</span><br><span class="line">  对每个新创建的条件FP树重复此过程 (<span class="string">"Recursion: Mining Each Conditional FP-tree"</span>)</span><br><span class="line"> Until the resulting FP-tree <span class="keyword">is</span> empty, <span class="keyword">or</span> it contains only one path—single path will generate all the combinations of its sub-paths, each of which <span class="keyword">is</span> a frequent pattern</span><br><span class="line">  在生成的FP树为空之前，或者它只包含一个路径 - 单个路径将生成其子路径的所有组合，<span class="string">'每个路径都是一个频繁的模式'</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/06/数据分析与挖掘Exam/fp_Summary.png" width="600"><br></center><h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kmeans 相关算法</span><br><span class="line">分析比较</span><br><span class="line">ap基本概念</span><br></pre></td></tr></table></figure><ul><li><p>What is clustering</p><p>聚类就是按照某个特定标准(如距离准则)<strong>把一个数据集分割成不同的类或簇</strong>，使得同一个簇内的数据对象的<code>相似性</code>尽可能大，同时不在同一个簇中的数据对象的<code>差异性</code>也尽可能地大。即聚类后<code>同一类的数据尽可能聚集到一起，不同数据尽量分离</code>。</p><ul><li><p>Unsupervised learning </p><p>聚类是一种<code>输入数据无标签</code>的“分类”方式（即非监督学习），通常并不需要使用训练数据进行学习，仅把相似的东西聚到一起，并不关心所得的簇具体代表什么</p></li></ul></li></ul><h3 id="Algorithms-1"><a href="#Algorithms-1" class="headerlink" title="Algorithms"></a>Algorithms</h3><h4 id="Partition-based—k-means"><a href="#Partition-based—k-means" class="headerlink" title="Partition-based—k-means"></a>Partition-based—k-means</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/k-Means.gif" width="400"><br></center><p>k-Means : 选取<code>平均值</code>作为新的聚类中心 </p><ul><li>k-means对初始值的设置很敏感 <ul><li><strong>K-means++</strong>：选取<code>与当前所属聚类中心距离最远</code>的点作为新的聚类中心</li></ul></li><li>k-means对噪声和离群值非常敏感<ul><li><strong>K-Medoids</strong>：选取<code>中心点</code>（计算该点到当前聚簇中所有点距离之和，最终距离之后最小的点）作为新的聚类中心</li><li><strong>K-Medians</strong>：选取<code>中位数</code>作为新的聚类中心</li></ul></li><li><p>k-means只用于numerical，不适用于categorical类型数据</p><ul><li><strong>K-Modes</strong>：选取<code>众数</code>作为新的聚类中心</li></ul></li><li><p>k-means不能解决非凸non-convex数据</p><ul><li><strong>Kernel K-Means</strong>：使用核函数(多项式/高斯径向基/Sigmoid核函数)将数据投影到高维特征空间，然后执行K-Means聚类</li></ul></li></ul><h4 id="Hierarchical-based—two-ways"><a href="#Hierarchical-based—two-ways" class="headerlink" title="Hierarchical-based—two ways"></a>Hierarchical-based—two ways</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'凝聚'</span>：从单一集群开始，一次连续合并两个集群，构建<span class="string">'自下而上'</span>的集群层次结构</span><br><span class="line">- <span class="string">'分裂'</span>：从一个庞大的宏集群开始，将其连续分成两组，生成一个<span class="string">'自上而下'</span>的集群层次结构</span><br></pre></td></tr></table></figure><h5 id="Brich"><a href="#Brich" class="headerlink" title="Brich"></a>Brich</h5><center><br><img src="/2019/01/06/数据分析与挖掘Exam/CFTree.png" width="500"><br></center><h4 id="Density-based—DBSCAN"><a href="#Density-based—DBSCAN" class="headerlink" title="Density-based—DBSCAN"></a>Density-based—DBSCAN</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/DBSCAN_BasicConcept.png" width="500"><br></center><p>DBSCAN密度聚类：由密度可达关系导出的<code>最大密度相连的样本集合</code>，即为我们最终聚类的一个类别，或者说一个簇。</p><h4 id="AP-2007-Science"><a href="#AP-2007-Science" class="headerlink" title="AP (2007, Science)"></a>AP (2007, Science)</h4><p>AP算法通过迭代过程不断更新每一个点的$responsibility$和$availability$,直到产生$m$个高质量的$exemplar$,同时将其余的数据点分配到相应的聚类中。</p><h4 id="Local-density-based-2014-Science"><a href="#Local-density-based-2014-Science" class="headerlink" title="Local density-based (2014, Science)"></a>Local density-based (2014, Science)</h4><blockquote><p>1.找出聚类中心  2.剩余点的类别指派 3.去除噪音</p></blockquote><h3 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/06/数据分析与挖掘Exam/clustering_Summary.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/clustering_Summary2.png" width="600"><br></center><h2 id="Graph-clustering"><a href="#Graph-clustering" class="headerlink" title="Graph clustering"></a>Graph clustering</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">谱聚类 modularity模块化 复杂网络的概念</span><br></pre></td></tr></table></figure><ul><li><p>What is graph clustering </p><ul><li><p>Complex network</p><p>在我们的现实生活中，许多复杂系统都可以建模成一种复杂网络进行分析，比如常见的电力网络、航空网络、交通网络、计算机网络以及社交网络等等。复杂网络不仅是一种数据的表现形式，它同样也是一种科学研究的手段。</p></li><li><p>Graph clustering</p><p>和特征聚类不同，图聚类比较难以观察，部分算法会以各点之间的距离作为突破口，可以这样形容：张三，是王五的好朋友，刚认识李四，对赵六很是反感。那么，对于该节点，我们无法直接得出他的特征，但能知道他的<code>活动圈</code>。利用图聚类，可以将同一社交范围的人聚合到一起。</p></li><li><p>Community </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'k-clique community'</span>: Union of all k-cliques that can be `reached <span class="keyword">from</span> each other` through a series of adjacent k-cliques.</span><br><span class="line">k-派系连通：一个k-派系可以通过若干个相邻的k-派系到达另一个k-派系，则称这两个k-派系彼此联通</span><br></pre></td></tr></table></figure></li><li><p>Module  </p></li></ul></li></ul><h3 id="Algorithms-2"><a href="#Algorithms-2" class="headerlink" title="Algorithms"></a>Algorithms</h3><h4 id="CPM"><a href="#CPM" class="headerlink" title="CPM"></a>CPM</h4><center class="half"><br><img src="/2019/01/06/数据分析与挖掘Exam/CPM1.png" width="300"><br><img src="/2019/01/06/数据分析与挖掘Exam/CPM2.png" width="300"><br></center><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Step1: 找到网络中大小为K的完全子图 Locate maximal cliques </span><br><span class="line">Step2: 将每个完全子图定义为一个节点，建立一个重叠矩阵</span><br><span class="line">Step3: 将重叠矩阵变成社团邻接矩阵(其中重叠矩阵中对角线小于k、非对角线小于k<span class="number">-1</span>的元素全置为<span class="number">0</span>,所有非<span class="number">0</span>项置为<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="Spectral-clustering"><a href="#Spectral-clustering" class="headerlink" title="Spectral clustering"></a>Spectral clustering</h4><p>谱聚类（Spectral Clustering），就是先用<code>Laplacian eigenmaps对数据降维</code>（简单地说，就是先将数据转换成邻接矩阵或相似性矩阵，再转换成Laplacian矩阵，再对Laplacian矩阵进行特征分解，把最小的K个特征向量排列在一起），然后再<code>使用k-means</code>完成聚类。谱聚类是个很好的方法，效果通常比k-means好，计算复杂度还低，这都要归功于降维的作用。 </p><h4 id="GNandQ"><a href="#GNandQ" class="headerlink" title="GNandQ"></a>GNandQ</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 计算网络中所有边缘的中介性.</span><br><span class="line"><span class="number">2.</span> 去除间隙最大的边缘.</span><br><span class="line"><span class="number">3.</span> 重新计算受移除影响的所有边缘的间隙.</span><br><span class="line"><span class="number">4.</span> 从步骤<span class="number">2</span>重复，直到没有边缘.</span><br></pre></td></tr></table></figure><h4 id="MCL"><a href="#MCL" class="headerlink" title="MCL"></a>MCL</h4><p>在MCL中， <strong>Expansion</strong> 和 <strong>Inflation</strong> 将不断的交替进行，<strong>Expansion</strong> 使得不同的区域之间的联系加强，而 <strong>Inflation</strong> 则不断的<code>分化</code>各点之间的联系(强者恒强，弱者恒弱)。经过多次迭代，将渐渐出现聚集现象，以此便达到了聚类的效果。</p><h3 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/06/数据分析与挖掘Exam/graphMining_Summary.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/CommunityDetection_Summary.png" width="600"><br></center><h2 id="Calculate"><a href="#Calculate" class="headerlink" title="Calculate"></a>Calculate</h2><h3 id="dataProcessing"><a href="#dataProcessing" class="headerlink" title="dataProcessing"></a>dataProcessing</h3><h4 id="Proximity-Measure-for-Binary-Attributes"><a href="#Proximity-Measure-for-Binary-Attributes" class="headerlink" title="Proximity Measure for Binary Attributes"></a>Proximity Measure for Binary Attributes</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/ProximityMeasureforBinaryAttributes.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/Dissimilarity betweenAsymmetricBinaryVariables.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/CalculatingCosineSimilarity.png" width="600"><br></center><h4 id="Correlation-Analysis"><a href="#Correlation-Analysis" class="headerlink" title="Correlation Analysis"></a>Correlation Analysis</h4><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CorrelationAnalysis.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CorrelationAnalysisExample.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CorrelationBetweenTwoNumericalVariables.png" width="600"><br></center><h4 id="Covariance"><a href="#Covariance" class="headerlink" title="Covariance"></a>Covariance</h4><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/VarianceForSingleVariable.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CovarianceForTwoVariables.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Example_CalculationOfCovariance.png" width="600"><br></center><h4 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/Normalization.png" width="600"><br></center><h4 id="Simple-Discretization-Binning"><a href="#Simple-Discretization-Binning" class="headerlink" title="Simple Discretization: Binning"></a>Simple Discretization: Binning</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/Binning.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/BinningExample.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/BinningvsClustering.png" width="600"><br></center><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><h4 id="ID3-Decision-Tree：Information-Gain"><a href="#ID3-Decision-Tree：Information-Gain" class="headerlink" title="ID3 Decision Tree：Information Gain"></a>ID3 Decision Tree：Information Gain</h4><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Example-AttributeSelection_withInformationGain.png" width="600"><br></center><h4 id="CART-Decision-Tree：-Gini-Index"><a href="#CART-Decision-Tree：-Gini-Index" class="headerlink" title="CART Decision Tree： Gini Index"></a>CART Decision Tree： Gini Index</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/ComputationOfGiniIndex.png" width="600"><br></center><h4 id="Classifier-Evaluation-Metrics-Example"><a href="#Classifier-Evaluation-Metrics-Example" class="headerlink" title="Classifier Evaluation Metrics: Example"></a>Classifier Evaluation Metrics: Example</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/ClassifierEvaluationMetrics.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/ClassifierEvaluationMetrics1.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/ClassifierEvaluationMetricsExample.png" width="600"><br></center><h4 id="Naïve-Bayesian-Classifier"><a href="#Naïve-Bayesian-Classifier" class="headerlink" title="Naïve Bayesian Classifier"></a>Naïve Bayesian Classifier</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/Naïve Bayesian Classifier0.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/Naïve Bayesian Classifier1.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/AvoidingtheZero-ProbabilityProblem.png" width="600"><br></center><h4 id="Bayesian-Belief-Network"><a href="#Bayesian-Belief-Network" class="headerlink" title="Bayesian Belief Network"></a>Bayesian Belief Network</h4><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Bayesian Network1.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Bayesian Network2.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Bayesian Network3.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/Bayesian Network4.png" width="600"><br></center><h4 id="SVM-1"><a href="#SVM-1" class="headerlink" title="SVM"></a>SVM</h4><p>$\vec{w}=\sum_{i=1}^{N}\lambda_iy_i\vec{x_i} $        </p><p>$\lambda_i(y_i(\vec{w} * \vec{x_i}+b ))=0$</p><center><br><img src="/2019/01/06/数据分析与挖掘Exam/SVM_Example.png" width="600"><br></center><h3 id="Frequent-patterns-1"><a href="#Frequent-patterns-1" class="headerlink" title="Frequent patterns"></a>Frequent patterns</h3><h4 id="Association-Rules-supprt-amp-amp-confidence"><a href="#Association-Rules-supprt-amp-amp-confidence" class="headerlink" title="Association Rules: supprt &amp;&amp; confidence"></a>Association Rules: supprt &amp;&amp; confidence</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/AssociationRules.png" width="600"><br></center><h4 id="FP-growth-1"><a href="#FP-growth-1" class="headerlink" title="FP-growth"></a>FP-growth</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/FP-TreeConstruct.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/FP-TreeFindPatterns.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/FP-Tree_mConditional.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/MiningEachConditionalFP-tree.png" width="600"><br></center><h3 id="Clustering-1"><a href="#Clustering-1" class="headerlink" title="Clustering"></a>Clustering</h3><h4 id="Kernel-K-Means"><a href="#Kernel-K-Means" class="headerlink" title="Kernel K-Means"></a>Kernel K-Means</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/KernelK-Means.png" width="600"><br></center><h3 id="Community-detection"><a href="#Community-detection" class="headerlink" title="Community detection"></a>Community detection</h3><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CPMExample1.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CPMExample2.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/CPMExample3.png" width="600"><br></center><h4 id="Spectral-Clustering"><a href="#Spectral-Clustering" class="headerlink" title="Spectral Clustering"></a>Spectral Clustering</h4><center><br><img src="/2019/01/06/数据分析与挖掘Exam/SpectralClusteringExample1.png" width="600"><br><img src="/2019/01/06/数据分析与挖掘Exam/SpectralClusteringExample2.png" width="600"><br></center><h4 id="MCL-1"><a href="#MCL-1" class="headerlink" title="MCL"></a>MCL</h4><center><br>    <img src="/2019/01/06/数据分析与挖掘Exam/MarkovChains.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/MarkovChains2.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/WeightedGraphs.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/MCL_SelfLoop.png" width="600"><br>    <img src="/2019/01/06/数据分析与挖掘Exam/MCL_Inflation.png" width="600"><br></center><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h3 id="Classification-1"><a href="#Classification-1" class="headerlink" title="Classification"></a>Classification</h3><h4 id="经典"><a href="#经典" class="headerlink" title="经典"></a>经典</h4><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">关注点</th><th style="text-align:center">注意</th><th style="text-align:center">相似度量</th></tr></thead><tbody><tr><td style="text-align:center">Decision Tree</td><td style="text-align:center">选择属性的方式</td><td style="text-align:center">信息增益、信息增益比、基尼指数</td><td style="text-align:center">同左</td></tr><tr><td style="text-align:center">SVM</td><td style="text-align:center">核函数</td><td style="text-align:center">让离超平面比较近的点尽可能的远离超平面</td><td style="text-align:center">高维映射</td></tr><tr><td style="text-align:center">Bayes</td><td style="text-align:center">后验概率最大化</td><td style="text-align:center">若属性间存在依赖关联，使用贝叶斯置信网络</td><td style="text-align:center">概率</td></tr><tr><td style="text-align:center">ANN</td><td style="text-align:center">“黑盒”</td><td style="text-align:center">后向传播更新权重，优化模型</td></tr></tbody></table><h4 id="集成方法"><a href="#集成方法" class="headerlink" title="集成方法"></a>集成方法</h4><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">关注点</th><th style="text-align:center">注意</th><th style="text-align:center">相似度量</th></tr></thead><tbody><tr><td style="text-align:center">Bagging</td><td style="text-align:center">平等”投票”</td><td style="text-align:center">票数高的预测即为最终预测结果</td><td style="text-align:center">多模型</td></tr><tr><td style="text-align:center">Boosting</td><td style="text-align:center">加权”投票”</td><td style="text-align:center">权重为模型准确率</td><td style="text-align:center">多模型</td></tr><tr><td style="text-align:center">Random Forest</td><td style="text-align:center">“决策树”的装袋</td><td style="text-align:center">随机选择属性(平等)、随机线性组合(权重)</td><td style="text-align:center">多模型</td></tr></tbody></table><h3 id="频繁模式"><a href="#频繁模式" class="headerlink" title="频繁模式"></a>频繁模式</h3><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">关注点</th><th style="text-align:center">注意</th><th style="text-align:center">相似度量</th></tr></thead><tbody><tr><td style="text-align:center">Apriori</td><td style="text-align:center">候选消除算法</td><td style="text-align:center">两条定律</td><td style="text-align:center">最小支持度</td></tr><tr><td style="text-align:center">FP-growth</td><td style="text-align:center">扫描两遍数据记录即可</td><td style="text-align:center">构造FP-Tree,基于条件模式(前缀)递归构造FP树</td><td style="text-align:center">最小支持度</td></tr></tbody></table><h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">关注点</th><th style="text-align:center">注意</th><th style="text-align:center">相似度量</th></tr></thead><tbody><tr><td style="text-align:center">K-Means</td><td style="text-align:center">以”均值”更新聚类中心</td><td style="text-align:center">++:最远点、Medoid:中心点、Medians:中位数、Mode、Kernel</td><td style="text-align:center">距离</td></tr><tr><td style="text-align:center">BIRCH</td><td style="text-align:center">CF-Tree结点即聚类的簇</td><td style="text-align:center">利用层次方法的平衡迭代规约和聚类：使用CF树并逐步调整子集群的质量</td><td style="text-align:center">最大样本半径阈值T</td></tr><tr><td style="text-align:center">DBSCAN</td><td style="text-align:center">由密度可达关系导出的最大密度相连的样本集合，即簇</td><td style="text-align:center"></td><td style="text-align:center">(ϵ, MinPts)</td></tr><tr><td style="text-align:center">E-M algorithm</td><td style="text-align:center">”最大似然估计“</td><td style="text-align:center">K-Means （距离） -&gt;&gt; E-M algorithm (概率分布)</td><td style="text-align:center">概率</td></tr><tr><td style="text-align:center">AP算法</td><td style="text-align:center">不断更新每一个点的responsibility和availability</td><td style="text-align:center">产生m个高质量的exemplar后，指派剩余点</td><td style="text-align:center">归属度、吸引度</td></tr><tr><td style="text-align:center">Local density-based</td><td style="text-align:center">假设聚类中心周围都是密度比其低的点，同时这些点到该聚类中心的距离比其到其他聚类中心更近</td><td style="text-align:center">δ<em>{min}和ρ</em>{min}找到聚类中心后，指派剩余点</td><td style="text-align:center">密度、距离</td></tr></tbody></table><h3 id="图聚类"><a href="#图聚类" class="headerlink" title="图聚类"></a>图聚类</h3><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">关注点</th><th style="text-align:center">注意</th><th style="text-align:center">相似度量</th></tr></thead><tbody><tr><td style="text-align:center">CPM</td><td style="text-align:center">完全子图-&gt;重叠矩阵-&gt;社区邻接矩阵</td><td style="text-align:center">构造矩阵时完全子图皆为结点</td><td style="text-align:center">重叠结点</td></tr><tr><td style="text-align:center">谱聚类</td><td style="text-align:center">拉普拉斯特征映射（降维） + K-Means</td><td style="text-align:center">构造邻接矩阵的方式选择、Ratio-Cut/N-Cut</td><td style="text-align:center">距离</td></tr><tr><td style="text-align:center">G Nand Q</td><td style="text-align:center">删除边介数最大的边</td><td style="text-align:center">边介数:网络中任意两个节点通过此边的最短路径的数目</td><td style="text-align:center">边介数</td></tr><tr><td style="text-align:center">MCL</td><td style="text-align:center"><strong>Expansion</strong> 和 <strong>Inflation</strong> 将不断的交替进行</td><td style="text-align:center"><strong>Expansion</strong>：加强区域间的联系（随机游走）<br>Inflation：分化联系（强者恒强）</td><td style="text-align:center">概率</td></tr></tbody></table><h2 id="Todo"><a href="#Todo" class="headerlink" title="Todo"></a>Todo</h2><ul><li><p>看相关参考书目《数据挖掘：概念与技术》《数据挖掘导论》课后例题  着重看”简单计算”</p></li><li><p>Collaborative Filtering</p><p><a href="https://www.cnblogs.com/pinard/p/6349233.html" target="_blank" rel="noopener">协同过滤推荐算法总结</a></p><p><a href="https://www.cnblogs.com/pinard/p/6351319.html" target="_blank" rel="noopener">矩阵分解在协同过滤推荐算法中的应用</a></p><p><a href="https://www.cnblogs.com/pinard/p/6362647.html" target="_blank" rel="noopener">SimRank协同过滤推荐算法</a></p></li><li><p><a href="https://www.cnblogs.com/pinard/p/6912636.html" target="_blank" rel="noopener">EM算法原理总结</a></p></li><li><p>特征工程</p><p><a href="https://www.cnblogs.com/pinard/p/9032759.html" target="_blank" rel="noopener">特征工程之特征选择</a></p><p><a href="https://www.cnblogs.com/pinard/p/9061549.html" target="_blank" rel="noopener">特征工程之特征表达</a></p><p><a href="https://www.cnblogs.com/pinard/p/9093890.html" target="_blank" rel="noopener">特征工程之特征预处理</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【内容描述】&lt;a href=&quot;https://captainzj.github.io/2019/01/06/数据分析与挖掘/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《数据分析与挖掘》&lt;/a&gt;之后篇&lt;/p&gt;
    
    </summary>
    
      <category term="XD" scheme="http://yoursite.com/categories/XD/"/>
    
    
  </entry>
  
  <entry>
    <title>数据分析与挖掘</title>
    <link href="http://yoursite.com/2019/01/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%8C%96%E6%8E%98/"/>
    <id>http://yoursite.com/2019/01/01/数据分析与挖掘/</id>
    <published>2019-01-01T06:42:25.000Z</published>
    <updated>2019-01-09T13:13:34.196Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【内容描述】 基于《数据挖掘：概念与技术》的简述，欲了解细节，强烈建议读原书！！！</p><a id="more"></a><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><h4 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Relational records'</span>  关系记录</span><br><span class="line">  - Relational tables, highly structured 关系表，高度结构化</span><br><span class="line">* <span class="string">'Data matrix'</span>, e.g., numerical matrix, crosstabs 数据矩阵，例如数值矩阵，交叉表</span><br><span class="line">* <span class="string">'Transaction data'</span> 交易数据</span><br><span class="line">* <span class="string">'Document data'</span>: Term-frequency vector (matrix) of text documents</span><br><span class="line">  文档数据：文本文档的术语 - 频率向量（矩阵）</span><br><span class="line">* <span class="string">'Transportation network'</span> 交通网络</span><br><span class="line">* <span class="string">'World Wide Web'</span> 万维网</span><br><span class="line">* <span class="string">'Molecular Structures'</span> 分子结构</span><br><span class="line">* <span class="string">'Social or information networks'</span> 社交或信息网络</span><br></pre></td></tr></table></figure><ul><li><p><strong>Attribute Types</strong> </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Nominal'</span>: categories, states, <span class="keyword">or</span> “names of things” <span class="comment"># 标称属性: 类别，状态或“事物名称”</span></span><br><span class="line">- Hair_color = &#123;auburn, black, blond, brown, grey, red, white&#125;</span><br><span class="line">- marital status, occupation, ID numbers, zip codes 婚姻状况，职业，身份证号码，邮政编码</span><br><span class="line">* <span class="string">'Binary'</span> <span class="comment"># 二元属性</span></span><br><span class="line">- Nominal attribute <span class="keyword">with</span> only <span class="number">2</span> states (<span class="number">0</span> <span class="keyword">and</span> <span class="number">1</span>) 仅有<span class="number">2</span>个状态（<span class="number">0</span>和<span class="number">1</span>）的标称属性</span><br><span class="line">- Symmetric binary: both outcomes equally important.  e.g., gender</span><br><span class="line">  对称二元：两种结果同样重要. 例如，性别</span><br><span class="line">- Asymmetric binary: outcomes <span class="keyword">not</span> equally important.  e.g., medical test (positive vs. negative)</span><br><span class="line">  不对称二元：结果不是同等重要的.  例如，医学检验（正面与负面）</span><br><span class="line">- Convention: assign <span class="number">1</span> to most important outcome (e.g., HIV positive)</span><br><span class="line">  公约：为最重要的结果指定<span class="number">1</span>  （例如艾滋病毒阳性）</span><br><span class="line">* <span class="string">'Ordinal'</span>  <span class="comment"># 序数属性</span></span><br><span class="line">- Values have a meaningful order (ranking) but magnitude between successive values <span class="keyword">is</span> <span class="keyword">not</span> known</span><br><span class="line">  值具有有意义的顺序（排名），但连续值之间的大小未知</span><br><span class="line">- Size = &#123;small, medium, large&#125;, grades, army rankings</span><br><span class="line">  大小= &#123;小，中，大&#125;，成绩，军队排名</span><br><span class="line">* <span class="string">'Numeric'</span> <span class="comment"># 数值属性</span></span><br><span class="line"> - `Interval` 间隔</span><br><span class="line">- Measured on a scale of equal-sized units  按相同大小的单位测量</span><br><span class="line">- Values have order 数值有序 E.g., temperature <span class="keyword">in</span> C˚<span class="keyword">or</span> F˚, calendar dates</span><br><span class="line">- No true zero-point 无真正<span class="string">"零点"</span></span><br><span class="line">- `Ratio` 比率(倍数)</span><br><span class="line">- Inherent zero-point 固有零点</span><br><span class="line">- We can speak of values <span class="keyword">as</span> being an order of magnitude larger than the unit of measurement (<span class="number">10</span> K˚ <span class="keyword">is</span> twice <span class="keyword">as</span> high <span class="keyword">as</span> <span class="number">5</span> K˚).</span><br><span class="line">  我们可以说价值比测量单位大一个数量级（<span class="number">10</span>K˚是<span class="number">5</span>K˚的两倍）</span><br><span class="line">- e.g., temperature <span class="keyword">in</span> Kelvin, length, counts, monetary quantities</span><br><span class="line">  例如，以开尔文为单位的温度，长度，计数，货币数量</span><br><span class="line">* <span class="string">'Discrete Attribute'</span>  <span class="comment"># 离散属性</span></span><br><span class="line">- Has only a finite <span class="keyword">or</span> countably infinite set of values 只有一组有限或可数无限的值</span><br><span class="line">- E.g., zip codes, profession, <span class="keyword">or</span> the set of words <span class="keyword">in</span> a collection of documents </span><br><span class="line">  例如，邮政编码，专业或文档集合中的单词集</span><br><span class="line">- Sometimes, represented <span class="keyword">as</span> integer variables 有时，表示为`整数变量`</span><br><span class="line">- Note: Binary attributes are a special case of discrete attributes </span><br><span class="line">  注意：二进制属性是离散属性的特例</span><br><span class="line">* <span class="string">'Continuous Attribute'</span>  <span class="comment"># 连续属性</span></span><br><span class="line">- Has real numbers <span class="keyword">as</span> attribute values  将实数作为属性值</span><br><span class="line">- E.g., temperature, height, <span class="keyword">or</span> weight  例如，温度，高度或重量</span><br><span class="line">- Practically, real values can only be measured <span class="keyword">and</span> represented using a finite number of digits</span><br><span class="line">  实际上，只能使用有限数字来测量和表示实际值</span><br><span class="line">- Continuous attributes are typically represented <span class="keyword">as</span> floating-point variables</span><br><span class="line">  连续属性通常表示为`浮点变量`</span><br></pre></td></tr></table></figure></li></ul><h4 id="Data-statistics"><a href="#Data-statistics" class="headerlink" title="Data statistics"></a>Data statistics</h4><h5 id="Data-dispersion-分散-characteristics"><a href="#Data-dispersion-分散-characteristics" class="headerlink" title="Data dispersion(分散) characteristics"></a>Data dispersion(分散) characteristics</h5><ul><li><p><strong>Mean</strong></p><ul><li><p>Mean (<code>algebraic measure</code>) (sample vs. population):</p><p>Note: $n$ is sample size and $N$ is population size. </p><p>$\underbrace{\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i}_\text{sample}$    </p><p>$\underbrace{\mu  = \frac{1}{N}\sum_{i=1}^{n}x_i}_\text{population}$</p></li><li><p>Weighted arithmetic mean: 算术平均数/<code>加权平均数</code></p><p>$\bar{x}=\frac{\sum_{i=1}^{n}w_ix}{\sum_{i=1}^{n}w_i}$</p></li></ul></li><li><p><strong>Median</strong></p><p>Middle value if odd number of values, or average of the middle two values otherwise</p></li><li><p><strong>Mode</strong><br>Value that occurs <code>most frequently</code> in the data</p></li><li><p><strong>Properties of Normal Distribution Curve</strong></p><center><br>    <img src="/2019/01/01/数据分析与挖掘/NormalDistributionCurve.png" style="zoom:40%"><br></center></li><li><p><strong>Variance and Standard Deviation (sample: s, population: σ)</strong></p><ul><li><p><strong>Variance</strong>: (algebraic, scalable computation)</p><p>$s^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-x)^2=\frac{1}{n-1}[\sum_{i=1}^{n}{x_i}^2-\frac{1}{n}(\sum_{i=1}^{n}x_i)^2]$</p><p>${\sigma}^2 =\frac{1}{N}\sum_{i=1}^{n}(x_i-\mu)^2 = \frac{1}{N}\sum_{i=1}^{n}{x_i}^2-{\mu}^2 $</p></li><li><p><strong>Standard deviation</strong> $s$ (or $σ$) is the square root of variance $s^2$ (or $σ^2$)</p><p>$s = \sqrt{s^2}$</p><p>$\sigma = \sqrt{\sigma^2} $</p></li></ul></li><li><p><strong>standardized measure (z-score)</strong></p><p>$z=\frac{x-\mu}{\sigma}$</p></li></ul><h5 id="Graphic-Displays-of-Basic-Statistical-Descriptions"><a href="#Graphic-Displays-of-Basic-Statistical-Descriptions" class="headerlink" title="Graphic Displays of Basic Statistical Descriptions"></a>Graphic Displays of Basic Statistical Descriptions</h5><ul><li><p><strong>Boxplot:</strong> graphic display of five-number summary  箱线图</p><div style="width:1000px;margin:0;padding:0"><br>    <div style="float:left;width:200px;"><img src="/2019/01/01/数据分析与挖掘/Boxplot.png"></div><br>    <div style="float:right;width:800px;padding:14px"><br>        &bull; <b>Quartiles</b>: Q1 (25th percentile), Q3 (75th percentile)<br><br>        &bull; <b>Inter-quartile range</b>: IQR = Q3 – Q1 <br><br>        &bull; <b>Five number summary</b>: min, Q1, median, Q3, max<br><br>        &bull; <b>Boxplot</b>: Data is represented with a box<br><br>        &emsp; &bull; <b>Q1, Q3, IQR</b>:  The ends of the box are at the first and third quartiles, i.e., the height of the box is IQR<br><br>        &emsp; &bull; <b>Median (Q2)</b> is marked by a line within the box <br><br>        &emsp; &bull; <b>Whiskers</b>: two lines outside the box extended to Minimum and Maximum<br><br>    </div><br>    <div style="clear:both"></div><br></div></li><li><p><strong>Histogram:</strong> x-axis are values, y-axis repres. frequencies 柱状图/直方图</p></li><li><p><strong>Quantile plot:</strong>  each value $x_i$  is paired with $f_i$  indicating that approximately $100 f_i \%$ of data  are ​$\leq  x_i$ 分位图</p></li><li><p><strong>Quantile-quantile (q-q) plot:</strong> graphs the quantiles of one univariant distribution against the corresponding quantiles of another 绘制一个单变量分布的分位数与另一个分配的相应分位数的关系图.QQPlot图是用于直观验证一组数据是否来自某个分布，或者验证某两组数据是否来自同一（族）分布。在教学和软件中<code>常用的是检验数据是否来自于正态分布</code>。</p></li><li><p><strong>Scatter plot:</strong> each pair of values is a pair of coordinates and plotted as points in the plane 每对值是一对坐标并绘制为平面中的点 </p></li></ul><h5 id="Distance-on-Numeric-Data"><a href="#Distance-on-Numeric-Data" class="headerlink" title="Distance on Numeric Data"></a>Distance on Numeric Data</h5><p><strong>Dissimilarity (distance) matrix</strong>:  Usually symmetric, thus a <code>triangular matrix</code><br>$$<br>\begin{pmatrix}<br>0 &amp;  &amp;  &amp; \<br>d(2,1) &amp; 0  &amp;  &amp; \<br>… &amp; … &amp; … &amp; \<br>d(n,1) &amp; d(n,2)  &amp; … &amp; 0<br>\end{pmatrix}<br>$$</p><ul><li><p><strong>Minkowski distance</strong><br>$$<br>d(i,j)=\sqrt[p]{\left | x_{i1}-x_{j1} \right |^p+\left | x_{i2}-x_{j2} \right |^p+……+\left | x_{il}-x_{jl} \right |^p}<br>$$</p></li><li><p>$p = 1: (L_1 norm)$ <strong>Manhattan (or city block) distance</strong></p><p>E.g.,the Hamming distance: the number of bits that are different between two binary<br>vectors<br>$$<br>d(i,j)=\left | x_{i1}-x_{j1} \right |+\left | x_{i2}-x_{j2} \right |+……+\left | x_{il}-x_{jl} \right |<br>$$</p></li><li><p>$p = 2:  (L_2 norm)$ <strong>Euclidean distance</strong><br>$$<br>d(i,j)=\sqrt{\left | x_{i1}-x_{j1} \right |^2+\left | x_{i2}-x_{j2} \right |^2+……+\left | x_{il}-x_{jl} \right |^2}<br>$$</p></li><li><p>$p→ ∞: (L_{max} norm,L_∞ norm) $<strong>“supremum” distance</strong></p><p>The maximum difference between any component (attribute) of the vectors<br>$$<br>d(i,j)=\lim_{p→ ∞}\sqrt[p]{\left | x_{i1}-x_{j1} \right |^p+\left | x_{i2}-x_{j2} \right |^p+……+\left | x_{il}-x_{jl} \right |^p}=\max_{f=1}^{l}\left|x_{if}-x_{jf}\right|<br>$$</p></li></ul><h5 id="Proximity-邻近-Measure-for-Binary-Attributes"><a href="#Proximity-邻近-Measure-for-Binary-Attributes" class="headerlink" title="Proximity 邻近 Measure for Binary Attributes"></a>Proximity 邻近 Measure for Binary Attributes</h5><center><br>    <img src="/2019/01/01/数据分析与挖掘/ProximityMeasureforBinaryAttributes.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/Dissimilarity betweenAsymmetricBinaryVariables.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/CalculatingCosineSimilarity.png" width="600"><br></center><h3 id="Data-preprocessing"><a href="#Data-preprocessing" class="headerlink" title="Data preprocessing"></a>Data preprocessing</h3><center><br><img src="/2019/01/01/数据分析与挖掘/dataPreprocess_mainTask.png" width="600"><br></center><h4 id="Data-cleaning"><a href="#Data-cleaning" class="headerlink" title="Data cleaning"></a>Data cleaning</h4><ul><li><p>Handle <code>missing data</code>(Incomplete), smooth <code>noisy data</code>,identify or remove <code>outliers</code>, and resolve <code>inconsistencies</code> 处理丢失的数据，平滑噪声数据，识别或删除异常值，并解决不一致问题</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Data discrepancy detection'</span>  数据差异检测</span><br><span class="line">    - Use metadata (e.g., domain, range, dependency, distribution) </span><br><span class="line">      使用元数据（例如，域，范围，依赖关系，分发）</span><br><span class="line">    - Check field overloading  检查字段重载</span><br><span class="line">    - Check uniqueness rule, consecutive rule <span class="keyword">and</span> null rule</span><br><span class="line">      检查唯一性规则，连续规则和空规则</span><br><span class="line">    - Use commercial tools 使用商业工具</span><br><span class="line">      - Data scrubbing: use simple domain knowledge (e.g., postal code, spell-check) to detect errors <span class="keyword">and</span> make corrections </span><br><span class="line">        数据清理：使用简单的域知识（例如，邮政编码，拼写检查）来检测错误并进行更正</span><br><span class="line">      - Data auditing: by analyzing data to discover rules <span class="keyword">and</span> relationship to detect violators (e.g., correlation <span class="keyword">and</span> clustering to find outliers)  </span><br><span class="line">        数据审计：通过分析数据来发现规则和检测违规者的关系（例如，关联和聚类以查找异常值）</span><br><span class="line"></span><br><span class="line">* <span class="string">'Data migration and integration'</span> 数据迁移和集成</span><br><span class="line">  - Data migration tools: allow transformations to be specified 数据迁移工具：允许指定转换</span><br><span class="line">  - ETL (Extraction/Transformation/Loading) tools: allow users to specify transformations through a graphical user interface  </span><br><span class="line">    ETL（提取/转换/加载）工具：允许用户通过图形用户界面指定转换</span><br><span class="line"></span><br><span class="line">* <span class="string">'Integration of the two processes'</span> </span><br><span class="line">  - Iterative <span class="keyword">and</span> interactive (e.g., Potter’s Wheels)  迭代和互动（例如，波特的轮子）</span><br></pre></td></tr></table></figure></li></ul><h5 id="How-to-Handle-Missing-Data"><a href="#How-to-Handle-Missing-Data" class="headerlink" title="How to Handle Missing Data?"></a>How to Handle Missing Data?</h5><blockquote><p>1.忽略元组  2.手动填充  3. 自动（以unknown/均值/最可能的值）填充</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Ignore the tuple'</span>: usually done when <span class="class"><span class="keyword">class</span> <span class="title">label</span> <span class="title">is</span> <span class="title">missing</span> <span class="params">(when doing classification)</span>—<span class="title">not</span> <span class="title">effective</span> <span class="title">when</span> <span class="title">the</span> % <span class="title">of</span> <span class="title">missing</span> <span class="title">values</span> <span class="title">per</span> <span class="title">attribute</span> <span class="title">varies</span> <span class="title">considerably</span> </span></span><br><span class="line"><span class="class">  忽略元组：通常在缺少类标签时（进行分类时）完成 - 当每个属性的缺失值百分比变化很大时<span class="params">(该属性)</span>无效</span></span><br><span class="line"><span class="class"></span></span><br><span class="line">* Fill in the missing value 'manually': tedious + infeasible? </span><br><span class="line">  手动填写缺失值：单调乏味+不可行？</span><br><span class="line"></span><br><span class="line">* Fill <span class="keyword">in</span> it <span class="string">'automatically'</span> <span class="keyword">with</span></span><br><span class="line">  - a <span class="keyword">global</span> constant : e.g., “unknown”, a new <span class="class"><span class="keyword">class</span>?! </span></span><br><span class="line"><span class="class">  - <span class="title">the</span> <span class="title">attribute</span> <span class="title">mean</span>  属性平均值<span class="params">(与下一条的不同？)</span></span></span><br><span class="line"><span class="class">  - <span class="title">the</span> <span class="title">attribute</span> <span class="title">mean</span> <span class="title">for</span> <span class="title">all</span> <span class="title">samples</span> <span class="title">belonging</span> <span class="title">to</span> <span class="title">the</span> <span class="title">same</span> <span class="title">class</span>:</span> <span class="string">'smarter'</span></span><br><span class="line">  - the most probable value: inference-based such <span class="keyword">as</span> Bayesian formula <span class="keyword">or</span> decision tree</span><br></pre></td></tr></table></figure><h5 id="How-to-Handle-Noisy-Data"><a href="#How-to-Handle-Noisy-Data" class="headerlink" title="How to Handle Noisy Data?"></a>How to Handle Noisy Data?</h5><blockquote><p>1.分档  2.回归 3.聚类（无监督） 4.半监督</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* <span class="string">'Binning'</span> 分档</span><br><span class="line">  - First sort data <span class="keyword">and</span> partition into (equal-frequency) bins 首先将数据排序并分区为（等频）箱</span><br><span class="line">  - Then one can smooth by bin means, smooth by bin median, smooth by bin boundaries, etc.然后，可以通过bin均值平滑，通过bin中值平滑，通过bin边界平滑等。</span><br><span class="line">* <span class="string">'Regression'</span> 回归</span><br><span class="line">  - Smooth by fitting the data into regression functions 通过将数据拟合到回归函数中来平滑</span><br><span class="line">* <span class="string">'Clustering'</span> 聚类</span><br><span class="line">  - Detect <span class="keyword">and</span> remove outliers 检测并删除异常值</span><br><span class="line">* <span class="string">'Semi-supervised'</span>: Combined computer <span class="keyword">and</span> human inspection 半监督：计算机和人工检查相结合</span><br><span class="line">  - Detect suspicious values <span class="keyword">and</span> check by human (e.g., deal <span class="keyword">with</span> possible outliers) 检测可疑值并由人查验（例如，处理可能的异常值）</span><br></pre></td></tr></table></figure><h4 id="Data-integrating"><a href="#Data-integrating" class="headerlink" title="Data integrating"></a>Data integrating</h4><p>Integration of multiple databases, data cubes, or files 集成多个数据库，数据立方体或文件</p><blockquote><p>1.数据集成 2.模式集成 3.实体识别 4.检测和解决数据值的冲突</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Data integration'</span></span><br><span class="line">  - Combining data <span class="keyword">from</span> multiple sources into a coherent store </span><br><span class="line">    将来自多个来源的数据组合到一个连贯的存储中</span><br><span class="line">- <span class="string">'Schema integration'</span>: e.g., A.cust-id \equiv  B.cust-<span class="comment">#  模式集成</span></span><br><span class="line">  - Integrate metadata <span class="keyword">from</span> different sources </span><br><span class="line">集成来自不同来源的元数据</span><br><span class="line">- <span class="string">'Entity identification'</span> 实体识别</span><br><span class="line">  - Identify real world entities <span class="keyword">from</span> multiple data sources, e.g., Bill Clinton = William Clinton  </span><br><span class="line">    从多个数据源中识别真实世界的实体，例如Bill Clinton = William Clinton</span><br><span class="line">- <span class="string">'Detecting and resolving data value conflicts'</span>  检测和解决数据值冲突</span><br><span class="line">  - For the same real world entity, attribute values <span class="keyword">from</span> different sources are different </span><br><span class="line">    对于相同的现实世界实体，来自不同来源的属性值是不同的</span><br><span class="line">  - Possible reasons: different representations, different scales, e.g., metric vs. British units </span><br><span class="line">    可能的原因：不同的表示，不同的比例，例如，公制与英制单位</span><br></pre></td></tr></table></figure><h5 id="Handling-Redundancy-in-Data-Integration"><a href="#Handling-Redundancy-in-Data-Integration" class="headerlink" title="Handling Redundancy in Data Integration"></a>Handling Redundancy in Data Integration</h5><blockquote><p>1.冗余原因（对象标识、派生数据）2.检测手段（相关性和协方差分析）3.仔细整合</p></blockquote><ul><li><p>Redundant data occur often when integration of multiple databases 当多个数据库集成时，通常会出现冗余数据</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Object identification'</span>:  The same attribute <span class="keyword">or</span> object may have different names <span class="keyword">in</span> different databases </span><br><span class="line">  对象标识：相同的属性或对象在不同的数据库中可能具有不同的名称</span><br><span class="line">- <span class="string">'Derivable data:'</span> One attribute may be a “derived” attribute <span class="keyword">in</span> another table, e.g., annual revenue </span><br><span class="line">  派生数据：一个属性可以是另一个表中的“派生”属性，例如年收入</span><br></pre></td></tr></table></figure></li><li><p>Redundant attributes may be able to be detected by <a href="#Correlation Analysis">correlation analysis</a> and <a href="#Covariance">covariance analysis</a> 可以通过相关性分析和协方差分析来检测冗余属性</p></li><li><p>Careful integration of the data from multiple sources may help reduce/avoid redundancies and inconsistencies and improve mining speed and quality  仔细整合来自多个来源的数据可能有助于减少/避免冗余和不一致，并提高”采矿“速度和质量</p></li></ul><h4 id="Data-Reduction"><a href="#Data-Reduction" class="headerlink" title="Data Reduction"></a>Data Reduction</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Data reduction'</span> 数据压缩</span><br><span class="line">  - Obtain a reduced representation of the data set  获得数据集的缩减表示</span><br><span class="line">    - much smaller <span class="keyword">in</span> volume but yet produces almost the same analytical results </span><br><span class="line">      体积小得多，但产生几乎相同的分析结果</span><br><span class="line">- <span class="string">'Why data reduction ?'</span>—A database/data warehouse(仓库) may store terabytes of data</span><br><span class="line">  - Complex analysis may take a very long time to run on the complete data set </span><br><span class="line">    复杂分析可能需要很长时间才能在完整数据集上运行</span><br></pre></td></tr></table></figure><h5 id="Methods-for-data-reduction"><a href="#Methods-for-data-reduction" class="headerlink" title="Methods for data reduction"></a><strong>Methods for data reduction</strong></h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Regression and Log-Linear Models'</span>  （Parametric methods）</span><br><span class="line">- <span class="string">'Histograms, clustering, sampling'</span>  （Non-parametric methods）</span><br><span class="line">&gt; sampling: 选择具有代表性的子集；简单随机、放回、不放回、分层抽样</span><br><span class="line">- <span class="string">'Data cube aggregation'</span> 数据立方体聚合</span><br><span class="line">- <span class="string">'Data Compression'</span></span><br></pre></td></tr></table></figure><ul><li><p>Data cube aggregation 数据立方体聚合</p><p>The aggregated data for <strong>an individual entity of interest</strong>  感兴趣的实体聚合数据</p><center><br><img src="/2019/01/01/数据分析与挖掘/DataCubeAggregation.png" style="zoom:40%"><br></center><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Demographic Data &apos;人口统计学数据&apos;（Service、Age、Gender、Job level、Workforce Segment）</span><br><span class="line">- Organisational process data &apos;组织行为处理数据&apos;（Performance rating、Potential rating、Salary increases、Turnover、in training &amp; development）</span><br><span class="line">- Predictive attitudinal data &apos;预测态度数据&apos;（Competencies能力、Intention to stay、AffectIve commitment、Job satisfaction、Discretionary自动支配 effort）</span><br></pre></td></tr></table></figure></li><li><p>Data compression</p><center><br><img src="/2019/01/01/数据分析与挖掘/DataCompression.png" style="zoom:30%"><br></center></li></ul><h5 id="Dimensionality-Reduction-Techniques"><a href="#Dimensionality-Reduction-Techniques" class="headerlink" title="Dimensionality Reduction Techniques"></a>Dimensionality Reduction Techniques</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Dimensionality reduction methodologies</span></span><br><span class="line">- `Feature selection`: Find a subset of the original variables (<span class="keyword">or</span> features, attributes)    找寻合适子集(仅收集与分析任务相关的属性)</span><br><span class="line">- `Feature extraction`: Transform the data <span class="keyword">in</span> the high-dimensional space to a space of fewer dimensions  </span><br><span class="line">    高维映射至低维(降维)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Some typical dimensionality methods</span></span><br><span class="line">* Principal Component Analysis (<span class="string">'PCA'</span>) </span><br><span class="line">    - A statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components </span><br><span class="line">    一种统计过程，它使用<span class="string">'正交变换'</span>将可能相关变量的一组观察值转换为一组称为主成分的线性不相关变量值</span><br><span class="line">    - The original data are projected onto a much smaller space, resulting <span class="keyword">in</span> dimensionality reduction </span><br><span class="line">    将原始数据投影到更小的空间，从而减少维数 (Feature extraction 降维)</span><br><span class="line">    - Method:  Find the eigenvectors of the covariance matrix, <span class="keyword">and</span> these eigenvectors define the new space </span><br><span class="line">    找到协方差矩阵的特征向量，这些特征向量定义新的空间</span><br><span class="line"></span><br><span class="line">* <span class="string">'Supervised and nonlinear techniques'</span></span><br><span class="line">- `Feature subset selection`</span><br><span class="line">    - Best combined attribute selection(Best step-wise feature selection) <span class="keyword">and</span> elimination(Repeatedly eliminate the worst attribute)</span><br><span class="line">- `Feature creation`</span><br><span class="line">    - Create new attributes (features) that can capture the important information <span class="keyword">in</span> a data set more effectively than the original ones </span><br><span class="line">    创建新属性（功能），可以比原始信息更有效地捕获数据集中的重要信息   (比如，从成绩单中得出平均分/绩点)</span><br><span class="line">    - <span class="string">'Three general methodologies'</span></span><br><span class="line">    - `Attribute extraction` 降维</span><br><span class="line">        - Domain-specific</span><br><span class="line">        - Mapping data to new space (see: data reduction)</span><br><span class="line">        E.g., Fourier transformation, wavelet transformation, manifold approaches (<span class="keyword">not</span> covered)</span><br><span class="line">    - `Attribute construction` </span><br><span class="line">        - Combining features (see: discriminative frequent patterns <span class="keyword">in</span> Chapter on “Advanced Classification”)</span><br><span class="line">        - Data discretization</span><br></pre></td></tr></table></figure><h4 id="Data-transforming"><a href="#Data-transforming" class="headerlink" title="Data transforming"></a>Data transforming</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- A function that maps the entire set of values of a given attribute to a new set of replacement values s.t. each old value can be identified <span class="keyword">with</span> one of the new values  </span><br><span class="line">一种函数，它将给定属性的整个值集映射到一组新的替换值 使得 可以使用其中一个新值标识每个旧值</span><br><span class="line"></span><br><span class="line">- Methods</span><br><span class="line">  - <span class="string">'Smoothing'</span>: Remove noise <span class="keyword">from</span> data</span><br><span class="line">  - <span class="string">'Attribute/feature construction'</span>  属性/特征构建</span><br><span class="line">    - New attributes constructed <span class="keyword">from</span> the given ones</span><br><span class="line">  - <span class="string">'Aggregation'</span>: Summarization, data cube construction</span><br><span class="line">  - <span class="string">'Normalization'</span>: Scaled to fall within a smaller, specified range</span><br><span class="line">    - min-max normalization</span><br><span class="line">    - z-score normalization</span><br><span class="line">    - normalization by decimal scaling</span><br><span class="line">  - <span class="string">'Discretization'</span> 离散化: Concept hierarchy climbing</span><br></pre></td></tr></table></figure><h5 id="Normalization-归一化"><a href="#Normalization-归一化" class="headerlink" title="Normalization 归一化"></a>Normalization 归一化</h5><center><br><img src="/2019/01/01/数据分析与挖掘/Normalization.png" width="600"><br></center><h5 id="Concept-hierarchy-generation-概念层次生成"><a href="#Concept-hierarchy-generation-概念层次生成" class="headerlink" title="Concept hierarchy generation 概念层次生成"></a>Concept hierarchy generation 概念层次生成</h5><center><br><img src="/2019/01/01/数据分析与挖掘/ConceptHierarchyGeneration.png" width="600"><br></center><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Data Discretization Methods</span></span><br><span class="line">- <span class="string">'Binning'</span> </span><br><span class="line">- Top-down split, unsupervised</span><br><span class="line">- <span class="string">'Histogram'</span> analysis</span><br><span class="line">- Top-down split, unsupervised</span><br><span class="line">- <span class="string">'Clustering'</span> analysis </span><br><span class="line">- Unsupervised, top-down split <span class="keyword">or</span> bottom-up merge</span><br><span class="line">- <span class="string">'Decision-tree'</span> analysis</span><br><span class="line">- Supervised, top-down split</span><br><span class="line">- <span class="string">'Correlation'</span> (e.g., χ<span class="number">2</span>) analysis </span><br><span class="line">- Unsupervised, bottom-up merge</span><br><span class="line">- Note: All the methods can be applied `recursively`</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Concept hierarchy organizes concepts (i.e., attribute values) hierarchically <span class="keyword">and</span> <span class="keyword">is</span> usually associated <span class="keyword">with</span> each dimension <span class="keyword">in</span> a data warehouse </span><br><span class="line">  概念层次结构按层次组织概念（例如属性值），并且通常与数据仓库中的每个维度相关联</span><br><span class="line">- Concept hierarchies facilitate drilling <span class="keyword">and</span> rolling <span class="keyword">in</span> data warehouses to view data <span class="keyword">in</span> multiple granularity </span><br><span class="line">  概念层次结构有助于在数据仓库中钻取和滚动，以多种粒度查看数据</span><br><span class="line">- Concept hierarchy formation: Recursively reduce the data by collecting <span class="keyword">and</span> replacing low level concepts (such <span class="keyword">as</span> numeric values <span class="keyword">for</span> age) by higher level concepts (such <span class="keyword">as</span> youth, adult, <span class="keyword">or</span> senior) </span><br><span class="line">   概念层次结构：通过收集和替换更高级别概念（例如青年，成人或高级）的低级概念（例如年龄的数字值）来递归地减少数据</span><br><span class="line">- Concept hierarchies can be explicitly specified by domain experts <span class="keyword">and</span>/<span class="keyword">or</span> data warehouse designers </span><br><span class="line">  概念层次结构可以由域专家和/或数据仓库设计者明确指定</span><br><span class="line">- Concept hierarchy can be automatically formed <span class="keyword">for</span> both numeric <span class="keyword">and</span> nominal data—For numeric data, use discretization methods shown </span><br><span class="line">  可以为数字和标称数据自动形成概念层次结构 - 对于数字数据，使用显示的离散化方法</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Concept Hierarchy Generation for Nominal Data</span></span><br><span class="line">- Specification of a partial/total ordering of attributes explicitly at the schema level by users <span class="keyword">or</span> experts</span><br><span class="line">- <span class="string">'street &lt; city &lt; state &lt; country'</span></span><br><span class="line">- Specification of a hierarchy <span class="keyword">for</span> a set of values by explicit data grouping</span><br><span class="line">- <span class="string">'&#123;Urbana, Champaign, Chicago&#125; &lt; Illinois'</span></span><br><span class="line">- Specification of only a partial set of attributes</span><br><span class="line">- E.g., only <span class="string">'street &lt; city'</span>, <span class="keyword">not</span> others</span><br><span class="line">- Automatic generation of hierarchies (<span class="keyword">or</span> attribute levels) by the analysis of the number of distinct values</span><br><span class="line">- E.g., <span class="keyword">for</span> a set of attributes:<span class="string">'&#123;street, city, state, country&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Automatic Concept Hierarchy Generation</span></span><br><span class="line">- Some hierarchies can be automatically generated based on <span class="string">'the analysis of the number'</span> of distinct values per attribute <span class="keyword">in</span> the data set </span><br><span class="line">- The attribute <span class="keyword">with</span> the most distinct values <span class="keyword">is</span> placed at the lowest level of the hierarchy</span><br><span class="line">- Exceptions, e.g., weekday, month, quarter, year</span><br></pre></td></tr></table></figure><center><br><img src="/2019/01/01/数据分析与挖掘/AutomaticConceptHierarchyGeneration.png" width="600"><br></center><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><center><br>    <img src="/2019/01/01/数据分析与挖掘/Summary_datapreprocessing.png" width="600"><br></center><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><ul><li><p><strong>What is classification?</strong></p><p>根据训练集和类标签（分类属性中的值）构建模型，并将其用于分类新数据，预测其标签。</p><ul><li><p>Supervised learning </p><center><br><img src="/2019/01/01/数据分析与挖掘/SupervisedLearning.png" width="600"><br></center></li></ul></li></ul><pre><code>**监督学习**是机器学习任务的一种。它`从有标记的训练数据中推导出预测标签`。有标记的训练数据是指每个训练实例都包括输入和期望的输出。一句话：**给定数据，预测标签**。(分类、回归)**无监督学习**是机器学习任务的一种。它`从无标记的训练数据中推断结论`。最典型的无监督学习就是聚类分析，它可以在探索性数据分析阶段用于发现隐藏的模式或者对数据进行分组。一句话：**给定数据，寻找隐藏的结构**。</code></pre><ul><li><p><strong>Classification Steps</strong> </p><ol><li><strong>Model construction</strong> 模型构建</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Each sample <span class="keyword">is</span> assumed to belong to a predefined <span class="class"><span class="keyword">class</span> <span class="params">(shown by the class label)</span> </span></span><br><span class="line"><span class="class">  假设每个样本属于预定义的类（由类标签显示）</span></span><br><span class="line"><span class="class">- <span class="title">The</span> <span class="title">set</span> <span class="title">of</span> <span class="title">samples</span> <span class="title">used</span> <span class="title">for</span> <span class="title">model</span> <span class="title">construction</span> <span class="title">is</span> <span class="title">training</span> <span class="title">set</span>  </span></span><br><span class="line"><span class="class">  用于模型构建的样本集是训练集</span></span><br><span class="line"><span class="class">- '<span class="title">Model</span>':</span> Represented <span class="keyword">as</span> decision trees, rules, mathematical formulas, <span class="keyword">or</span> other forms </span><br><span class="line">  模型：表示为决策树，规则，数学公式或其他形式</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>Model Validation and Testing</strong></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Test'</span>: Estimate accuracy of the model </span><br><span class="line">  - The known label of test sample <span class="keyword">is</span> compared <span class="keyword">with</span> the classified result <span class="keyword">from</span> the model  </span><br><span class="line">    将已知的测试样品标签与模型的分类结果进行比较</span><br><span class="line">  - Accuracy: % of test set samples that are correctly classified by the model </span><br><span class="line">    准确度：按模型正确分类的测试集样本的百分比 </span><br><span class="line">  - Test set <span class="keyword">is</span> independent of training set  测试集独立于训练集</span><br><span class="line">- <span class="string">'Validation'</span>: If the test set <span class="keyword">is</span> used to select <span class="keyword">or</span> refine models, it <span class="keyword">is</span> called validation (development/test) set </span><br><span class="line">  验证：如果测试集用于选择或改进模型，则称为验证（开发/测试）集 To be better【与测试集相较，强调refine models】</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>Model Deployment</strong></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">If the accuracy <span class="keyword">is</span> acceptable, use the model to classify new data 【模型部署】</span><br></pre></td></tr></table></figure></li></ul><h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a><strong>Algorithms</strong></h3><h4 id="Decision-tree-ID3-C4-5-CART"><a href="#Decision-tree-ID3-C4-5-CART" class="headerlink" title="Decision tree-ID3,C4.5,CART"></a><a href="https://captainzj.github.io/2018/11/24/Classification-Algorithm/" target="_blank" rel="noopener">Decision tree-ID3,C4.5,CART</a></h4><p><a href="https://www.cnblogs.com/pinard/p/6050306.html" target="_blank" rel="noopener">决策树算法原理(上)</a>、<a href="https://www.cnblogs.com/pinard/p/6053344.html" target="_blank" rel="noopener">决策树算法原理(下)</a>、<a href="https://www.cnblogs.com/pinard/p/6056319.html" target="_blank" rel="noopener">scikit-learn决策树算法类库使用小结</a> </p><ul><li><p>Basic algorithm </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Tree <span class="keyword">is</span> constructed <span class="keyword">in</span> a top-down, recursive, divide-<span class="keyword">and</span>-conquer manner</span><br><span class="line">  树以自上而下，递归，分而治之的方式构建</span><br><span class="line">    - At start, all the training examples are at the root</span><br><span class="line">      一开始，所有的训练样例都是根源</span><br><span class="line">    - Examples are partitioned recursively based on selected attributes</span><br><span class="line">      样例基于被选定的属性递归地划分</span><br><span class="line">    - On each node, attributes are selected based on the training examples on that node, <span class="keyword">and</span> a heuristic <span class="keyword">or</span> statistical measure (e.g., information gain)</span><br><span class="line">      在每个节点上，基于<span class="string">'该节点上的训练示例'</span>以及<span class="string">'启发式或统计度量（例如，信息增益）'</span>来<span class="string">'选择属性'</span>。</span><br></pre></td></tr></table></figure><ul><li>Conditions for stopping partitioning </li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- All samples <span class="keyword">for</span> a given node belong to the same <span class="class"><span class="keyword">class</span> 给定节点的所有样本都属于同一个类</span></span><br><span class="line"><span class="class">- <span class="title">There</span> <span class="title">are</span> <span class="title">no</span> <span class="title">remaining</span> <span class="title">attributes</span> <span class="title">for</span> <span class="title">further</span> <span class="title">partitioning</span>  没有剩余属性可用于进一步分区</span></span><br><span class="line"><span class="class">- <span class="title">There</span> <span class="title">are</span> <span class="title">no</span> <span class="title">samples</span> <span class="title">left</span>  没有剩下的样例</span></span><br></pre></td></tr></table></figure><ul><li>Prediction</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'Majority voting'</span> <span class="keyword">is</span> employed <span class="keyword">for</span> classifying the leaf</span><br></pre></td></tr></table></figure></li><li><p><a href="https://captainzj.github.io/2018/11/24/Classification-Algorithm/#%E4%BF%A1%E6%81%AF%E7%86%B5-Entropy" target="_blank" rel="noopener">Entropy</a>   <a href="#Example: Attribute Selection with Information Gain">Example: Attribute Selection with Information Gain</a>   <a href="#Computation of Gini Index">Computation of Gini Index</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Entropy 信息熵:  表征混乱程度 </span><br><span class="line">- Conditional Entropy条件熵: 在已知随机变量X的条件下随机变量Y的不确定性(概率)</span><br><span class="line">- Mutual Information互信息/Information gain信息增益: 得知特征X的信息而使得类Y的信息的不确定性减少的程度(越大越好) -&gt;&gt; ID3决策树</span><br><span class="line">- Gain Ratio信息增益比: 解决使用信息增益存在偏向于选择取值较多的特征的问题(越大越好) -&gt;&gt; C4.5决策树 </span><br><span class="line">- GINI index基尼指数： 表征不纯度(越小越好)  -&gt;&gt;  CART分类树</span><br></pre></td></tr></table></figure></li><li><p>剪枝</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* 预剪枝(prepruning),通过提前停止树的构建(例如，通过决定在给定的结点`不再分裂或划分`训练元组的子集)而对树<span class="string">"剪枝"</span>。如果划分一个结点的元组导致低于预定义(信息增益、基尼指数等度量方式)阈值的划分，则给定子集的进一步划分将停止。然而，选取一个适当的阈值是困难的。高阈值可能导致过分简化的树，而低阈值可能使得树的简化不足。</span><br><span class="line">* 后剪枝(postpruning)，它由<span class="string">"完全生长"</span>的树剪去子树。通过删除结点的分支并用树叶替换它而剪掉给定结点上的子树。</span><br><span class="line">- E.g. CART使用代价复杂度剪枝算法</span><br><span class="line">* 组合方法：预剪枝和后剪枝交叉使用。后剪枝所需要的计算比预剪枝多，但是通常产生更可靠的树。</span><br></pre></td></tr></table></figure></li><li><p>Advantage</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）&apos;简单直观&apos;，生成的决策树很直观。</span><br><span class="line">2）基本&apos;不需要预处理&apos;，不需要提前归一化，处理缺失值。</span><br><span class="line">3）使用决策树预测的代价是O(log2m)。 m为样本数。</span><br><span class="line">4）既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。</span><br><span class="line">5）可以&apos;处理多维度输出&apos;的分类问题。</span><br><span class="line">6）相比于神经网络之类的黑盒分类模型，决策树在逻辑上有很好的&apos;可解释性&apos;</span><br><span class="line">7）可以交叉验证的&apos;剪枝&apos;来选择模型，从而提高泛化能力。</span><br><span class="line">8）对于异常点的&apos;容错能力&apos;好，健壮性高。</span><br></pre></td></tr></table></figure></li><li><p>Disadvantage</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>）决策树算法非常容<span class="string">'易过拟合'</span>，导致<span class="string">'泛化能力不强'</span>.可以通过设置节点最少样本数量和限制决策树深度来改进.</span><br><span class="line"><span class="number">2</span>）决策树会因为样本发生一点点的改动，就会导致树<span class="string">'结构的剧烈改变'</span>。这个可以通过集成学习之类的方法解决.</span><br><span class="line"><span class="number">3</span>）寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，<span class="string">'容易陷入局部最优'</span>。可以通过集成学习之类的方法来改善。</span><br><span class="line"><span class="number">4</span>）有些比较<span class="string">'复杂的关系'</span>，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。</span><br><span class="line"><span class="number">5</span>）如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。</span><br><span class="line">6）处理大数据集，决策树的构造可能变得效率低下('可伸缩问题') -&gt;&gt; RainForest(雨林)，能适应可用的内存量，并应用于任意决策树归纳算法</span><br></pre></td></tr></table></figure></li><li><p>决策树算法比较</p><p>|  算法  |  支持模型  | 树结构 |      特征选择      | 连续值处理 | 缺失值处理 |  剪枝  |<br>| :—-: | :——–: | :—-: | :—————-: | :——–: | :——–: | :—-: |<br>| <code>ID3</code>  |    分类    | 多叉树 |     <code>信息增益</code>     |   不支持   |   不支持   | 不支持 |<br>| <code>C4.5</code> |    分类    | 多叉树 |    <code>信息增益比</code>    |    支持    |    支持    |  支持  |<br>| <code>CART</code> | 分类，回归 | 二叉树 | <code>基尼系数，均方差</code> |    支持    |    支持    |  支持  |</p></li></ul><h4 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h4><ul><li>Define: Find a linear/non-linear hyperplane (decision boundary) that will separate the data</li><li>Optimize：希望所有的点都离超平面远 -&gt;  可以让离超平面比较近的点尽可能的远离超平面</li><li>kernel核函数：将数据从低维空间映射到高维空间</li></ul><p><a href="https://www.cnblogs.com/pinard/p/6097604.html" target="_blank" rel="noopener">支持向量机原理(一) 线性支持向量机</a>、<a href="https://www.cnblogs.com/pinard/p/6100722.html" target="_blank" rel="noopener">支持向量机原理(二) 线性支持向量机的软间隔最大化模型</a>、<a href="https://www.cnblogs.com/pinard/p/6103615.html" target="_blank" rel="noopener">支持向量机原理(三)线性不可分支持向量机与核函数</a>、<a href="https://www.cnblogs.com/pinard/p/6111471.html" target="_blank" rel="noopener">支持向量机原理(四)SMO算法原理</a>、<a href="https://www.cnblogs.com/pinard/p/6113120.html" target="_blank" rel="noopener">支持向量机原理(五)线性支持回归</a>、<a href="https://www.cnblogs.com/pinard/p/6117515.html" target="_blank" rel="noopener">scikit-learn 支持向量机算法库使用小结</a>、<a href="https://www.cnblogs.com/pinard/p/6126077.html" target="_blank" rel="noopener">支持向量机高斯核调参小结</a></p><h4 id="Bayes"><a href="#Bayes" class="headerlink" title="Bayes"></a>Bayes</h4><ul><li><p>Basic Concepts</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* P(H|X): 后验概率. 基于相关性描述(证据)X, <span class="string">'假设H'</span>成立的概率</span><br><span class="line">* P(H): 先验概率.  一般情况下(没有相关约束)，<span class="string">'假设H'</span>成立的概率</span><br><span class="line"></span><br><span class="line">在分类问题中,希望确定 给定“证据”X，假设H成立的概率P(H|X).</span><br></pre></td></tr></table></figure><p><strong>贝叶斯定理：</strong> $P(H|X)=\frac{P(X|H)P(H)}{P(X)}$</p></li><li><p>Naïve Bayesian Classifier</p><blockquote><p>后验概率最大化来判断分类</p></blockquote><p>1) 如果没有Y的先验概率，则计算Y的K个先验概率：$P(Y=C_k)$</p><p>2) 分别计算第k个类别的第j维特征的第l个个取值条件概率：$P(X_j=x_{jl}|Y=C_k)$</p><p>3）对于实例$X^{(test)}$，分别计算：$P(Y=C_k)\prod_{j=1}^{n}P(X_j=x_j^{(test)}|Y=C_k)$</p><p>4) 确定实例$X^{(test)}$的分类$C_{result}  = \underbrace{argmax}_{C_k}P(Y=C_k)\prod_{j=1}^{n}P(X_j=X_j^{(test)}|Y=C_k) $ </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Advantages</span></span><br><span class="line"> Easy to implement  易于实现</span><br><span class="line"> Good results obtained <span class="keyword">in</span> most of the cases 大多数情况下获得了良好的结果</span><br><span class="line"><span class="comment"># Disadvantages</span></span><br><span class="line"> Assumption: class conditional independence, therefore loss of accuracy类条件独立-&gt;准确率缺失</span><br><span class="line"> Practically, dependencies exist among variables</span><br><span class="line">  实际上，变量之间存在依赖关系</span><br><span class="line"> E.g., hospitals: patients: Profile: age, family history, etc. Symptoms: fever, cough etc., Disease: lung cancer, diabetes,etc.</span><br><span class="line"> Dependencies among these cannot be modeled by Naïve Bayesian Classifier</span><br><span class="line">      这些依赖关系不能用朴素贝叶斯分类器建模</span><br><span class="line"><span class="comment"># How to deal with these dependencies? Bayesian Belief Networks</span></span><br><span class="line">  如何处理这些依赖关系？贝叶斯置信网络</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://www.cnblogs.com/pinard/p/6069267.html" target="_blank" rel="noopener">朴素贝叶斯算法原理小结</a>、<a href="https://www.cnblogs.com/pinard/p/6074222.html" target="_blank" rel="noopener">scikit-learn 朴素贝叶斯类库使用小结</a></p><h4 id="ANN"><a href="#ANN" class="headerlink" title="ANN"></a>ANN</h4><blockquote><p>受生物神经元的启发，将<strong>多输入单输出</strong>的信息处理单元作为人工神经网络中的一个神经元。人工神经网络的基本结构如下：输入层(输入层的神经元数目对应于训练集数据的属性数目)、隐藏层、输出层(输出层的神经元数目对应于网络预测的分类数目)</p></blockquote><center><br>    <img src="/2019/01/01/数据分析与挖掘/ANN_Architecture.png" width="600"><br></center><ul><li><p>Backpropagation</p><blockquote><p>Backpropagate the error (by updating weights and biases)</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Terminating condition (when error is very small, etc.)</span></span><br><span class="line"> Small changes <span class="keyword">in</span> weights  已接近<span class="string">"最优"</span></span><br><span class="line"> Small errors  结果可接受</span><br><span class="line"> Number of predefined iterations </span><br><span class="line"></span><br><span class="line"><span class="comment"># more</span></span><br><span class="line"> 反向传播可能会停留在局部最小值，但实际上它通常表现良好</span><br></pre></td></tr></table></figure></li></ul><h5 id="DeepLearning"><a href="#DeepLearning" class="headerlink" title="DeepLearning"></a>DeepLearning</h5><blockquote><p>通过更深的layers，自动提取特征（构建特征空间），以达到更”深层次”的学习效果</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Train networks <span class="keyword">with</span> many layers (vs. shallow nets <span class="keyword">with</span> just a couple of layers) </span><br><span class="line">  <span class="string">'训练具有多层的网络'</span>（与仅有几层的浅网络）</span><br><span class="line"> More neurons than previous networks 与以前的网络相比，有更多的神经元</span><br><span class="line"> More complex ways to connect layers 更复杂的连接层的方法</span><br><span class="line"> Tremendous computing power to train networks 以巨大计算能力训练网络</span><br><span class="line"> Automatic feature extraction <span class="string">'自动特征提取'</span></span><br><span class="line">- Multiple layers work to build <span class="string">'an improved feature space'</span></span><br><span class="line">  多个层用于构建改进的特征空间</span><br><span class="line"> Analogy: Signals passing through regions of the visual cortex</span><br><span class="line">  类比：信号通过视觉皮层的区域</span><br><span class="line">     Example: For face recognition: edge → nose → face, layer-by-layer</span><br><span class="line">      示例：用于面部识别：边缘→鼻子→面部，逐层</span><br><span class="line">- <span class="string">'Popular Deep Learning Frameworks'</span> <span class="keyword">for</span> Classification </span><br><span class="line"> Deep Feedforward Neural Networks 深度前馈神经网络</span><br><span class="line"> Convolutional Neural Networks 卷积神经网络</span><br><span class="line"> Recurrent Neural Networks 回归神经网络</span><br><span class="line"></span><br><span class="line"><span class="comment"># More</span></span><br><span class="line"> 为解决梯度消失/梯度爆炸、训练退化的问题，提出ResNet</span><br><span class="line"> 为实现特征的复用，提出DenseNet</span><br></pre></td></tr></table></figure><h3 id="Ensemble-methods"><a href="#Ensemble-methods" class="headerlink" title="Ensemble methods"></a>Ensemble methods</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Ensemble Methods: Increasing the Accuracy</span></span><br><span class="line">Ensemble methods</span><br><span class="line">- Use a combination of models to increase accuracy</span><br><span class="line">      使用模型组合来提高准确性</span><br><span class="line">- Combine a series of k learned models, M1, M2, ..., Mk, <span class="keyword">with</span> the aim of creating an improved model M*</span><br><span class="line">      结合一系列k学习模型，M1，M2，...，Mk，旨在创建一个改进的模型M*</span><br><span class="line"></span><br><span class="line">Popular ensemble methods</span><br><span class="line">- <span class="string">'Bagging'</span>: Trains each model using a subset of the training set, <span class="keyword">and</span> models learned <span class="keyword">in</span> parallel</span><br><span class="line">      Bagging: 使用训练集的子集训练每个模型，并且并行学习模型</span><br><span class="line">- <span class="string">'Boosting'</span>: Trains each new model instance to emphasize the training instances that previous models mis-classified, <span class="keyword">and</span> models learned <span class="keyword">in</span> order</span><br><span class="line">      Boosting：训练每个新模型实例以强调先前模型错误分类的训练实例，以及按顺序学习的模型</span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/pinard/p/6131423.html" target="_blank" rel="noopener">集成学习原理小结</a></p><h4 id="Bagging-Bootstrap-Aggregation"><a href="#Bagging-Bootstrap-Aggregation" class="headerlink" title="Bagging: Bootstrap Aggregation"></a>Bagging: Bootstrap Aggregation</h4><center><br>    <img src="/2019/01/01/数据分析与挖掘/BootstrapAggregation.png" width="600"><br></center><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Analogy'</span>: Diagnosis based on multiple doctors’ <span class="string">'majority vote'</span></span><br><span class="line">- <span class="string">'Training'</span></span><br><span class="line">- Given a set D of d tuples, at each iteration i, a training set Di of d tuples <span class="keyword">is</span> sampled <span class="keyword">with</span> replacement <span class="keyword">from</span> D (i.e., bootstrap)</span><br><span class="line">      给定d个元组的D组，在每次迭代i中，对D元组的训练集Di进行<span class="string">'采样'</span>，并用D替换（即<span class="string">'自举'</span>）</span><br><span class="line">- A classifier model <span class="string">'Mi'</span> <span class="keyword">is</span> learned <span class="keyword">for</span> each training set <span class="string">'Di'</span></span><br><span class="line">      为每个训练集Di学习分类器模型Mi.</span><br><span class="line">- <span class="string">'Classification'</span>: classify an <span class="string">'unknown sample X'</span></span><br><span class="line">- Each classifier Mi returns its <span class="class"><span class="keyword">class</span> <span class="title">prediction</span></span></span><br><span class="line"><span class="class">- <span class="title">The</span> <span class="title">bagged</span> <span class="title">classifier</span> <span class="title">M</span>* '<span class="title">counts</span> <span class="title">the</span> <span class="title">votes</span>' <span class="title">and</span> <span class="title">assigns</span> <span class="title">the</span> <span class="title">class</span> <span class="title">with</span> <span class="title">the</span> <span class="title">most</span></span></span><br><span class="line"><span class="class"><span class="title">votes</span> <span class="title">to</span> <span class="title">X</span> </span></span><br><span class="line"><span class="class">- '<span class="title">Prediction</span>':</span> It can be applied to the prediction of <span class="string">'continuous values'</span> by <span class="string">'taking the</span></span><br><span class="line"><span class="string">average value'</span> of each prediction <span class="keyword">for</span> a given test tuple</span><br><span class="line">  预测: 它可以应用于连续值的预测 by 给定测试元组的每个预测的平均值</span><br><span class="line">- <span class="string">'Accuracy'</span>: Improved accuracy <span class="keyword">in</span> prediction</span><br><span class="line">- Often significantly better than a single classifier derived <span class="keyword">from</span> D</span><br><span class="line">      通常明显优于源自D的单一分类器</span><br><span class="line">- For noise data: Not considerably worse, more robust</span><br><span class="line">      对于噪声数据：不会更糟，而是更健壮</span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/pinard/p/6156009.html" target="_blank" rel="noopener">Bagging与随机森林算法原理小结</a></p><h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h4><blockquote><p>（Bagging）投票得分    -&gt;  （Boosting）加权得分</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Analogy: Consult several doctors, based on <span class="string">'a combination of weighted'</span> diagnoses—weight assigned based on the previous diagnosis accuracy</span><br><span class="line">- How boosting works?</span><br><span class="line">- Weights are assigned to each training tuple</span><br><span class="line">      <span class="string">'权重'</span>分配给每个训练元组</span><br><span class="line">- A series of k classifiers <span class="keyword">is</span> iteratively learned</span><br><span class="line">      迭代学习一系列k个分类器</span><br><span class="line">- After a classifier Mi <span class="keyword">is</span> learned, the weights are updated to allow the subsequent classifier, Mi+<span class="number">1</span>, to <span class="string">'pay more attention to the training tuples that were misclassified'</span> by Mi</span><br><span class="line">      在学习分类器Mi之后，权重被更新以允许随后的分类器Mi+<span class="number">1</span><span class="string">'更多地关注被Mi错误分类的训练元组'</span></span><br><span class="line">- The final M* <span class="string">'combines the votes'</span> of each individual classifier, where the weight of each classifie<span class="string">r's vote is a function of its accuracy</span></span><br><span class="line"><span class="string">      最终的M*结合了每个分类器的投票，每个分类器的投票'</span>权重<span class="string">'是其'</span>准确性<span class="string">'的函数</span></span><br><span class="line"><span class="string">- Boosting algorithm can be extended for numeric prediction</span></span><br><span class="line"><span class="string">  可以扩展Boosting算法进行'</span>数值预测<span class="string">'</span></span><br><span class="line"><span class="string">- Comparing with bagging: Boosting tends to have greater accuracy, but it also risks overfitting the model to misclassified data</span></span><br><span class="line"><span class="string">  与装袋相比：boosting往往具有更高的'</span>准确性<span class="string">'，但也存在过度拟合模型错误分类数据的'</span>风险<span class="string">'</span></span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/pinard/p/6133937.html" target="_blank" rel="noopener">集成学习之Adaboost算法原理小结</a>、<a href="https://www.cnblogs.com/pinard/p/6136914.html" target="_blank" rel="noopener">scikit-learn Adaboost类库使用小结</a></p><h4 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h4><blockquote><p>Avariation of bagging for decision trees 对<strong>决策树的bagging</strong>的’变异’</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Random Forest (first proposed by L. Breiman in 2001)</span></span><br><span class="line">- Avariation of bagging <span class="keyword">for</span> decision trees 对决策树的bagging的<span class="string">'变异'</span></span><br><span class="line">- Data bagging 数据装袋</span><br><span class="line">- Use a subset of training data by sampling <span class="keyword">with</span> replacement <span class="keyword">for</span> each tree</span><br><span class="line">      通过<span class="string">'采样'</span>为每棵树<span class="string">'替换'</span>使用训练数据的子集</span><br><span class="line">- Feature bagging</span><br><span class="line">- At each node use a random selection of attributes <span class="keyword">as</span> candidates <span class="keyword">and</span> split by the best attribute among them</span><br><span class="line">      在每个节点使用<span class="string">'随机'</span>选择的属性作为<span class="string">'候选'</span>并且以它们中的<span class="string">'最佳'</span>属性进行<span class="string">'划分'</span></span><br><span class="line">- Compared to original bagging,increases the diversity among generated trees</span><br><span class="line">  与原始套袋相比，增加了生成树的<span class="string">'多样性'</span></span><br><span class="line">- During classification, each tree <span class="string">'votes'</span> <span class="keyword">and</span> the <span class="string">'most popular'</span> <span class="class"><span class="keyword">class</span> <span class="title">is</span> <span class="title">returned</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"># <span class="title">Two</span> <span class="title">Methods</span> <span class="title">to</span> <span class="title">construct</span> <span class="title">Random</span> <span class="title">Forest</span></span></span><br><span class="line"><span class="class">- <span class="title">Forest</span>-<span class="title">RI</span> <span class="params">(random input selection)</span>:</span> Randomly select, at each node, F attributes <span class="keyword">as</span> candidates <span class="keyword">for</span> the split at the node. The CART methodology <span class="keyword">is</span> used to grow the trees to maximum size</span><br><span class="line">      Forest-RI（<span class="string">'随机输入'</span>选择）：在每个节点上随机选择F属性作为节点分割的候选者。 CART方法用于将树增长到最大尺寸</span><br><span class="line">- Forest-RC (random linear combinations): Creates new attributes (<span class="keyword">or</span> features) that are a linear combination of the existing attributes (reduces the correlation between individual classifiers)</span><br><span class="line">      Forest-RC（<span class="string">'随机线性组合'</span>）：创建属于现有属性的线性组合的新属性（或特征）（减少各个分类器之间的相关性）</span><br><span class="line">- Comparable <span class="keyword">in</span> accuracy to Adaboost, but more robust to errors <span class="keyword">and</span> outliers</span><br><span class="line">  与Adaboost相比具有可比性，但对错误和异常值<span class="string">'更具鲁棒性'</span></span><br><span class="line">- Insensitive to the number of attributes selected <span class="keyword">for</span> consideration at each split, <span class="keyword">and</span> faster than typical bagging <span class="keyword">or</span> boosting</span><br><span class="line">  对每次拆分时选择的<span class="string">'属性数量不敏感'</span>，并且比典型的bagging或boosting<span class="string">'速度更快'</span></span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/pinard/p/6160412.html" target="_blank" rel="noopener">scikit-learn随机森林调参小结</a></p><h3 id="Model-evaluation-and-selection"><a href="#Model-evaluation-and-selection" class="headerlink" title="Model evaluation and selection"></a><strong>Model evaluation and selection</strong></h3><h4 id="Classifier-Evaluation-Metrics"><a href="#Classifier-Evaluation-Metrics" class="headerlink" title="Classifier Evaluation Metrics"></a>Classifier Evaluation Metrics</h4><p><a href="#Classifier Evaluation Metrics: Example">Classifier Evaluation Metrics: Example</a></p><h5 id="Confusion-matrix-and-criteria"><a href="#Confusion-matrix-and-criteria" class="headerlink" title="Confusion matrix and criteria"></a>Confusion matrix and criteria</h5><center><br>    <img src="/2019/01/01/数据分析与挖掘/ConfusionMatrix.png" width="600"><br></center><p><a href="https://www.cnblogs.com/pinard/p/5993450.html" target="_blank" rel="noopener">精确率与召回率，RoC曲线与PR曲线</a></p><h4 id="Estimating-a-classifier’s-accuracy"><a href="#Estimating-a-classifier’s-accuracy" class="headerlink" title="Estimating a classifier’s accuracy"></a>Estimating a classifier’s accuracy</h4><h5 id="Cross-evaluation"><a href="#Cross-evaluation" class="headerlink" title="Cross-evaluation"></a>Cross-evaluation</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Cross-validation (k-fold, where k = 10 is most popular)</span></span><br><span class="line">- Randomly partition the data into k mutually exclusive subsets, each approximately equal size </span><br><span class="line">  随机将数据划分为k个互斥的子集，每个子集的大小大致相等</span><br><span class="line">- At i-th iteration, use Di <span class="keyword">as</span> test set <span class="keyword">and</span> others <span class="keyword">as</span> training set </span><br><span class="line">  在第i次迭代中，使用Di作为测试集，使用其他作为训练集</span><br><span class="line">- Leave-one-out: k folds where k = <span class="string">'#'</span> of tuples, <span class="keyword">for</span> small sized data </span><br><span class="line">  留一个：k折叠，其中k = <span class="string">'#'</span> 元组的数量，对于小尺寸数据</span><br><span class="line">- *Stratified cross-validation*: folds are stratified so that class distribution, in each fold is approximately the same as that in the initial data </span><br><span class="line">   *分层交叉验证*：折叠是分层的，因此每个折叠中的类分布与初始数据中的类别分布大致相同</span><br><span class="line"></span><br><span class="line"><span class="comment"># Holdout method</span></span><br><span class="line">- Given data <span class="keyword">is</span> randomly partitioned into two independent sets</span><br><span class="line">  给定数据被随机分成两个独立的集合</span><br><span class="line">- Training set (e.g., <span class="number">2</span>/<span class="number">3</span>) <span class="keyword">for</span> model construction </span><br><span class="line">      模型构建的训练集（例如，<span class="number">2</span>/<span class="number">3</span>）</span><br><span class="line">- Test set (e.g., <span class="number">1</span>/<span class="number">3</span>) <span class="keyword">for</span> accuracy estimation</span><br><span class="line">      测试集（例如，<span class="number">1</span>/<span class="number">3</span>）用于准确度估计</span><br><span class="line">- Repeated random sub-sampling validation: a variation of holdout</span><br><span class="line">  重复随机子采样验证：保持的变化</span><br><span class="line">- Repeat holdout k times, accuracy = avg. of the accuracies obtained</span><br><span class="line">      重复k次，精度= 所得准确性的平均值</span><br><span class="line">      </span><br><span class="line"><span class="comment"># Bootstrap 引导程序</span></span><br><span class="line">- Works well <span class="keyword">with</span> small data sets <span class="string">'适用于小型数据集'</span></span><br><span class="line">- Samples the given training tuples uniformly <span class="keyword">with</span> replacement</span><br><span class="line">  均匀地对给定的训练元组进行<span class="string">'取样'</span></span><br><span class="line">- Each time a tuple <span class="keyword">is</span> selected, it <span class="keyword">is</span> equally likely to be selected again <span class="keyword">and</span> re-</span><br><span class="line">added to the training set</span><br><span class="line">  每次选择元组时，同样可能再次选择并重新添加到训练集</span><br><span class="line">- Several bootstrap methods, <span class="keyword">and</span> a common one <span class="keyword">is</span> <span class="number">.632</span> bootstrap</span><br><span class="line">  有几种引导方法，常见的方法是<span class="number">.632</span>引导程序 (大约<span class="number">63.2</span>％的原始数据最终在bootstrap中，其余<span class="number">36.8</span>％形成测试集)</span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/pinard/p/5992719.html" target="_blank" rel="noopener">交叉验证(Cross Validation)原理小结</a></p><h4 id="Issues-Affecting-Model-Selection"><a href="#Issues-Affecting-Model-Selection" class="headerlink" title="Issues Affecting Model Selection"></a>Issues Affecting Model Selection</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Accuracy'</span> 准确性</span><br><span class="line">- classifier accuracy: predicting <span class="class"><span class="keyword">class</span> <span class="title">label</span></span></span><br><span class="line"><span class="class">- '<span class="title">Speed</span>' 速度</span></span><br><span class="line"><span class="class">- <span class="title">time</span> <span class="title">to</span> <span class="title">construct</span> <span class="title">the</span> <span class="title">model</span> <span class="params">(training time)</span> 构建模型的时间（训练时间）</span></span><br><span class="line"><span class="class">- <span class="title">time</span> <span class="title">to</span> <span class="title">use</span> <span class="title">the</span> <span class="title">model</span> <span class="params">(classification/prediction time)</span>  使用模型的时间（分类/预测时间）</span></span><br><span class="line"><span class="class">- '<span class="title">Robustness</span>' 鲁棒性<span class="params">(稳健性)</span>:</span> handling noise <span class="keyword">and</span> missing values</span><br><span class="line">- <span class="string">'Scalability'</span> 可伸缩性: efficiency <span class="keyword">in</span> disk-resident databases 磁盘驻留数据库的效率</span><br><span class="line">- <span class="string">'Interpretability'</span> 可解释性</span><br><span class="line">- understanding <span class="keyword">and</span> insight provided by the model 模型提供的理解和洞察力</span><br><span class="line">- <span class="string">'Other measures'</span>, e.g., goodness of rules, such <span class="keyword">as</span> decision tree size <span class="keyword">or</span> compactness of classification rules</span><br><span class="line">  其他措施，例如规则的好处，例如决策树大小或分类规则的紧凑性</span><br></pre></td></tr></table></figure><h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/01/数据分析与挖掘/classification_summary1.png" width="600"><br><img src="/2019/01/01/数据分析与挖掘/classification_summary2.png" width="600"><br><img src="/2019/01/01/数据分析与挖掘/classification_summary3.png" width="600"><br></center><h2 id="Frequent-patterns"><a href="#Frequent-patterns" class="headerlink" title="Frequent patterns"></a>Frequent patterns</h2><ul><li><p><strong>What is a frequent pattern</strong> </p><figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="comment"># basic concept</span></span><br><span class="line"> 满足最小支持度的项集F -&gt;&gt; F为'频繁项集'(frequent pattern)</span><br><span class="line"> 项集L的任意超集均为非频繁项集 -&gt;&gt; L为'最大频繁模式'(Max-Pattern)/最大频繁项集(Maximal Frequent Itemset)</span><br><span class="line"> 项集X的直接超集(最小的严格超集)的支持度计数都不等于(小于)ta本身的支持度计数 -&gt;&gt; X为'闭合频繁项集'(closed-pattern)</span><br></pre></td></tr></table></figure></li></ul><h3 id="Association-rule"><a href="#Association-rule" class="headerlink" title="Association rule"></a><strong>Association rule</strong></h3><blockquote><p>关联规则就是有关联的规则，形式是这样定义的：<em>两个不相交的非空集合X、Y，如果有X–&gt;Y，就说X–&gt;Y是一条关联规则</em>。举个例子，在上面的表中，我们发现购买啤酒就一定会购买尿布，{啤酒}–&gt;{尿布}就是一条关联规则。关联规则的强度用支持度$Support$和置信度$Confidence$等描述</p></blockquote><center><br>    <img src="/2019/01/01/数据分析与挖掘/AssociationRules.png" width="600"><br></center><p>一般来说，要选择一个数据集合中的频繁数据集，则需要自定义评估标准。最常用的评估标准是用自定义的支持度，或者是自定义支持度和置信度的一个组合。</p><ul><li><p>关联规则挖掘步骤</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="string">'生成频繁项集'</span></span><br><span class="line">   这一阶段找出所有满足最小支持度的项集，找出的这些项集称为频繁项集</span><br><span class="line"><span class="number">2.</span> <span class="string">'生成规则'</span></span><br><span class="line">   在上一步产生的频繁项集的基础上生成满足最小置信度的规则，产生的规则称为强规则</span><br></pre></td></tr></table></figure></li></ul><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><h4 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a><strong>Apriori</strong></h4><p>为了减少频繁项集的生成时间，我们应该尽早的消除一些完全不可能是频繁项集的集合，故而引出Apriori的两条定律：</p><ol><li><em>如果一个集合是频繁项集，则它的所有子集都是频繁项集</em>。</li><li><em>如果一个集合不是频繁项集，则它的所有超集都不是频繁项集。</em></li></ol><p>利用这两条定律，我们抛掉很多的候选项集，Apriori算法就是利用这两个定理来实现快速挖掘频繁项集的。<a href="https://www.cnblogs.com/pinard/p/6293298.html" target="_blank" rel="noopener">Apriori算法原理总结</a>、<a href="https://www.cnblogs.com/fengfenggirl/p/associate_apriori.html" target="_blank" rel="noopener">关联规则挖掘基本概念与Aprior算法</a></p><hr><blockquote><p>Apriori算法属于候选消除算法，是一个生成候选集、消除不满足条件的候选集、并不断循环直到不再产生候选集的过程。</p></blockquote><center><br><img src="/2019/01/01/数据分析与挖掘/Apriori.png" width="600"><br></center><p>上面的图演示了Apriori算法的过程，注意看由二级频繁项集生成三级候选项集时，没有{牛奶,面包,啤酒}，那是因为{面包,啤酒}不是二级频繁项集，这里利用了Apriori定理。最后生成三级频繁项集后，没有更高一级的候选项集，因此整个算法结束，{牛奶,面包,尿布}是最大频繁子集</p><hr><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># How to generate candidates? </span></span><br><span class="line"> Step <span class="number">1</span>: self-joining Lk</span><br><span class="line"> Step <span class="number">2</span>: pruning</span><br><span class="line"><span class="comment"># Example of Candidate-generation</span></span><br><span class="line"> L3=&#123;abc, abd, acd, ace, bcd&#125;<span class="comment"># INPUT</span></span><br><span class="line"> Self-joining: L3*L3<span class="comment"># Step1</span></span><br><span class="line"> abcd <span class="keyword">from</span> abc <span class="keyword">and</span> abd </span><br><span class="line">     acde <span class="keyword">from</span> acd <span class="keyword">and</span> ace</span><br><span class="line"> Pruning:<span class="comment"># Step2</span></span><br><span class="line"> acde <span class="keyword">is</span> removed because ade <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">in</span> L3 </span><br><span class="line"> C4 = &#123;abcd&#125;<span class="comment"># OUTPUT</span></span><br></pre></td></tr></table></figure><p>我们发现Apriori算法是一个候选消除算法，每一次消除都需要扫描一次所有数据记录，造成整个算法在<strong>面临大数据集</strong>时显得效率低下（<code>多次扫描事务数据库</code>、<code>产生大量的候选集</code>、<code>对候选集的支持度计算产生了繁琐的工作量</code>）. 故而，我们需要了解$Fp-Growth$算法（如下）</p><h4 id="FP-growth"><a href="#FP-growth" class="headerlink" title="FP-growth"></a><strong>FP-growth</strong></h4><p>FpGrowth算法通过构造一个树结构来压缩数据记录，使得挖掘频繁项集只需要<strong>扫描两次数据记录</strong>，而且该算法不需要生成候选集合，所以效率会比较高。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Step <span class="number">1</span>：扫描数据记录，生成一级频繁项集，并按出现次数由多到少排序</span><br><span class="line">Step <span class="number">2</span>：再次扫描数据记录，对每条记录中出现在Step <span class="number">1</span>产生的表中的项，按表中的顺序排序。初始时，新建一个根结点，标记为null；</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Method</span></span><br><span class="line"> For each frequent item, construct its conditional pattern-base, <span class="keyword">and</span> then its conditional FP-tree</span><br><span class="line">  对于每个频繁项，<span class="string">'构造其条件模式库'</span>，然后<span class="string">'构造其条件FP树'</span></span><br><span class="line"> Repeat the process on <span class="string">'each'</span> newly created conditional FP-tree</span><br><span class="line">  对每个新创建的条件FP树重复此过程 (<span class="string">"Recursion: Mining Each Conditional FP-tree"</span>)</span><br><span class="line"> Until the resulting FP-tree <span class="keyword">is</span> empty, <span class="keyword">or</span> it contains only one path—single path will generate all the combinations of its sub-paths, each of which <span class="keyword">is</span> a frequent pattern</span><br><span class="line">  在生成的FP树为空之前，或者它只包含一个路径 - 单个路径将生成其子路径的所有组合，<span class="string">'每个路径都是一个频繁的模式'</span></span><br></pre></td></tr></table></figure><center><br>    <img src="/2019/01/01/数据分析与挖掘/FP-TreeConstruct.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/FP-TreeFindPatterns.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/FP-Tree_mConditional.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/MiningEachConditionalFP-tree.png" width="600"><br></center><p><a href="https://www.cnblogs.com/pinard/p/6307064.html" target="_blank" rel="noopener">FP Tree算法原理总结</a>、<a href="https://www.cnblogs.com/fengfenggirl/p/associate_fpgowth.html" target="_blank" rel="noopener">关联规则FpGrowth算法</a></p><h3 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/01/数据分析与挖掘/fp_Summary.png" width="600"><br></center><h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><ul><li><p>What is clustering</p><p>聚类就是按照某个特定标准(如距离准则)<strong>把一个数据集分割成不同的类或簇</strong>，使得同一个簇内的数据对象的<code>相似性</code>尽可能大，同时不在同一个簇中的数据对象的<code>差异性</code>也尽可能地大。即聚类后<code>同一类的数据尽可能聚集到一起，不同数据尽量分离</code>。</p><ul><li><p>Unsupervised learning </p><p>聚类是一种<code>输入数据无标签</code>的“分类”方式（即非监督学习），通常并不需要使用训练数据进行学习，仅把相似的东西聚到一起，并不关心所得的簇具体代表什么</p></li></ul></li></ul><h3 id="Partition-based—k-means"><a href="#Partition-based—k-means" class="headerlink" title="Partition-based—k-means"></a>Partition-based—k-means</h3><p>K-Means算法的思想很简单，对于给定的样本集，按照样本之间的距离大小，<code>将样本集划分为K个簇</code>。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大。</p><center><br>    <img src="/2019/01/01/数据分析与挖掘/k-Means.gif" width="400"><br></center><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- There are many variants of the K-Means method, varying <span class="keyword">in</span> different aspects</span><br><span class="line">  K-Means方法有许多变体，在不同方面有所不同</span><br><span class="line">- Choosing better initial centroid estimates</span><br><span class="line">  选择更好的初始质心估计</span><br><span class="line"> <span class="string">'k-means对初始值的设置很敏感'</span>: K-means++, Intelligent K-Means, Genetic K-Means</span><br><span class="line">- Choosing different representative prototypes <span class="keyword">for</span> the clusters</span><br><span class="line">  为集群选择不同的代表性原型</span><br><span class="line"> <span class="string">'k-means对噪声和离群值非常敏感'</span>: K-Medoids, K-Medians</span><br><span class="line"> <span class="string">'k-means只用于numerical，不适用于categorical类型数据'</span>: K-Modes</span><br><span class="line">- Applying feature transformation techniques</span><br><span class="line">  应用特征转换技术 </span><br><span class="line"> Weighted K-Means</span><br><span class="line"> <span class="string">'k-means不能解决非凸non-convex数据'</span>: Kernel K-Means</span><br></pre></td></tr></table></figure><ul><li><p>K-means++：选取新数据点作为新的聚类中心时，遵循的原则是与当前所属聚类中心距离最远的点，被选取作为聚类中心的概率较大</p></li><li><p>K-Medoids：Instead of taking the <strong>mean</strong> value of the object in a cluster as a reference<br>point, <strong>medoids</strong> can be used, which is the <code>most centrally located</code> object in a cluster 不使用聚类中对象的平均值作为参考点，而是可以使用中心点medoids，它是集群中最集中的对象（计算该点到当前聚簇中所有点距离之和，最终距离之后最小的点，则视为新的中心点）</p></li><li><p>K-Medians: Instead of taking the <strong>mean</strong> value of the object in a cluster as a reference point, <strong>medians</strong> are used (L1-norm as the distance measure) 不使用聚类中对象的平均值作为参考点，而是使用<code>中位数</code>（L1范数作为距离度量）</p></li><li><p>K-Modes: An extension to K-Means by replacing <strong>means</strong> of clusters with <strong>modes</strong> 通过用<code>众数</code>替换簇的平均值来扩展K-Means</p></li><li><p>Kernel K-Means : Project data onto the high-dimensional feature space using the kernel function, and then perform K-Means clustering 使用核函数将数据投影到高维特征空间，然后执行K-Means聚类</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Typical kernel functions:</span><br><span class="line"> Polynomial kernel of degree <span class="string">'多项式核函数'</span></span><br><span class="line"> Gaussian radial basis function (RBF) kernel <span class="string">'高斯径向基核函数'</span></span><br><span class="line"> Sigmoid kernel <span class="string">'Sigmoid核函数'</span></span><br></pre></td></tr></table></figure></li></ul><p><a href="https://www.cnblogs.com/pinard/p/6164214.html" target="_blank" rel="noopener">K-Means聚类算法原理</a>、<a href="https://www.cnblogs.com/pinard/p/6169370.html" target="_blank" rel="noopener">用scikit-learn学习K-Means聚类</a></p><h3 id="Hierarchical-based—two-ways"><a href="#Hierarchical-based—two-ways" class="headerlink" title="Hierarchical-based—two ways"></a>Hierarchical-based—two ways</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Hierarchical clustering</span><br><span class="line"> Generate a clustering hierarchy(drawn <span class="keyword">as</span> a dendrogram) 生成聚类层次结构（绘制为树形图）</span><br><span class="line"> <span class="string">'Not required to specify K'</span>, the number of clusters 不需要指定聚类簇数</span><br><span class="line"> More deterministic 更具确定性</span><br><span class="line"> No iterative refinement 无迭代校准</span><br></pre></td></tr></table></figure><ul><li><p>Two categories of algorithms</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'Agglomerative'</span>: Start <span class="keyword">with</span> singleton clusters, continuously merge two clusters at a time to build a bottom-up hierarchy of clusters</span><br><span class="line">  <span class="string">'凝聚'</span>：从单一集群开始，一次连续合并两个集群，构建<span class="string">'自下而上'</span>的集群层次结构</span><br><span class="line"> Agglomerative clustering varies on <span class="string">'different similarity measures'</span> among clusters</span><br><span class="line">         Single link (<span class="string">'nearest'</span> neighbor)  Average link (group <span class="string">'average'</span>)</span><br><span class="line">     Complete link (<span class="string">'diameter'</span>直径)     Centroid link (<span class="string">'centroid'</span>重心 similarity)</span><br><span class="line">- <span class="string">'Divisive'</span>: Start <span class="keyword">with</span> a huge macro-cluster, split it continuously into two groups, generating a top-down hierarchy of clusters</span><br><span class="line">  <span class="string">'分裂'</span>：从一个庞大的宏集群开始，将其连续分成两组，生成一个<span class="string">'自上而下'</span>的集群层次结构</span><br></pre></td></tr></table></figure></li></ul><h4 id="BIRCH"><a href="#BIRCH" class="headerlink" title="BIRCH"></a><strong>BIRCH</strong></h4><blockquote><p>BIRCH (Balanced Iterative Reducing and Clustering Using Hierarchies): Use CF-tree and incrementally adjust the quality of sub-clusters 利用层次方法的<code>平衡迭代</code>规约和聚类：使用CF树并逐步调整子集群的质量</p></blockquote><center><br><img src="/2019/01/01/数据分析与挖掘/CFTree.png" width="500"><br></center><p>将所有的训练集样本建立了CF Tree，一个基本的BIRCH算法就完成了，对应的输出就是若干个CF节点，每个节点里的样本点就是一个聚类的簇。<a href="https://www.cnblogs.com/pinard/p/6179132.html" target="_blank" rel="noopener">BIRCH聚类算法原理</a>、<a href="https://www.cnblogs.com/pinard/p/6200579.html" target="_blank" rel="noopener">用scikit-learn学习BIRCH聚类</a></p><h4 id="CURE"><a href="#CURE" class="headerlink" title="CURE"></a><strong>CURE</strong></h4><blockquote><p>CURE (Clustering Using REpresentatives): Represent a cluster using a set of well-scattered representative points  使用一组分散的代表点来表示聚类</p></blockquote><h4 id="CHAMELEON"><a href="#CHAMELEON" class="headerlink" title="CHAMELEON"></a>CHAMELEON</h4><blockquote><p>Hierarchical Clustering Using Dynamic Modeling,  A graph partitioning approach</p></blockquote><h4 id="Probabilistic-Hierarchical-Clustering"><a href="#Probabilistic-Hierarchical-Clustering" class="headerlink" title="Probabilistic Hierarchical Clustering"></a>Probabilistic Hierarchical Clustering</h4><blockquote><p>Use probabilistic models to measure distances between clusters  使用概率模型来测量簇之间的距离</p></blockquote><h3 id="Density-based—DBSCAN"><a href="#Density-based—DBSCAN" class="headerlink" title="Density-based—DBSCAN"></a>Density-based—DBSCAN</h3><blockquote><p>Clustering based on density (a local cluster criterion), such as density-connected points  基于密度的聚类（局部聚类标准），例如密度连接点</p></blockquote><h4 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h4><center><br>    <img src="/2019/01/01/数据分析与挖掘/DBSCAN_BasicConcept.png" width="500"><br></center><p>图中<code>MinPts=5</code>，红色的点都是<code>核心对象</code>，因为其ϵ-邻域至少有5个样本。黑色的样本是非核心对象。所有核心对象<code>密度直达</code>的样本在以红色核心对象为中心的超球体内，如果不在超球体内，则不能密度直达。图中用绿色箭头连起来的核心对象组成了<code>密度可达</code>的样本序列。在这些密度可达的样本序列的ϵ-邻域内所有的样本相互都是<code>密度相连</code>(对称性)的。</p><hr><p>DBSCAN密度聚类：由密度可达关系导出的最大密度相连的样本集合，即为我们最终聚类的一个类别，或者说一个簇。<a href="https://www.cnblogs.com/pinard/p/6208966.html" target="_blank" rel="noopener">DBSCAN密度聚类</a>、<a href="https://www.cnblogs.com/pinard/p/6217852.html" target="_blank" rel="noopener">用scikit-learn学习DBSCAN聚类</a></p><h3 id="E-M-algorithm"><a href="#E-M-algorithm" class="headerlink" title="E-M algorithm"></a>E-M algorithm</h3><blockquote><p>K-Means （距离） -&gt;&gt;  E-M algorithm (概率分布)</p></blockquote><p>假设需要调查某校的男生和女生的身高分布。假设在校园里随机抽样100个男生和100个女生，共200个人。不知道抽取的这200个人里面的每一个人到底是从男生的那个身高分布里面抽取的，还是女生的那个身高分布抽取的。即就是，抽取得到的每个样本都不知道是从哪个分布抽取的。</p><p>EM的意思是“Expectation Maximization”，在上述问题中，先随便猜一下男生(身高)的正态分布的参数:如均值和方差是多少。例如男生的均值是1米7，方差是0.1米(当然了，刚开始肯定没那么准)，然后计算出每个人更可能属于第一个还是第二个正态分布中的(例如，这个人的身高是1米8，那很明显，他最大可能属于男生的那个分布)，这个是属于Expectation一步。有了每个人的归属，或者说已经大概地按上面的方法将这200个人分为男生和女生两部分，就可以根据之前说的最大似然那样，通过这些被大概分为男生的n个人来重新估计第一个分布的参数，女生的那个分布同样方法重新估计。这个是Maximization。然后，当更新了这两个分布的时候，每一个属于这两个分布的概率又变了，那么就再需要调整E步……如此往复，直到参数基本不再发生变化为止。</p><p>一个最直观了解EM算法思路的是K-Means算法。在K-Means聚类时，每个聚类簇的质心是隐含数据。我们会假设K个初始化质心，即EM算法的E步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即EM算法的M步。重复这个E步和M步，直到质心不再变化为止，这样就完成了K-Means聚类。EM算法的描述还很粗糙，我们需要用数学的语言精准描述。详见<a href="https://www.cnblogs.com/pinard/p/6912636.html" target="_blank" rel="noopener">EM算法原理总结</a></p><h3 id="AP-2007-Science"><a href="#AP-2007-Science" class="headerlink" title="AP (2007, Science)"></a>AP (2007, Science)</h3><p>AP（Affinity Propagation）一般翻译为近邻传播聚类<a href="https://blog.csdn.net/u010161379/article/details/51636926" target="_blank" rel="noopener">Affinity Propagation: AP聚类算法</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># basic concept</span></span><br><span class="line">* <span class="string">'Exemplar'</span>范例：即聚类簇中心点；</span><br><span class="line">* <span class="string">'similarity'</span>s(i,j)：数据点i与数据点j的<span class="string">'相似度值'</span>，一般使用欧氏距离的的负值表示，即s(i,j)值越大表示点i与j的距离越近，AP算法中理解为数据点j作为数据点i的聚类中心的能力； </span><br><span class="line">    * 相似度矩阵：作为算法的初始化矩阵，n个点就有由n乘n个相似度值组成的矩阵； </span><br><span class="line">* <span class="string">'Preference参考度'</span>s(i,i)：若按欧氏距离计算其值应为<span class="number">0</span>，但在AP聚类中其`表示数据点i作为聚类中心的程度`，因此不能为<span class="number">0</span>。迭代开始前假设所有点成为聚类中心的能力相同，因此参考度一般设为相似度矩阵中所有值得最小值或者中位数，但是参考度越大则说明个数据点成为聚类中心的能力越强，则最终聚类中心的个数则越多； </span><br><span class="line">* <span class="string">'Responsibility'</span>，r(i,k)：吸引度信息，表示数据点k`适合`作为数据点i的聚类中心的程度；(`k想做i的主公`)</span><br><span class="line">* <span class="string">'Availability'</span>，a(i,k)：归属度信息，表示数据点i选择数据点k作为其聚类中心的`合适`程度；(`i想做k的勇士`)</span><br><span class="line">* <span class="string">'Damping factor'</span>阻尼系数：为防止数据震荡，引入的衰减系数，`起到收敛作用`，每个信息值等于前一次迭代更新的信息值的λ倍加上此轮更新值得<span class="number">1</span>-λ倍，其中λ在<span class="number">0</span><span class="number">-1</span>之间，默认为<span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>AP算法通过迭代过程不断更新每一个点的responsibility和availability,直到产生m个高质量的exemplar,同时将其余的数据点分配到相应的聚类中。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 算法流程： </span></span><br><span class="line"><span class="number">1.</span> 更新相似度矩阵中每个点的吸引度信息，计算归属度信息； </span><br><span class="line"><span class="number">2.</span> 更新归属度信息，计算吸引度信息； </span><br><span class="line"><span class="number">3.</span> 对样本点的吸引度信息和归属度信息求和，检测其选择聚类中心的决策；若经过若干次迭代之后其聚类中心不变、或者迭代次数超过既定的次数、又或者一个子区域内的关于样本点的决策经过数次迭代后保持不变，则算法结束。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关于其算法流程，知乎上kael 用户将AP聚类过程比喻为选举过程： </span></span><br><span class="line">* 所有人都参加选举（大家都是选民也都是参选人），要选出几个作为代表 </span><br><span class="line">* s(i,k)就相当于i对选k这个人的一个固有的偏好程度 </span><br><span class="line">* r(i,k)表示用s(i,k)减去最强竞争者的评分，可以理解为k在对i这个选民的竞争中的优势程度 </span><br><span class="line">* r(i,k)的更新过程对应选民i对各个参选人的挑选（越出众越有吸引力） </span><br><span class="line">* a(i,k)：从公式里可以看到，所有r(i’,k)&gt;<span class="number">0</span>的值都对a有正的加成。对应到我们这个比喻中，就相当于选民i通过网上关于k的民意调查看到：有很多人（即i’们）都觉得k不错（r(i’,k)&gt;<span class="number">0</span>），那么选民i也就会相应地觉得k不错，是个可以相信的选择 </span><br><span class="line">* a(i,k)的更新过程对应关于参选人k的民意调查对于选民i的影响（已经有了很多跟随者的人更有吸引力） </span><br><span class="line">* 两者交替的过程也就可以理解为`不断地参考各个参选人给出的民意调查`和`选民在各个参选人之间不断地比较`。 </span><br><span class="line">* r(i,k)的思想反映的是`竞争`，a(i,k)则是为了`让聚类更成功`。</span><br></pre></td></tr></table></figure><h3 id="Local-density-based-2014-Science"><a href="#Local-density-based-2014-Science" class="headerlink" title="Local density-based (2014, Science)"></a>Local density-based (2014, Science)</h3><blockquote><p>该方法假设聚类中心周围都是密度比其低的点，同时这些点到该聚类中心的距离比其到其他聚类中心更近。</p></blockquote><center><br><img src="/2019/01/01/数据分析与挖掘/LocalDensity-based.png" width="600"><br></center><ol><li>找出聚类中心:以通过给定的$δ<em>{min}$和$ρ</em>{min}$筛选出同时满足($ρ<em>i$ &gt; $ρ</em>{min}$)和($δ_ i$ &gt; $δ_{min}$)条件的点作为聚类中心点。 </li><li>剩余点的类别指派: 当前点的类别标签等于高于当前点密度的最近的点的标签一致。从而对所有点的类别进行了指定。</li><li>去除噪音：先算出类别之间的边界，然后找出边界中密度值最高的点的密度作为阈值只保留类别中大于或等于此密度值的点</li></ol><h3 id="Evaluation-of-Clustering"><a href="#Evaluation-of-Clustering" class="headerlink" title="Evaluation of Clustering"></a>Evaluation of Clustering</h3><h4 id="Clustering-evaluation"><a href="#Clustering-evaluation" class="headerlink" title="Clustering evaluation"></a>Clustering evaluation</h4><blockquote><p>Clustering Evaluation: Evaluating the <code>goodness</code> of clustering results (No commonly recognized best suitable measure in practice) 聚类评估：评估聚类结果的优劣（在实践中没有公认的最佳合适度量）</p></blockquote><h5 id="Three-categorization-of-measures"><a href="#Three-categorization-of-measures" class="headerlink" title="Three categorization of measures"></a>Three categorization of measures</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- <span class="string">'External'</span>: Supervised, employ criteria <span class="keyword">not</span> inherent to the dataset</span><br><span class="line">  外部：监督，采用数据集不固有的标准 (使用<span class="string">'新数据'</span>)</span><br><span class="line"> Compare a clustering against prior <span class="keyword">or</span> expert-specified knowledge (i.e., the ground truth) using certain clustering quality measure</span><br><span class="line">  使用某些聚类质量测量将聚类与先前或专家指定的知识（即基础事实）进行比较</span><br><span class="line">- <span class="string">'Internal'</span>: Unsupervised, criteria derived <span class="keyword">from</span> data itself</span><br><span class="line">  内部：无监督，来自<span class="string">'数据本身'</span>的标准</span><br><span class="line"> Evaluate the goodness of a clustering by considering how well the clusters are separated <span class="keyword">and</span> how compact the clusters are, e.g., silhouette coefficient</span><br><span class="line">  通过考虑群集的分离程度以及群集的紧密程度（例如，轮廓系数）来评估群集的良好性</span><br><span class="line">- <span class="string">'Relative'</span>: Directly compare different clusterings, usually those obtained via different parameter settings <span class="keyword">for</span> the same algorithm</span><br><span class="line">  相对：直接比较不同的聚类，通常是通过<span class="string">'相同算法的不同参数'</span>设置获得的聚类</span><br></pre></td></tr></table></figure><h4 id="Clustering-stability"><a href="#Clustering-stability" class="headerlink" title="Clustering stability"></a>Clustering stability</h4><blockquote><p>Clustering stability : To understand the sensitivity of the clustering result to various algorithm parameters, e.g., # of clusters  聚类稳定性：理解聚类结果对各种<code>算法参数的敏感性</code>，例如聚类数</p></blockquote><h5 id="Methods-for-Finding-K-the-Number-of-Clusters"><a href="#Methods-for-Finding-K-the-Number-of-Clusters" class="headerlink" title="Methods for Finding K, the Number of Clusters"></a>Methods for Finding K, the Number of Clusters</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Empirical method <span class="string">'经验'</span>方法</span><br><span class="line"> <span class="comment"># of clusters: k ≈ sqrt(n / 2) for a dataset of n points (e.g., n = 200, k = 10)</span></span><br><span class="line">- Elbow method: Use the turning point <span class="keyword">in</span> the curve of the sum of within cluster variance <span class="keyword">with</span> respect to the <span class="comment"># of clusters</span></span><br><span class="line">  使用聚类方差之和与曲线群数之和的曲线中的<span class="string">'转折点'</span></span><br><span class="line">- Cross validation method </span><br><span class="line">  交叉验证法 (<span class="string">'试错，择优'</span>)</span><br><span class="line"> Divide a given data set into m parts</span><br><span class="line"> Use m – <span class="number">1</span> parts to obtain a clustering model</span><br><span class="line"> Use <span class="string">'the remaining part to test'</span> the quality of the clustering</span><br><span class="line"> For example, <span class="keyword">for</span> each point <span class="keyword">in</span> the test set, find the closest centroid, <span class="keyword">and</span> use the sum of squared distance between all points <span class="keyword">in</span> the test set <span class="keyword">and</span> the closest centroids to measure how well <span class="string">'the model fits the test set'</span></span><br><span class="line"> For any k &gt; <span class="number">0</span>, <span class="string">'repeat it m times'</span>, compare the overall quality measure w.r.t. different k’s, <span class="keyword">and</span> find <span class="comment"># of clusters that fits the data the best</span></span><br></pre></td></tr></table></figure><h4 id="Clustering-tendency"><a href="#Clustering-tendency" class="headerlink" title="Clustering tendency"></a>Clustering tendency</h4><blockquote><p>Clustering tendency: Assess the suitability of clustering, i.e., whether the data has any inherent grouping structure  聚类趋势：评估聚类的<code>适用性</code>，即数据是否具有任何<code>固有的分组结构</code></p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- Still, there are some <span class="string">'clusterability assessment methods'</span>, such <span class="keyword">as</span></span><br><span class="line"> <span class="string">'Spatial histogram'</span>: Contrast the histogram of the data <span class="keyword">with</span> that generated <span class="keyword">from</span></span><br><span class="line">random samples</span><br><span class="line">  空间直方图：将数据的直方图与生成的直方图进行对比</span><br><span class="line"> <span class="string">'Distance distribution'</span>: Compare the pairwise point distance <span class="keyword">from</span> the data <span class="keyword">with</span> those <span class="keyword">from</span> the randomly generated samples</span><br><span class="line">  距离分布：将数据的成对点距离与随机生成的样本的距离进行比较</span><br><span class="line"> <span class="string">'Hopkins Statistic'</span>: A sparse sampling test <span class="keyword">for</span> spatial randomness</span><br><span class="line">  霍普金斯统计：空间随机性的稀疏抽样测试</span><br></pre></td></tr></table></figure><h3 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h3><center><br>    <img src="/2019/01/01/数据分析与挖掘/clustering_Summary.png" width="600"><br>    <img src="/2019/01/01/数据分析与挖掘/clustering_Summary2.png" width="600"><br></center><h2 id="Graph-clustering"><a href="#Graph-clustering" class="headerlink" title="Graph clustering"></a>Graph clustering</h2><ul><li><p>What is graph clustering </p><ul><li><p><strong>Complex network</strong></p><p>在我们的现实生活中，许多复杂系统都可以建模成一种复杂网络进行分析，比如常见的电力网络、航空网络、交通网络、计算机网络以及社交网络等等。复杂网络不仅是一种数据的表现形式，它同样也是一种科学研究的手段。</p></li><li><p>Graph clustering</p></li><li><p>Community </p></li><li><p>Module  </p></li></ul></li></ul><h3 id="Community-detection-algorithms"><a href="#Community-detection-algorithms" class="headerlink" title="Community detection_algorithms"></a>Community detection_algorithms</h3><h4 id="CPM-（Clique-Percolation-Method）"><a href="#CPM-（Clique-Percolation-Method）" class="headerlink" title="CPM （Clique Percolation Method）"></a>CPM （Clique Percolation Method）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># basic concept</span></span><br><span class="line"> <span class="string">'Clique'</span>: Complete graph  完全图(所有节点两两相连)</span><br><span class="line"> <span class="string">'k-clique'</span>: Complete graph <span class="keyword">with</span> k vertice(顶点) k-派系</span><br><span class="line"> <span class="string">'Adjacent k-cliques'</span>: Two k-cliques are adjacent when they `share k<span class="number">-1</span> nodes`</span><br><span class="line">   k-派系相邻：两个不同的k-派系共享k<span class="number">-1</span>个节点，认为他们相邻</span><br><span class="line"> <span class="string">'k-clique community'</span>: Union of all k-cliques that can be `reached <span class="keyword">from</span> each other` through a series of adjacent k-cliques.</span><br><span class="line">   k-派系连通：一个k-派系可以通过若干个相邻的k-派系到达另一个k-派系，则称这两个k-派系彼此联通</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Step1: 找到网络中大小为K的完全子图 Locate maximal cliques </span><br><span class="line">Step2: 将每个完全子图定义为一个节点，建立一个重叠矩阵</span><br><span class="line">Step3: 将重叠矩阵变成社区邻接矩阵(其中重叠矩阵中对角线小于k、非对角线小于k<span class="number">-1</span>的元素全置为<span class="number">0</span>,所有非<span class="number">0</span>项置为<span class="number">1</span>)</span><br></pre></td></tr></table></figure><center class="half"><br><img src="/2019/01/01/数据分析与挖掘/CPM1.png" width="300"><br><img src="/2019/01/01/数据分析与挖掘/CPM2.png" width="300"><br></center><p>从图中可以看出包含了两个社区{1，2，3，4}和{4，5，6，7，8}，节点4属于两个社区的重叠节点</p><p><a href="https://www.cnblogs.com/bethansy/p/6704712.html" target="_blank" rel="noopener">CPM（Cluster Percolation method）派系过滤算法</a></p><h4 id="Spectral-clustering"><a href="#Spectral-clustering" class="headerlink" title="Spectral clustering"></a>Spectral clustering</h4><center><br><img src="/2019/01/01/数据分析与挖掘/SpectralClustering.png" width="600"><br></center><p>谱聚类（Spectral Clustering），就是先用<code>Laplacian eigenmaps对数据降维</code>（简单地说，就是先将数据转换成邻接矩阵或相似性矩阵，再转换成Laplacian矩阵，再对Laplacian矩阵进行特征分解，把最小的K个特征向量排列在一起），然后再<code>使用k-means</code>完成聚类。谱聚类是个很好的方法，效果通常比k-means好，计算复杂度还低，这都要归功于降维的作用。 </p><p><a href="https://www.cnblogs.com/pinard/p/6221564.html" target="_blank" rel="noopener">谱聚类（spectral clustering）原理总结_刘建平</a>、<a href="https://www.cnblogs.com/pinard/p/6235920.html" target="_blank" rel="noopener">用scikit-learn学习谱聚类</a></p><h4 id="Modularity-based-methods-–-G-Nand-Q"><a href="#Modularity-based-methods-–-G-Nand-Q" class="headerlink" title="Modularity based methods – G Nand Q"></a>Modularity based methods – G Nand Q</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> Calculate the betweenness <span class="keyword">for</span> all edges <span class="keyword">in</span> the network</span><br><span class="line">   计算每一条边的边介数.</span><br><span class="line"><span class="number">2.</span> Remove the edge <span class="keyword">with</span> the highest betweenness.</span><br><span class="line">   删除边介数最大的边.</span><br><span class="line"><span class="number">3.</span> Recalculate betweennesses <span class="keyword">for</span> all edges affected by the removal.</span><br><span class="line">   重新计算网络中剩下的边的边介数.</span><br><span class="line"><span class="number">4.</span> Repeat <span class="keyword">from</span> step <span class="number">2</span> until no edges remain.</span><br><span class="line">   从步骤<span class="number">2</span>重复，直到没有边剩余.</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/aspirinvagrant/article/details/45599071" target="_blank" rel="noopener">社区发现算法（二）</a></p><h4 id="MCL"><a href="#MCL" class="headerlink" title="MCL"></a>MCL</h4><blockquote><p>MCL (Markov Cluster Algorithm) is a graph clustering algorithm. </p></blockquote><ul><li><p>Graph Clustering</p><p>和特征聚类不同，<code>图聚类</code>比较难以观察，整个算法以各点之间的距离作为突破口，可以这样形容：张三，是王五的好朋友，刚认识李四，对赵六很是反感。那么，对于该节点，我们无法直接得出他的特征，但能知道他的<code>活动圈</code>。利用图聚类，可以将同一社交范围的人聚合到一起。MCL就是属于图聚类的一种。</p></li><li><p>位于同一簇的点，其内部的联系应当紧密，而和外部的联系则比较少（惺惺相惜）</p><ul><li>如果你从一个点出发，到达其中的一个邻近点，那么你在’簇内的可能性’远大于’离开当前簇，到达新簇’的可能性——这就是MCL的核心思想。</li></ul></li></ul><h5 id="Random-walk"><a href="#Random-walk" class="headerlink" title="Random walk"></a>Random walk</h5><p>如果在一张图上进行多次的“<strong>Random Walks</strong>”，那么就有很大可能发现簇群，达到聚类的目的。而“<strong>Random Walks</strong>”的实现则是通过“<strong>Markov Chains</strong>”（马尔柯夫链）。</p><h5 id="Markov-chains"><a href="#Markov-chains" class="headerlink" title="Markov chains"></a>Markov chains</h5><p>Markov Chain——如果有由随机变量$X1,X2,X3$⋯组成的数列。$Xn$的值则是在时间$n$的状态，如果$X_{n+1}$对于过去状态的条件概率分布满足：$P(X_{n+1}=x|X_0,X_1,X_2,⋯,X_n)=P(X_{n+1}=x|X_n)$，则我们称其是一条Markov Chain.</p><ul><li>Markov Process——在给定当前知识或信息的情况下，过去（即当期以前的历史状态）对于预测将来（即当期以后的未来状态）是无关的。</li><li>下一步骤的概率仅依赖于当前概率</li></ul><h5 id="MCL-Algorithm"><a href="#MCL-Algorithm" class="headerlink" title="MCL Algorithm"></a>MCL Algorithm</h5><p>在MCL中， <strong>Expansion</strong> 和 <strong>Inflation</strong> 将不断的交替进行，<strong>Expansion</strong> 使得不同的区域之间的联系加强，而 <strong>Inflation</strong> 则不断的<code>分化</code>各点之间的联系(强者恒强，弱者恒弱)。经过多次迭代，将渐渐出现聚集现象，以此便达到了聚类的效果。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 输入：一个非全连通图，Expansion 时的参数e和 Inflation 的参数r</span><br><span class="line"><span class="number">2.</span> 建立邻接矩阵</span><br><span class="line"><span class="number">3.</span> 添加自环(避免<span class="number">0</span>概率情况)</span><br><span class="line"><span class="number">4.</span> 标准化概率矩阵</span><br><span class="line"><span class="number">5.</span> Expansion操作，每次对矩阵进行e次幂方</span><br><span class="line"><span class="number">6.</span> Inflation操作，每次对矩阵内元素进行r次幂方，再进行标准化</span><br><span class="line"><span class="number">7.</span> 重复步骤<span class="number">5</span>和<span class="number">6</span>，直到达到稳定</span><br><span class="line"><span class="number">8.</span> 将结果矩阵转化为聚簇</span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/magle/p/7672957.html" target="_blank" rel="noopener">聚类算法——MCL</a></p><h3 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h3><center><br><img src="/2019/01/01/数据分析与挖掘/graphMining_Summary.png" width="600"><br><img src="/2019/01/01/数据分析与挖掘/CommunityDetection_Summary.png" width="600"><br></center><h2 id="Todo"><a href="#Todo" class="headerlink" title="Todo"></a>Todo</h2><ul><li><p>看相关参考书目《数据挖掘：概念与技术》《数据挖掘导论》课后例题  着重看”简单计算”</p></li><li><p>Collaborative Filtering</p><p><a href="https://www.cnblogs.com/pinard/p/6349233.html" target="_blank" rel="noopener">协同过滤推荐算法总结</a></p><p><a href="https://www.cnblogs.com/pinard/p/6351319.html" target="_blank" rel="noopener">矩阵分解在协同过滤推荐算法中的应用</a></p><p><a href="https://www.cnblogs.com/pinard/p/6362647.html" target="_blank" rel="noopener">SimRank协同过滤推荐算法</a></p></li><li><p><a href="https://www.cnblogs.com/pinard/p/6912636.html" target="_blank" rel="noopener">EM算法原理总结</a></p></li><li><p>特征工程</p><p><a href="https://www.cnblogs.com/pinard/p/9032759.html" target="_blank" rel="noopener">特征工程之特征选择</a></p><p><a href="https://www.cnblogs.com/pinard/p/9061549.html" target="_blank" rel="noopener">特征工程之特征表达</a></p><p><a href="https://www.cnblogs.com/pinard/p/9093890.html" target="_blank" rel="noopener">特征工程之特征预处理</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【内容描述】 基于《数据挖掘：概念与技术》的简述，欲了解细节，强烈建议读原书！！！&lt;/p&gt;
    
    </summary>
    
      <category term="XD" scheme="http://yoursite.com/categories/XD/"/>
    
    
  </entry>
  
  <entry>
    <title>visdom_Tutorial</title>
    <link href="http://yoursite.com/2018/12/31/visdom-Tutorial/"/>
    <id>http://yoursite.com/2018/12/31/visdom-Tutorial/</id>
    <published>2018-12-31T12:32:33.000Z</published>
    <updated>2019-01-16T08:17:12.494Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>Github linkage: <a href="https://github.com/facebookresearch" target="_blank" rel="noopener">facebookresearch</a>/<a href="https://github.com/facebookresearch/visdom" target="_blank" rel="noopener">visdom</a></p><p>Tutorial：<a href="https://www.pytorchtutorial.com/pytorch-visdom/" target="_blank" rel="noopener">PyTorch 可视化工具 Visdom 介绍</a></p><h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><h4 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Install Python server and client，如果您使用python的话，装这一个就可以了。</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install visdom</span></span><br></pre></td></tr></table></figure><h4 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> visdom</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> or (The visdom <span class="built_in">command</span> is equivalent to running python -m visdom.server)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> python -m visdom.server</span></span><br></pre></td></tr></table></figure><blockquote><p>If the above does not work, try using an SSH tunnel to your server by adding the following line to your local <code>~/.ssh/config</code>: <code>LocalForward 127.0.0.1:8097 127.0.0.1:8097</code></p></blockquote><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> visdom</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>vis = visdom.Visdom()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>vis.text(<span class="string">'Hello, world!'</span>)</span><br><span class="line"><span class="string">'window_36ef496c02a28c'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>vis.image(np.ones((<span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>)))</span><br><span class="line"><span class="string">'window_36ef496f76bad6'</span></span><br></pre></td></tr></table></figure><p><center><br>    <img src="/2018/12/31/visdom-Tutorial/vis.text().png" width="600"><br></center></p><h5 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python example/demo.py</span><br><span class="line">th example/demo1.lua</span><br><span class="line">th example/demo2.lua</span><br></pre></td></tr></table></figure><p>安装好Torch后，花了比较长的时间去弄明白，th&gt;、itorch、ipython和Torch之间的<a href="https://blog.csdn.net/Ethan_Apple/article/details/48627639" target="_blank" rel="noopener">关系</a>，因为不弄明白，很难进行后续的学习。首先，要验证是否安装好Torch，在终端输入th命令，若有Torch相关信息返回，则表示安装成功。且这时候，终端命令会变为：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">th&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure><p>其实，熟悉Linux的人应该懂，这就是类似shell的东西，就是Torch的shell（我是这么理解的，不准确还望校正），而由于Torch是基于Lua语言的开发平台，所以我们可以理解th是Lua的一个更高级的接口吧；也就是说，我们对于Torch的操作，是通过th（Lua）的命令集来实现的。并且，以后如果写代码，保存的文件格式也是<em>.lua，这时候，直接在终端使用th </em>.lua即可编译执行。</p><p><center><br><img src="/2018/12/31/visdom-Tutorial/demo.png" width="600"><br></center></p><h5 id="code"><a href="#code" class="headerlink" title="code"></a><a href="https://github.com/Captainzj/Visdom_Tutorial" target="_blank" rel="noopener">code</a></h5><h3 id="Explain"><a href="#Explain" class="headerlink" title="Explain"></a>Explain</h3><h4 id="Env-save-path"><a href="#Env-save-path" class="headerlink" title="Env save path"></a>Env save path</h4><p>点击clear按钮可以清空当前env的所有pane，点击save按钮可将当前env保存成json文件，保存路径位于<code>~/.visdom/</code>目录下。也可修改env的名字后点击fork，保存当前env的状态至更名后的env。</p><h3 id="Error"><a href="#Error" class="headerlink" title="Error"></a>Error</h3><h4 id="SSL-CERTIFICATE-VERIFY-FAILED"><a href="#SSL-CERTIFICATE-VERIFY-FAILED" class="headerlink" title="SSL: CERTIFICATE_VERIFY_FAILED"></a>SSL: CERTIFICATE_VERIFY_FAILED</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">➜  ~ visdom</span><br><span class="line">Downloading scripts. It might take a while.</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/jquery@3.1.1/dist/jquery.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/bootstrap@3.3.7/dist/js/bootstrap.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/react@16.2.0/umd/react.production.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/react-dom@16.2.0/umd/react-dom.production.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/react-modal@3.1.10/dist/react-modal.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://cdn.plot.ly/plotly-latest.min.js</span><br><span class="line">ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading https://unpkg.com/sjcl@1.0.7/sjcl.js</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><a href="https://github.com/facebookresearch/visdom/issues/240" target="_blank" rel="noopener">Solution</a>:</p><p>Your best option is probably to try and do a manual install of the dependencies as described in <code>CONTRIBUTING.md</code>. Alternatively, you could try to bypass the SSL certification by adding the following at the top of <code>py/server.py</code> before start the server:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br></pre></td></tr></table></figure><p>Note that this is <strong>very dangerous</strong>, so immediately remove this monkey-patch after the server started successfully the first time, and restart the server. (The server only downloads the dependencies the first time you start it.)</p><p>I’m closing the issue because <a href="https://github.com/facebookresearch/visdom/pull/242" target="_blank" rel="noopener">#242</a> fixed the issue in the error logging. Thanks for reporting!</p><blockquote><p>After adding the codes, please re-install the visdom</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">$ pip3 uninstall visdom</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">$ pip3 install -e .</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">$ python3 setup.py install</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure></blockquote><p>Details :</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">➜  'visdom-master' pip3 uninstall visdom</span><br><span class="line">Uninstalling visdom-0.1.8.5:</span><br><span class="line">  Would remove:</span><br><span class="line">    /Library/Frameworks/Python.framework/Versions/3.6/bin/visdom</span><br><span class="line">    /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/visdom.egg-link</span><br><span class="line">Proceed (y/n)? y</span><br><span class="line">  Successfully uninstalled visdom-0.1.8.5</span><br><span class="line">➜  'visdom-master' pip uninstall visdom</span><br><span class="line">Skipping visdom as it is not installed.</span><br><span class="line">➜  'visdom-master' pip3 install -e .</span><br><span class="line">Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">Obtaining file:///Users/Captain/Desktop/visdom-master</span><br><span class="line">Requirement already satisfied: numpy&gt;=1.8 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (1.14.5)</span><br><span class="line">Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (1.1.0)</span><br><span class="line">Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (2.21.0)</span><br><span class="line">Requirement already satisfied: tornado in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (5.1.1)</span><br><span class="line">Requirement already satisfied: pyzmq in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (17.1.2)</span><br><span class="line">Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (1.11.0)</span><br><span class="line">Requirement already satisfied: torchfile in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (0.1.0)</span><br><span class="line">Requirement already satisfied: websocket-client in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (0.54.0)</span><br><span class="line">Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from visdom==0.1.8.5) (5.3.0)</span><br><span class="line">Requirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests-&gt;visdom==0.1.8.5) (1.24.1)</span><br><span class="line">Requirement already satisfied: certifi&gt;=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests-&gt;visdom==0.1.8.5) (2018.11.29)</span><br><span class="line">Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests-&gt;visdom==0.1.8.5) (3.0.4)</span><br><span class="line">Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests-&gt;visdom==0.1.8.5) (2.8)</span><br><span class="line">Installing collected packages: visdom</span><br><span class="line">  Running setup.py develop for visdom</span><br><span class="line">Successfully installed visdom</span><br><span class="line">➜  'visdom-master' python3 setup.py install</span><br><span class="line">running install</span><br><span class="line">running bdist_egg</span><br><span class="line">running egg_info</span><br><span class="line">writing py/visdom.egg-info/PKG-INFO</span><br><span class="line">writing dependency_links to py/visdom.egg-info/dependency_links.txt</span><br><span class="line">writing entry points to py/visdom.egg-info/entry_points.txt</span><br><span class="line">writing requirements to py/visdom.egg-info/requires.txt</span><br><span class="line">writing top-level names to py/visdom.egg-info/top_level.txt</span><br><span class="line">reading manifest file 'py/visdom.egg-info/SOURCES.txt'</span><br><span class="line">reading manifest template 'MANIFEST.in'</span><br><span class="line">warning: no previously-included files matching '__pycache__' found under directory '*'</span><br><span class="line">warning: no previously-included files matching '*.py[co]' found under directory '*'</span><br><span class="line">writing manifest file 'py/visdom.egg-info/SOURCES.txt'</span><br><span class="line">installing library code to build/bdist.macosx-10.6-intel/egg</span><br><span class="line">running install_lib</span><br><span class="line">running build_py</span><br><span class="line">creating build</span><br><span class="line">creating build/lib</span><br><span class="line">creating build/lib/visdom</span><br><span class="line">copying py/visdom/server.py -&gt; build/lib/visdom</span><br><span class="line">copying py/visdom/__init__.py -&gt; build/lib/visdom</span><br><span class="line">copying py/visdom/VERSION -&gt; build/lib/visdom</span><br><span class="line">copying py/visdom/__init__.pyi -&gt; build/lib/visdom</span><br><span class="line">copying py/visdom/py.typed -&gt; build/lib/visdom</span><br><span class="line">creating build/lib/visdom/static</span><br><span class="line">copying py/visdom/static/index.html -&gt; build/lib/visdom/static</span><br><span class="line">copying py/visdom/static/login.html -&gt; build/lib/visdom/static</span><br><span class="line">copying py/visdom/static/version.built -&gt; build/lib/visdom/static</span><br><span class="line">creating build/lib/visdom/static/css</span><br><span class="line">copying py/visdom/static/css/login.css -&gt; build/lib/visdom/static/css</span><br><span class="line">copying py/visdom/static/css/style.css -&gt; build/lib/visdom/static/css</span><br><span class="line">creating build/lib/visdom/static/js</span><br><span class="line">copying py/visdom/static/js/main.js -&gt; build/lib/visdom/static/js</span><br><span class="line">creating build/bdist.macosx-10.6-intel</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">copying build/lib/visdom/server.py -&gt; build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">copying build/lib/visdom/__init__.pyi -&gt; build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">copying build/lib/visdom/__init__.py -&gt; build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">copying build/lib/visdom/VERSION -&gt; build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg/visdom/static</span><br><span class="line">copying build/lib/visdom/static/index.html -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg/visdom/static/css</span><br><span class="line">copying build/lib/visdom/static/css/login.css -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static/css</span><br><span class="line">copying build/lib/visdom/static/css/style.css -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static/css</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg/visdom/static/js</span><br><span class="line">copying build/lib/visdom/static/js/main.js -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static/js</span><br><span class="line">copying build/lib/visdom/static/login.html -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static</span><br><span class="line">copying build/lib/visdom/static/version.built -&gt; build/bdist.macosx-10.6-intel/egg/visdom/static</span><br><span class="line">copying build/lib/visdom/py.typed -&gt; build/bdist.macosx-10.6-intel/egg/visdom</span><br><span class="line">byte-compiling build/bdist.macosx-10.6-intel/egg/visdom/server.py to server.cpython-36.pyc</span><br><span class="line">byte-compiling build/bdist.macosx-10.6-intel/egg/visdom/__init__.py to __init__.cpython-36.pyc</span><br><span class="line">creating build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/PKG-INFO -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/SOURCES.txt -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/dependency_links.txt -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/entry_points.txt -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/not-zip-safe -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/requires.txt -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">copying py/visdom.egg-info/top_level.txt -&gt; build/bdist.macosx-10.6-intel/egg/EGG-INFO</span><br><span class="line">creating dist</span><br><span class="line">creating 'dist/visdom-0.1.8.5-py3.6.egg' and adding 'build/bdist.macosx-10.6-intel/egg' to it</span><br><span class="line">removing 'build/bdist.macosx-10.6-intel/egg' (and everything under it)</span><br><span class="line">Processing visdom-0.1.8.5-py3.6.egg</span><br><span class="line">creating /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/visdom-0.1.8.5-py3.6.egg</span><br><span class="line">Extracting visdom-0.1.8.5-py3.6.egg to /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Removing visdom 0.1.8.5 from easy-install.pth file</span><br><span class="line">Adding visdom 0.1.8.5 to easy-install.pth file</span><br><span class="line">Installing visdom script to /Library/Frameworks/Python.framework/Versions/3.6/bin</span><br><span class="line"></span><br><span class="line">Installed /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/visdom-0.1.8.5-py3.6.egg</span><br><span class="line">Processing dependencies for visdom==0.1.8.5</span><br><span class="line">Searching for Pillow==5.3.0</span><br><span class="line">Best match: Pillow 5.3.0</span><br><span class="line">Adding Pillow 5.3.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for websocket-client==0.54.0</span><br><span class="line">Best match: websocket-client 0.54.0</span><br><span class="line">Adding websocket-client 0.54.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for torchfile==0.1.0</span><br><span class="line">Best match: torchfile 0.1.0</span><br><span class="line">Adding torchfile 0.1.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for six==1.11.0</span><br><span class="line">Best match: six 1.11.0</span><br><span class="line">Adding six 1.11.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for pyzmq==17.1.2</span><br><span class="line">Best match: pyzmq 17.1.2</span><br><span class="line">Adding pyzmq 17.1.2 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for tornado==5.1.1</span><br><span class="line">Best match: tornado 5.1.1</span><br><span class="line">Adding tornado 5.1.1 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for requests==2.21.0</span><br><span class="line">Best match: requests 2.21.0</span><br><span class="line">Adding requests 2.21.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for scipy==1.1.0</span><br><span class="line">Best match: scipy 1.1.0</span><br><span class="line">Adding scipy 1.1.0 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for numpy==1.14.5</span><br><span class="line">Best match: numpy 1.14.5</span><br><span class="line">Adding numpy 1.14.5 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for chardet==3.0.4</span><br><span class="line">Best match: chardet 3.0.4</span><br><span class="line">Adding chardet 3.0.4 to easy-install.pth file</span><br><span class="line">Installing chardetect script to /Library/Frameworks/Python.framework/Versions/3.6/bin</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for certifi==2018.11.29</span><br><span class="line">Best match: certifi 2018.11.29</span><br><span class="line">Adding certifi 2018.11.29 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for urllib3==1.24.1</span><br><span class="line">Best match: urllib3 1.24.1</span><br><span class="line">Adding urllib3 1.24.1 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Searching for idna==2.8</span><br><span class="line">Best match: idna 2.8</span><br><span class="line">Adding idna 2.8 to easy-install.pth file</span><br><span class="line"></span><br><span class="line">Using /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</span><br><span class="line">Finished processing dependencies for visdom==0.1.8.5</span><br><span class="line">➜  'visdom-master'</span><br></pre></td></tr></table></figure><h4 id="No-LuaRocks-module-found-for-mnist"><a href="#No-LuaRocks-module-found-for-mnist" class="headerlink" title="No LuaRocks module found for mnist"></a>No LuaRocks module found for mnist</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">➜  <span class="string">'visdom-master'</span> th example/demo2.lua</span><br><span class="line">| running on CPU...</span><br><span class="line">/Users/Captain/torch/install/bin/luajit: /Users/Captain/torch/install/share/lua/<span class="number">5.1</span>/trepl/init.lua:<span class="number">389</span>: module <span class="string">'mnist'</span> <span class="keyword">not</span> found:No LuaRocks module found <span class="keyword">for</span> mnist</span><br><span class="line">no field package.preload[<span class="string">'mnist'</span>]</span><br><span class="line">no file <span class="string">'/Users/Captain/.luarocks/share/lua/5.1/mnist.lua'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/.luarocks/share/lua/5.1/mnist/init.lua'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/torch/install/share/lua/5.1/mnist.lua'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/torch/install/share/lua/5.1/mnist/init.lua'</span></span><br><span class="line">no file <span class="string">'./mnist.lua'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/torch/install/share/luajit-2.1.0-beta1/mnist.lua'</span></span><br><span class="line">no file <span class="string">'/usr/local/share/lua/5.1/mnist.lua'</span></span><br><span class="line">no file <span class="string">'/usr/local/share/lua/5.1/mnist/init.lua'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/.luarocks/lib/lua/5.1/mnist.so'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/torch/install/lib/lua/5.1/mnist.so'</span></span><br><span class="line">no file <span class="string">'/Users/Captain/torch/install/lib/mnist.dylib'</span></span><br><span class="line">no file <span class="string">'./mnist.so'</span></span><br><span class="line">no file <span class="string">'/usr/local/lib/lua/5.1/mnist.so'</span></span><br><span class="line">no file <span class="string">'/usr/local/lib/lua/5.1/loadall.so'</span></span><br><span class="line">stack traceback:</span><br><span class="line">[C]: <span class="keyword">in</span> function <span class="string">'error'</span></span><br><span class="line">/Users/Captain/torch/install/share/lua/<span class="number">5.1</span>/trepl/init.lua:<span class="number">389</span>: <span class="keyword">in</span> function <span class="string">'require'</span></span><br><span class="line">example/demo2.lua:<span class="number">29</span>: <span class="keyword">in</span> function <span class="string">'getIterator'</span></span><br><span class="line">example/demo2.lua:<span class="number">53</span>: <span class="keyword">in</span> main chunk</span><br><span class="line">[C]: <span class="keyword">in</span> function <span class="string">'dofile'</span></span><br><span class="line">...tain/torch/install/lib/luarocks/rocks/trepl/scm<span class="number">-1</span>/bin/th:<span class="number">150</span>: <span class="keyword">in</span> main chunk</span><br><span class="line">[C]: at <span class="number">0x0109dd2360</span></span><br></pre></td></tr></table></figure><p>Solution:</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> luarocks install mnist</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Classification with Pre-trained Model</title>
    <link href="http://yoursite.com/2018/12/31/Classification-with-Pretrained-Model/"/>
    <id>http://yoursite.com/2018/12/31/Classification-with-Pretrained-Model/</id>
    <published>2018-12-31T06:53:44.000Z</published>
    <updated>2018-12-31T07:19:37.924Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>参考：</p><ul><li><a href="https://blog.csdn.net/u010165147/article/details/72829969" target="_blank" rel="noopener">使用pytorch预训练模型分类与特征提取</a></li><li><a href="https://blog.csdn.net/geek_of_csdn/article/details/84343971#comments" target="_blank" rel="noopener">Pytorch：利用预训练好的VGG16网络提取图片特征</a></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable </span><br><span class="line"><span class="keyword">import</span> torch.cuda</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"> </span><br><span class="line">img_to_tensor = transforms.ToTensor()</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">()</span>:</span></span><br><span class="line">    resmodel=models.resnet34(pretrained=<span class="keyword">True</span>)</span><br><span class="line">    resmodel.cuda()<span class="comment">#将模型从CPU发送到GPU,如果没有GPU则删除该行</span></span><br><span class="line">    <span class="keyword">return</span> resmodel</span><br><span class="line"> </span><br><span class="line"><span class="comment">#分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(resmodel,imgpath)</span>:</span></span><br><span class="line">    resmodel.eval()<span class="comment">#必需，否则预测结果是错误的</span></span><br><span class="line">    </span><br><span class="line">    img=Image.open(imgpath)</span><br><span class="line">    img=img.resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">    tensor=img_to_tensor(img)</span><br><span class="line">    </span><br><span class="line">    tensor=tensor.resize_(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    tensor=tensor.cuda()<span class="comment">#将数据发送到GPU，数据和模型在同一个设备上运行</span></span><br><span class="line">            </span><br><span class="line">    result=resmodel(Variable(tensor))</span><br><span class="line">    result_npy=result.data.cpu().numpy()<span class="comment">#将结果传到CPU，并转换为numpy格式</span></span><br><span class="line">    max_index=np.argmax(result_npy[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> max_index</span><br><span class="line">    </span><br><span class="line"><span class="comment">#特征提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_feature</span><span class="params">(resmodel,imgpath)</span>:</span></span><br><span class="line">    resmodel.fc=torch.nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line">    resmodel.eval()</span><br><span class="line">    </span><br><span class="line">    img=Image.open(imgpath)</span><br><span class="line">    img=img.resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">    tensor=img_to_tensor(img)</span><br><span class="line">    </span><br><span class="line">    tensor=tensor.resize_(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    tensor=tensor.cuda()</span><br><span class="line">            </span><br><span class="line">    result=resmodel(Variable(tensor))</span><br><span class="line">    result_npy=result.data.cpu().numpy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result_npy[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    model=make_model()</span><br><span class="line">    imgpath=<span class="string">'path_to_img/xxx.jpg'</span> <span class="comment"># imgpath='ILSVRC2012_val_00001101.JPEG' 此时图片与该代码文件放在同一目录下</span></span><br><span class="line">    <span class="keyword">print</span> inference(model,imgpath)</span><br><span class="line">    <span class="keyword">print</span> extract_feature(model, imgpath)</span><br></pre></td></tr></table></figure><p>注：</p><ul><li><p>关于使用的img</p><p>img.jpg是随便找的一张图，要求是3通道的（RGB，不能是黑白的，如果是黑白的要自己拓展成3通道）.建议先看下这里的文章：<a href="https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c" target="_blank" rel="noopener">https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c</a>。另外，建议不要用pytorch提供的vgg模型来提取特征，效果不是很好，最好是通过别的框架的，例如keras提供的vgg模型来提取特征，保存为文件之后再调用pytorch</p></li><li><p><code>#分类</code> 的返回值max_index</p><p>index为0～999的值，0对应n01440764，1对应n01443537，是一个映射表参考：<a href="https://blog.csdn.net/u010165147/article/details/72848497" target="_blank" rel="noopener">https://blog.csdn.net/u010165147/article/details/72848497</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>torchvision_pretrainedModel</title>
    <link href="http://yoursite.com/2018/12/28/torchvision-pretrainedModel/"/>
    <id>http://yoursite.com/2018/12/28/torchvision-pretrainedModel/</id>
    <published>2018-12-28T08:09:59.000Z</published>
    <updated>2018-12-31T07:16:32.881Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>关于“Save &amp;&amp; Load Model” 可参见<a href="https://captainzj.github.io/2018/12/28/Pytorch-Save-Load-Model/" target="_blank" rel="noopener">说明</a>.</p><h3 id="直接加载预训练模型"><a href="#直接加载预训练模型" class="headerlink" title="直接加载预训练模型"></a>直接加载预训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">model = torchvision.models.densenet169(pretrained=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><strong>Save model</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.save(model.state_dict(),<span class="string">'model.pth'</span>)</span><br></pre></td></tr></table></figure><h4 id="View-model-params"><a href="#View-model-params" class="headerlink" title="View model params "></a><strong>View model params </strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pretrained_dict = model.state_dict()  <span class="comment"># densenet169</span></span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> pretrained_dict.items():</span><br><span class="line">    print(k,v.size())    <span class="comment">#打印网络中的变量名</span></span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features.conv0.weight torch.Size([<span class="number">64</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line">features.norm0.weight torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.bias torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.running_mean torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.running_var torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.norm1.weight torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.bias torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.running_mean torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.running_var torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.weight torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.bias torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.running_mean torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.running_var torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer2.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">96</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer2.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer3.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer3.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.weight torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.bias torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.running_mean torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.running_var torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer4.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">160</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer4.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.weight torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.bias torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.running_mean torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.running_var torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer5.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">192</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer5.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.weight torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.bias torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.running_mean torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.running_var torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer6.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">224</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer6.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.transition1.norm.weight torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.bias torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.running_mean torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.running_var torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.num_batches_tracked torch.Size([])</span><br><span class="line">features.transition1.conv.weight torch.Size([<span class="number">128</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">.... </span><br><span class="line">features.denseblock4.denselayer32.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.norm5.weight torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.bias torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.running_mean torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.running_var torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.num_batches_tracked torch.Size([])</span><br><span class="line">classifier.weight torch.Size([<span class="number">1000</span>, <span class="number">1664</span>])</span><br><span class="line">classifier.bias torch.Size([<span class="number">1000</span>])</span><br></pre></td></tr></table></figure><h4 id="View-model-structure"><a href="#View-model-structure" class="headerlink" title="View model structure"></a>View model structure</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = torch.nn.Sequential(*list(model.children())[:]) <span class="comment"># densenet169</span></span><br><span class="line">print(feature)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Sequential(</span><br><span class="line">    (conv0): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">    (norm0): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">    (relu0): ReLU(inplace)</span><br><span class="line">    (pool0): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (denseblock1): _DenseBlock(</span><br><span class="line">      (denselayer1): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">      (denselayer2): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">  ... ...</span><br><span class="line">        (denselayer32): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">1632</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">1632</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (norm5): BatchNorm2d(<span class="number">1664</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">1664</span>, out_features=<span class="number">1000</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>基本上可以看出总体分为两个部分，这两个部分对应的名字可以用<code>print(model._modules.keys())</code>查询到：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查询结果</span></span><br><span class="line">odict_keys([<span class="string">'features'</span>, <span class="string">'classifier'</span>])</span><br></pre></td></tr></table></figure><p>之后可以直接用<code>model.features</code>直接只调用features部分，直接将分类部分抛弃掉。</p><h3 id="加载部分预训练模型"><a href="#加载部分预训练模型" class="headerlink" title="加载部分预训练模型"></a>加载部分预训练模型</h3><p>其实大多数时候我们需要根据我们的任务调节我们的模型，所以很难保证模型和公开的模型完全一样，但是预训练模型的参数确实有助于提高训练的准确率，为了结合二者的优点，就需要我们加载部分预训练模型。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载model，model是自己定义好的模型</span></span><br><span class="line">resnet50 = models.resnet50(pretrained=<span class="keyword">True</span>) </span><br><span class="line">model =Net(...) </span><br><span class="line"> </span><br><span class="line"><span class="comment">#读取参数 </span></span><br><span class="line">pretrained_dict =resnet50.state_dict()  </span><br><span class="line">model_dict = model.state_dict() </span><br><span class="line"> </span><br><span class="line"><span class="comment">#将pretrained_dict里不属于model_dict的键剔除掉,筛选符合自定义模型的键</span></span><br><span class="line">pretrained_dict =  &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125; </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更新现有的model_dict </span></span><br><span class="line">model_dict.update(pretrained_dict) <span class="comment"># update</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 加载我们真正需要的state_dict </span></span><br><span class="line">model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure><p>因为需要剔除原模型中不匹配的键，也就是层的名字，所以我们的新模型改变了的层需要和原模型对应层的名字不一样，比如：resnet最后一层的名字是fc(PyTorch中)，那么我们修改过的resnet的最后一层就不能取这个名字，可以叫fc_</p><h3 id="简单预训练"><a href="#简单预训练" class="headerlink" title="简单预训练"></a>简单预训练</h3><p>我们先从torchvision中调用基本模型，加载预训练模型，然后，重点来了，<strong>将其中的层直接替换为我们需要的层即可</strong>：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resnet = torchvision.models.resnet152(pretrained=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 原本为1000类，改为10类</span></span><br><span class="line">resnet.fc = torch.nn.Linear(<span class="number">2048</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>其中使用了pretrained参数，会直接加载预训练模型，内部实现和前文提到的加载预训练的方法一样。因为是先加载的预训练参数，相当于模型中已经有参数了，所以替换掉最后一层即可。OK！</p><h3 id="使用预训练模型分类与特征提取"><a href="#使用预训练模型分类与特征提取" class="headerlink" title="使用预训练模型分类与特征提取"></a>使用预训练模型分类与特征提取</h3><p># <strong>To  Completed</strong></p><p><strong>Reference：</strong></p><ul><li><p><a href="https://zhuanlan.zhihu.com/p/25980324" target="_blank" rel="noopener">PyTorch预训练[知乎]</a></p></li><li><p><a href="https://blog.csdn.net/u010165147/article/details/72829969" target="_blank" rel="noopener">使用pytorch预训练模型分类与特征提取</a></p></li><li><a href="https://blog.csdn.net/Geek_of_CSDN/article/details/84343971" target="_blank" rel="noopener">Pytorch：利用预训练好的VGG16网络提取图片特征</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Save&amp;&amp;Load_Model</title>
    <link href="http://yoursite.com/2018/12/28/Pytorch-Save-Load-Model/"/>
    <id>http://yoursite.com/2018/12/28/Pytorch-Save-Load-Model/</id>
    <published>2018-12-28T07:33:53.000Z</published>
    <updated>2019-01-15T13:50:10.222Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="方法一-推荐"><a href="#方法一-推荐" class="headerlink" title="方法一(推荐)"></a>方法一(推荐)</h2><p>第一种方法也是官方推荐的方法，只保存和恢复模型中的参数。</p><h3 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(the_model.state_dict(), PATH)</span><br></pre></td></tr></table></figure><h3 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">the_model = TheModelClass(*args, **kwargs)</span><br><span class="line">the_model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>使用这种方法，我们需要自己导入模型的结构信息。</p><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>使用这种方法，将会保存模型的参数和结构信息。</p><h3 id="保存-1"><a href="#保存-1" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(the_model, PATH)</span><br></pre></td></tr></table></figure><h3 id="恢复-1"><a href="#恢复-1" class="headerlink" title="恢复"></a>恢复</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">the_model = torch.load(PATH)</span><br></pre></td></tr></table></figure><h2 id="一个相对完整的例子"><a href="#一个相对完整的例子" class="headerlink" title="一个相对完整的例子"></a>一个相对完整的例子</h2><h3 id="save"><a href="#save" class="headerlink" title="save"></a>save</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(&#123;</span><br><span class="line">            <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,</span><br><span class="line">            <span class="string">'arch'</span>: args.arch,</span><br><span class="line">            <span class="string">'state_dict'</span>: model.state_dict(),</span><br><span class="line">            <span class="string">'best_prec1'</span>: best_prec1,</span><br><span class="line">        &#125;, <span class="string">'checkpoint.tar'</span> )</span><br></pre></td></tr></table></figure><h3 id="load"><a href="#load" class="headerlink" title="load"></a>load</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.resume:</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(args.resume):</span><br><span class="line">            print(<span class="string">"=&gt; loading checkpoint '&#123;&#125;'"</span>.format(args.resume))</span><br><span class="line">            checkpoint = torch.load(args.resume)</span><br><span class="line">            args.start_epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">            best_prec1 = checkpoint[<span class="string">'best_prec1'</span>]</span><br><span class="line">            model.load_state_dict(checkpoint[<span class="string">'state_dict'</span>])</span><br><span class="line">            print(<span class="string">"=&gt; loaded checkpoint '&#123;&#125;' (epoch &#123;&#125;)"</span></span><br><span class="line">                  .format(args.evaluate, checkpoint[<span class="string">'epoch'</span>]))</span><br></pre></td></tr></table></figure><h2 id="获取模型中某些层的参数"><a href="#获取模型中某些层的参数" class="headerlink" title="获取模型中某些层的参数"></a>获取模型中某些层的参数</h2><h3 id="model-state-dict"><a href="#model-state-dict" class="headerlink" title="model.state_dict()"></a>model.state_dict()</h3><p>对于恢复的模型，如果我们想查看某些层的参数，可以：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个网络</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">                  (<span class="string">'conv1'</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">                  (<span class="string">'relu1'</span>, nn.ReLU()),</span><br><span class="line">                  (<span class="string">'conv2'</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">                  (<span class="string">'relu2'</span>, nn.ReLU())</span><br><span class="line">                ]))</span><br><span class="line"><span class="comment"># 打印网络的结构</span></span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Sequential (</span><br><span class="line">  (conv1): Conv2d(<span class="number">1</span>, <span class="number">20</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu1): ReLU ()</span><br><span class="line">  (conv2): Conv2d(<span class="number">20</span>, <span class="number">64</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu2): ReLU ()</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>如果我们想获取conv1的weight和bias：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params=model.state_dict() </span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> params.items():</span><br><span class="line">    print(k)    <span class="comment">#打印网络中的变量名</span></span><br><span class="line"></span><br><span class="line">print(params[<span class="string">'conv1.weight'</span>])   <span class="comment">#打印conv1的weight.size()</span></span><br><span class="line">print(params[<span class="string">'conv1.bias'</span>])   <span class="comment">#打印conv1的bias.size()</span></span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv1.weight</span><br><span class="line">conv1.bias</span><br><span class="line">conv2.weight</span><br><span class="line">conv2.bias</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">torch.Size([<span class="number">20</span>])</span><br></pre></td></tr></table></figure><h3 id="model-named-parameters"><a href="#model-named-parameters" class="headerlink" title="model.named_parameters()"></a>model.named_parameters()</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = list(model.named_parameters())</span><br><span class="line">(name, param) = params[<span class="number">0</span>]</span><br><span class="line">print(name)</span><br><span class="line">print(param.grad)</span><br><span class="line">print(<span class="string">'-------------------------------------------------'</span>) </span><br><span class="line">(name1, param1) = params[<span class="number">1</span>]</span><br><span class="line">print(name1)</span><br><span class="line">print(param1.grad)</span><br><span class="line">print(<span class="string">'----------------------------------------------------'</span>)</span><br><span class="line">(name2, param2) = params[<span class="number">2</span>]</span><br><span class="line">print(name2) </span><br><span class="line">print(param2.grad)</span><br><span class="line">print(<span class="string">'----------------------------------------------------'</span>)</span><br><span class="line">(name3, param3) = params[<span class="number">3</span>]</span><br><span class="line">print(name3) </span><br><span class="line">print(param3.grad)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv1.weight</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">-------------------------------------------------</span><br><span class="line">conv1.bias</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">----------------------------------------------------</span><br><span class="line">conv2.weight</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">----------------------------------------------------</span><br><span class="line">conv2.bias</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure><p>参考：</p><ul><li><p><a href="https://www.pytorchtutorial.com/pytorch-note5-save-and-restore-models/" target="_blank" rel="noopener">PyTorch 学习笔记（五）：存储和恢复模型并查看参数</a></p></li><li><p><a href="https://blog.csdn.net/appleml/article/details/81000301" target="_blank" rel="noopener">pytorch查看网络中的参数</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Spectral_Clustering</title>
    <link href="http://yoursite.com/2018/12/28/Spectral-Clustering/"/>
    <id>http://yoursite.com/2018/12/28/Spectral-Clustering/</id>
    <published>2018-12-28T03:50:46.000Z</published>
    <updated>2018-12-28T03:54:40.120Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><br></p><div class="row">    <embed src="谱聚类.pdf" width="100%" height="550" type="application/pdf"></div><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>聚类综述</title>
    <link href="http://yoursite.com/2018/12/28/%E8%81%9A%E7%B1%BB%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2018/12/28/聚类综述/</id>
    <published>2018-12-28T03:23:11.000Z</published>
    <updated>2018-12-28T03:37:04.165Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><br></p><div class="row">    <embed src="聚类综述.pdf" width="100%" height="550" type="application/pdf"></div><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>医学数据格式</title>
    <link href="http://yoursite.com/2018/12/27/Medical-Data-Format/"/>
    <id>http://yoursite.com/2018/12/27/Medical-Data-Format/</id>
    <published>2018-12-27T09:08:13.000Z</published>
    <updated>2018-12-27T11:56:24.036Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>ToRead：</p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_12" target="_blank" rel="noopener">Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_47" target="_blank" rel="noopener">Unsupervised Domain Adaptation in Brain Lesion Segmentation with Adversarial Networks</a></p><p>Paper：</p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=2ahUKEwjXyObB2r_fAhXjRt8KHROrC5cQFjABegQIAxAB&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1702.05747&amp;usg=AOvVaw3kBlBAYVhnDhZxU1aBbgxG" target="_blank" rel="noopener">A Survey on Deep Learning in Medical Image Analysis</a></p><table><thead><tr><th>数据格式</th><th>含义（字段）</th><th>头部-&gt; 内容</th></tr></thead><tbody><tr><td>DICOM</td><td></td><td></td></tr><tr><td>nii</td><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><table><thead><tr><th>数据</th><th>Kind</th><th>knowledge point + theory</th></tr></thead><tbody><tr><td>MRI</td><td>T1\T2\Flair</td><td>区别， 各自针对的内容</td></tr><tr><td>CT</td><td>腹部CT\胸部\全身CT</td><td>扫描方式</td></tr><tr><td>PET</td><td></td></tr></tbody></table><h2 id="医学图像数据类型"><a href="#医学图像数据类型" class="headerlink" title="医学图像数据类型"></a>医学图像数据类型</h2><h3 id="MRI"><a href="#MRI" class="headerlink" title="MRI"></a>MRI</h3><h3 id="CT"><a href="#CT" class="headerlink" title="CT"></a>CT</h3><h3 id="PET"><a href="#PET" class="headerlink" title="PET"></a>PET</h3><h2 id="医学图像数据格式"><a href="#医学图像数据格式" class="headerlink" title="医学图像数据格式"></a>医学图像数据格式</h2><h3 id="DICOM"><a href="#DICOM" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>医学图像采用数字成像和通信（DICOM）作为存储和交换医学图像数据的标准解决方案。这个标准的第一个版本是在1985年发布的。发展到现在，该方案有了一些改变。该标准使用文件格式和通信协议。</p><p><strong>文件格式</strong> - 所有患者医疗图像都以DICOM文件格式保存。除了其他图像相关数据（例如用于拍摄图像的设备以及医疗处理的一些背景）之外，该格式具有关于患者的PHI（受保护的健康信息），例如姓名，性别，年龄。医学影像设备创建DICOM文件。医生使用DICOM查看器，可显示DICOM图像的计算机软件应用程序，读取和诊断图像中的发现。</p><p><strong>通信协议</strong> - DICOM通信协议用于搜索档案中的成像研究，并将成像研究恢复到工作站以显示。连接到医院网络的所有医疗成像应用程序都使用DICOM协议来交换信息，主要是DICOM图像，还包括患者和手术信息。还有更先进的网络命令，用于控制和跟踪治疗，调度程序，报告状态，分担医生和成像设备之间的工作量。关于DICOM标准细节，在这里推荐一个很好的博客<a href="http://link.zhihu.com/?target=http%3A//dicomiseasy.blogspot.com" target="_blank" rel="noopener">http://dicomiseasy.blogspot.com</a></p><h4 id="分析DICOM图像"><a href="#分析DICOM图像" class="headerlink" title="分析DICOM图像"></a><strong>分析DICOM图像</strong></h4><ul><li><strong>了解DICOM 格式数据</strong></li></ul><p>CT扫描的测量单位是Hounsfield单位（HU），它是放射性强度的量度。 仔细校准CT扫描仪以准确测量。 关于这方面的详细了解可以在这里到。<a href="https://web.archive.org/web/20070926231241/http://www.intl.elsevierhealth.com/e-books/pdf/940.pdf" target="_blank" rel="noopener">Introduction to CT physics</a></p><p>每个像素被分配一个数值（CT值），它是相应体素中所有衰减值的平均值。 将这个数字与水的衰减值进行比较，并在戈弗雷·豪斯菲尔德爵士（Sir Godfrey Hounsfield）之后以胡恩斯菲尔德单位（Hounsfield units，HU）的任意单位的比例显示。</p><ul><li><p>获得DICOM 数据库</p><ul><li>kaggle competitions and Datasets</li><li>Dicom Library</li><li>Osirix Datasets</li><li>Visible Human Datasets</li><li><p>The Zubal Phantom</p></li><li><p>杜克大学他们有公开的数据集</p></li></ul></li></ul><h3 id="nii"><a href="#nii" class="headerlink" title="nii"></a>nii</h3><h2 id="Matlab-python-医学工具包"><a href="#Matlab-python-医学工具包" class="headerlink" title="Matlab/python 医学工具包"></a>Matlab/python 医学工具包</h2><h3 id="DICOM-1"><a href="#DICOM-1" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="python-package"><a href="#python-package" class="headerlink" title="python package"></a>python package</h4><ul><li><strong>pydiocm</strong></li></ul><h2 id="浏览image数据工具"><a href="#浏览image数据工具" class="headerlink" title="浏览image数据工具"></a>浏览image数据工具</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/30915590" target="_blank" rel="noopener">医学图像处理与深度学习[知乎]</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深度学习之PyTorch实战计算机视觉Code</title>
    <link href="http://yoursite.com/2018/12/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8BPyTorch%E5%AE%9E%E6%88%98%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89Code/"/>
    <id>http://yoursite.com/2018/12/17/深度学习之PyTorch实战计算机视觉Code/</id>
    <published>2018-12-17T08:30:32.000Z</published>
    <updated>2019-01-22T13:06:26.509Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>code Linkage: <a href="https://github.com/Captainzj/PyTorch_Practice/blob/master/chapter-6/chapter-6.ipynb" target="_blank" rel="noopener">https://github.com/Captainzj/PyTorch_Practice/blob/master/chapter-6/chapter-6.ipynb</a><br><!-- more --></p><h3 id="6-1-1-Tensor的数据类型"><a href="#6-1-1-Tensor的数据类型" class="headerlink" title="6.1.1 Tensor的数据类型"></a>6.1.1 Tensor的数据类型</h3><blockquote><p>Tensor 张量：多维矩阵</p></blockquote><p><a href="https://pytorch.org/docs/stable/torch.html#tensors" target="_blank" rel="noopener">torch.tensor Docs</a></p><ul><li>torch.FloatTensor: 用于生成数据类型为浮点型的Tensor</li><li>torch.IntTensor: 用于生成数据类型为整型的Tensor</li><li>torch.rand: 随机生成的浮点数据在<code>0~1区间均匀分布</code></li><li>torch.randn: 随机生成的浮点数的取值满足<code>均值为0、方差为1</code>的正态分布</li><li>torch.arange(start=0, end, step=1): Returns a 1-D tensor of size  $ \left \lfloor \frac{end − start}{step} \right \rfloor$ with values from the interval <code>[start, end)</code> taken with common difference <code>step</code> beginning from start.</li><li>torch.zeros: Returns a tensor filled with the scalar value 0, with the shape defined by the variable argument <code>sizes</code>.</li></ul><h3 id="6-1-2-Tensor的运算"><a href="#6-1-2-Tensor的运算" class="headerlink" title="6.1.2 Tensor的运算"></a>6.1.2 Tensor的运算</h3><p><a href="https://pytorch.org/docs/stable/torch.html#math-operations" target="_blank" rel="noopener">math-operations Docs</a></p><ul><li>torch.add()<ul><li>torch.add(input, value, out=None): $out=input+value$</li><li>torch.add(input, value=1, other, out=None): $out=input+value×other$</li></ul></li><li>torch.clamp(input, min, max, out=None) → Tensor<br>Clamp(裁剪) all elements in input into the range <code>[ min, max ]</code></li><li><p>torch.div()</p><ul><li>torch.div(input, value, out=None) → Tensor: $out_i = \frac{input_i}{value}$</li><li>torch.div(input, other, out=None) → Tensor: $out_i = \frac{input_i}{other_i}$</li></ul></li><li><p>torch.mul()</p><ul><li>torch.mul(input, value, out=None): $out_i=value×input_i​$ </li><li>torch.mul(input, other, out=None):$out_i=input_i×other_i​$ </li></ul></li><li>torch.pow(): $out_i=x_i^{exponent}$</li><li>torch.mm(mat1, mat2, out=None) → Tensor: Performs a <code>matrix multiplication</code> of the matrices <code>mat1</code> and <code>mat2</code>.</li><li>torch.mv(mat, vec, out=None) → Tensor: Performs a matrix-vector product of the matrix <code>mat</code> and the vector <code>vec</code>.</li></ul><h3 id="6-1-3-搭建一个简易神经网络"><a href="#6-1-3-搭建一个简易神经网络" class="headerlink" title="6.1.3 搭建一个简易神经网络"></a>6.1.3 搭建一个简易神经网络</h3><blockquote><p>使用前向传播和后向传播实现了对这个模型的训练和对权重参数的优化</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">batch_n = <span class="number">100</span> <span class="comment"># batch_n是在一个批次中输入数据的数量</span></span><br><span class="line">hidden_layer = <span class="number">100</span> <span class="comment"># hidden_layer定义经过隐藏层后保留的数据特征的个数</span></span><br><span class="line">input_data = <span class="number">1000</span> <span class="comment"># 输入数据包含的数据特征有input_data个</span></span><br><span class="line">output_data = <span class="number">10</span> <span class="comment"># 输出out_put个分类结果值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [100,1000] --[1000,100]-&gt;&gt; [100,100] --[100,10]-&gt;&gt; [100,10]</span></span><br><span class="line">x = torch.randn(batch_n, input_data) <span class="comment"># x: 100*1000</span></span><br><span class="line">y = torch.randn(batch_n, output_data) <span class="comment"># y: 100*10</span></span><br><span class="line"></span><br><span class="line">w1 = torch.randn(input_data, hidden_layer) <span class="comment"># w1: 1000*100</span></span><br><span class="line">w2 = torch.randn(hidden_layer, output_data) <span class="comment"># w2:100*10</span></span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">20</span>   <span class="comment"># 训练次数</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span>  <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch_n):</span><br><span class="line">    h1 = x.mm(w1) <span class="comment">#100*100  </span></span><br><span class="line">    h1 = h1.clamp(min = <span class="number">0</span>)  <span class="comment"># ReLU activation Function</span></span><br><span class="line">    y_pred = h1.mm(w2) <span class="comment">#100*10  前向传播的预测结果</span></span><br><span class="line">    </span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()   <span class="comment"># 均方误差函数计算loss</span></span><br><span class="line">    print(<span class="string">"Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;"</span>.format(epoch,loss))  <span class="comment"># 可由输出观察到 Loss值逐渐减小</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    链式求导得w1、w2的梯度 grad_w1、grad_w2</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    grad_y_pred = <span class="number">2</span>*(y_pred - y) <span class="comment"># 100*10</span></span><br><span class="line">    grad_w2 = h1.t().mm(grad_y_pred) <span class="comment"># 100*10</span></span><br><span class="line">    </span><br><span class="line">    grad_h = grad_y_pred.clone() <span class="comment"># 100*10</span></span><br><span class="line">    grad_h = grad_h.mm(w2.t()) <span class="comment"># 100*100 = 100*10 × 10*100</span></span><br><span class="line">    grad_h.clamp_(min=<span class="number">0</span>) </span><br><span class="line">    </span><br><span class="line">    grad_w1 = x.t().mm(grad_h) <span class="comment"># 1000*10 = 1000*100 × 100*10</span></span><br><span class="line">    w1 -= learning_rate*grad_w1 <span class="comment"># 1000*10</span></span><br><span class="line">    w2 -= learning_rate*grad_w2 <span class="comment"># 100*10</span></span><br></pre></td></tr></table></figure><h3 id="6-2-1-torch-autograd和Variable"><a href="#6-2-1-torch-autograd和Variable" class="headerlink" title="6.2.1 torch.autograd和Variable"></a>6.2.1 torch.autograd和Variable</h3><blockquote><p>torch.autograd包可以使模型参数自动计算在优化过程中需要用到的梯度值，降低了实现后向传播代码的复杂度</p></blockquote><ol><li>w1 = Variable(…, requires_grad = True)</li><li>loss.backward() #让模型根据计算图自动计算每个节点的梯度值并根据需求进行保留</li><li>w1.grad.data.zero_() #将grad置零</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">batch_n = <span class="number">100</span></span><br><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = Variable(torch.randn(batch_n, input_data), requires_grad = <span class="keyword">False</span>)</span><br><span class="line">y = Variable(torch.randn(batch_n, output_data), requires_grad = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">w1 = Variable(torch.randn(input_data, hidden_layer), requires_grad = <span class="keyword">True</span>)</span><br><span class="line">w2 = Variable(torch.randn(hidden_layer, output_data), requires_grad = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">20</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch_n):</span><br><span class="line">    y_pred = x.mm(w1).clamp(min = <span class="number">0</span>).mm(w2)</span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    print(<span class="string">"Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;"</span>.format(epoch,loss))</span><br><span class="line">    </span><br><span class="line">    loss.backward()  <span class="comment">#让模型根据计算图自动计算每个节点的梯度值并根据需求进行保留</span></span><br><span class="line">    </span><br><span class="line">    w1.data -= learning_rate*w1.grad.data  </span><br><span class="line">    w2.data -= learning_rate*w2.grad.data</span><br><span class="line">    </span><br><span class="line">    w1.grad.data.zero_()  <span class="comment"># 置零</span></span><br><span class="line">    w2.grad.data.zero_()  <span class="comment"># 若不置零，则计算的梯度值会被一直累加</span></span><br></pre></td></tr></table></figure><h3 id="6-2-2-自定义传播函数"><a href="#6-2-2-自定义传播函数" class="headerlink" title="6.2.2 自定义传播函数"></a>6.2.2 自定义传播函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">batch_n = <span class="number">64</span></span><br><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, w1, w2)</span>:</span></span><br><span class="line">        x = torch.mm(input, w1)</span><br><span class="line">        x = torch.clamp(x, min = <span class="number">0</span>)</span><br><span class="line">        x =torch.mm(x, w2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = Variable(torch.randn(batch_n, input_data), requires_grad = <span class="keyword">False</span>)</span><br><span class="line">y = Variable(torch.randn(batch_n, output_data), requires_grad = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">w1 = Variable(torch.randn(input_data, hidden_layer), requires_grad = <span class="keyword">True</span>)</span><br><span class="line">w2 = Variable(torch.randn(hidden_layer, output_data) ,requires_grad = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">30</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch_n):</span><br><span class="line">    y_pred = model(x, w1, w2)  <span class="comment"># y_pred = x.mm(w1).clamp(min = 0).mm(w2)</span></span><br><span class="line">    </span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    print(<span class="string">"Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;"</span>.format(epoch,loss))</span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    w1.data -= learning_rate * w1.grad.data</span><br><span class="line">    w2.data -= learning_rate * w2.grad.data</span><br><span class="line">    </span><br><span class="line">    w1.grad.data.zero_()</span><br><span class="line">    w2.grad.data.zero_()</span><br></pre></td></tr></table></figure><h3 id="6-3-1-PyTorch之torch-nn"><a href="#6-3-1-PyTorch之torch-nn" class="headerlink" title="6.3.1 PyTorch之torch.nn"></a>6.3.1 PyTorch之torch.nn</h3><ul><li><p>torch.nn.Sequential</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line">models = torch.nn.Sequential(  <span class="comment"># 序列容器</span></span><br><span class="line">torch.nn.Linear(input_data, hidden_layer),  <span class="comment"># 从输入层到隐藏层的线性变换</span></span><br><span class="line">torch.nn.ReLU(),  <span class="comment"># 激活函数</span></span><br><span class="line">torch.nn.Linear(hidden_layer, output_data) <span class="comment"># 从隐藏层到输出层的线性变换</span></span><br><span class="line">)</span><br><span class="line">print(models)</span><br></pre></td></tr></table></figure></li><li><p>torch.nn.Sequential(OrderedDict([]))</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict  <span class="comment"># 有序字典</span></span><br><span class="line">models = torch.nn.Sequential(OrderedDict([  </span><br><span class="line">(<span class="string">"Line1"</span>,torch.nn.Linear(input_data, hidden_layer)),</span><br><span class="line">(<span class="string">"Relu1"</span>,torch.nn.ReLU()),</span><br><span class="line">(<span class="string">"Line2"</span>,torch.nn.Linear(hidden_layer, output_data))])</span><br><span class="line">)</span><br><span class="line">print(models)</span><br></pre></td></tr></table></figure></li><li><p>torch.nn.MSELoss()</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">loss_f = torch.nn.MSELoss()  <span class="comment">#定义loss_f # 均方误差函数类MSELoss计算损失值</span></span><br><span class="line">x = Variable(torch.randn(<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line">y = Variable(torch.randn(<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line">loss = loss_f(x,y) <span class="comment">#x、yd的维度需要一致</span></span><br><span class="line">print(loss.data)</span><br></pre></td></tr></table></figure></li><li><p>torch.nn.L1Loss()</p>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">loss_f = torch.nn.L1Loss()  <span class="comment"># 平均绝对误差函数</span></span><br><span class="line">x = Variable(torch.randn(<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line">y = Variable(torch.randn(<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line">loss = loss_f(x,y)</span><br><span class="line">print(loss.data)</span><br></pre></td></tr></table></figure></li><li><p>torch.nn.CrossEntropyLoss()</p><pre><code class="python"><span class="keyword">import</span> torch<span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variableloss_f = torch.nn.CrossEntropyLoss()  <span class="comment"># 交叉熵</span>x = Variable(torch.randn(<span class="number">3</span>, <span class="number">5</span>))y = Variable(torch.LongTensor(<span class="number">3</span>).random_(<span class="number">5</span>))loss = loss_f(x,y)print(loss.data)</code></pre></li><li><p>torch.nn 构建模型</p><pre><code class="python"><span class="keyword">import</span> torch<span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variablebatch_n = <span class="number">100</span>hidden_layer = <span class="number">100</span>input_data = <span class="number">1000</span>output_data = <span class="number">10</span>x = Variable(torch.randn(batch_n, input_data), requires_grad = <span class="keyword">False</span>)y = Variable(torch.randn(batch_n, output_data), requires_grad = <span class="keyword">False</span>)models = torch.nn.Sequential(torch.nn.Linear(input_data, hidden_layer),torch.nn.ReLU(),torch.nn.Linear(hidden_layer, output_data))epoch_n = <span class="number">10000</span>learning_rate = <span class="number">1e-4</span>loss_fn = torch.nn.MSELoss()<span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch_n):    y_pred = models(x)    loss = loss_fn(y_pred, y)    <span class="keyword">if</span> epoch%<span class="number">1000</span> == <span class="number">0</span>:        print(<span class="string">"Epoch:{}, Loss:{:.4f}"</span>.format(epoch,loss.data))    models.zero_grad()    loss.backward()    <span class="keyword">for</span> param <span class="keyword">in</span> models.parameters():  <span class="comment"># 遍历模型中的全部参数w1、w2</span>        param.data -= param.grad.data*learning_rate</code></pre><h3 id="6-3-2-PyTorch之torch-optim"><a href="#6-3-2-PyTorch之torch-optim" class="headerlink" title="6.3.2 PyTorch之torch.optim"></a>6.3.2 PyTorch之torch.optim</h3></li><li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam" target="_blank" rel="noopener">torch.optim.Adam()</a></li></ul><blockquote><ol><li>optimzer = torch.optim.Adam(models.parameters(), lr = learning_rate)</li><li>optimzer.step()</li></ol></blockquote><pre><code>```pythonimport torchfrom torch.autograd import Variablebatch_n = 100hidden_layer = 100input_data = 1000output_data = 10x = Variable(torch.randn(batch_n, input_data), requires_grad = False)y = Variable(torch.randn(batch_n, output_data), requires_grad=False)models = torch.nn.Sequential(torch.nn.Linear(input_data, hidden_layer),torch.nn.ReLU(),torch.nn.Linear(hidden_layer, output_data))epoch_n = 10000learning_rate = 1e-4loss_fn = torch.nn.MSELoss()optimzer = torch.optim.Adam(models.parameters(), lr = learning_rate)for epoch in range(epoch_n):    y_pred = models(x)    loss = loss_fn(y_pred, y)    if epoch%1000 == 0:        print(&quot;Epoch:{}, Loss:{:.4f}&quot;.format(epoch,loss.data))    optimzer.zero_grad()    loss.backward()    optimzer.step()``` </code></pre><h3 id="6-4-1-torch和torchvision"><a href="#6-4-1-torch和torchvision" class="headerlink" title="6.4.1 torch和torchvision"></a>6.4.1 torch和torchvision</h3><ul><li><code>torchvision</code>的主要功能是实现数据的处理、导入和预览</li><li><a href="https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision-transforms" target="_blank" rel="noopener"><code>torchvision.transforms</code></a> 指定导入数据集时需要对数据进行变换操作类型<br>例如，数据增强（对图片大小进行缩放、对图片进行水平或者垂直翻转…）可生成新的数据集</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>深度学习之PyTorch实战计算机视觉</title>
    <link href="http://yoursite.com/2018/12/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8BPyTorch%E5%AE%9E%E6%88%98%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    <id>http://yoursite.com/2018/12/17/深度学习之PyTorch实战计算机视觉/</id>
    <published>2018-12-17T03:46:57.000Z</published>
    <updated>2019-01-15T13:51:07.537Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="第6章-PyTorch基础"><a href="#第6章-PyTorch基础" class="headerlink" title="第6章 PyTorch基础"></a>第6章 PyTorch基础</h4><ul><li><p><strong>Why PyTorch</strong></p><p>pytorch可以说是torch的python版，然后增加了很多新的特性。pytorch在编写模型的时候最大的特点就是利用autograd技术来实现<code>自动求导</code>，也就是不需要我们再去麻烦地写一些反向的计算函数，这点上继承了torch。<a href="https://oldpan.me/archives/pytorch-torch-relation" target="_blank" rel="noopener">浅谈Pytorch与Torch的关系</a></p></li><li><p><strong>pytorch document</strong></p><p>Link：<a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></p></li></ul><h4 id="第7章-迁移学习"><a href="#第7章-迁移学习" class="headerlink" title="第7章 迁移学习"></a>第7章 迁移学习</h4><p>如果我们用这么多资源训练的模型能够<code>解决同一类问题</code>，那么模型的性价比会提高很多，这就促使使用迁移模型解决同 一类问题的方法出现 。因为该方法的出现，我们通过对 一个训练好的模型进行细微调整，就能将其应用到相似的问题中，最后还能取得很好的效果 ; 另外，对于原始数据较少的问题，我们也能够通过采用迁移模型进行有效解决 ，所以，如果能够选取合适的迁移学习方法，则会对解决我们所面临的问题有很大的帮助 。</p><h4 id="第8章-图像风格迁移实战"><a href="#第8章-图像风格迁移实战" class="headerlink" title="第8章 图像风格迁移实战"></a>第8章 图像风格迁移实战</h4><center class="third"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/cat.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/2-style1.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/y-output.jpg" width="200"><br></center><h4 id="第9章-多模型融合"><a href="#第9章-多模型融合" class="headerlink" title="第9章 多模型融合"></a>第9章 多模型融合</h4><blockquote><p>“集百家之所长”  </p></blockquote><ul><li><p><strong>结果融合法</strong></p><p>通用理论：各个模型的输出结果的差异性越高 ， 多模型融合的效果就会越好 。</p><ul><li><p>结果多数表决</p></li><li><p>结果直接平均</p><p>融合各模型的平均预测水平，<code>弥补个别模型的明显劣势</code>，预防过拟合和欠拟合的发生</p><p>评价：虽然在总体的准确率上有所提升，但在单个数据的预测能力上并不优秀</p></li><li><p>结果加权平均</p><p>评价：调节各个模型的权重参数对最后的融合模型的结果影响较大。 所以在使用权重平均的过程中，我们需要<code>不断尝试</code>使用不同的权重值组合，以达到多模型融合的最优解决方案 。</p></li></ul></li></ul><h4 id="第10章-循环神经网络"><a href="#第10章-循环神经网络" class="headerlink" title="第10章 循环神经网络"></a>第10章 循环神经网络</h4><p>在循环神经网络中循环单元可以随意控制输入数据及输出数据的数量，具有非常大的灵活性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://deeplearning4j.org/images/guide/rnn_masking_2.png" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>循环神经网络的网络简化模型，通过不断地对自身的网络结构进行复制来构造不同的循环神经网络模型。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>将上图展开，</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWMAAACOCAMAAADTsZk7AAAAwFBMVEX///8AAAC65OLw8PDKysr5/fwdGBqKiIn5+fnh4eG95eSQ0c3M7eovtq3Hx8cAqJ7p6ekyLzDT0tMlISOGhIX19fXt7e3Z2dnk5OR9fX2UlJTr+Petra2hoaHCwsLZ8O5paWrk9PO0tLR1dXVdXV6QkJCwr7CmpqZZV1hISEgVDxEsKCm6ubpbWVpBPj85NjccHB6g2dNGREVQu7EVFRaH19Bxz8lZx8Bubm8OAAYkJCYLCw8ZEhSs4t6a3dgOraJVb5LtAAAQNklEQVR4nO1dDXeiPBbOLSyE2RkHQT5khGEUBIVqa7u71unu+///1SYIih1QSLTavjzndI6dGhIebu5HcnNBqEOHDh06dOjQoUOHDseA0whfewyfHLZvDvxrD+KTY6Yh66ET5EvCBAP1VtcexeeGmCA0jK49is8NAywtvvYgPjvEYXrtIXTowA1sifa1x/C50QuAYD5Qrz2Qz4sJzCJL0eQXuFmljNPhmKO55g6v6/z7MN1+EALwrjqSesSKAOzKLHLQZMjRezo1OFrTAZSkN56bfBe7ENwBQgvm52/+xigKmDs3AsHljM9gsv8sgMx3sQsh9hD+zWwtUsJvyH5jPukcuGTPA6v0m6zf5KLFsoc4YiTXR6ivsLY2CL/KhrlzCqdf/s3je2CXghxoQVmMhVb6UYGePGLuWwAj01UcGByoGhU0rqtdCmmmjN2cWnvVTiqtkUD+Vdi8JgyauuCb3fKy/JvGYb0vDu2hEICA4Z6NwGFjyvKz1TI3/9XrH/luNcZQnoQu3KQ+3kKVkUJgIszkJPAtekWBiSw6mwy/dVsT3NJv/TXXQC6LcUo81elIQxaTszvj6twlmkajgYTHsAY8hL1yC29UHW8RjnN97LK4ysrAOv2levjIcAdr10Su2L6x0U8KkiMIeYZxaaT53anOlEGjqe7p7xwBNbOZHMcCQ2tlCY6CkSAGwOeifGoMCccKecjahEGOiSTLAMlSguRml4SI2fjIzTPg1A1Ht6yK0YrL3zH41hvEM6nQm4zvdrCKtUE2jIA5lKbwk7N4tB7P2t/lMQQuz2vBtdalzs+z5uvfcvCBhER64fC8NJD6HCvA7surz956B/KouCbjhTEFfc4x0SZzHdi3UfBC0udcumYL50W65TSh2Vx/lVj80gzqnJDEHkl7IOlnWFfHfUl/uV2/QoOZdA/MeUwu3EszYNY1gT5LZnNuVZo9qtu1egNPAc3yGVtjXxFBSVklUVkbzhI5PFu2GVbL+yS4zeX5LRRgiq4K9Ph8t7D9cuYfsGUUSii9Yav38TkmkKWzXOZSuC7HcsfxaXRy3AAdx5dHx/Hl8WE5VgKfxB3ujG4QdBwfAY8cu3R/V3Tox1vkWBkOPYSiScjI8XQ4MJEpT9JrcqzRttud6FvkGI2oDCh0gGxyvKDBWdhjk2NTUDHCpinwcUxT5XrbpdGb5Nh+xggNsxwfJo6HZIoKdImAhWMRQsLx2lc4bd6zgvKszZvkmKaaWdlSEBvHXoyQQ1N0mHRFQHPkslnOxbHvjfLOb5JjtBDRdqucjWML8h1/Jo4dGaG0Rz9xcRz6RdLBbXK8jrTtXjmjXwEozPY/mDgWFwhvnzAXxykUC9+3ybE7zBdcGTneuNslSSaOFUDT7aIzF8fKLnfmNjkWC24YOfbzpFQmjjHY+ZrzO8R5gv9A1BKRKCUO3jd11ipSHBk5dvJWbP7xaplvtL5HLK090Oxvk5jas/TFgKvEeTtj9R4cE/uMIughiy8tjwNX4Xi3wfkeHJvEBxrfj5DDvDXMi4+7XlHCcZsH9hiHA8M5S1cs+BtwnKQuSlej622qFhzjiCkrquAYj5luIecYc07j4xzHMwNpcD0x3nEcikxmN+dYcBymDOstx7b8u8fSeofjHA9D6i5eqCyA0BOJdSFuki326rrIOVY2bKkkOcdjxtMuW44nFuI8QvaGYy2dTse94popnSUXE+PwgVz+nvwEtV0UcjwBptzAQo4Z83TkhP7LmWD7hmPvHgAk6QVgMeI88d4E9oamWxERntR+RfXzVKoJ05O2/O0EwWymc7p9NBGwNN5jsG/fW8LM1VSMTWsawPzy5bJswMiZpah36qwEXmhyOW2tpQ2yJoLPLjKeyHn6DIm7A8VDiEvZhcoE7i/tFQuArR4R0NP2yBuQ6aoWstj2FDOWaaWZlFGpakvaWslb28OmrAg+vPkqjuFNMCdCcobk28ef9X/DD7aDnKF9/Nx44XUJQXE6o/lpRGN/l0rrk0VC6aEYE1p7iX5qfEAlQNabrwZ/aiy1r/M7xo/ff9X/MXZSJC6OHGyxB3NiIVbbhDyf3CYBMcLNsnk1n1ZLCnK/y2wn/F5MGw93JxiJXTDpapzgN71CXNhZ01ZsynZYdfLBljgVEaIcf6+XZLoEaUG9GLugD8diFMDSyjboemEYOg0P5+IJLGTPc2bgZ8JstTGa9gpit5cOkuJwaKQhN4xdC1mNU22FRUayGFAxWcqCVR1neOz51QUen/5dTzKtx2T8rm0rQ678tCVYSBkWTnSj1PgYRtupmsKKGrwobW721HmyndVGmHt9so2wIpMLpk0LYmjIpuMcQOJqljcA8GqKE61feV24x6cv/6lVF5khqc1z9/YP3ljMibXJ1dvUb2An5L3us4CGIKMW4rLYK8loO83uibFSibaxZ02XICdLmQxzXVg54R5qgkW1LMg/dvj19e6///vXv//z9O0k/nr6Qkg+Yvjq0S/Jq9IyoLfLFnzc8sT9tPz9yQsVMwafhArCqKQIY6nGugUl3ffjxz9y/Pj18+uXu/8+Pv7zNB7v7lqQ7EW7iSMeMDM5vQRmyHv5dqTyBFyeDvNGJdduVlb49unid6pct0tUrotlVp/f8Ubr324U5XpwRzEh+cevXz9/fv365TTu7lqRLCVFKQTnILryGgS0LtwXTM388h8Gycm2GJZO3oP5eqBz9foodHd98CsVwWFdrEHlqdWsVCQUmu2Q44ziu4YokSwchZHC/CXOJGe4KA9Fo1KNjzc2F3Poh5lEzA9kxoXTHbswnweZc6Ucak76uE50rCRz8oj+NF1N6mL55+K4RHIfjkPX9VegBzOHBwPUqEhEJ9pKui4Rj5jcbHLgDTsv1LSc7ngOdBXzjXagHDuNOv5DIx3WxbIrzcL5OL77UrhwmngU0VyCrboYHZwyHr0QIVB7xxuvJDIJxrSZf+Dfrcm94uNNNWf+CsuQqgsjObCv1EW2j3fs9aWXfBIcQH4zFavU3Rk5vrv7/lTRwx+IIR5tnWLlIDiZNQg8eiAVS0fT8v2YTZySPlHm+Wxf66X/9xo4JSPQnSr+pm/qYlU5wufk+Nu3f5y+UZSu93cUSHtBnjY4gW/Eo10DPC/tmwwb7DK4wz1JWtnxWy4qvn0INa5ZbzIPYrilX/Wd89m8u78aSfGbEa6KB9+DtltN3t5tclpHq4P9SXaf/Swwos713qtzqidEGgWS67r5995y/LOFHP/11ESK30CDJJu+qgxx6yAggljLwkif4Vz5Gob0prG35CsNLSRJQfK0dhhl+S5xvHWQG/nHX5gpJir5HvQgmEGVPlUVZSvlilItab0ElkGwAP0tS8SAkRsn6sMSvbpHF73ALAgSmP0he1hRtlrFoFX9TsGWwKXf0gKoc7O1shosx9JZKE0i5e+n8NcTO8WIrpb5/jCqWha3nicGEsjAtd81ooZ7su/LFarSD+jWCvlZ1u9AGePh2q9aRMUDqj0GNjLWfoPNZDwEeNGJZ1h7YHpVLspJePoj0DuJfz0x6eIGGBDDJBNvQ2ldWInWnXZ+G8hk2km1ge7gEPb9ZvpLTeVBVn9PcaqeSY2aboPHJw4pzlB3J84EYX9joMGxzZ/Kxt4M4ZA4d+GpuV7dNQnXnEWK7Na7uDPwvbfum3eG2nqP375xUlwnbEQaXQFU46gYu1Vuq7VBkZFo+JQtVKpZBMsch4MGu5A75MSm8ArJYWXKMdw3v0wdHr/zUVwTHRGIK+SiZ/t4vuO86glgUF3kj6JT6tSp3vN/tiIcBbiFGBcu9kLSpTnsX/VAlLXf/Cq1ePzGeYFJnc9jPhB6g+jorfagqi4WhlBF4foUSXhZHfjE7og8YLf5rr1YLDKReHC+2nnMwkh6u0/9BlktV7W0QiUWfruRf+jRq33lk2JiXfSakj4CHaB8vIhM8Frp327oyaWTi6UpSJUTOVwayGizZ+CDn3+aS5NXiB1P00SXBNH+ifhmQ2eauHf6esvioReF8v1zFKBzieNT7fYYD4TekX+ssf2qv1YFiPc2PX9xquvgtbr0mNMyCdCePxR7V06CjGkePc/ck+c/+rQTbW+Q3F3AaueLkpNzcNwnKqxmxYDOIfXoOJ0XXa8SVzp0fMqpUEDXX6qk1TLzzhtCnuvF8paxnRiGqjbKqig4Nmdun4T3IUCAxM1zgDOOxeeHYcViX2v0IJESVg8S96UkYfaNZEgSSedP+zMkSZ8Xq4btji7tOH6wSFiOqRyrgOl7TwjHKjE1yuYMHPuRBrZ7erenEqmPE1lbstGEl5qs4zV36THkQvzKWGWu4FiNqcAIyHG36uLBIBy7dI6dQ1cIWWInY7oSaaYPWLPgDZzltPJnSgWKCELENJuSzOYdcJy9U3JpEY6zV5+sz1J0VeNKMdd5oqhznQ8lHLNliWd5ZAN3y/Ey43hMbwiorkhp1kjHcQ6PLUGdrnuNevISI5Woc7zJOEbJ1L53qe+GF5EdnuetfJ+AY/YccVv2XTIDjBE9dYSRKJLPjk94FYhaFuS1qHEd+yrwt+b4nfBROXZXgYUUf+Z1HB8DnxxnwU92CvpjcCwuiDxgZ9M6VZdwrM0WRIGFSftDO5RjYb1xiNe/mLR14swsPSSiRMvz1l2/L7ZyHGfstq/JTeV4TWUJMxzRy+R4+7oxubWfnGZbSLKAbrVGSAlbjrOjKUr7jHPK8QO1vSbDqz4ybpxsabX9rpSbNQl317llZByr2cRL2zsqlOPsIYkMx3EzbmY0mq7djKlHTNsJ8u46t4yMY2s7Ydu3JhxbmcWp3HQ6gYybzHQp7ctwUyOAxplUDM9TPuByyDiOMm3qt29NOE6zpVGWLWjKsZo9oVH7JZ1wRUIIP/vo8x9duiwyjukbdkuFppqDckyNj8Diw1GO7YxjlqIDk80s7/RjcGyRGSuwvMyUcGyDhXD7XC6U64oN8fkGfBHrx+AYeYv7xodoy6A2r7eIJ0zrmxnH5v0s4FwU8Nv7nO+LDxvn7REz7jG8GzqOL4+O48uj4/jy+AQcH6tscBP4+Bzj5dXKPDZEx/Hl0XF8efBxLHFx/MrReA/cv3WOLYmH4xlPcTrnPK8hNY9UmulwJlhXK7vboUOHDucEVwYw5m/PDXyey1wIRhCj4ZJjgCmoWoOKAZVQYIoXZ3gvdO9BVftnSf27CGx14/Acu0eWM2H2TS1tdpY3b/ecgWzcsCAzluTdw37maPx8npei2HDLDJMYgnObJvrNzpPycJ4Xb/cuVQj9HMDaQACLQ5VZ6Th0GMtZ2posrkQuTZVB1VzZqa3hcHVYDxpyfIzMPE7CTsvNy2CAlKV2pNzkEbgzjGjhx6KtMmA7GjLzm5Thuzri4u5ktg3ilEOpq+QZG1mO0Yb9IjcrxTsoi+J8ns8W+Acu+026EzU//3/rSRJcILc4dl2XzDfGvLEhhxxlhY99V0HaFd+ScnmkRbkag/H1ZzxvTaNTJ0sCG9++TuWAm8shdiZsAvnM4R3Eoy3HZvz3WAQ2GJceeExO0Razdt6hQ4cOHa6C/wPwKzj/NKrpoAAAAABJRU5ErkJggg==" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>虽然循环神经网络已经能够很好地对输入的序列数据进行处理 ，是不能进行长期记忆，其带来的影响就是如果近期输入的数据发生了变化，则会对当前的输出结果产生重大影响 。 为了避免这种情况的出现，研究者开发了 LSTM ( Long Short Term Memory)类型 的循环神经网络模型 。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn lstm" title="">                </div>                <div class="image-caption">Image result for rnn lstm</div>            </figure><h4 id="第11章-自动编码器"><a href="#第11章-自动编码器" class="headerlink" title="第11章 自动编码器"></a>第11章 自动编码器</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for autoEncoder" title="">                </div>                <div class="image-caption">Image result for autoEncoder</div>            </figure><p>自动编码器模型的最大用途就是实现输入数据的清洗，比如去除输入数据中的噪声数据、对输入数据的某些关键特征进行增强和放大，等等 。 举一个比较简单的例子，假设我们现在有一些被打上了马赛克的图片需要进行除码处理，这时就可以通过自动编码器模型来解决这个 问题 。 其实可以将这个除码的过程看作对数据进行除噪的过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch_Package_Introductions</title>
    <link href="http://yoursite.com/2018/12/15/PyTorch-Package/"/>
    <id>http://yoursite.com/2018/12/15/PyTorch-Package/</id>
    <published>2018-12-15T12:22:24.000Z</published>
    <updated>2019-01-15T13:49:28.212Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><h4 id="torch-Tensor-view"><a href="#torch-Tensor-view" class="headerlink" title="torch.Tensor.view"></a>torch.Tensor.view</h4><p><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view" target="_blank" rel="noopener"><code>view</code>(*<em>shape</em>) → Tensor</a> Returns a new tensor with the same data as the <code>self</code> tensor but of a different <code>shape</code>.</p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.view(<span class="number">16</span>)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred(推导) from other dimensions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>])  <span class="comment"># 2 = (4*4)/8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=x.view(<span class="number">2</span>,<span class="number">-1</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>]) <span class="comment"># 8 = (4*4)/2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=x.view(<span class="number">4</span>,<span class="number">-1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>]) <span class="comment"># 4 = (4*4)/4</span></span><br></pre></td></tr></table></figure><ul><li><strong>Parameters:</strong> <strong>shape</strong> (<em>torch.Size</em> <em>or</em> <em>int…</em>) – the desired size</li></ul><h4 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h4><p><a href="https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops" target="_blank" rel="noopener">Docs</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)  <span class="comment"># dim:0 按列级联(排成一列)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">1</span>)  <span class="comment"># dim:1 按行级联(排成一行)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>,</span><br><span class="line">         <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>,</span><br><span class="line">         <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br></pre></td></tr></table></figure><h2 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h2><h3 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h3><h4 id="torch-nn-Module"><a href="#torch-nn-Module" class="headerlink" title="torch.nn.Module"></a>torch.nn.Module</h4><h5 id="forward-input"><a href="#forward-input" class="headerlink" title="forward(*input)"></a>forward(*<em>input</em>)</h5><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward" target="_blank" rel="noopener"><code>forward</code>(*<em>input</em>)</a>  Defines the computation performed at every call.</p><h4 id="torch-nn-Sequential"><a href="#torch-nn-Sequential" class="headerlink" title="torch.nn.Sequential"></a>torch.nn.Sequential</h4><p><a href="https://pytorch.org/docs/stable/nn.html#sequential" target="_blank" rel="noopener">torch.nn.Sequential</a> 类是 torch.nn 中的一种序列容器，通过在容器中嵌套各种实现神经网络中具体功能相关的类，来完成对神 经网络模型 的搭建，最主要的是，<code>参数会按照我们定义好的序列自动传递下去</code>。我们可以将嵌套在容器中的各个部分看作各种不同的模块，这些模块可以自由组合。模块的加入 一般有两种方式 ， 一种是<strong>直接嵌套</strong>，另 一 种是以 <strong>orderdict</strong> 有序字典的方式进行传入，这两种方式的唯一区别是，使用后者搭建的模型的每个模块都有我们自定义的名字 ， 而前者默认使用从零开始的数字序列作为每个模块的名字。</p><h3 id="Convolution-Layers"><a href="#Convolution-Layers" class="headerlink" title="Convolution Layers"></a>Convolution Layers</h3><center><br>    <img src="/2018/12/15/PyTorch-Package/channel.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/SimpleCNN.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/LinearSize.png" width="600"><br></center><p><a href="https://www.youtube.com/watch?v=LgFNRIFxuUo" target="_blank" rel="noopener">PyTorch Lecture 10: Basic CNN</a></p><h4 id="torch-nn-Conv1d"><a href="#torch-nn-Conv1d" class="headerlink" title="torch.nn.Conv1d"></a>torch.nn.Conv1d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv1d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv1d(<span class="number">16</span>,  , <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">24</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$ (N, C_{\text{in}}, L)$  —  $\text{input.size :} (20, 16, 50)$</li><li><p>$ (N, C_{\text{out}}, L_{\text{out}})$ — $\text{output.size :} (20,  33, 24)$ </p><ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation}<br>\times (\text{kernel_size} - 1) - 1}{\text{stride}} + 1\right\rfloor \Rightarrow  24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size)}$.</p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) –the learnable bias of the module of shape $\text{(out_channels)}$.</li></ul><h4 id="torch-nn-Conv2d"><a href="#torch-nn-Conv2d" class="headerlink" title="torch.nn.Conv2d"></a>torch.nn.Conv2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnconv2din95channels-out95channels-kernel95size-stride1-padding0-dilation1-groups1-biastrue" target="_blank" rel="noopener">文档说明</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding and dilation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">26</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, H_{in}, W_{in})$  — $\text{input.size :} (20, 16, 50, 100)$</li><li>$(N, C_{out}, H_{out}, W_{out})$ — $\text{output.size :} (20, 33, 26, 100)$<ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor  \Rightarrow 26  = \left\lfloor\frac{50  + 2 \times 4- 3<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 100 =  \left\lfloor\frac{100  + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size[0], kernel_size[1])}$.</li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h4 id="torch-nn-Conv3d"><a href="#torch-nn-Conv3d" class="headerlink" title="torch.nn.Conv3d"></a>torch.nn.Conv3d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv3d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">8</span>, <span class="number">50</span>, <span class="number">99</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, D_{in}, H_{in}, W_{in})$  — $\text{input.size :}20, 16, 10, 50, 100)$</li><li><p>$(N, C_{out}, D_{out}, H_{out}, W_{out})$  — $\text{output.size :} (20, 33, 8, 50, 99)$ </p><ul><li>$H_{out} = \left\lfloor\frac{H{in} + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \<br>\Rightarrow 50 =  \left\lfloor\frac{50 + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li><li>$D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor \\Rightarrow 8 =  \left\lfloor\frac{10 + 2 \times 4 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2]<br>\times (\text{kernel_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor \\Rightarrow 99 = \left\lfloor\frac{100 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape$\text{ (out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2])}$ </p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h3 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h3><h4 id="torch-nn-MaxPool2d"><a href="#torch-nn-MaxPool2d" class="headerlink" title="torch.nn.MaxPool2d"></a>torch.nn.MaxPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#maxpool2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnmaxpool2dkernel95size-stridenone-padding0-dilation1-return95indicesfalse-ceil95modefalse" target="_blank" rel="noopener">文档说明</a></p><p>Applies a 2D max pooling over an input signal composed of several input planes.</p><p>In the simplest case, the output value of the layer with input size$(N, C, H, W)​$, output $(N, C, H_{out}, W_{out})​$ and <code>kernel_size</code> $(kH, kW)​$can be precisely described as:</p><p>$\begin{aligned}<br>out(N_i, C_j, h, w) ={} &amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \text{input}(N_i, C_j, \text{stride[0]} \times h + m,<br>\text{stride[1]} \times w + n)<br>\end{aligned}$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li><p>$(N, C, H_{in}, W_{in})$ — $\text{input.size:}(20, 16, 50, 32) $</p></li><li><p>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</p></li><li><p>$H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]}<br>\times (\text{kernel_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor \\Rightarrow 24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor $</p></li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]}<br>\times (\text{kernel_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor \ \Rightarrow 31 = \left\lfloor\frac{32 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul><h4 id="torch-nn-AvgPool2d"><a href="#torch-nn-AvgPool2d" class="headerlink" title="torch.nn.AvgPool2d"></a>torch.nn.AvgPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#avgpool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C, H_{in}, W_{in})$ — $\text{input.size: } (20, 16, 50, 32)$</li><li>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] -<br>\text{kernel_size}[0]}{\text{stride}[0]} + 1\right\rfloor \Rightarrow 24 = \left\lfloor\frac{50  + 2 \times 0 -<br>3}{2} + 1\right\rfloor$</li><li><p>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] -<br>\text{kernel_size}[1]}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 31 = \left\lfloor\frac{32  + 2 \times 0 -<br>2}{1} + 1\right\rfloor$</p></li><li><p><strong><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#dropout-layers" target="_blank" rel="noopener">torch.nn.Dropout</a></strong> torch.nn.Dropout 类用于防止卷积神经网络在训练的过程中发生过拟合 ， 其工作原理简单来说就是在模型训练的过程中，以一定的随机概率将卷积神经网络模型的部分参数归零(“丢弃”)， 以达到减少相邻两层神经连接的目的。</p></li></ul><h3 id="Non-Linear-Activations"><a href="#Non-Linear-Activations" class="headerlink" title="Non-Linear Activations"></a>Non-Linear Activations</h3><h4 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h4><p><a href="https://pytorch.org/docs/stable/nn.html#relu" target="_blank" rel="noopener">Docs</a></p><center><br>    <img src="https://pytorch.org/docs/stable/_images/ReLU.png" width="400"><br></center><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.ReLU()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">-0.5070</span>, <span class="number">0.4540</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.0000</span>, <span class="number">0.4540</span>])</span><br></pre></td></tr></table></figure><ul><li>Input:$(N, <em>)$ where </em> means, any number of additional dimensions</li><li>Output: $(N, *)$, same shape as the input</li></ul><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><h4 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h4><p><a href="https://pytorch.org/docs/stable/nn.html#linear" target="_blank" rel="noopener">Docs</a></p><p>Applies a linear transformation to the incoming data: $y = xA^T + b$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Linear(<span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">128</span>, <span class="number">20</span>)  <span class="comment"># (N,∗,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(output.size())</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">30</span>])   <span class="comment"># (N,∗,out_features)</span></span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[<span class="number">-0.8833</span>,  <span class="number">0.1130</span>,  <span class="number">0.0446</span>,  ..., <span class="number">-0.2786</span>,  <span class="number">2.0762</span>,  <span class="number">0.6139</span>],</span><br><span class="line">        [<span class="number">-0.9236</span>,  <span class="number">3.1720</span>, <span class="number">-0.9857</span>,  ...,  <span class="number">0.1017</span>, <span class="number">-0.4042</span>, <span class="number">-0.1072</span>],</span><br><span class="line">        [ <span class="number">0.0153</span>,  <span class="number">0.8800</span>, <span class="number">-0.6031</span>,  ..., <span class="number">-0.2836</span>,  <span class="number">0.7584</span>, <span class="number">-2.3324</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.9628</span>, <span class="number">-0.3177</span>, <span class="number">-0.7577</span>,  ...,  <span class="number">0.2819</span>,  <span class="number">0.9684</span>, <span class="number">-1.8474</span>],</span><br><span class="line">        [ <span class="number">0.3380</span>,  <span class="number">1.0946</span>, <span class="number">-1.3399</span>,  ..., <span class="number">-0.0043</span>, <span class="number">-0.9811</span>,  <span class="number">0.3067</span>],</span><br><span class="line">        [ <span class="number">0.6834</span>,  <span class="number">0.5804</span>, <span class="number">-0.8192</span>,  ...,  <span class="number">1.2167</span>,  <span class="number">1.3583</span>, <span class="number">-1.5123</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">1.0747</span>,  <span class="number">1.2864</span>,  <span class="number">0.6512</span>,  ...,  <span class="number">0.1053</span>, <span class="number">-0.0487</span>, <span class="number">-0.1705</span>],</span><br><span class="line">        [ <span class="number">0.2707</span>, <span class="number">-0.7018</span>, <span class="number">-0.4553</span>,  ..., <span class="number">-0.2100</span>, <span class="number">-0.3003</span>,  <span class="number">1.0038</span>],</span><br><span class="line">        [ <span class="number">0.1943</span>, <span class="number">-0.3070</span>, <span class="number">-0.3651</span>,  ...,  <span class="number">1.1940</span>, <span class="number">-0.2991</span>,  <span class="number">0.0455</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.4118</span>, <span class="number">-0.3984</span>,  <span class="number">0.2089</span>,  ...,  <span class="number">0.7984</span>, <span class="number">-0.6598</span>,  <span class="number">0.2150</span>],</span><br><span class="line">        [<span class="number">-0.1639</span>, <span class="number">-1.5081</span>, <span class="number">-0.4011</span>,  ...,  <span class="number">0.9673</span>,  <span class="number">0.3524</span>,  <span class="number">0.0993</span>],</span><br><span class="line">        [ <span class="number">0.5961</span>, <span class="number">-0.4150</span>, <span class="number">-0.1207</span>,  ...,  <span class="number">0.3189</span>, <span class="number">-0.0829</span>,  <span class="number">0.5195</span>]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">30</span>, <span class="number">20</span>])  <span class="comment"># (out_features,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">30</span>])   <span class="comment">#  (out_features)</span></span><br></pre></td></tr></table></figure><h3 id="NormalizationLayers"><a href="#NormalizationLayers" class="headerlink" title="NormalizationLayers"></a>NormalizationLayers</h3><p><a href="https://www.youtube.com/watch?v=NGO0oxdz-zs" target="_blank" rel="noopener">Batch Normalization 批标准化 (PyTorch tutorial 神经网络 教学)</a> </p><p><a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)_Morvan</a>让数值保持在激活函数的有效区间，可避免梯度消失。Batch Normalization (BN) 就被添加在每一个全连接和激励函数之间.</p><p><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">深度学习中 Batch Normalization为什么效果好？</a> </p><h4 id="BatchNorm2d"><a href="#BatchNorm2d" class="headerlink" title="BatchNorm2d"></a>BatchNorm2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#batchnorm2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>])  <span class="comment">#  (same shape as input）</span></span><br></pre></td></tr></table></figure><h3 id="Dropout-Layers"><a href="#Dropout-Layers" class="headerlink" title="Dropout Layers"></a>Dropout Layers</h3><h4 id="torch-nn-Dropout"><a href="#torch-nn-Dropout" class="headerlink" title="torch.nn.Dropout"></a>torch.nn.Dropout</h4><p><a href="https://pytorch.org/docs/stable/nn.html#dropout" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])  <span class="comment">#  Output is of the same shape as input</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[ <span class="number">1.7224</span>,  <span class="number">1.3201</span>, <span class="number">-0.8480</span>],</span><br><span class="line">        [ <span class="number">1.8960</span>, <span class="number">-0.1245</span>,  <span class="number">0.6991</span>],</span><br><span class="line">        [ <span class="number">1.1756</span>,  <span class="number">0.2378</span>,  <span class="number">1.4059</span>],</span><br><span class="line">        [ <span class="number">0.2427</span>,  <span class="number">0.2278</span>, <span class="number">-0.7612</span>],</span><br><span class="line">        [<span class="number">-0.8882</span>,  <span class="number">0.2088</span>,  <span class="number">1.5004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">2.1530</span>,  <span class="number">1.6501</span>, <span class="number">-1.0601</span>],</span><br><span class="line">        [ <span class="number">2.3700</span>, <span class="number">-0.1556</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">1.4694</span>,  <span class="number">0.2972</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.3034</span>,  <span class="number">0.0000</span>, <span class="number">-0.9515</span>],</span><br><span class="line">        [<span class="number">-0.0000</span>,  <span class="number">0.2610</span>,  <span class="number">1.8755</span>]])</span><br></pre></td></tr></table></figure><h3 id="torch-nn-init"><a href="#torch-nn-init" class="headerlink" title="torch.nn.init"></a>torch.nn.init</h3><h4 id="torch-nn-init-kaiming-uniform"><a href="#torch-nn-init-kaiming-uniform" class="headerlink" title="torch.nn.init.kaiming_uniform_"></a>torch.nn.init.kaiming_uniform_</h4><p><a href="https://pytorch.org/docs/stable/nn.html?highlight=nn.init#torch.nn.init.kaiming_normal_" target="_blank" rel="noopener">Docs</a></p><h2 id="torch-nn-functional"><a href="#torch-nn-functional" class="headerlink" title="torch.nn.functional"></a>torch.nn.functional</h2><h3 id="Pooling-functions"><a href="#Pooling-functions" class="headerlink" title="Pooling functions"></a>Pooling functions</h3><h4 id="adaptive-avg-pool2d"><a href="#adaptive-avg-pool2d" class="headerlink" title="adaptive_avg_pool2d"></a>adaptive_avg_pool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#adaptive-avg-pool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 5x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d((<span class="number">5</span>,<span class="number">7</span>))  <span class="comment"># output_size – (H, W) </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 7x7 (square)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d(<span class="number">7</span>)  <span class="comment"># a single H for a square image H x H</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 10x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool2d((<span class="keyword">None</span>, <span class="number">7</span>))  <span class="comment"># None, which means the size will be the same as that of the input.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">7</span>])</span><br></pre></td></tr></table></figure><h4 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h4><ul><li><p><strong>torchvision.transforms.Resize:</strong>用于对载入的图片数据按我们需求的大小进行缩放。 传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列， 其中 ， h 代表高度， w 代表宽度，但是如果使用的是 一 个整型数据，那么表示缩放的宽度和高度都是这个整型数据的值 。 </p></li><li><p><strong>torchvision.transforms.Scale</strong>: 用于对载入的图片数据按我 们 需求的大小进 行缩 放，用法和 torchvision.transforms.Resize类似。 </p></li><li><p><strong>torchvision.transforms.CenterCrop:</strong>用 于对载入的图片以图片中心为参考点 ， 按我们需要的大小进行裁剪 。传递给这个类 的参数可以是一个整型数据 ，也可以 是一个类似 于( h,w)的序列 。 </p></li><li><p><strong>torchvision.transforms.RandomCrop:</strong> 用于对载入的图片按我们需要的大小进行随机裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列。 </p></li><li><p><strong>torchvision.transforms.RandomHorizontaIFlip:</strong> 用于对载入的图片按随机概率进行水平翻转。我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则使用 默认的概率值 0.5。</p></li><li><p><strong>torchvision.transforms.RandomVerticalFlip:</strong> 用于对载入的图片按随机概率进行垂直翻转。 我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则 使用默 认的概率值 0.5。 </p></li><li><p><strong>torchvision.transforms.ToTensor:</strong> 用于对载入的图片数据进行类型转换 ， 将之前构成 PIL 图片的数据转换成 Tensor数据类型的变量 ，让 PyTorch 能够对其进行计算和处理。 </p></li><li><p><strong>torchvision.transforms.ToPILlmage:</strong> 用于将 Tensor变量的数据转换成 PIL 图片数据， 主要是为了方便图片内容的显示。</p></li></ul><h2 id="torch-utils-model-zoo"><a href="#torch-utils-model-zoo" class="headerlink" title="torch.utils.model_zoo"></a>torch.utils.model_zoo</h2><p><a href="https://pytorch.org/docs/stable/model_zoo.html#module-torch.utils.model_zoo" target="_blank" rel="noopener">torch.utils.model_zoo.load_url</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>state_dict = torch.utils.model_zoo.load_url(<span class="string">'https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>白话深度学习与TensorFlow_笔记</title>
    <link href="http://yoursite.com/2018/12/12/%E7%99%BD%E8%AF%9D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8ETensorFlow-%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/12/12/白话深度学习与TensorFlow-笔记/</id>
    <published>2018-12-12T09:32:42.000Z</published>
    <updated>2018-12-17T06:24:01.592Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读说明】这本书适合零基础的初学者</p><a id="more"></a><h4 id="第5章-手写板功能"><a href="#第5章-手写板功能" class="headerlink" title="第5章 手写板功能"></a>第5章 手写板功能</h4><ul><li><p>手写识别</p><p>Github Link：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p><p>文件目录：<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist</a></p></li></ul><h4 id="第6章-卷积神经网络"><a href="#第6章-卷积神经网络" class="headerlink" title="第6章 卷积神经网络"></a>第6章 卷积神经网络</h4><ul><li><p><strong>卷积</strong></p><center><br><img src="https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-59-29-pm.png?w=748" style="zoom:80%"><br></center></li><li><p><strong>卷积核</strong> </p><center><br>    <img src="https://www.oreilly.com/library/view/neural-networks-with/9781788397872/assets/2009c470-759a-4fb7-a1a3-982c4bae841c.png" style="zoom:30%"><br></center></li></ul><ul><li><p><strong>池化层 Pooling Layer</strong></p><blockquote><p>池化层的作用实际上对 Feature Map 所做的数据处理又进行了一次所谓的池化处理。常见的池化层处理有两种方式:一种叫 Max Pooling，一种叫 Mean Pooling (也叫 Average Pooling)</p></blockquote><center><br>    <img src="https://i.stack.imgur.com/bhXRN.png" style="zoom:60%"><br></center></li></ul><h4 id="第7章-综合问题"><a href="#第7章-综合问题" class="headerlink" title="第7章 综合问题"></a>第7章 综合问题</h4><ul><li><p><strong>ReLU 函数 Activation Function</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/ReLU.png"><br></center><p><strong>优点：</strong></p><p>其一 ，在第一象限中<code>不会有明显的梯度消失问题</code>，因为导数恒为 1，而 w 在初始化的 时候也是有大有小，连乘的时候不会轻易出现很小或者很大的数值，这就是一个非常好的 特性了 。 </p><p>其二，由于导数为 1，所以求解它的导数要比求解 Sigmoid 函数的导数<code>时间代价要小</code> 一些.</p><blockquote><p>因而现在的工程人员在近几年的网络中都喜欢大量使用 ReLU 函数 。 在笔者的工程经验中也是至少 80% 以上的工程都是倾向于优先使用 ReLU 函数作为激励函数的 。 </p></blockquote></li><li><p><strong>归一化 normalization</strong></p><blockquote><p>统一“单位”，让模型对各参数数值变化的敏感程度保持一致，“没有偏见”</p></blockquote></li><li><p><strong>正则化 regulization</strong></p><blockquote><p>防止过拟合，提高泛化能力</p></blockquote></li><li><p><strong>超参数 hyper parameter</strong></p><blockquote><p>不能通过算法学习到的参数，例如 K-Means 算法中的簇数 N，还有就是像在深度学习中涉及的学习率 $\eta $</p></blockquote></li><li><p><strong>Dropout</strong></p><blockquote><p>在一轮训练阶段丢弃一部分网络节点 。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</span><br></pre></td></tr></table></figure></li></ul><h4 id="第8章-循环神经网络"><a href="#第8章-循环神经网络" class="headerlink" title="第8章 循环神经网络"></a>第8章 循环神经网络</h4><ul><li><p><strong><a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">隐马尔可夫模型</a></strong></p><center><br>    <img src="data:image/png;base64,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"><br></center></li></ul><blockquote><p>马尔可夫链的核心是说，在给定当前知识或信息的情况下，观察对象过去的历史状态对于<br>将来的预测来说预测是无关的 。 也可以说，在观察一个系统变化的时候，它下一个状态(第<br>n+l个状态)如何的概率只需要观察和统计<code>当前状态</code>(第n个状态)即可以正确得出。</p></blockquote><ul><li><p><strong>RNN 和 BPTT 算法</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/BPTT.png" style="zoom:50%"><br></center></li><li><p><strong>LSTM算法</strong></p><center><br>    <img src="data:image/png;base64,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" style="zoom:150%"><br></center></li><li><p><strong>聊天机器人</strong></p><p>Github链接：<a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener">https://github.com/Conchylicultor/DeepQA</a></p><p>issue:</p><ul><li><p>OK <a href="https://github.com/Conchylicultor/DeepQA/issues/68" target="_blank" rel="noopener">Error about BasicLSTMCell </a></p></li><li><p>After using Nicholas C.’s pre-trained model ,<code>still not work</code>.</p><p>To resolve  <a href="https://github.com/Conchylicultor/DeepQA/issues/149" target="_blank" rel="noopener">WARNING: Restoring previous model</a></p><ul><li><p>I think the pretrained model is not work</p></li><li><p><a href="https://mcastedu-my.sharepoint.com/personal/nicholas_cutajar_a100636_mcast_edu_mt/Documents/Forms/All.aspx?slrid=ba91ab9e-d04d-7000-6ce2-3d1610bc6c24&amp;FolderCTID=0x012000ACF25C8BFBFE2F4A85CE16FF1E3C2BBC&amp;id=%2Fpersonal%2Fnicholas_cutajar_a100636_mcast_edu_mt%2FDocuments%2FDeepQA%20-%20Pre%20Trained%20Models" target="_blank" rel="noopener">N C</a></p></li></ul></li></ul></li></ul><h4 id="第9章-深度残差网络"><a href="#第9章-深度残差网络" class="headerlink" title="第9章 深度残差网络"></a>第9章 深度残差网络</h4><p>Github Link：</p><p><a href="https://github.com/ry/tensorflow-resnet" target="_blank" rel="noopener">https://github.com/ry/tensorflow-resnet</a></p><p><a href="https://github.com/raghakot/keras-resnet" target="_blank" rel="noopener">https://github.com/raghakot/keras-resnet</a></p><p><a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">https://github.com/KaimingHe/deep-residual-networks</a></p><h4 id="第10章-受限玻尔兹曼机"><a href="#第10章-受限玻尔兹曼机" class="headerlink" title="第10章 受限玻尔兹曼机"></a>第10章 受限玻尔兹曼机</h4><p><a href="https://github.com/meownoid/tensorfow-rbm" target="_blank" rel="noopener">https://github.com/meownoid/tensorfow-rbm</a>  解码器(autodecoder)</p><p><a href="https://github.com/Cospel/rbm-ae-tf" target="_blank" rel="noopener">https://github.com/Cospel/rbm-ae-tf</a> 降维工具</p><h4 id="第11章-强化学习"><a href="#第11章-强化学习" class="headerlink" title="第11章 强化学习"></a>第11章 强化学习</h4><ul><li><p><strong><a href="http://gym.openai.com/" target="_blank" rel="noopener">OpenAI Gym</a></strong></p><p>Github Link：<a href="https://github.com/openai/gym" target="_blank" rel="noopener">https://github.com/openai/gym</a></p></li><li><p><strong>Playing Atari with Deep Reinforcement Learning</strong></p><p>Github Link：<a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" target="_blank" rel="noopener">https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner</a></p></li></ul><h4 id="第12章-对抗学习"><a href="#第12章-对抗学习" class="headerlink" title="第12章 对抗学习"></a>第12章 对抗学习</h4><ul><li><p><strong>DCGAN</strong></p><p>Github Link：<a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">https://github.com/carpedm20/DCGAN-tensorflow</a></p></li></ul><h4 id="第13章-有趣的深度学习应用"><a href="#第13章-有趣的深度学习应用" class="headerlink" title="第13章 有趣的深度学习应用"></a>第13章 有趣的深度学习应用</h4><ul><li><p>人脸识别</p><p>GIthub link：<a href="https://github.com/davidsandberg/facenet" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet</a></p><p>LFW datasets: <a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p></li><li><p>作诗姬</p><p>Github link：<a href="https://github.com/XingxingZhang/rnnpg" target="_blank" rel="noopener">https://github.com/XingxingZhang/rnnpg</a></p></li><li><p>VGG</p><p>Github link：<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python neural_style.py --content &lt;content file&gt; --styles &lt;style file&gt; --output &lt;output file&gt;</span><br><span class="line"></span><br><span class="line">Example:</span><br><span class="line">python neural_style.py –content examples/cat.jpg –styles examples/2-style1.jpg –output y-output.jpg</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(tensorflow) ➜  neural-style-master python neural_style.py --content examples/cat.jpg --styles examples/2-style1.jpg --output y-output.jpg --network imagenet-vgg-verydeep-19.mat</span><br><span class="line">Optimization started...</span><br><span class="line">Iteration    1/1000</span><br><span class="line">Iteration    2/1000 (16 sec elapsed, 4 hr 26 min remaining)</span><br><span class="line">Iteration    3/1000 (30 sec elapsed, 4 hr 10 min remaining)</span><br><span class="line">Iteration    4/1000 (43 sec elapsed, 4 hr 0 min remaining)</span><br><span class="line">Iteration    5/1000 (55 sec elapsed, 3 hr 50 min remaining)</span><br><span class="line">...</span><br><span class="line">Iteration  999/1000 (3 hr 22 min elapsed, 24 sec remaining)</span><br><span class="line">Iteration 1000/1000 (3 hr 23 min elapsed, 12 sec remaining)</span><br><span class="line">content loss: 796114</span><br><span class="line">  style loss: 234885</span><br><span class="line">     tv loss: 44175.5</span><br><span class="line">  total loss: 1.07517e+06</span><br></pre></td></tr></table></figure><center class="third"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/cat.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/2-style1.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/y-output.jpg" width="200"><br></center></li></ul><h4 id="Other-Concepts"><a href="#Other-Concepts" class="headerlink" title="Other Concepts"></a>Other Concepts</h4><ul><li><p><strong>VC维 Vapnik-Chervonenkis Dimension</strong></p><blockquote><p>H的VC维表示为VC(H) ，指能够被H分散的最大集合的大小。若H能分散任意大小的集合，那么VC(H)为无穷大。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读说明】这本书适合零基础的初学者&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>软件过程与项目管理</title>
    <link href="http://yoursite.com/2018/12/10/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2018/12/10/软件过程与项目管理/</id>
    <published>2018-12-10T11:02:40.000Z</published>
    <updated>2019-01-16T08:23:21.777Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><h3 id="Introduction-to-Project-Management"><a href="#Introduction-to-Project-Management" class="headerlink" title="Introduction to Project Management"></a>Introduction to Project Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-c0568a46ba885ed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="The-Project-Management-and-Information-Technology-Context"><a href="#The-Project-Management-and-Information-Technology-Context" class="headerlink" title="The Project Management and Information Technology Context"></a>The Project Management and Information Technology Context</h3><h3 id="The-Project-Management-Process-Groups"><a href="#The-Project-Management-Process-Groups" class="headerlink" title="The Project Management Process Groups"></a>The Project Management Process Groups</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Initiating processes - 启动过程</span><br><span class="line">Planning processes - 计划过程</span><br><span class="line">Executing processes - 执行过程组</span><br><span class="line">Monitoring and controlling processes- 监控过程</span><br><span class="line">Closing processes -闭合过程</span><br></pre></td></tr></table></figure><h3 id="Project-Integration-Management"><a href="#Project-Integration-Management" class="headerlink" title="Project Integration Management"></a>Project Integration Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-0ea7fa98a3c3eb4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Scope-Management"><a href="#Project-Scope-Management" class="headerlink" title="Project Scope Management"></a>Project Scope Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a0e80e3077f6b3c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Schedule-Management"><a href="#Project-Schedule-Management" class="headerlink" title="Project Schedule Management"></a>Project Schedule Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-34622539853a259b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Cost-Management"><a href="#Project-Cost-Management" class="headerlink" title="Project Cost Management"></a>Project Cost Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-cc09a65d92af001a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="630"><br></center><center><br>        <img src="https://upload-images.jianshu.io/upload_images/5267500-0170a5c22ef465af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="Project-Quality-Management"><a href="#Project-Quality-Management" class="headerlink" title="Project Quality Management"></a>Project Quality Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-6ee33da505abded3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Resource-Management"><a href="#Project-Resource-Management" class="headerlink" title="Project Resource Management"></a>Project Resource Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-7374cb810a56778a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Communications-Management"><a href="#Project-Communications-Management" class="headerlink" title="Project Communications Management"></a>Project Communications Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-e1777f730d2a1f31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Risk-Management"><a href="#Project-Risk-Management" class="headerlink" title="Project Risk Management"></a>Project Risk Management</h3><h4 id="processes"><a href="#processes" class="headerlink" title="processes"></a>processes</h4><ol><li><p><strong>Planning risk management:</strong> deciding how to approach and plan the risk management activities for the project 决定如何处理和规划项目的风险管理活动</p><ul><li>The project team should review project documents as well as corporate risk management <code>policies</code>, <code>risk categories</code>,<code>lessons-learned</code> reports from past projects, and<code>templates</code> for creating a risk management plan</li></ul></li><li><p><strong>Identifying risks</strong>: determining which risks are likely to affect a project and documenting the characteristics of each 确定哪些风险可能影响项目并记录每个风险的特征</p><ul><li>tools and techniques <ul><li>Brainstorming</li><li>The Delphi Technique: 专家小组；匿名输入；书面答复</li><li>Interviewing</li><li>SWOT analysis: Strengths,weaknesses, opportunities, and threats</li></ul></li><li>Output<ul><li>Risk Register </li></ul></li></ul></li><li><p><strong>Performing qualitative risk analysis</strong>: prioritizing risks based on their probability and impact of occurrence 根据风险的概率和发生的影响确定风险的优先级</p><ul><li>tools and techniques <ul><li>Probability/impact matrixes</li><li>The Top Ten Risk Item Tracking</li><li>Expert judgment</li></ul></li></ul></li><li><p><strong>Performing quantitative risk analysis</strong>: numerically estimating the effects of risks on project objectives 数字估算风险对项目目标的影响</p><ul><li>Main techniques <ul><li>Decision tree analysis 决策树分析  EMV(Expected Monetary Value )</li><li>Simulation 模拟   <strong>Monte Carlo analysis</strong></li><li>Sensitivity analysis 敏感性分析</li></ul></li></ul></li><li><p><strong>Planning risk responses</strong>: taking steps to enhance opportunities and reduce threats to meeting project objectives  采取措施增加机会并减少对实现项目目标的威胁</p><ul><li><p>Negative</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-401c059f77196a16.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="500"><br></center></li><li><p>Positive</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-d40395b0292ca1c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="300"><br></center></li></ul></li><li><p><strong>Implementing risk responses</strong>: implementing the risk response plans  实施风险应对计划</p></li><li><p><strong>Monitoring risk</strong>: monitoring identified and residual risks, identifying new risks, carrying out risk response plans, and evaluating the effectiveness of risk strategies throughout the life of the project 监控已识别和剩余风险，识别新风险，执行风险应对计划，并在项目的整个生命周期内评估风险策略的有效性</p></li></ol><ul><li>Main output of this process is a <code>risk management plan</code></li></ul><h3 id="PROJECT-PROCUREMENT-MANAGEMENT"><a href="#PROJECT-PROCUREMENT-MANAGEMENT" class="headerlink" title="PROJECT PROCUREMENT MANAGEMENT"></a>PROJECT PROCUREMENT MANAGEMENT</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-141f7fc025e82374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h4 id="Types-of-outsourcing"><a href="#Types-of-outsourcing" class="headerlink" title="Types of outsourcing"></a>Types of outsourcing</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Local outsourcing</span><br><span class="line">- Offshore outsourcing</span><br><span class="line">- Nearshore outsourcing</span><br></pre></td></tr></table></figure><h4 id="Types-of-Contracts"><a href="#Types-of-Contracts" class="headerlink" title="Types of Contracts"></a>Types of Contracts</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 'Fixed price' or lump sum contracts: involve a fixed total price for a well-defined product or service   #卖家不利</span><br><span class="line">- `Point of Total Assumption` (PTA): cost at which the contractor assumes total responsibility for each additional dollar of contract cost</span><br><span class="line">- 'Fixed Price' / Lump Sum / Firm Fixed Price : Risk is on the seller</span><br><span class="line">- Fixed Price with Economic Price Adjustment Contracts ('FP-EPA'): 旨在保护买方和卖方免受其无法控制的外部条件的影响。 如`通货膨胀变化`，或成本增加。</span><br><span class="line">- Fixed Price Incentive Fee ('FPIF') 固定价格激励: 根据卖家表现支付额外奖励，例如更快/更便宜/更好,比如 项目早期每月完成一次，向卖方支付额外的10,000美元</span><br><span class="line">- Fixed Price Award Fee ('FPAF')固定价格奖励: 买方根据业绩支付固定价格和奖励金额（奖金）</span><br><span class="line"></span><br><span class="line">- 'Cost-reimbursable' contracts: involve payment to the seller for direct and indirect costs   #买家不利</span><br><span class="line">- Cost plus incentive fee, cost plus fixed fee, and cost plus percentage of costs</span><br><span class="line">- Cost + Fee (CPF)/ Cost Plus Percentage of Costs ('CPPC') :涉及向卖方支付已完成工作所产生的`所有合法实际费用`，以及费用的百分比。</span><br><span class="line">- Cost Plus Fixed Fee.('CPFF'). 成本加固定费用</span><br><span class="line">- Cost Plus Incentive Fee ('CPIF'). 成本加奖励</span><br><span class="line">- Cost Plus Award Fee ('CPAF'). 成本加奖励费</span><br><span class="line"></span><br><span class="line">- 'Time and material' contracts: hybrid of both fixed price and cost reimbursable contracts  用于在授予合同时`无法确定工作量`的服务工作 例如: 合同=每天1美元加上每线性木材5美元的材料</span><br><span class="line"></span><br><span class="line">- 'Unit price' contracts: require the buyer to pay the seller a predetermined amount per unit of service</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-91e6cc7316e81548.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ContractRisk.png" title="">                </div>                <div class="image-caption">ContractRisk.png</div>            </figure><h3 id="PROJECT-STAKEHOLDER-MANAGEMENT"><a href="#PROJECT-STAKEHOLDER-MANAGEMENT" class="headerlink" title="PROJECT STAKEHOLDER MANAGEMENT"></a>PROJECT STAKEHOLDER MANAGEMENT</h3><h4 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h4><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-f52bfa58c3aa23aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><ol><li><p><strong>Identifying stakeholders</strong>: identifying everyone involved in the project or affected by it, and determining the best ways to manage relationships with them.</p><ul><li><p>output: <code>stakeholder register</code> includes basic information on stakeholders</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a78cfe957aaaa2b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width=""><br></center><ul><li><p><strong>Identification information</strong>: stakeholders’ names, positions, locations, roles in the project, and contact information</p></li><li><p><strong>Assessment information</strong>: stakeholders’ major requirements and expectations, potential influences, and phases of the project in which stakeholders have the most interest</p></li><li><p><strong>Stakeholder classification</strong>: is the stakeholder internal or external to the organization? Is the stakeholder a supporter of the project or resistant to it?</p></li></ul></li></ul></li><li><p><strong>Planning stakeholder management</strong>: determining strategies to effectively engage stakeholders in project decisions and activities based on their needs, interests, and potential impact.</p><ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Managing stakeholder engagement:</strong> communicating and working with project stakeholders to satisfy their needs and expectations, resolving issues, and fostering engagement in project decisions and activities<ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Monitoring stakeholder engagement</strong>:monitoring stakeholder relationships and adjusting plans and strategies for engaging stakeholders as needed<ul><li>Outputs: <code>work performance information</code>, <code>change requests</code>, <code>project management plan updates</code>, and <code>project documents updates</code>.</li></ul></li></ol><h2 id="Exam"><a href="#Exam" class="headerlink" title="Exam"></a>Exam</h2><h3 id="考后说明"><a href="#考后说明" class="headerlink" title="考后说明"></a>考后说明</h3><ul><li><strong>True or False</strong>： 只要理解<a href="#知识点啊~朋友们">知识点</a>部分的内容，就够了，不必去记忆。考卷的”False”很明显</li><li><strong>Single choice</strong>：刷一遍题库，对题目有印象就行。考试都是原题，选项次序都不变</li><li><strong>Fill in the blanks</strong>：刷一遍题库，考试都是原题</li><li><strong>Writing</strong>：still 背题库，<strong>默写</strong>式答题</li></ul><blockquote><p><strong>Summary：</strong> 此门课程难点还是 前期完成的项目本身  笔试部分则是”记到便是赚到“  (2018.12.10)</p></blockquote><h3 id="知识点啊-朋友们"><a href="#知识点啊-朋友们" class="headerlink" title="知识点啊~朋友们"></a>知识点啊~朋友们</h3><h4 id="项目管理简介"><a href="#项目管理简介" class="headerlink" title="项目管理简介"></a>项目管理简介</h4><p>1.<code>项目</code>与运营不同，因为它们在达到目标或项目终止时<code>结束</code>。<br>2.使用<code>渐进式细化</code>开发项目。项目通常在开始时被广泛定义，随着时间的推移，项目的具体细节变得更加清晰。因此，应该<code>逐步开发</code>项目。</p><p>3.一个项目涉及<code>不确定性</code>。每个项目都是独一无二的，因此有时很难明确定义目标，估计完成所需的时间，或确定需要多少费用。这种不确定性是项目管理如此具有挑战性的主要原因之一。<br>4.管理<code>三重约束</code>涉及在项目的范围，时间和成本目标之间进行权衡。经验丰富的项目经理知道必须决定三重约束的哪个方面最重要。<br>5.<code>利益相关者</code>是参与或受项目活动影响的人，包括项目发起人，项目团队，支持人员，客户，用户，供应商，甚至是项目的反对者。<br>6.<code>项目管理知识领域</code>描述了项目经理必须发展的关键能力。<code>项目采购管理</code>涉及从执行组织外部为项目获取或采购商品和服务。<br>7.<code>项目经理</code>不仅<code>负责</code>项目成果的交付。他们是<code>负责</code>这些项目开发的产品和流程成功的变革推动者。</p><p>8.<code>IT项目经理</code>必须愿意发展不仅仅是他们的<code>技术技能</code>，才能成为富有成效的团队成员和成功的项目经理。每个人，无论他们多么技术，都应该培养<code>商业和软技能</code>。</p><h4 id="项目管理和信息技术背景"><a href="#项目管理和信息技术背景" class="headerlink" title="项目管理和信息技术背景"></a>项目管理和信息技术背景</h4><p>1.使用<code>系统方法</code>对于成功的项目管理至关重要。如果高层管理人员和项目经理要了解项目与整个组织的关系，他们必须<code>遵循</code>系统理念。<br>2.矩阵组织的<code>项目经理</code>有来自<code>各个职能领域的工作人员</code>从事项目工作。<br>3.<code>组织文化</code>非常强大，许多人认为许多公司问题的根本原因不在于组织结构或员工;他们在文化中。<br>4.在围绕团体或团队而不是个人组织工作活动的组织中，项目工作最为成功。强调团队工作的<code>组织文化</code>最适合管理项目。<br>5.在项目生命周期的<code>早期阶段</code>，资源需求通常最低，不确定性水平最高。在<code>后期阶段</code>对项目进行重大改变要昂贵得多。<br>6.由于组织通常会在项目<code>持续时投入更多资金</code>，因此应在每个阶段之后进行<code>管理评审</code>，以评估进度，潜在成功以及与组织目标的持续兼容性。<br>7.<code>虚拟团队</code>是一群使用通信技术在时间和空间边界上一起工作的人。团队成员可能都在同一个国家的同一家公司工作，或者他们可能包括员工以及独立顾问，供应商，甚至志愿者，他们提供来自全球的专业知识。</p><h4 id="项目管理流程组"><a href="#项目管理流程组" class="headerlink" title="项目管理流程组"></a>项目管理流程组</h4><p>1.<code>启动流程</code>包括定义和授权项目或项目阶段。启动过程在项目的<code>每个阶段</code>进行。<br>2.<code>启动和关闭任务通常是最短的</code>（分别在项目或阶段的开始和结束时），并且它们需要最少的资源和时间。<br>3.<code>监控和控制流程</code>与所有其他项目管理流程组<code>重叠</code>，因为可以随时进行更改。<br>4.<code>敏捷</code>是一种适应性产品生命周期，当可交付成果具有<code>高度变化</code>和<code>高交付频率</code>时使用。<br>5.六西格玛项目使用两种主要方法：<code>DMAIC</code>（定义，测量，分析，改进和控制）用于改进现有业务流程，并使用<code>DMADV</code>（定义，测量，分析，设计和验证）创建新产品或流程设计，以实现可预测的，无缺陷的性能。<br>6.<code>启动会议</code>是在项目开始时举行的会议，以便利益相关者可以相互见面，审查项目的目标，并讨论未来的计划。启动会议通常在<code>业务案例和项目章程完成后</code>举行，但可以根据需要提前举行。</p><p>7.<code>WBS</code>是项目管理中非常重要的工具，因为它为决定如何开展工作提供了基础。 WBS还为<code>创建项目进度表</code>和<code>执行挣值管理</code>提供了基础，用于<code>衡量和预测项目绩效</code>。<br>8.因为<code>Scrum</code>暗示团队成员是由ScrumMaster指导的<code>自我导向组</code>，所以<code>团队合同不是必需的</code>。<br>9.燃尽图表(<code>burndown chart</code>)显示了每天冲刺中<code>剩余的累积工作量</code>。<br>10.<code>冲刺审查</code>是团队向产品所有者展示冲刺期间<code>完成的内容</code>的会议。</p><p>11.Scrum框架中<code>监控和控制</code>的两个主要项目是<code>每日Scrum</code>和<code>冲刺审查</code>。<br>12.<code>结账流程</code>包括正式接受项目或项目阶段并有效结束。作为阶段或项目的一部分，<code>管理活动</code>（例如归档项目文件，结束合同，记录经验教训以及接受正式接受交付的工作）通常涉及此流程组。</p><h4 id="项目集成管理"><a href="#项目集成管理" class="headerlink" title="项目集成管理"></a>项目集成管理</h4><p>1.<code>界面管理</code>涉及识别和管理项目各个元素之间的<code>交互点</code>。<br>2.<code>项目集成管理包括界面管理</code>，涉及识别和管理项目各个元素之间的交互点。随着项目涉及的人数增加，<code>接口数量可能呈指数级增长</code>。<br>3.有些人喜欢使用<code>思维导图</code>进行SWOT分析，这种技术使用从核心思想辐射出来的分支来构建思想和想法。<br>4.许多信息系统被归类为<code>“战略性”</code>，因为它们直接支持<code>关键业务战略</code>。例如，信息系统可以帮助组织支持作为低成本生产者的战略。<br>5.随着项目的进展，组织必须<code>重新评估</code>每个项目的需求，资金和意愿，以确定是否应该继续，重新定义或终止项目。<br>6.由于要求和期望不明确，许多项目都失败了，所以从<code>项目章程</code>开始就很有意义。<br>7.<code>项目管理计划</code>不仅仅是甘特图。</p><h4 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a><a href="#第5章 - 项目范围管理">项目范围管理</a></h4><p>1.<code>范围基准</code>包括已批准的项目范围声明及其关联的WBS和WBS字典。</p><p>2.<code>WBS的主要目的</code>是定义完成项目所需的所有工作。<br>3.<code>工作包</code>是WBS最低级别的任务。它表示项目经理监视和控制的工作级别。<br>4.创建一个好的WBS非常<code>困难</code>。为此，您必须了解项目及其范围，并纳入利益相关方的需求和知识。<br>5.执行任务executing task在项目之间<code>变化最大</code>，但其他项目管理过程组下的许多任务对于所有项目都是类似的。<br>6.创建一个好的WBS及其WBS字典的基本原则是，<code>一个工作单元应该只出现在WBS中的一个地方</code>。<br>7.即使项目范围相当明确，许多IT项目仍然存在<code>范围蔓延</code> - 项目范围越来越大的趋势。许多IT项目因范围蔓延而失败。</p><h4 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a><a href="#第6章 - 项目进度管理">项目进度管理</a></h4><p>1.<code>活动或任务</code>是通常在工作分解结构（WBS）上找到的工作要素，其具有预期的持续时间，成本和资源要求。<br>2.在项目进度管理中，定义活动的<code>主要输出</code>是活动列表，活动属性，里程碑列表和项目管理计划更新。<br>3.<code>项目进度表</code>从发起项目的基本文件中发展而来。<code>项目章程</code>经常提到计划的项目开始和结束日期，作为更详细的计划的起点。<br>4.<code>时间表管理计划</code>包括有关报告格式的信息。此信息描述了项目所需的计划报告的格式和频率。此外，它还包括有关流程描述的信息，并描述了如何执行所有计划管理流程。<br>5.项目的<code>里程碑</code>是一个重要事件，通常<code>没有持续时间</code>。通常需要多次活动和大量工作来完成里程碑，但里程碑本身就像是帮助识别必要活动的<code>标记</code>。<br>6.<code>依赖关系</code>或关系涉及项目活动或任务的<code>顺序</code>。确定活动之间的这些关系或依赖关系对于开发和管理项目进度表具有重大影响。<br>7.<code>网络图</code>是显示<code>活动排序</code>的首选技术。网络图是项目活动及其排序之间逻辑关系的示意图。<br>8.网络图是项目活动及其排序之间逻辑关系的示意图。网络图中的箭头表示活动顺序或任务之间的关系。<br>9.当两个或多个节点在单个节点之前时发生<code>合并</code>。另一方面，当两个或多个活动跟随单个节点时发生<code>突发</code>。<br>10.<code>甘特图</code>提供了一种标准格式，用于通过以日历形式列出项目活动及其相应的开始和结束日期来显示项目进度信息。在甘特图中，黑色菱形符号代表了一个里程碑<br>11.<code>跟踪甘特图</code>基于项目任务完成的工作百分比或实际开始和结束日期。它允许项目经理<code>监控</code>各个任务和整个项目的进度。<br>12.在<code>关键路径分析</code>中，几个任务在项目上并行完成，大多数项目通过网络图有多条路径。包含关键任务的最长路径或路径是驱动项目完成日期的原因。<br>13.<code>crashing</code>的主要优点是缩短了完成项目所需的时间。主要缺点是它通常会增加项目总成本。<br>14.<code>关键链调度</code>是一种在创建项目计划时考虑有限资源的方法，并包含用于保护项目完成日期的<code>缓冲区</code>。它假设资源不是多任务或至少最小化多任务处理。</p><h4 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a><a href="#第7章 - 项目成本管理">项目成本管理</a></h4><p>1.<code>超支</code>是实际成本超过估计值的额外百分比或金额。<br>2.<code>现金流量分析</code>是确定项目的估计年度成本和收益以及由此产生的年度现金流量的一种方法。项目经理必须进行现金流量分析以<code>确定净现值</code>。<br>3.<code>沉没成本</code>是过去花费的钱。在决定投资或继续投资哪些项目时，不应包括沉没成本。<br>4.<code>管理储备</code>允许未来<code>不可预测</code>的情况。例如，如果项目经理生病了两周或者一个重要的供应商停业，可以留出管理储备来支付由此产生的费用。<br>5.<code>估算</code>通常在项目的<code>不同阶段进行</code>，随着时间的推移应该变得更加准确。<br>6.<code>类似的估计</code>需要大量的专家判断，并且通常比其他技术成本更低。但是，它也不太准确。<br>7.项目<code>成本估算不准确</code>的原因之一是<code>人类偏向于低估</code>。因此，项目经理和高层管理人员必须审核估算并提出重要问题，以确保估算不会有偏差<br>8.方差和指数的公式以<code>EV</code>（赢得值）开头。通过从EV中减去实际成本或计划值来计算差异，并且通过将EV除以实际成本或计划值来计算指数。<br>9.如果<code>CPI</code>小于1或小于100％，则该项目超出预算。另一方面，如果CPI大于1％或超过100％，则项目预算可控。</p><h4 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a><a href="#第8章 - 项目质量管理">项目质量管理</a></h4><p>1.<code>实验设计</code>是一种有助于确定哪些变量对过程总体结果影响最大的技术。您还可以将实验设计应用于<code>项目管理问题</code>，例如成本和进度权衡。<br>2.<code>可靠性</code>是指产品或服务在正常条件下按<strong>预期</strong>运行的能力。<br>3.所有项目利益相关方必须<strong>共同努力</strong>，以<code>平衡项目</code>的质量，范围，时间和成本方面。但是，<code>项目经理最终负责</code>其项目的质量管理。<br>4.<code>接受决定确定</code>作为项目一部分生产的产品或服务是否将被接受或拒绝。如果他们被接受，他们被认为是<strong>经过验证的可交付成果</strong>。<br>5.<code>运行图表</code>显示过程随时间变化的<strong>历史和模式</strong>。它是一个折线图，显示按发生顺序绘制的数据点。<br>6.<code>测试</code>需要在系统开发生命周期的几乎<code>每个阶段进行</code>，而不仅仅是在组织发布或将产品交给客户之前。<br>7.在全面质量控制中，产品质量比生产率更重要，工人可以在<code>出现质量问题时停止生产</code>。<br>8.符合要求意味着项目的流程和产品<code>符合书面规范</code>。例如，如果项目范围声明要求交付100台具有特定处理器和内存的计算机，则可以轻松检查是否已交付合适的计算机。</p><h4 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a><a href="#第9章 - 项目资源管理">项目人力资源管理</a></h4><p>1.<code>马斯洛的需求层次</code>表明人们的行为受到一系列需求的<code>指导或激励</code>。<br>2.根据赫兹伯格的说法，<code>激励者</code>，如更高的工资，更多的监督，或更有吸引力的工作环境，将激励工人做更多的工作。他提到导致工作满意度的因素作为激励因素和可能导致不满意的因素作为卫生因素。<br>3.需要制度权力或社会<code>权力的人</code>希望组织其他人来推进组织的目标。<br>4.相信<code>X理论</code>的人认为工人在可能的情况下不喜欢和避免工作，因此管理者必须使用<strong>强制，威胁和各种控制方案</strong>让工人做出足够的努力来实现目标。他们认为普通工人希望被指导并且更愿意避免责任，没有什么野心，并且希望安全高于一切。</p><p>5.Thamhain和Wilemon发现，当项目经理过于依赖权力，金钱或惩罚来影响人们时，项目更有可能失败。当项目经理使用<code>工作挑战和专业知识来影响人们</code>时，项目更有可能成功。<br>6.<code>合法的权力</code>使人们根据权威的地位做事。这种权力类似于权威的影响基础。<br>7.如OBS中所述，责任分配矩阵（<code>RAM</code>）将WBS中描述的项目工作映射到负责执行工作的人员。<br>8.<code>资源调配</code>可以减少项目人员和会计部门的问题。劳动力水平和人力资源的增加和减少往往会产生<code>额外的工作和混乱</code>。<br>9.<code>平滑模式</code>是项目经理强调或避免差异领域并强调协议领域的模式。这种方法也称为适应性，当关系具有高度重要性且任务不重要时，最好使用这种方法。</p><h4 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a><a href="#第10章 - 项目沟通管理">项目沟通管理</a></h4><p>1.举行会议的准则之一是确定是否可以<code>避免会议</code>。如果有更好的方法来实现手头的目标，就不要开会。<br>2.项目经理经常将所有<code>经验教训</code>报告中的信息合并到项目总结报告中。<br>3.提高组织的沟通能力需要组织中的<code>文化变革</code>，这需要花费大量时间，努力工作和耐心。<br>4.要使项目取得成功，每个项目团队成员都需要这<code>两种技能</code>，并需要通过正规教育和在职培训不断开发这些技能。<br>5.<code>地理位置和文化背景影响项目沟通的复杂性</code>。如果项目利益相关者在不同的国家，通常很难或不可能在正常工作时间内安排双向沟通的时间。<br>6.<strong>项目沟通管理</strong>涉及包含影响项目中开发的产品或服务的关键性能特征的<code>详细技术信息</code>。记录可能影响产品性能的<code>技术规范</code>的任何<strong>变更</strong>甚至更为重要。<br>7.沟通的一个重要方面是<code>参与项目的人数</code>。随着数量的增加，通信的复杂性也会增加，因为人们可以通过更多的渠道或途径进行交流。随着团队规模的增加，沟通变得更加复杂。</p><h4 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a><a href="第11章 - 项目风险管理">项目风险管理</a></h4><p>1.项目风险管理<code>涉及</code>了解项目可能出现的潜在问题以及它们如何阻碍项目成功。但是，也有积极的风险或机会，可以为项目带来良好的结果。<br>2.<code>寻求风险的人</code>更喜欢更不确定的结果，并且通常愿意支付惩罚来承担风险。<br>3.项目风险管理的第一步是通过<code>执行风险管理计划</code>来决定如何处理特定项目的知识领域。<br>4.<code>应急计划</code>是预定义的行动，如果发生已识别的风险事件，项目团队将采取这些行动。<br>5.<code>头脑风暴</code>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<code>德尔菲技术</code>是一种基于对未来事件的独立和匿名输入的系统化交互式预测程序。<br>6.项目经理可以绘制风险对<code>概率/影响矩阵或图表</code>的概率和影响，其中列出了风险发生的相对概率和风险发生的相对影响。<br>7.<code>十大风险项目跟踪</code>是一种定性风险分析工具。<br>8.已识别的风险可能<code>无法实现</code>，或者其发生或丧失的可能性可能会<code>减少</code>。</p><h4 id="项目采购管理"><a href="#项目采购管理" class="headerlink" title="项目采购管理"></a><a href="#第12章-项目采购管理">项目采购管理</a></h4><p>1.提供采购服务的组织或个人称为<code>供应商</code>。供应商也称为供应商，承包商，分包商或销售商。<br>2.在外包时，组织应谨慎保护可能在供应商手中易受攻击的<code>战略信息</code>。<br>3.计划采购涉及通过使用组织外部的产品或服务来确定最佳地满足哪些项目需求。如果不需要从组织外部购买产品或服务，则<code>不需要进一步的采购管理</code>。<br>4.成本可偿还合同通常包括费用，例如利润百分比或达到或超过选定项目目标的激励。与固定价格合同相比，买方通过<code>成本可偿还合同</code>承担更多风险。<br>5.<code>固定价格（FFP）</code>合约对买方的风险最小，其次是<code>固定价格激励费（FPIF）</code>合约。<br>6.制造或购买分析涉及估算提供产品或服务的内部成本，并将估算与外包成本进行<code>比较</code>。<br>7.如果公司使用设备20天，他们最好<code>租赁</code>，总费用为10,000美元（20 x 500美元）。 10,000美元的购买成本将增加2,000美元的运营成本（20 x 100美元）。<br>8.评估投标的关键因素，特别是涉及IT的项目，是投标人<code>过去的业绩记录</code>。检查性能记录和参考可以<code>降低</code>选择跟踪记录不佳的供应商的<code>风险</code>。<br>9.控制采购可确保卖方的<code>业绩符合合同要求</code>。合同关系是一种法律关系，这意味着它受州和联邦合同法的约束。</p><h4 id="项目利益相关者管理"><a href="#项目利益相关者管理" class="headerlink" title="项目利益相关者管理"></a>项目利益相关者管理</h4><p>1.与通信和人力资源管理相关的许多概念也<code>适用</code>于利益相关者管理，但需要开展<code>独特的活动</code>以实现良好的利益相关者管理。<br>2.<code>识别</code>利益相关者涉及识别参与项目或受其影响的每个人，并确定<code>管理</code>与他们之间关系的最佳方式。该过程的主要输出是<code>利益相关者登记</code>。<br>3.内部项目利益相关者通常<code>包括</code>项目发起人，项目团队，支持人员和项目的内部客户。其他内部利益相关者包括高层管理人员，其他职能经理和其他项目经理，因为组织资源有限。<br>4.由于员工流动，合作伙伴关系和其他事件，利益相关者可能在项目期间发生<code>变化</code>。<br>5.领先的利益相关者是了解项目及其潜在影响并积极参与<code>帮助项目成功</code>的人<br>6.项目经理必须了解并与各利益相关方合作;因此，他们应该专门讨论如何使用各种沟通方法及其人际关系和管理技能来<code>吸引利益相关者</code>。<br>7.您无法控制利益相关者，但您可以<code>监控干系人的参与程度</code>。参与涉及对话，人们寻求理解和解决共同关心的问题。<br>8.应邀请主要利益攸关方积极<code>参加启动会议</code>，而不仅仅是参加会议。项目经理应该强调，会议<code>期望进行对话</code>，包括利益相关者喜欢的文本或任何沟通方式。</p><h3 id="填空题"><a href="#填空题" class="headerlink" title="填空题"></a>填空题</h3><h4 id="第4章-项目集成管理"><a href="#第4章-项目集成管理" class="headerlink" title="第4章 - 项目集成管理"></a>第4章 - 项目集成管理</h4><ol><li>____涉及通过分析优势和劣势，研究机会和威胁，预测未来趋势以及预测新产品和服务的需求来确定长期目标。<br>答案：战略规划</li><li>____涉及分析公司的优势，劣势，机会和威胁，并用于协助战略规划。<br>答案：SWOT分析</li><li>____是一种技术，它使用从核心思想辐射出来的分支来构建思想和想法。<br>答案：思维导图</li><li>____指的是改善组织的机会。<br>答案：机遇</li><li>____是从效益中减去项目成本然后除以成本的结果。<br>答案：投资回报率（ROI）</li><li>____是一种工具，它提供了一个基于许多标准选择项目的系统过程。<br>答案：加权评分模型</li><li>____是记录的起点，测量或观察，以便可以用于将来的比较。变化。<br>答案：基线</li><li>____涉及在整个项目生命周期中识别，评估和管理变更。<br>答案：综合变更控制</li></ol><h4 id="第5章-项目范围管理"><a href="#第5章-项目范围管理" class="headerlink" title="第5章 - 项目范围管理"></a>第5章 - 项目范围管理</h4><ol><li>____创建涉及将主要项目可交付成果细分为更小，更易于管理的组件。<br>答案：工作分解结构（WBS）</li><li>____是指“项目必须满足的条件或能力，或者在产品，服务或结果中出现以满足协议或其他正式规定的条件或能力。”<br>答案：要求</li><li>____包括已批准的项目范围声明及其关联的WBS和WBS字典。<br>答案：范围基线</li><li>工作包是WBS的____级任务。<br>答案：最低</li><li>____在创建WBS的方法中，团队成员首先确定尽可能多的与项目相关的特定任务。<br>答案：自下而上</li><li>____是一种技术，它使用从核心思想中散发出来的分支来构建创建WBS时的思想和想法。<br>答案：思维导图</li><li>____是项目范围越来越大的趋势。<br>答案：范围蔓延</li><li>____执行范围验证的主要工具是和小组决策制定技术。<br>答案：检查</li><li>____涉及开发系统的工作副本或系统的某些方面。<br>答案：原型设计</li></ol><h4 id="第6章-项目进度管理"><a href="#第6章-项目进度管理" class="headerlink" title="第6章 - 项目进度管理"></a>第6章 - 项目进度管理</h4><ol><li>____是完成任务所需的工作日或工作小时数。<br>答案：努力</li><li>在项目进度表中，灵活性最小的变量是____。<br>答案：时间</li><li>____涉及确保及时完成项目所需的过程。<br>答案：项目进度管理</li><li>____是要列入项目进度表的活动的表格。<br>答案：活动清单</li><li>____是项目活动及其排序之间逻辑关系的示意图。<br>答案：网络图</li><li>在____关系中，“from”活动必须在“to”活动完成之前开始。<br>答案：从头到尾</li><li>____没有持续时间和资源，但偶尔需要在AOA网络图上显示活动之间的逻辑关系。<br>答案：虚拟活动</li></ol><h4 id="第7章-项目成本管理"><a href="#第7章-项目成本管理" class="headerlink" title="第7章 - 项目成本管理"></a>第7章 - 项目成本管理</h4><ol><li>____过程的主要成果是活动成本估算，估算基础和项目文件更新。<br>答案：成本估算</li><li>____流程的主要成果是成本绩效基准，项目资金要求和项目文件更新。<br>答案：成本预算</li><li>____理论指出，当重复生产许多物品时，随着生产更多单位，这些物品的单位成本会以规律的方式减少。<br>答案：学习曲线</li><li>____估算是在项目的早期阶段或甚至在项目正式启动之前完成的。<br>答案：粗略的数量级（ROM）</li><li>____是项目经理用来衡量和监控成本绩效的分阶段预算。<br>答案：成本基准</li></ol><h4 id="第8章-项目质量管理"><a href="#第8章-项目质量管理" class="headerlink" title="第8章 - 项目质量管理"></a>第8章 - 项目质量管理</h4><ol><li>____这个词意味着产品可以按照预期使用。<br>答案：适合使用</li><li>____是一种质量计划技术，有助于确定哪些变量对过程的总体结果影响最大。<br>答案：实验设计</li><li>____图表将有关质量问题的投诉追溯到负责任的生产操作。<br>答案：因果关系<br>鱼刺<br>石川</li><li>Watts S. Humphrey将____定义为在交付程序之前必须更改的任何内容。<br>答案：软件缺陷</li><li>____是一个公司部门的非监督人员和工作领导小组，他们自愿组织如何提高部门工作效率的小组研究。<br>答案：质量圈子</li><li>____意味着对失败负责或不满足质量期望。<br>答案：不合格的成本</li><li>Genichi Taguchi的____方法着重于通过用科学探究替代试错法来消除缺陷。<br>答案：稳健的设计</li></ol><h4 id="第9章-项目资源管理"><a href="#第9章-项目资源管理" class="headerlink" title="第9章 - 项目资源管理"></a>第9章 - 项目资源管理</h4><ol><li>根据马斯洛的说法，只有满足____需求后，个人才能满足增长需求。<br>答案：缺陷</li><li>赫茨伯格称之为导致工作满意度的因素____。<br>答案：激励者</li><li>____是整体等于其各部分之和的概念。<br>答案：协同作用</li><li>____正在倾听，意图理解。<br>答案：移情倾听</li><li>____是和谐，一致，一致或亲和的关系，对沟通很重要。<br>答案：交流</li><li>____根据所需的详细程度将工作分配给负责任和执行的组织，团队或个人。<br>答案：责任分配矩阵（RAM）</li><li>____是一种特定类型的组织结构图，显示哪些组织单位负责哪些工作项。<br>答案：OBS（组织分解结构）</li></ol><h4 id="第10章-项目沟通管理"><a href="#第10章-项目沟通管理" class="headerlink" title="第10章 - 项目沟通管理"></a>第10章 - 项目沟通管理</h4><ol><li><p>许多信息技术专业人员在<strong>_</strong>项目中工作，他们从未与项目赞助商，其他团队成员或其他项目利益相关者会面。<br>答案：虚拟</p></li><li><p>____分析包括信息的联系人，信息到期时以及信息的首选格式等信息。<br>答案：利益相关方沟通</p></li><li>在试图评估项目利益相关者的承诺时，<strong>_</strong>会议或网络会议可能是最合适的媒介。<br>答案：面对面</li><li>控制通信的主要目标是确保整个____的最佳信息流。<br>答案：项目生命周期</li><li>所有会议必须有____和预期结果。<br>答案：目的</li><li>____强制会议组织者计划会议，并让潜在参与者有机会决定是否需要参加。<br>答案：议程</li></ol><h4 id="第11章-项目风险管理"><a href="#第11章-项目风险管理" class="headerlink" title="第11章 - 项目风险管理"></a>第11章 - 项目风险管理</h4><ol><li>项目<strong>_</strong>是一种不确定性，可能对实现项目目标产生负面或正面影响。<br>答案：风险</li><li>是从潜在收益中获得的满足或愉悦的数量。<br>答案：风险效用</li><li>是项目潜在风险类别的等级。<br>答案：风险分解结构</li><li>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<br>答案：头脑风暴</li><li>是包含各种风险管理流程结果的文件。<br>答案：风险登记</li><li>是风险事件概率和风险事件货币价值的乘积。<br>答案：EMV<br>预期的货币价值<br>预期货币价值（EMV）<br>EMV（预期货币价值）</li><li>风险是在实施所有应对策略后仍然存在的风险。<br>答案：剩余</li></ol><h4 id="第12章-项目采购管理"><a href="#第12章-项目采购管理" class="headerlink" title="第12章-项目采购管理"></a>第12章-项目采购管理</h4><ol><li>____是指从外部来源获取商品和/或服务的过程。<br>答案：采购</li><li>____是一项具有相互约束力的协议，规定卖方有义务提供指定的产品或服务，并规定买方有义务支付这些产品或服务。<br>答案：合同</li><li>____决定是指组织决定在组织内部制造某些产品或执行某些服务是否符合其最佳利益，或者是否最好从外部组织购买。<br>答案：制造或购买</li><li>____合同包括由于通货膨胀等条件的变化而对合同价格进行预定义的最终调整的特殊规定。<br>答案：固定价格与经济价格调整（FP-EPA），固定价格与经济，价格调整，FP-EPA</li><li>____合同是固定价格和成本可偿还合同的混合体。<br>答案：时间和材料（T＆M），时间和材料，T＆M</li><li>____是允许买方或供应商终止合同的合同条款。<br>答案：终止条款</li><li>____是卖方在满足买方需求时采用不同方法编制的文件。<br>答案：提案</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="XD" scheme="http://yoursite.com/categories/XD/"/>
    
    
  </entry>
  
  <entry>
    <title>GoogLeNet</title>
    <link href="http://yoursite.com/2018/12/07/GoogLeNet/"/>
    <id>http://yoursite.com/2018/12/07/GoogLeNet/</id>
    <published>2018-12-07T02:44:09.000Z</published>
    <updated>2019-01-01T14:00:24.759Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】未完待续</p><a id="more"></a><p>参考链接：<a href="https://blog.csdn.net/shuzfan/article/details/50738394#googlenet-inception-v2" target="_blank" rel="noopener">GoogLeNet系列解读</a>、<a href="https://blog.csdn.net/qq_31531635/article/details/72232651" target="_blank" rel="noopener">深度学习之GoogLeNet解读</a>、<a href="https://www.jianshu.com/p/33197e469414" target="_blank" rel="noopener">GoogLeNet的心路历程</a></p><p>ToRead：<a href="https://blog.csdn.net/docrazy5351/article/details/78993269" target="_blank" rel="noopener">深入理解GoogLeNet结构</a></p><h2 id="GoogLeNet-Incepetion-V1"><a href="#GoogLeNet-Incepetion-V1" class="headerlink" title="GoogLeNet Incepetion V1"></a>GoogLeNet Incepetion <a href="https://www.jianshu.com/p/a2ad00eddbd5" target="_blank" rel="noopener">V1</a></h2><p>GoogLeNet, 一个22层的深度网络，2014年ILSVRC挑战赛冠军，将Top5 的错误率降低到6.67%。这是一种 类似于 <strong>网中网（Network In Network）</strong>的结构，即原来的结点也是一个网络。</p><p>这是GoogLeNet的最早版本，出现在2014年的《<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Going deeper with convolutions</a>》。之所以名为“GoogLeNet”而非“GoogleNet”,文章说是为了向早期的LeNet致敬。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>深度学习以及神经网络快速发展，人们不再只关注更给力的硬件、更大的数据集、更大的模型，而是更在意新的idea、新的算法以及模型的改进。</p><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生<strong>过拟合</strong>也会大大<strong>增加计算量</strong>。</p><p>文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献1表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。<strong>这点表明臃肿的稀疏网络可能被不失性能地简化。</strong> 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。</p><p>早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了<code>随机稀疏连接</code>。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。</p><p>所以，现在的问题是有没有一种方法，<strong>既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能</strong>。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。</p><h3 id="Architectural-Details"><a href="#Architectural-Details" class="headerlink" title="Architectural Details"></a>Architectural Details</h3><p>Inception 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。<br>作者首先提出下图这样的基本结构： </p><center><br>    <img src="/2018/12/07/GoogLeNet/V1_Figure2(a).jpg" style="zoom:60%"><br></center><p>对上图做以下说明：<br>1 . 采用不同大小的卷积核意味着不同大小的感受野，最后拼接<code>意味着不同尺度特征的融合</code>；<br>2 . 之所以卷积核大小采用1、3和5，主要是<code>为了方便对齐</code>。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以<code>直接拼接</code>在一起了；<br>3 . 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。<br>4 . 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p><p><strong>但是，使用5x5的卷积核仍然会带来巨大的计算量</strong>。 为此，文章借鉴NIN，采用<code>1x1卷积核来进行降维</code>。<br>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。<a href="https://blog.csdn.net/capecape/article/details/78296796#4维度计算" target="_blank" rel="noopener">详细的降维计算过程</a></p><p>具体改进后的Inception Module如下图： </p><center><br><img src="/2018/12/07/GoogLeNet/V1_Figure2(b).jpg" style="zoom:60%"><br></center><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p>GoogLeNet的整体结构如下图：</p><center><br><img src="/2018/12/07/GoogLeNet/GooLeNet.jpg" style="zoom:60%"><br></center><p>对上图做如下说明：<br>1 . 显然GoogLeNet采用了模块化的结构，方便增添和修改；<br>2 . 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；<br>3 . 虽然移除了全连接，但是网络中依然使用了Dropout ;<br>4 . 为了<code>避免梯度消失</code>，网络额外增加了2个辅助的softmax（average pooling）用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</p><p>下图是一个比较清晰的结构图：</p><center><br><img src="/2018/12/07/GoogLeNet/V1_Figure3.jpg" style="zoom:60%"><br></center><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>GoogLeNet是谷歌团队为了参加ILSVRC 2014比赛而精心准备的，为了达到最佳的性能，除了使用上述的网络结构外，还做了大量的辅助工作：包括训练多个model求平均、裁剪不同尺度的图像做多次验证等等。详细的这些可以参看文章的实验部分。</p><p>本文的主要想法其实是想通过<code>构建密集的块结构来近似最优的稀疏结构</code>，从而达到<code>提高性能而又不大量增加计算量</code>的目的。GoogleNet的caffemodel大小约50M，但性能却很优异。</p><h2 id="GoogLeNet-Inception-V2"><a href="#GoogLeNet-Inception-V2" class="headerlink" title="GoogLeNet Inception V2"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/4270f5acc066" target="_blank" rel="noopener">V2</a></h2><ul><li><a href="https://link.jianshu.com?t=http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>，top5 error 4.8%</li></ul><p>这篇文章做出的贡献不是一般的大，它提出了Batch Normalization（BN），以至于网上关于它的介绍铺天盖地，但中文优秀原创没几个，都是转载来转载去，挑几个好的比如：<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/u012816943/article/details/51691868" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="noopener"><strong>这个</strong></a>。</p><h2 id="GoogLeNet-Inception-v3"><a href="#GoogLeNet-Inception-v3" class="headerlink" title="GoogLeNet Inception v3"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/0cc42b8e6d25" target="_blank" rel="noopener">v3</a></h2><p>GoogLeNet凭借其优秀的表现，得到了很多研究人员的学习和使用，因此Google团队又对其进行了进一步发掘改进，产生了升级版本的GoogLeNet。这一节介绍的版本记为V2，文章为：《<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a>》。</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>14年以来，构建更深的网络逐渐成为主流，但是模型的变大也使计算效率越来越低。这里，文章试图找到一种方法在<strong>扩大网络的同时又尽可能地发挥计算性能</strong>。</p><p>首先，GoogLeNet V1出现的同期，性能与之接近的大概只有VGGNet了，并且二者在图像分类之外的很多领域都得到了成功的应用。但是相比之下，GoogLeNet的计算效率明显高于VGGNet，大约只有500万参数，只相当于Alexnet的1/12(GoogLeNet的caffemodel大约50M，VGGNet的caffemodel则要超过600M)。</p><p>GoogLeNet的表现很好，但是，如果想要通过简单地放大Inception结构来构建更大的网络，则会立即提高计算消耗。此外，在V1版本中，文章也没给出有关构建Inception结构注意事项的清晰描述。因此，在文章中作者<strong>首先给出了一些已经被证明有效的用于放大网络的通用准则和优化方法</strong>。这些准则和方法适用但不局限于Inception结构。</p><h3 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h3><p>下面的准则来源于大量的实验，因此包含一定的推测，但实际证明基本都是有效的。</p><p><strong>1 . 避免表达瓶颈，特别是在网络靠前的地方</strong>。 信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。<br>另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）</p><p><strong>2 . 高维特征更易处理</strong>。 高维特征更易区分，会加快训练。</p><p><strong>3. 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息</strong>。 比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。</p><p><strong>4 . 平衡网络的宽度与深度</strong>。</p><p>上述的这些并不能直接用来提高网络质量，而<code>仅用来在大环境下作指导</code>。</p><h3 id="Factorizing-Convolutions-with-Large-Filter-Size"><a href="#Factorizing-Convolutions-with-Large-Filter-Size" class="headerlink" title="Factorizing Convolutions with Large Filter Size"></a>Factorizing Convolutions with Large Filter Size</h3><p>大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。为此，作者提出可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量)如下图： </p><center><br><img src="/2018/12/07/GoogLeNet/V2_Figure1.jpg" style="zoom:80%"><br></center><p>然后就会有2个疑问：</p><p><strong>1 . 这种替代会造成表达能力的下降吗？</strong><br>后面有大量实验可以表明<code>不会造成表达缺失</code>；</p><p><strong>2 . 3x3卷积之后还要再加激活吗？ </strong><br>作者也做了对比试验，表明添加非线性激活会提高性能。</p><p>从上面来看，大卷积核完全可以由一系列的3x3卷积核来替代，那能不能分解的更小一点呢。文章考虑了 <strong>nx1</strong> 卷积核。<br>如下图所示的取代3x3卷积： </p><center><br><img src="/2018/12/07/GoogLeNet/V2_Figure3.jpg" style="zoom:80%"><br></center><p>于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，作者发现<strong>在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好</strong>。（对于mxm大小的feature map,建议m在12到20之间）。</p><p>总结如下图：</p><center><br><img src="/2018/12/07/GoogLeNet/V2_Figure4_5_6.jpg" style="zoom:80%"><br></center><p><strong>(1)</strong> 图4是GoogLeNet V1中使用的Inception结构；</p><p><strong>(2)</strong> 图5是用3x3卷积序列来代替大卷积核；</p><p><strong>(3)</strong> 图6是用nx1卷积来代替大卷积核，这里设定n=7来应对17x17大小的feature map。该结构被正式用在GoogLeNet V2中。</p><h2 id="GoogLeNet-Inception-v4"><a href="#GoogLeNet-Inception-v4" class="headerlink" title="GoogLeNet Inception v4"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/e0464e8d6db4" target="_blank" rel="noopener">v4</a></h2><ul><li><a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1602.07261" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>，top5 error 3.08%</li></ul><p>Szegedy读了此<a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener"><strong>论文</strong></a>后，蹦出了结合GoogLeNet与Residual Connections的奇思妙想，于是就有了上面那篇论文，主要贡献如下：</p><ul><li>1、在Inception v3的基础上发明了Inception v4，v4比v3更加复杂，复杂到不可思议</li><li>2、结合ResNet与GoogLeNet，发明了Inception-ResNet-v1、Inception-ResNet-v2，其中Inception-ResNet-v2效果非常好，但相比ResNet，Inception-ResNet-v2的复杂度非常惊人，跟Inception v4差不多</li><li>3、加入了Residual Connections以后，网络的训练速度加快了</li><li>4、在网络复杂度相近的情况下，Inception-ResNet-v2略优于Inception-v4</li><li>5、Residual Connections貌似只能加速网络收敛，真正提高网络精度的是“<strong>更大的网络规模</strong>”</li></ul><p>以上就是Inception v4论文的主要贡献了，没有什么创新，只是在前人的基础上修修补补、移花接木，但这篇文章工作量不小，需要花费大量时间训练作者提出的3种网络。</p><blockquote><p>至此，GoogLeNet四篇相关论文就介绍完了，纵观GoogLeNet的发展历程，Szegedy为我们提供了许多可以借鉴的网络设计方法，比如Inception结构、非对称卷积、Batch Normalization、取消全连层……等等。就连Szegedy本人，也汲取了ResNet的精髓，合体两种网络设计出了Inception-ResNet。所以多读论文，多学习别人的idea，是非常重要的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】未完待续&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
  </entry>
  
</feed>
