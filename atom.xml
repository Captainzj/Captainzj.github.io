<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Go Further</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-12-10T12:17:58.079Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>CaptainSE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>软件过程与项目管理</title>
    <link href="http://yoursite.com/2018/12/10/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2018/12/10/软件过程与项目管理/</id>
    <published>2018-12-10T11:02:40.000Z</published>
    <updated>2018-12-10T12:17:58.079Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><h3 id="Introduction-to-Project-Management"><a href="#Introduction-to-Project-Management" class="headerlink" title="Introduction to Project Management"></a>Introduction to Project Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-c0568a46ba885ed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="The-Project-Management-and-Information-Technology-Context"><a href="#The-Project-Management-and-Information-Technology-Context" class="headerlink" title="The Project Management and Information Technology Context"></a>The Project Management and Information Technology Context</h3><h3 id="The-Project-Management-Process-Groups"><a href="#The-Project-Management-Process-Groups" class="headerlink" title="The Project Management Process Groups"></a>The Project Management Process Groups</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Initiating processes - 启动过程</span><br><span class="line">Planning processes - 计划过程</span><br><span class="line">Executing processes - 执行过程组</span><br><span class="line">Monitoring and controlling processes- 监控过程</span><br><span class="line">Closing processes -闭合过程</span><br></pre></td></tr></table></figure><h3 id="Project-Integration-Management"><a href="#Project-Integration-Management" class="headerlink" title="Project Integration Management"></a>Project Integration Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-0ea7fa98a3c3eb4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Scope-Management"><a href="#Project-Scope-Management" class="headerlink" title="Project Scope Management"></a>Project Scope Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a0e80e3077f6b3c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Schedule-Management"><a href="#Project-Schedule-Management" class="headerlink" title="Project Schedule Management"></a>Project Schedule Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-34622539853a259b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Cost-Management"><a href="#Project-Cost-Management" class="headerlink" title="Project Cost Management"></a>Project Cost Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-cc09a65d92af001a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="630"><br></center><center><br>        <img src="https://upload-images.jianshu.io/upload_images/5267500-0170a5c22ef465af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="Project-Quality-Management"><a href="#Project-Quality-Management" class="headerlink" title="Project Quality Management"></a>Project Quality Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-6ee33da505abded3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Resource-Management"><a href="#Project-Resource-Management" class="headerlink" title="Project Resource Management"></a>Project Resource Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-7374cb810a56778a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Communications-Management"><a href="#Project-Communications-Management" class="headerlink" title="Project Communications Management"></a>Project Communications Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-e1777f730d2a1f31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Risk-Management"><a href="#Project-Risk-Management" class="headerlink" title="Project Risk Management"></a>Project Risk Management</h3><h4 id="processes"><a href="#processes" class="headerlink" title="processes"></a>processes</h4><ol><li><p><strong>Planning risk management:</strong> deciding how to approach and plan the risk management activities for the project 决定如何处理和规划项目的风险管理活动</p><ul><li>The project team should review project documents as well as corporate risk management <code>policies</code>, <code>risk categories</code>,<code>lessons-learned</code> reports from past projects, and<code>templates</code> for creating a risk management plan</li></ul></li><li><p><strong>Identifying risks</strong>: determining which risks are likely to affect a project and documenting the characteristics of each 确定哪些风险可能影响项目并记录每个风险的特征</p><ul><li>tools and techniques <ul><li>Brainstorming</li><li>The Delphi Technique: 专家小组；匿名输入；书面答复</li><li>Interviewing</li><li>SWOT analysis: Strengths,weaknesses, opportunities, and threats</li></ul></li><li>Output<ul><li>Risk Register </li></ul></li></ul></li><li><p><strong>Performing qualitative risk analysis</strong>: prioritizing risks based on their probability and impact of occurrence 根据风险的概率和发生的影响确定风险的优先级</p><ul><li>tools and techniques <ul><li>Probability/impact matrixes</li><li>The Top Ten Risk Item Tracking</li><li>Expert judgment</li></ul></li></ul></li><li><p><strong>Performing quantitative risk analysis</strong>: numerically estimating the effects of risks on project objectives 数字估算风险对项目目标的影响</p><ul><li>Main techniques <ul><li>Decision tree analysis 决策树分析  EMV(Expected Monetary Value )</li><li>Simulation 模拟   <strong>Monte Carlo analysis</strong></li><li>Sensitivity analysis 敏感性分析</li></ul></li></ul></li><li><p><strong>Planning risk responses</strong>: taking steps to enhance opportunities and reduce threats to meeting project objectives  采取措施增加机会并减少对实现项目目标的威胁</p><ul><li><p>Negative</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-401c059f77196a16.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="500"><br></center></li><li><p>Positive</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-d40395b0292ca1c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="300"><br></center></li></ul></li><li><p><strong>Implementing risk responses</strong>: implementing the risk response plans  实施风险应对计划</p></li><li><p><strong>Monitoring risk</strong>: monitoring identified and residual risks, identifying new risks, carrying out risk response plans, and evaluating the effectiveness of risk strategies throughout the life of the project 监控已识别和剩余风险，识别新风险，执行风险应对计划，并在项目的整个生命周期内评估风险策略的有效性</p></li></ol><ul><li>Main output of this process is a <code>risk management plan</code></li></ul><h3 id="PROJECT-PROCUREMENT-MANAGEMENT"><a href="#PROJECT-PROCUREMENT-MANAGEMENT" class="headerlink" title="PROJECT PROCUREMENT MANAGEMENT"></a>PROJECT PROCUREMENT MANAGEMENT</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-141f7fc025e82374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h4 id="Types-of-outsourcing"><a href="#Types-of-outsourcing" class="headerlink" title="Types of outsourcing"></a>Types of outsourcing</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- Local outsourcing</span><br><span class="line">- Offshore outsourcing</span><br><span class="line">- Nearshore outsourcing</span><br></pre></td></tr></table></figure><h4 id="Types-of-Contracts"><a href="#Types-of-Contracts" class="headerlink" title="Types of Contracts"></a>Types of Contracts</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">- 'Fixed price' or lump sum contracts: involve a fixed total price for a well-defined product or service   #卖家不利</span><br><span class="line">- `Point of Total Assumption` (PTA): cost at which the contractor assumes total responsibility for each additional dollar of contract cost</span><br><span class="line">- 'Fixed Price' / Lump Sum / Firm Fixed Price : Risk is on the seller</span><br><span class="line">- Fixed Price with Economic Price Adjustment Contracts ('FP-EPA'): 旨在保护买方和卖方免受其无法控制的外部条件的影响。 如`通货膨胀变化`，或成本增加。</span><br><span class="line">- Fixed Price Incentive Fee ('FPIF') 固定价格激励: 根据卖家表现支付额外奖励，例如更快/更便宜/更好,比如 项目早期每月完成一次，向卖方支付额外的10,000美元</span><br><span class="line">- Fixed Price Award Fee ('FPAF')固定价格奖励: 买方根据业绩支付固定价格和奖励金额（奖金）</span><br><span class="line"></span><br><span class="line">- 'Cost-reimbursable' contracts: involve payment to the seller for direct and indirect costs   #买家不利</span><br><span class="line">- Cost plus incentive fee, cost plus fixed fee, and cost plus percentage of costs</span><br><span class="line">- Cost + Fee (CPF)/ Cost Plus Percentage of Costs ('CPPC') :涉及向卖方支付已完成工作所产生的`所有合法实际费用`，以及费用的百分比。</span><br><span class="line">- Cost Plus Fixed Fee.('CPFF'). 成本加固定费用</span><br><span class="line">- Cost Plus Incentive Fee ('CPIF'). 成本加奖励</span><br><span class="line">- Cost Plus Award Fee ('CPAF'). 成本加奖励费</span><br><span class="line"></span><br><span class="line">- 'Time and material' contracts: hybrid of both fixed price and cost reimbursable contracts  用于在授予合同时`无法确定工作量`的服务工作 例如: 合同=每天1美元加上每线性木材5美元的材料</span><br><span class="line"></span><br><span class="line">- 'Unit price' contracts: require the buyer to pay the seller a predetermined amount per unit of service</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-91e6cc7316e81548.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ContractRisk.png" title="">                </div>                <div class="image-caption">ContractRisk.png</div>            </figure><h3 id="PROJECT-STAKEHOLDER-MANAGEMENT"><a href="#PROJECT-STAKEHOLDER-MANAGEMENT" class="headerlink" title="PROJECT STAKEHOLDER MANAGEMENT"></a>PROJECT STAKEHOLDER MANAGEMENT</h3><h4 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h4><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-f52bfa58c3aa23aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><ol><li><p><strong>Identifying stakeholders</strong>: identifying everyone involved in the project or affected by it, and determining the best ways to manage relationships with them.</p><ul><li><p>output: <code>stakeholder register</code> includes basic information on stakeholders</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a78cfe957aaaa2b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width=""><br></center><ul><li><p><strong>Identification information</strong>: stakeholders’ names, positions, locations, roles in the project, and contact information</p></li><li><p><strong>Assessment information</strong>: stakeholders’ major requirements and expectations, potential influences, and phases of the project in which stakeholders have the most interest</p></li><li><p><strong>Stakeholder classification</strong>: is the stakeholder internal or external to the organization? Is the stakeholder a supporter of the project or resistant to it?</p></li></ul></li></ul></li><li><p><strong>Planning stakeholder management</strong>: determining strategies to effectively engage stakeholders in project decisions and activities based on their needs, interests, and potential impact.</p><ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Managing stakeholder engagement:</strong> communicating and working with project stakeholders to satisfy their needs and expectations, resolving issues, and fostering engagement in project decisions and activities<ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Monitoring stakeholder engagement</strong>:monitoring stakeholder relationships and adjusting plans and strategies for engaging stakeholders as needed<ul><li>Outputs: <code>work performance information</code>, <code>change requests</code>, <code>project management plan updates</code>, and <code>project documents updates</code>.</li></ul></li></ol><h2 id="Exam"><a href="#Exam" class="headerlink" title="Exam"></a>Exam</h2><h3 id="考后说明"><a href="#考后说明" class="headerlink" title="考后说明"></a>考后说明</h3><ul><li><strong>True or False</strong>： 只要理解<a href="#知识点啊~朋友们">知识点</a>部分的内容，就够了，不必去记忆。考卷的”False”很明显</li><li><strong>Single choice</strong>：刷一遍题库，对题目有印象就行。考试都是原题，选项次序都不变</li><li><strong>Fill in the blanks</strong>：刷一遍题库，考试都是原题</li><li><strong>Writing</strong>：still 背题库，<strong>默写</strong>式答题</li></ul><blockquote><p><strong>Summary：</strong> 此门课程难点还是 前期完成的项目本身  笔试部分则是”记到便是赚到“  (2018.12.10)</p></blockquote><h3 id="知识点啊-朋友们"><a href="#知识点啊-朋友们" class="headerlink" title="知识点啊~朋友们"></a>知识点啊~朋友们</h3><h4 id="项目管理简介"><a href="#项目管理简介" class="headerlink" title="项目管理简介"></a>项目管理简介</h4><p>1.<code>项目</code>与运营不同，因为它们在达到目标或项目终止时<code>结束</code>。<br>2.使用<code>渐进式细化</code>开发项目。项目通常在开始时被广泛定义，随着时间的推移，项目的具体细节变得更加清晰。因此，应该<code>逐步开发</code>项目。</p><p>3.一个项目涉及<code>不确定性</code>。每个项目都是独一无二的，因此有时很难明确定义目标，估计完成所需的时间，或确定需要多少费用。这种不确定性是项目管理如此具有挑战性的主要原因之一。<br>4.管理<code>三重约束</code>涉及在项目的范围，时间和成本目标之间进行权衡。经验丰富的项目经理知道必须决定三重约束的哪个方面最重要。<br>5.<code>利益相关者</code>是参与或受项目活动影响的人，包括项目发起人，项目团队，支持人员，客户，用户，供应商，甚至是项目的反对者。<br>6.<code>项目管理知识领域</code>描述了项目经理必须发展的关键能力。<code>项目采购管理</code>涉及从执行组织外部为项目获取或采购商品和服务。<br>7.<code>项目经理</code>不仅<code>负责</code>项目成果的交付。他们是<code>负责</code>这些项目开发的产品和流程成功的变革推动者。</p><p>8.<code>IT项目经理</code>必须愿意发展不仅仅是他们的<code>技术技能</code>，才能成为富有成效的团队成员和成功的项目经理。每个人，无论他们多么技术，都应该培养<code>商业和软技能</code>。</p><h4 id="项目管理和信息技术背景"><a href="#项目管理和信息技术背景" class="headerlink" title="项目管理和信息技术背景"></a>项目管理和信息技术背景</h4><p>1.使用<code>系统方法</code>对于成功的项目管理至关重要。如果高层管理人员和项目经理要了解项目与整个组织的关系，他们必须<code>遵循</code>系统理念。<br>2.矩阵组织的<code>项目经理</code>有来自<code>各个职能领域的工作人员</code>从事项目工作。<br>3.<code>组织文化</code>非常强大，许多人认为许多公司问题的根本原因不在于组织结构或员工;他们在文化中。<br>4.在围绕团体或团队而不是个人组织工作活动的组织中，项目工作最为成功。强调团队工作的<code>组织文化</code>最适合管理项目。<br>5.在项目生命周期的<code>早期阶段</code>，资源需求通常最低，不确定性水平最高。在<code>后期阶段</code>对项目进行重大改变要昂贵得多。<br>6.由于组织通常会在项目<code>持续时投入更多资金</code>，因此应在每个阶段之后进行<code>管理评审</code>，以评估进度，潜在成功以及与组织目标的持续兼容性。<br>7.<code>虚拟团队</code>是一群使用通信技术在时间和空间边界上一起工作的人。团队成员可能都在同一个国家的同一家公司工作，或者他们可能包括员工以及独立顾问，供应商，甚至志愿者，他们提供来自全球的专业知识。</p><h4 id="项目管理流程组"><a href="#项目管理流程组" class="headerlink" title="项目管理流程组"></a>项目管理流程组</h4><p>1.<code>启动流程</code>包括定义和授权项目或项目阶段。启动过程在项目的<code>每个阶段</code>进行。<br>2.<code>启动和关闭任务通常是最短的</code>（分别在项目或阶段的开始和结束时），并且它们需要最少的资源和时间。<br>3.<code>监控和控制流程</code>与所有其他项目管理流程组<code>重叠</code>，因为可以随时进行更改。<br>4.<code>敏捷</code>是一种适应性产品生命周期，当可交付成果具有<code>高度变化</code>和<code>高交付频率</code>时使用。<br>5.六西格玛项目使用两种主要方法：<code>DMAIC</code>（定义，测量，分析，改进和控制）用于改进现有业务流程，并使用<code>DMADV</code>（定义，测量，分析，设计和验证）创建新产品或流程设计，以实现可预测的，无缺陷的性能。<br>6.<code>启动会议</code>是在项目开始时举行的会议，以便利益相关者可以相互见面，审查项目的目标，并讨论未来的计划。启动会议通常在<code>业务案例和项目章程完成后</code>举行，但可以根据需要提前举行。</p><p>7.<code>WBS</code>是项目管理中非常重要的工具，因为它为决定如何开展工作提供了基础。 WBS还为<code>创建项目进度表</code>和<code>执行挣值管理</code>提供了基础，用于<code>衡量和预测项目绩效</code>。<br>8.因为<code>Scrum</code>暗示团队成员是由ScrumMaster指导的<code>自我导向组</code>，所以<code>团队合同不是必需的</code>。<br>9.燃尽图表(<code>burndown chart</code>)显示了每天冲刺中<code>剩余的累积工作量</code>。<br>10.<code>冲刺审查</code>是团队向产品所有者展示冲刺期间<code>完成的内容</code>的会议。</p><p>11.Scrum框架中<code>监控和控制</code>的两个主要项目是<code>每日Scrum</code>和<code>冲刺审查</code>。<br>12.<code>结账流程</code>包括正式接受项目或项目阶段并有效结束。作为阶段或项目的一部分，<code>管理活动</code>（例如归档项目文件，结束合同，记录经验教训以及接受正式接受交付的工作）通常涉及此流程组。</p><h4 id="项目集成管理"><a href="#项目集成管理" class="headerlink" title="项目集成管理"></a>项目集成管理</h4><p>1.<code>界面管理</code>涉及识别和管理项目各个元素之间的<code>交互点</code>。<br>2.<code>项目集成管理包括界面管理</code>，涉及识别和管理项目各个元素之间的交互点。随着项目涉及的人数增加，<code>接口数量可能呈指数级增长</code>。<br>3.有些人喜欢使用<code>思维导图</code>进行SWOT分析，这种技术使用从核心思想辐射出来的分支来构建思想和想法。<br>4.许多信息系统被归类为<code>“战略性”</code>，因为它们直接支持<code>关键业务战略</code>。例如，信息系统可以帮助组织支持作为低成本生产者的战略。<br>5.随着项目的进展，组织必须<code>重新评估</code>每个项目的需求，资金和意愿，以确定是否应该继续，重新定义或终止项目。<br>6.由于要求和期望不明确，许多项目都失败了，所以从<code>项目章程</code>开始就很有意义。<br>7.<code>项目管理计划</code>不仅仅是甘特图。</p><h4 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a><a href="#第5章 - 项目范围管理">项目范围管理</a></h4><p>1.<code>范围基准</code>包括已批准的项目范围声明及其关联的WBS和WBS字典。</p><p>2.<code>WBS的主要目的</code>是定义完成项目所需的所有工作。<br>3.<code>工作包</code>是WBS最低级别的任务。它表示项目经理监视和控制的工作级别。<br>4.创建一个好的WBS非常<code>困难</code>。为此，您必须了解项目及其范围，并纳入利益相关方的需求和知识。<br>5.执行任务executing task在项目之间<code>变化最大</code>，但其他项目管理过程组下的许多任务对于所有项目都是类似的。<br>6.创建一个好的WBS及其WBS字典的基本原则是，<code>一个工作单元应该只出现在WBS中的一个地方</code>。<br>7.即使项目范围相当明确，许多IT项目仍然存在<code>范围蔓延</code> - 项目范围越来越大的趋势。许多IT项目因范围蔓延而失败。</p><h4 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a><a href="#第6章 - 项目进度管理">项目进度管理</a></h4><p>1.<code>活动或任务</code>是通常在工作分解结构（WBS）上找到的工作要素，其具有预期的持续时间，成本和资源要求。<br>2.在项目进度管理中，定义活动的<code>主要输出</code>是活动列表，活动属性，里程碑列表和项目管理计划更新。<br>3.<code>项目进度表</code>从发起项目的基本文件中发展而来。<code>项目章程</code>经常提到计划的项目开始和结束日期，作为更详细的计划的起点。<br>4.<code>时间表管理计划</code>包括有关报告格式的信息。此信息描述了项目所需的计划报告的格式和频率。此外，它还包括有关流程描述的信息，并描述了如何执行所有计划管理流程。<br>5.项目的<code>里程碑</code>是一个重要事件，通常<code>没有持续时间</code>。通常需要多次活动和大量工作来完成里程碑，但里程碑本身就像是帮助识别必要活动的<code>标记</code>。<br>6.<code>依赖关系</code>或关系涉及项目活动或任务的<code>顺序</code>。确定活动之间的这些关系或依赖关系对于开发和管理项目进度表具有重大影响。<br>7.<code>网络图</code>是显示<code>活动排序</code>的首选技术。网络图是项目活动及其排序之间逻辑关系的示意图。<br>8.网络图是项目活动及其排序之间逻辑关系的示意图。网络图中的箭头表示活动顺序或任务之间的关系。<br>9.当两个或多个节点在单个节点之前时发生<code>合并</code>。另一方面，当两个或多个活动跟随单个节点时发生<code>突发</code>。<br>10.<code>甘特图</code>提供了一种标准格式，用于通过以日历形式列出项目活动及其相应的开始和结束日期来显示项目进度信息。在甘特图中，黑色菱形符号代表了一个里程碑<br>11.<code>跟踪甘特图</code>基于项目任务完成的工作百分比或实际开始和结束日期。它允许项目经理<code>监控</code>各个任务和整个项目的进度。<br>12.在<code>关键路径分析</code>中，几个任务在项目上并行完成，大多数项目通过网络图有多条路径。包含关键任务的最长路径或路径是驱动项目完成日期的原因。<br>13.<code>crashing</code>的主要优点是缩短了完成项目所需的时间。主要缺点是它通常会增加项目总成本。<br>14.<code>关键链调度</code>是一种在创建项目计划时考虑有限资源的方法，并包含用于保护项目完成日期的<code>缓冲区</code>。它假设资源不是多任务或至少最小化多任务处理。</p><h4 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a><a href="#第7章 - 项目成本管理">项目成本管理</a></h4><p>1.<code>超支</code>是实际成本超过估计值的额外百分比或金额。<br>2.<code>现金流量分析</code>是确定项目的估计年度成本和收益以及由此产生的年度现金流量的一种方法。项目经理必须进行现金流量分析以<code>确定净现值</code>。<br>3.<code>沉没成本</code>是过去花费的钱。在决定投资或继续投资哪些项目时，不应包括沉没成本。<br>4.<code>管理储备</code>允许未来<code>不可预测</code>的情况。例如，如果项目经理生病了两周或者一个重要的供应商停业，可以留出管理储备来支付由此产生的费用。<br>5.<code>估算</code>通常在项目的<code>不同阶段进行</code>，随着时间的推移应该变得更加准确。<br>6.<code>类似的估计</code>需要大量的专家判断，并且通常比其他技术成本更低。但是，它也不太准确。<br>7.项目<code>成本估算不准确</code>的原因之一是<code>人类偏向于低估</code>。因此，项目经理和高层管理人员必须审核估算并提出重要问题，以确保估算不会有偏差<br>8.方差和指数的公式以<code>EV</code>（赢得值）开头。通过从EV中减去实际成本或计划值来计算差异，并且通过将EV除以实际成本或计划值来计算指数。<br>9.如果<code>CPI</code>小于1或小于100％，则该项目超出预算。另一方面，如果CPI大于1％或超过100％，则项目预算可控。</p><h4 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a><a href="#第8章 - 项目质量管理">项目质量管理</a></h4><p>1.<code>实验设计</code>是一种有助于确定哪些变量对过程总体结果影响最大的技术。您还可以将实验设计应用于<code>项目管理问题</code>，例如成本和进度权衡。<br>2.<code>可靠性</code>是指产品或服务在正常条件下按<strong>预期</strong>运行的能力。<br>3.所有项目利益相关方必须<strong>共同努力</strong>，以<code>平衡项目</code>的质量，范围，时间和成本方面。但是，<code>项目经理最终负责</code>其项目的质量管理。<br>4.<code>接受决定确定</code>作为项目一部分生产的产品或服务是否将被接受或拒绝。如果他们被接受，他们被认为是<strong>经过验证的可交付成果</strong>。<br>5.<code>运行图表</code>显示过程随时间变化的<strong>历史和模式</strong>。它是一个折线图，显示按发生顺序绘制的数据点。<br>6.<code>测试</code>需要在系统开发生命周期的几乎<code>每个阶段进行</code>，而不仅仅是在组织发布或将产品交给客户之前。<br>7.在全面质量控制中，产品质量比生产率更重要，工人可以在<code>出现质量问题时停止生产</code>。<br>8.符合要求意味着项目的流程和产品<code>符合书面规范</code>。例如，如果项目范围声明要求交付100台具有特定处理器和内存的计算机，则可以轻松检查是否已交付合适的计算机。</p><h4 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a><a href="#第9章 - 项目资源管理">项目人力资源管理</a></h4><p>1.<code>马斯洛的需求层次</code>表明人们的行为受到一系列需求的<code>指导或激励</code>。<br>2.根据赫兹伯格的说法，<code>激励者</code>，如更高的工资，更多的监督，或更有吸引力的工作环境，将激励工人做更多的工作。他提到导致工作满意度的因素作为激励因素和可能导致不满意的因素作为卫生因素。<br>3.需要制度权力或社会<code>权力的人</code>希望组织其他人来推进组织的目标。<br>4.相信<code>X理论</code>的人认为工人在可能的情况下不喜欢和避免工作，因此管理者必须使用<strong>强制，威胁和各种控制方案</strong>让工人做出足够的努力来实现目标。他们认为普通工人希望被指导并且更愿意避免责任，没有什么野心，并且希望安全高于一切。</p><p>5.Thamhain和Wilemon发现，当项目经理过于依赖权力，金钱或惩罚来影响人们时，项目更有可能失败。当项目经理使用<code>工作挑战和专业知识来影响人们</code>时，项目更有可能成功。<br>6.<code>合法的权力</code>使人们根据权威的地位做事。这种权力类似于权威的影响基础。<br>7.如OBS中所述，责任分配矩阵（<code>RAM</code>）将WBS中描述的项目工作映射到负责执行工作的人员。<br>8.<code>资源调配</code>可以减少项目人员和会计部门的问题。劳动力水平和人力资源的增加和减少往往会产生<code>额外的工作和混乱</code>。<br>9.<code>平滑模式</code>是项目经理强调或避免差异领域并强调协议领域的模式。这种方法也称为适应性，当关系具有高度重要性且任务不重要时，最好使用这种方法。</p><h4 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a><a href="#第10章 - 项目沟通管理">项目沟通管理</a></h4><p>1.举行会议的准则之一是确定是否可以<code>避免会议</code>。如果有更好的方法来实现手头的目标，就不要开会。<br>2.项目经理经常将所有<code>经验教训</code>报告中的信息合并到项目总结报告中。<br>3.提高组织的沟通能力需要组织中的<code>文化变革</code>，这需要花费大量时间，努力工作和耐心。<br>4.要使项目取得成功，每个项目团队成员都需要这<code>两种技能</code>，并需要通过正规教育和在职培训不断开发这些技能。<br>5.<code>地理位置和文化背景影响项目沟通的复杂性</code>。如果项目利益相关者在不同的国家，通常很难或不可能在正常工作时间内安排双向沟通的时间。<br>6.<strong>项目沟通管理</strong>涉及包含影响项目中开发的产品或服务的关键性能特征的<code>详细技术信息</code>。记录可能影响产品性能的<code>技术规范</code>的任何<strong>变更</strong>甚至更为重要。<br>7.沟通的一个重要方面是<code>参与项目的人数</code>。随着数量的增加，通信的复杂性也会增加，因为人们可以通过更多的渠道或途径进行交流。随着团队规模的增加，沟通变得更加复杂。</p><h4 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a><a href="第11章 - 项目风险管理">项目风险管理</a></h4><p>1.项目风险管理<code>涉及</code>了解项目可能出现的潜在问题以及它们如何阻碍项目成功。但是，也有积极的风险或机会，可以为项目带来良好的结果。<br>2.<code>寻求风险的人</code>更喜欢更不确定的结果，并且通常愿意支付惩罚来承担风险。<br>3.项目风险管理的第一步是通过<code>执行风险管理计划</code>来决定如何处理特定项目的知识领域。<br>4.<code>应急计划</code>是预定义的行动，如果发生已识别的风险事件，项目团队将采取这些行动。<br>5.<code>头脑风暴</code>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<code>德尔菲技术</code>是一种基于对未来事件的独立和匿名输入的系统化交互式预测程序。<br>6.项目经理可以绘制风险对<code>概率/影响矩阵或图表</code>的概率和影响，其中列出了风险发生的相对概率和风险发生的相对影响。<br>7.<code>十大风险项目跟踪</code>是一种定性风险分析工具。<br>8.已识别的风险可能<code>无法实现</code>，或者其发生或丧失的可能性可能会<code>减少</code>。</p><h4 id="项目采购管理"><a href="#项目采购管理" class="headerlink" title="项目采购管理"></a><a href="#第12章-项目采购管理">项目采购管理</a></h4><p>1.提供采购服务的组织或个人称为<code>供应商</code>。供应商也称为供应商，承包商，分包商或销售商。<br>2.在外包时，组织应谨慎保护可能在供应商手中易受攻击的<code>战略信息</code>。<br>3.计划采购涉及通过使用组织外部的产品或服务来确定最佳地满足哪些项目需求。如果不需要从组织外部购买产品或服务，则<code>不需要进一步的采购管理</code>。<br>4.成本可偿还合同通常包括费用，例如利润百分比或达到或超过选定项目目标的激励。与固定价格合同相比，买方通过<code>成本可偿还合同</code>承担更多风险。<br>5.<code>固定价格（FFP）</code>合约对买方的风险最小，其次是<code>固定价格激励费（FPIF）</code>合约。<br>6.制造或购买分析涉及估算提供产品或服务的内部成本，并将估算与外包成本进行<code>比较</code>。<br>7.如果公司使用设备20天，他们最好<code>租赁</code>，总费用为10,000美元（20 x 500美元）。 10,000美元的购买成本将增加2,000美元的运营成本（20 x 100美元）。<br>8.评估投标的关键因素，特别是涉及IT的项目，是投标人<code>过去的业绩记录</code>。检查性能记录和参考可以<code>降低</code>选择跟踪记录不佳的供应商的<code>风险</code>。<br>9.控制采购可确保卖方的<code>业绩符合合同要求</code>。合同关系是一种法律关系，这意味着它受州和联邦合同法的约束。</p><h4 id="项目利益相关者管理"><a href="#项目利益相关者管理" class="headerlink" title="项目利益相关者管理"></a>项目利益相关者管理</h4><p>1.与通信和人力资源管理相关的许多概念也<code>适用</code>于利益相关者管理，但需要开展<code>独特的活动</code>以实现良好的利益相关者管理。<br>2.<code>识别</code>利益相关者涉及识别参与项目或受其影响的每个人，并确定<code>管理</code>与他们之间关系的最佳方式。该过程的主要输出是<code>利益相关者登记</code>。<br>3.内部项目利益相关者通常<code>包括</code>项目发起人，项目团队，支持人员和项目的内部客户。其他内部利益相关者包括高层管理人员，其他职能经理和其他项目经理，因为组织资源有限。<br>4.由于员工流动，合作伙伴关系和其他事件，利益相关者可能在项目期间发生<code>变化</code>。<br>5.领先的利益相关者是了解项目及其潜在影响并积极参与<code>帮助项目成功</code>的人<br>6.项目经理必须了解并与各利益相关方合作;因此，他们应该专门讨论如何使用各种沟通方法及其人际关系和管理技能来<code>吸引利益相关者</code>。<br>7.您无法控制利益相关者，但您可以<code>监控干系人的参与程度</code>。参与涉及对话，人们寻求理解和解决共同关心的问题。<br>8.应邀请主要利益攸关方积极<code>参加启动会议</code>，而不仅仅是参加会议。项目经理应该强调，会议<code>期望进行对话</code>，包括利益相关者喜欢的文本或任何沟通方式。</p><h3 id="填空题"><a href="#填空题" class="headerlink" title="填空题"></a>填空题</h3><h4 id="第4章-项目集成管理"><a href="#第4章-项目集成管理" class="headerlink" title="第4章 - 项目集成管理"></a>第4章 - 项目集成管理</h4><ol><li>____涉及通过分析优势和劣势，研究机会和威胁，预测未来趋势以及预测新产品和服务的需求来确定长期目标。<br>答案：战略规划</li><li>____涉及分析公司的优势，劣势，机会和威胁，并用于协助战略规划。<br>答案：SWOT分析</li><li>____是一种技术，它使用从核心思想辐射出来的分支来构建思想和想法。<br>答案：思维导图</li><li>____指的是改善组织的机会。<br>答案：机遇</li><li>____是从效益中减去项目成本然后除以成本的结果。<br>答案：投资回报率（ROI）</li><li>____是一种工具，它提供了一个基于许多标准选择项目的系统过程。<br>答案：加权评分模型</li><li>____是记录的起点，测量或观察，以便可以用于将来的比较。变化。<br>答案：基线</li><li>____涉及在整个项目生命周期中识别，评估和管理变更。<br>答案：综合变更控制</li></ol><h4 id="第5章-项目范围管理"><a href="#第5章-项目范围管理" class="headerlink" title="第5章 - 项目范围管理"></a>第5章 - 项目范围管理</h4><ol><li>____创建涉及将主要项目可交付成果细分为更小，更易于管理的组件。<br>答案：工作分解结构（WBS）</li><li>____是指“项目必须满足的条件或能力，或者在产品，服务或结果中出现以满足协议或其他正式规定的条件或能力。”<br>答案：要求</li><li>____包括已批准的项目范围声明及其关联的WBS和WBS字典。<br>答案：范围基线</li><li>工作包是WBS的____级任务。<br>答案：最低</li><li>____在创建WBS的方法中，团队成员首先确定尽可能多的与项目相关的特定任务。<br>答案：自下而上</li><li>____是一种技术，它使用从核心思想中散发出来的分支来构建创建WBS时的思想和想法。<br>答案：思维导图</li><li>____是项目范围越来越大的趋势。<br>答案：范围蔓延</li><li>____执行范围验证的主要工具是和小组决策制定技术。<br>答案：检查</li><li>____涉及开发系统的工作副本或系统的某些方面。<br>答案：原型设计</li></ol><h4 id="第6章-项目进度管理"><a href="#第6章-项目进度管理" class="headerlink" title="第6章 - 项目进度管理"></a>第6章 - 项目进度管理</h4><ol><li>____是完成任务所需的工作日或工作小时数。<br>答案：努力</li><li>在项目进度表中，灵活性最小的变量是____。<br>答案：时间</li><li>____涉及确保及时完成项目所需的过程。<br>答案：项目进度管理</li><li>____是要列入项目进度表的活动的表格。<br>答案：活动清单</li><li>____是项目活动及其排序之间逻辑关系的示意图。<br>答案：网络图</li><li>在____关系中，“from”活动必须在“to”活动完成之前开始。<br>答案：从头到尾</li><li>____没有持续时间和资源，但偶尔需要在AOA网络图上显示活动之间的逻辑关系。<br>答案：虚拟活动</li></ol><h4 id="第7章-项目成本管理"><a href="#第7章-项目成本管理" class="headerlink" title="第7章 - 项目成本管理"></a>第7章 - 项目成本管理</h4><ol><li>____过程的主要成果是活动成本估算，估算基础和项目文件更新。<br>答案：成本估算</li><li>____流程的主要成果是成本绩效基准，项目资金要求和项目文件更新。<br>答案：成本预算</li><li>____理论指出，当重复生产许多物品时，随着生产更多单位，这些物品的单位成本会以规律的方式减少。<br>答案：学习曲线</li><li>____估算是在项目的早期阶段或甚至在项目正式启动之前完成的。<br>答案：粗略的数量级（ROM）</li><li>____是项目经理用来衡量和监控成本绩效的分阶段预算。<br>答案：成本基准</li></ol><h4 id="第8章-项目质量管理"><a href="#第8章-项目质量管理" class="headerlink" title="第8章 - 项目质量管理"></a>第8章 - 项目质量管理</h4><ol><li>____这个词意味着产品可以按照预期使用。<br>答案：适合使用</li><li>____是一种质量计划技术，有助于确定哪些变量对过程的总体结果影响最大。<br>答案：实验设计</li><li>____图表将有关质量问题的投诉追溯到负责任的生产操作。<br>答案：因果关系<br>鱼刺<br>石川</li><li>Watts S. Humphrey将____定义为在交付程序之前必须更改的任何内容。<br>答案：软件缺陷</li><li>____是一个公司部门的非监督人员和工作领导小组，他们自愿组织如何提高部门工作效率的小组研究。<br>答案：质量圈子</li><li>____意味着对失败负责或不满足质量期望。<br>答案：不合格的成本</li><li>Genichi Taguchi的____方法着重于通过用科学探究替代试错法来消除缺陷。<br>答案：稳健的设计</li></ol><h4 id="第9章-项目资源管理"><a href="#第9章-项目资源管理" class="headerlink" title="第9章 - 项目资源管理"></a>第9章 - 项目资源管理</h4><ol><li>根据马斯洛的说法，只有满足____需求后，个人才能满足增长需求。<br>答案：缺陷</li><li>赫茨伯格称之为导致工作满意度的因素____。<br>答案：激励者</li><li>____是整体等于其各部分之和的概念。<br>答案：协同作用</li><li>____正在倾听，意图理解。<br>答案：移情倾听</li><li>____是和谐，一致，一致或亲和的关系，对沟通很重要。<br>答案：交流</li><li>____根据所需的详细程度将工作分配给负责任和执行的组织，团队或个人。<br>答案：责任分配矩阵（RAM）</li><li>____是一种特定类型的组织结构图，显示哪些组织单位负责哪些工作项。<br>答案：OBS（组织分解结构）</li></ol><h4 id="第10章-项目沟通管理"><a href="#第10章-项目沟通管理" class="headerlink" title="第10章 - 项目沟通管理"></a>第10章 - 项目沟通管理</h4><ol><li><p>许多信息技术专业人员在<strong>_</strong>项目中工作，他们从未与项目赞助商，其他团队成员或其他项目利益相关者会面。<br>答案：虚拟</p></li><li><p>____分析包括信息的联系人，信息到期时以及信息的首选格式等信息。<br>答案：利益相关方沟通</p></li><li>在试图评估项目利益相关者的承诺时，<strong>_</strong>会议或网络会议可能是最合适的媒介。<br>答案：面对面</li><li>控制通信的主要目标是确保整个____的最佳信息流。<br>答案：项目生命周期</li><li>所有会议必须有____和预期结果。<br>答案：目的</li><li>____强制会议组织者计划会议，并让潜在参与者有机会决定是否需要参加。<br>答案：议程</li></ol><h4 id="第11章-项目风险管理"><a href="#第11章-项目风险管理" class="headerlink" title="第11章 - 项目风险管理"></a>第11章 - 项目风险管理</h4><ol><li>项目<strong>_</strong>是一种不确定性，可能对实现项目目标产生负面或正面影响。<br>答案：风险</li><li>是从潜在收益中获得的满足或愉悦的数量。<br>答案：风险效用</li><li>是项目潜在风险类别的等级。<br>答案：风险分解结构</li><li>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<br>答案：头脑风暴</li><li>是包含各种风险管理流程结果的文件。<br>答案：风险登记</li><li>是风险事件概率和风险事件货币价值的乘积。<br>答案：EMV<br>预期的货币价值<br>预期货币价值（EMV）<br>EMV（预期货币价值）</li><li>风险是在实施所有应对策略后仍然存在的风险。<br>答案：剩余</li></ol><h4 id="第12章-项目采购管理"><a href="#第12章-项目采购管理" class="headerlink" title="第12章-项目采购管理"></a>第12章-项目采购管理</h4><ol><li>____是指从外部来源获取商品和/或服务的过程。<br>答案：采购</li><li>____是一项具有相互约束力的协议，规定卖方有义务提供指定的产品或服务，并规定买方有义务支付这些产品或服务。<br>答案：合同</li><li>____决定是指组织决定在组织内部制造某些产品或执行某些服务是否符合其最佳利益，或者是否最好从外部组织购买。<br>答案：制造或购买</li><li>____合同包括由于通货膨胀等条件的变化而对合同价格进行预定义的最终调整的特殊规定。<br>答案：固定价格与经济价格调整（FP-EPA），固定价格与经济，价格调整，FP-EPA</li><li>____合同是固定价格和成本可偿还合同的混合体。<br>答案：时间和材料（T＆M），时间和材料，T＆M</li><li>____是允许买方或供应商终止合同的合同条款。<br>答案：终止条款</li><li>____是卖方在满足买方需求时采用不同方法编制的文件。<br>答案：提案</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GooLeNet</title>
    <link href="http://yoursite.com/2018/12/07/GooLeNet/"/>
    <id>http://yoursite.com/2018/12/07/GooLeNet/</id>
    <published>2018-12-07T02:44:09.000Z</published>
    <updated>2018-12-11T12:40:45.132Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】未完待续</p><a id="more"></a><p>参考链接：<a href="https://blog.csdn.net/shuzfan/article/details/50738394#googlenet-inception-v2" target="_blank" rel="noopener">GoogLeNet系列解读</a>、<a href="https://blog.csdn.net/qq_31531635/article/details/72232651" target="_blank" rel="noopener">深度学习之GoogLeNet解读</a>、<a href="https://www.jianshu.com/p/33197e469414" target="_blank" rel="noopener">GoogLeNet的心路历程</a></p><p>ToRead：<a href="https://blog.csdn.net/docrazy5351/article/details/78993269" target="_blank" rel="noopener">深入理解GoogLeNet结构</a></p><h2 id="GoogLeNet-Incepetion-V1"><a href="#GoogLeNet-Incepetion-V1" class="headerlink" title="GoogLeNet Incepetion V1"></a>GoogLeNet Incepetion <a href="https://www.jianshu.com/p/a2ad00eddbd5" target="_blank" rel="noopener">V1</a></h2><p>GoogLeNet, 一个22层的深度网络，2014年ILSVRC挑战赛冠军，将Top5 的错误率降低到6.67%。这是一种 类似于 <strong>网中网（Network In Network）</strong>的结构，即原来的结点也是一个网络。</p><p>这是GoogLeNet的最早版本，出现在2014年的《<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Going deeper with convolutions</a>》。之所以名为“GoogLeNet”而非“GoogleNet”,文章说是为了向早期的LeNet致敬。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>深度学习以及神经网络快速发展，人们不再只关注更给力的硬件、更大的数据集、更大的模型，而是更在意新的idea、新的算法以及模型的改进。</p><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生<strong>过拟合</strong>也会大大<strong>增加计算量</strong>。</p><p>文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献1表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。<strong>这点表明臃肿的稀疏网络可能被不失性能地简化。</strong> 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。</p><p>早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了<code>随机稀疏连接</code>。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。</p><p>所以，现在的问题是有没有一种方法，<strong>既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能</strong>。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。</p><h3 id="Architectural-Details"><a href="#Architectural-Details" class="headerlink" title="Architectural Details"></a>Architectural Details</h3><p>Inception 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。<br>作者首先提出下图这样的基本结构： </p><center><br>    <img src="/2018/12/07/GooLeNet/V1_Figure2(a).jpg" style="zoom:60%"><br></center><p>对上图做以下说明：<br>1 . 采用不同大小的卷积核意味着不同大小的感受野，最后拼接<code>意味着不同尺度特征的融合</code>；<br>2 . 之所以卷积核大小采用1、3和5，主要是<code>为了方便对齐</code>。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以<code>直接拼接</code>在一起了；<br>3 . 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。<br>4 . 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p><p><strong>但是，使用5x5的卷积核仍然会带来巨大的计算量</strong>。 为此，文章借鉴NIN，采用<code>1x1卷积核来进行降维</code>。<br>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。<a href="https://blog.csdn.net/capecape/article/details/78296796#4维度计算" target="_blank" rel="noopener">详细的降维计算过程</a></p><p>具体改进后的Inception Module如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure2(b).jpg" style="zoom:60%"><br></center><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p>GoogLeNet的整体结构如下图：</p><center><br><img src="/2018/12/07/GooLeNet/GooLeNet.jpg" style="zoom:60%"><br></center><p>对上图做如下说明：<br>1 . 显然GoogLeNet采用了模块化的结构，方便增添和修改；<br>2 . 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；<br>3 . 虽然移除了全连接，但是网络中依然使用了Dropout ;<br>4 . 为了<code>避免梯度消失</code>，网络额外增加了2个辅助的softmax（average pooling）用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</p><p>下图是一个比较清晰的结构图：</p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure3.jpg" style="zoom:60%"><br></center><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>GoogLeNet是谷歌团队为了参加ILSVRC 2014比赛而精心准备的，为了达到最佳的性能，除了使用上述的网络结构外，还做了大量的辅助工作：包括训练多个model求平均、裁剪不同尺度的图像做多次验证等等。详细的这些可以参看文章的实验部分。</p><p>本文的主要想法其实是想通过<code>构建密集的块结构来近似最优的稀疏结构</code>，从而达到<code>提高性能而又不大量增加计算量</code>的目的。GoogleNet的caffemodel大小约50M，但性能却很优异。</p><h2 id="GoogLeNet-Inception-V2"><a href="#GoogLeNet-Inception-V2" class="headerlink" title="GoogLeNet Inception V2"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/4270f5acc066" target="_blank" rel="noopener">V2</a></h2><ul><li><a href="https://link.jianshu.com?t=http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>，top5 error 4.8%</li></ul><p>这篇文章做出的贡献不是一般的大，它提出了Batch Normalization（BN），以至于网上关于它的介绍铺天盖地，但中文优秀原创没几个，都是转载来转载去，挑几个好的比如：<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/u012816943/article/details/51691868" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="noopener"><strong>这个</strong></a>。</p><h2 id="GoogLeNet-Inception-v3"><a href="#GoogLeNet-Inception-v3" class="headerlink" title="GoogLeNet Inception v3"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/0cc42b8e6d25" target="_blank" rel="noopener">v3</a></h2><p>GoogLeNet凭借其优秀的表现，得到了很多研究人员的学习和使用，因此Google团队又对其进行了进一步发掘改进，产生了升级版本的GoogLeNet。这一节介绍的版本记为V2，文章为：《<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a>》。</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>14年以来，构建更深的网络逐渐成为主流，但是模型的变大也使计算效率越来越低。这里，文章试图找到一种方法在<strong>扩大网络的同时又尽可能地发挥计算性能</strong>。</p><p>首先，GoogLeNet V1出现的同期，性能与之接近的大概只有VGGNet了，并且二者在图像分类之外的很多领域都得到了成功的应用。但是相比之下，GoogLeNet的计算效率明显高于VGGNet，大约只有500万参数，只相当于Alexnet的1/12(GoogLeNet的caffemodel大约50M，VGGNet的caffemodel则要超过600M)。</p><p>GoogLeNet的表现很好，但是，如果想要通过简单地放大Inception结构来构建更大的网络，则会立即提高计算消耗。此外，在V1版本中，文章也没给出有关构建Inception结构注意事项的清晰描述。因此，在文章中作者<strong>首先给出了一些已经被证明有效的用于放大网络的通用准则和优化方法</strong>。这些准则和方法适用但不局限于Inception结构。</p><h3 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h3><p>下面的准则来源于大量的实验，因此包含一定的推测，但实际证明基本都是有效的。</p><p><strong>1 . 避免表达瓶颈，特别是在网络靠前的地方</strong>。 信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。<br>另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）</p><p><strong>2 . 高维特征更易处理</strong>。 高维特征更易区分，会加快训练。</p><p><strong>3. 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息</strong>。 比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。</p><p><strong>4 . 平衡网络的宽度与深度</strong>。</p><p>上述的这些并不能直接用来提高网络质量，而<code>仅用来在大环境下作指导</code>。</p><h3 id="Factorizing-Convolutions-with-Large-Filter-Size"><a href="#Factorizing-Convolutions-with-Large-Filter-Size" class="headerlink" title="Factorizing Convolutions with Large Filter Size"></a>Factorizing Convolutions with Large Filter Size</h3><p>大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。为此，作者提出可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量)如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure1.jpg" style="zoom:80%"><br></center><p>然后就会有2个疑问：</p><p><strong>1 . 这种替代会造成表达能力的下降吗？</strong><br>后面有大量实验可以表明<code>不会造成表达缺失</code>；</p><p><strong>2 . 3x3卷积之后还要再加激活吗？ </strong><br>作者也做了对比试验，表明添加非线性激活会提高性能。</p><p>从上面来看，大卷积核完全可以由一系列的3x3卷积核来替代，那能不能分解的更小一点呢。文章考虑了 <strong>nx1</strong> 卷积核。<br>如下图所示的取代3x3卷积： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure3.jpg" style="zoom:80%"><br></center><p>于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，作者发现<strong>在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好</strong>。（对于mxm大小的feature map,建议m在12到20之间）。</p><p>总结如下图：</p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure4_5_6.jpg" style="zoom:80%"><br></center><p><strong>(1)</strong> 图4是GoogLeNet V1中使用的Inception结构；</p><p><strong>(2)</strong> 图5是用3x3卷积序列来代替大卷积核；</p><p><strong>(3)</strong> 图6是用nx1卷积来代替大卷积核，这里设定n=7来应对17x17大小的feature map。该结构被正式用在GoogLeNet V2中。</p><h2 id="GoogLeNet-Inception-v4"><a href="#GoogLeNet-Inception-v4" class="headerlink" title="GoogLeNet Inception v4"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/e0464e8d6db4" target="_blank" rel="noopener">v4</a></h2><ul><li><a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1602.07261" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>，top5 error 3.08%</li></ul><p>Szegedy读了此<a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener"><strong>论文</strong></a>后，蹦出了结合GoogLeNet与Residual Connections的奇思妙想，于是就有了上面那篇论文，主要贡献如下：</p><ul><li>1、在Inception v3的基础上发明了Inception v4，v4比v3更加复杂，复杂到不可思议</li><li>2、结合ResNet与GoogLeNet，发明了Inception-ResNet-v1、Inception-ResNet-v2，其中Inception-ResNet-v2效果非常好，但相比ResNet，Inception-ResNet-v2的复杂度非常惊人，跟Inception v4差不多</li><li>3、加入了Residual Connections以后，网络的训练速度加快了</li><li>4、在网络复杂度相近的情况下，Inception-ResNet-v2略优于Inception-v4</li><li>5、Residual Connections貌似只能加速网络收敛，真正提高网络精度的是“<strong>更大的网络规模</strong>”</li></ul><p>以上就是Inception v4论文的主要贡献了，没有什么创新，只是在前人的基础上修修补补、移花接木，但这篇文章工作量不小，需要花费大量时间训练作者提出的3种网络。</p><blockquote><p>至此，GoogLeNet四篇相关论文就介绍完了，纵观GoogLeNet的发展历程，Szegedy为我们提供了许多可以借鉴的网络设计方法，比如Inception结构、非对称卷积、Batch Normalization、取消全连层……等等。就连Szegedy本人，也汲取了ResNet的精髓，合体两种网络设计出了Inception-ResNet。所以多读论文，多学习别人的idea，是非常重要的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】未完待续&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>DenseNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/03/DenseNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/03/DenseNet-Introduction/</id>
    <published>2018-12-03T08:39:14.000Z</published>
    <updated>2018-12-03T15:26:59.184Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>原文链接：<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">Densely Connected Convolutional Netwroks</a></p><p>译文链接：<a href="https://zhuanlan.zhihu.com/p/31647627" target="_blank" rel="noopener">DenseNet论文翻译及pytorch实现解析（上）</a>、<a href="https://blog.csdn.net/tumi678/article/details/78667966" target="_blank" rel="noopener">Densely Connected Convolutional Networks翻译</a></p><p>参考链接：<a href="https://blog.csdn.net/u014380165/article/details/75142664" target="_blank" rel="noopener">DenseNet算法详解(ToRead  评价最高)</a>、<a href="https://zhuanlan.zhihu.com/p/28190802" target="_blank" rel="noopener">《Densely Connected Convolutional Networks》论文笔记（精而简）</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络（简明）</a>、<a href="https://www.leiphone.com/news/201708/0MNOwwfvWiAu43WO.html" target="_blank" rel="noopener">DenseNet 的“what”、“why”和“how”(思路清晰)</a>、<a href="https://zhuanlan.zhihu.com/p/43057737" target="_blank" rel="noopener">DenseNet详解(图解清晰)</a></p><p>ToRead：<a href="https://blog.csdn.net/Bryan__/article/details/77337109" target="_blank" rel="noopener">DenseNet 简介(数学说明)</a>、<a href="https://zhuanlan.zhihu.com/p/37189203" target="_blank" rel="noopener">DenseNet：比ResNet更优的CNN模型(形象细致)</a></p><p><strong>DenseNet的优点</strong>：</p><ul><li>减轻梯度消失的问题；</li><li>加强了特征的<code>传导</code>和<code>利用</code>；</li><li>减少了参数量（与ResNet相比，在实现同等准确率的条件下，DenseNet的参数量要小于ResNet）</li><li>减少了计算量</li></ul><h4 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h4><h5 id="Dense-block"><a href="#Dense-block" class="headerlink" title="Dense block"></a><strong>Dense block</strong></h5><p>​    网络的每一层都直接与其前面层相连（可以直接将梯度从后层传向前层），实现<code>特征的重复利用</code>，这就使得网络更加“参数高效”。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure1.jpg" style="zoom:80%"><br></center><h5 id="Transition-layer"><a href="#Transition-layer" class="headerlink" title="Transition layer"></a><strong>Transition layer</strong></h5><p>​    该层位于两个dense block之间，由conv层和pooling层组成。之前说过，在一个dense block里，空间维度是保持不变的，为了能进行下采样，故而在两个dense block之间插入transition layer，进一步减少特征图的数量，提升模型的紧凑程度。</p><h5 id="Growth-rate"><a href="#Growth-rate" class="headerlink" title="Growth rate"></a><strong>Growth rate</strong></h5><p>​    论文里涉及到growth rate这个概念。它指的是一个dense block里各个层输出feature maps的通道数，在同一个dense block里bn-relu-conv输出的通道数都是一样的。如上图，它的growth rate=4。一般，为了不使网络变得太宽，以及增加参数的利用效率，growth rate一般不会设得太大。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table1.jpg"><br></center><h5 id="Bottleneck-layers"><a href="#Bottleneck-layers" class="headerlink" title="Bottleneck layers "></a><strong>Bottleneck layers </strong></h5><p>​    在一个dense block里，尽管每层输出的通道数并不大（growth rate一般不会设得很大），但是输入是由前面层的feature maps串接起来的，所以输入的通道数会很大。为了提高计算效率，作者<code>引进1*1 conv层作为bottleneck layer，放置在每层的前面，用来降低通道数(减小参数量)</code>。带有bottleneck layer的DenseNet被称为DenseNet-B。</p><h5 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a><strong>Compression</strong></h5><p>​    如果transition layer对上一个dense block进行了通道数的降维（即压缩），则称这类DenseNet为    <code>DenseNet-C</code>。同时使用了bottleneck layer和compression的DenseNet称为<code>DenseNet-BC</code>。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure4_left.png"><br></center><p>上图是DenseNet和它的几种变体进行parameter efficiency 的比较，可以看出在实现同等accuracy的条件下，DenseNet-BC所用的参数量最少，实现最大的parameter efficiency。</p><hr><p>完整的DenseNet网络结构：</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure2.png"><br>    <figcaption>Figure 2</figcaption><br></center><p>上图是由三个dense block组成的，两个block之间的conv+pool为transition layer。dense block3后面的pooling是global average pooling，然后再接一个全连接层+softmax。</p><hr><h4 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><strong>算法分析</strong></h4><h5 id="Model-compactness"><a href="#Model-compactness" class="headerlink" title="Model compactness"></a>Model compactness</h5><p>由于DenseNet对输入进行cat操作,一个直观的影响就是每一层学到的feature map都能被之后所有层直接使用,这使得特征可以在整个网络中重用,也使得模型更加简洁.</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure4.jpg"><br></center><p>从上图中我们可以看出DenseNet的参数效率:左图包含了对多种DenseNet结构参数和最终性能的统计,我们可以看出当模型实现相同的test error时,原始的DenseNet往往要比DenseNet-BC拥有2-3倍的参数量.中间图为DenseNet-BC与ResNet的对比,在相同的模型精度下,DenseNet-BC只需要ResNet约三分之一的参数数量.右图为1001层超过10M参数量的ResNet与100层只有0.8M参数量的DenseNet-BC在训练时的对比,虽然他们在约相同的训练epoch时收敛,但DenseNet-BC却只需要ResNet不足十分之一的参数量.</p><h5 id="Implicit-Deep-Supervision"><a href="#Implicit-Deep-Supervision" class="headerlink" title="Implicit Deep Supervision"></a>Implicit Deep Supervision</h5><p>解释DenseNet为何拥有如此高性能的另一个原因是网络中的每一层不仅接受了原始网络中来自loss的监督,同时由于存在多个bypass与shortcut,网络的监督是多样的.Deep supervision的优势同样在deeply-supervised nets (DSN)中也被证实.(DSN中每一个Hidden layer都有一个分类器,强迫其学习一些有区分度的特征).与DSN不同的是,DenseNet拥有单一的loss function, 模型构造和梯度计算更加简易.</p><h5 id="Feature-Reuse"><a href="#Feature-Reuse" class="headerlink" title="Feature Reuse"></a>Feature Reuse</h5><p>在设计初,DenseNet便被设计成让一层网络可以使用所有之前层网络feature map的网络结构,为了探索feature的复用情况,作者进行了相关实验.作者训练的L=40,K=12的DenseNet,对于任意Denseblock中的所有卷积层,计算之前某层feature map在该层权重的绝对值平均数.这一平均数表明了这一层对于之前某一层feature的利用率,下图为由该平均数绘制出的热力图:</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure5.jpg" style="zoom:60%"><br></center><p>从图中我们可以得出以下结论:</p><p>a) 一些较早层提取出的特征仍可能被较深层直接使用<br>b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征<br>c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,即Compression的必要性.<br>d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生.</p><h4 id="实现结果"><a href="#实现结果" class="headerlink" title="实现结果"></a>实现结果</h4><p>作者在多个benchmark数据集上训练了多种DenseNet模型,并与state-of-art的模型(主要是ResNet和其变种)对比:</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table2.jpg"><br></center><p>由上表我们可以看出,DenseNet只需要较小的Growth rate(12,24)便可以实现state-of-art的性能,结合了Bottleneck和Compression的DenseNet-BC具有远小于ResNet及其变种的参数数量,且无论DenseNet或者DenseNet-BC,都在原始数据集和增广数据集上实现了超越ResNet的性能.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ResNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/02/ResNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/02/ResNet-Introduction/</id>
    <published>2018-12-02T11:03:11.000Z</published>
    <updated>2018-12-03T14:35:38.115Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>论文出处：<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>译文链接：<a href="http://blog.csdn.net/wspba/article/details/57074389" target="_blank" rel="noopener">http://blog.csdn.net/wspba/article/details/57074389</a></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/32085715" target="_blank" rel="noopener">ResNet学习笔记</a>、<a href="https://www.jianshu.com/p/46d76bd56766" target="_blank" rel="noopener">深度详解ResNet及其六大变体</a>、<a href="https://www.jianshu.com/p/e58437f39f65" target="_blank" rel="noopener">残差网络ResNet笔记</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络</a></p><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>随着CNN网络的发展，尤其的VGG网络的提出，大家发现网络的层数是一个关键因素，貌似越深的网络效果越好。但是<code>随着网络层数的增加，问题也随之而来</code>。</p><p>首先出现的问题是<strong>梯度消失/梯度爆炸</strong>，这就导致训练难以收敛。<code>归一初始化</code>（normalized initialization）和<code>中间归一化</code>（intermediate normalization）在很大程度上解决了这一问题，它使得数十层的网络在反向传播的随机梯度下降（SGD）上能够收敛。</p><p>当深层网络能够收敛时，一个<strong>退化</strong>问题又出现了：随着网络深度的增加，准确率达到饱和然后迅速退化。意外的是，这种退化<strong>并不是由过拟合造成的</strong>，并且在一个合理的深度模型中增加更多的层却导致了<strong>更高的错误率</strong>。<strong>Fig.1</strong>展示了一个典型的例子：</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 1.jpg" style="zoom:80%"><br></center><br>对于更深的模型，这有一种通过构建的解决方案：<strong>恒等映射identity mapping</strong>(所谓的恒等映射，即输入$x$经过某一个函数（设为$G(x)$）作用输出还是$x$本身，即$G(x)=x$)，来构建增加的层，而其它层直接从浅层模型中复制而来。这个构建的解决方案也表明了，一个更深的模型不应当产生比它的浅层版本更高的训练错误率。但是，<strong>相关的实验结果说明传统的网络（”plain” networks）很难去学习恒等映射</strong>，即会出现因为深度增加而导致性能下降的问题（即使采用了恒等映射方法）。<br><br>#### Identity Mapping by Shortcuts<br><br>本文中，我们提出了一种<strong>深度残差学习</strong>框架来解决这种因为深度增加而导致性能下降的问题。<br>我们假设$F(x)$代表某个只包含有两三层的block的映射函数， $x$ 是block的输入，$F(x)$ 是block的输出。假设他们具有相同的维度。在训练的过程中我们希望能够通过修改网络中的 $w$ 和 $b$ 去拟合一个理想的 $\mathcal{H}(x)$ (从输入到输出的一个理想的映射函数)。也就是我们的目标是修改 $\mathcal{F}(x)$ 中的 $w$ 和 $b$ 逼近 $\mathcal{H}(x)$ 。<br>如果我们改变思路，用$\mathcal{F}(x)$  来逼近$\mathcal{H}(x)-x$，那么我们最终得到bolck的输出$\mathcal{H}(x)$就由 $\mathcal{F}(x)$ 变为$\mathcal{F}(x)+x$ （这里的加指的是对应位置上的元素相加，也就是element-wise addition），这里的直接将输入连接到输出的结构也称为shortcut。 这里我们假设优化残差映射$\mathcal{F}({x})$比优化原来的映射 $\mathcal{H}({x})$容易。<br><br>- 改变前目标： 训练$\mathcal{F}(x)$ 逼近 $\mathcal{H}(x)$<br>- 改变后目标：训练 $\mathcal{F}(x)$ 逼近$\mathcal{H}(x)-x$   (即 $\mathcal{F}(x)+x$ 逼近$\mathcal{H}(x)$)<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 2.1.jpg" style="zoom:80%"><br></center><br>左边的original block需要调整其内部参数，使得输入的x经过卷积操作后最终输出的F(x)等于x，即实现了恒等映射F(x)=x，等号左边是block的输出，右边是block的输入。但是这种结构的卷积网络很难调整其参数完美地实现F(x)=x。再看右边的Res block。因为shortcut的引入，整个block的输出变成了F(x)+x，block的输入还是x。此时网络需要调整其内部参数使得F(x)+x=x，也就是直接令其内部的所有参数为0，使得F(x)=0，F(x)+x=x就变成了0+x = x，等号左边是block的输出，右边是block的输入。输出等于输入，即<strong>完美地完成了恒等映射</strong>。因此使用ResNet结构搭建的深度网络至少与浅层网络具有相同的拟合能力，不会出现之前的网络退化问题。<br><br>——<br><br><br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 2.png" style="zoom:40%"><br></center><br><strong>We consider a building block defined as</strong>：  $\begin{equation} {y}= \mathcal{F}({x}, {W_{i}}) + W_{s}{x}. \end{equation}$<br><br><br>#### Shortcut的三种方式<br><br>由于ResNet要求 $F(x)$与 $x$ 的维度大小要一致才能够相加，因此在$F(x)$ 与$x$ 维度不相同时就需要对$x$的维度做调整，文章中提出了三种调整的方式：<br><br>1. 如果 $x$ 的维度增加，就使用0来填充增加出来的维度（A方式）<br>2. 如果 $x$ 的维度增加，使用线性变换来增加多出来的维度，在程序里表现为使用一个1x1的卷积核进行调整维度（B方式）<br>3. 对于所有的shortcut，都使用线性变换，也就是1x1的卷积（C方式）<br><br>由下面的实验结果可以，分析ABC这三种方式。A方式采用0填充.，完全不存在任何的残差学习能力。B方式与C方式相比，错误率略高。但是B方式的模型复杂度要远低于C方式，因此，作者最终在所有的网络中采用方式B。B方式在 $x$ 的维度与$F(x)$的维度相同时，直接用 $x$ 加上 $F(x)$，在 $x$ 的维度与 $F(x)$的维度不同时，才采用1x1的卷积层对 $x$ 的维度进行调整。<br><br>——<br><br>#### 对ResNet的解读<br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/shortcuts_1.png" style="zoom:80%"><br></center><p>ResNet架构有很多独立有效路径（或者说残差网络其实是很多并行子网络的组合），而且大部分路径在移除了部分层之后会保持完整无损。相反，VGG网络只有一个有效路径，因此移除一个层都会对它的唯一路径的性能产生极大的影响。</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/distribution of path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/gradient magnitude per path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/total gradient magnitude per path length.png" width="200"><br></center><p>图(左)大部分的路径都流经了19到35个残差块。为了得到路径长度k的梯度幅度，作者们首先向网络输入了一批数据，然后任意采样了k个残差块。当反向传递梯度时，他们仅将采样的残差块通过权重层进行传递。图(中)表示随着路径长度的增加，梯度幅度会迅速下降。我们现在可以将每一路径长度与其期望的梯度大小相乘，看每一路径长度在训练中起到多大的作用，就像图(右)。</p><p>令人惊讶的是，大多分布都来自于9到18的路径长度，但它们都只包含少量的总路径（或者说ResNet是由大多数中度网络和一小部分浅度网络和深度网络组成的，说明虽然表面上ResNet网络很深，但是其实起实际作用的网络层数并没有很深。），如图(左)。这是一个非常有趣的发现，因为这暗示着<code>ResNet无法解决过长路径的梯度消失问题</code>，<strong>ResNet的成功实际上源自于它缩短了它的有效路径(effective path)的长度</strong>。</p><p> Stochastic depth通过在训练期间随机丢弃层来改善深度残留网络的训练。这表明并不是所有的层都是需要的，并且强调在深度（剩余）网络中存在大量的冗余。</p><hr><h4 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h4><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 3.png" style="zoom:40%"><br></center><br>Plain Network 主要是受 VGG 网络启发，主要采用<strong>3*3滤波器</strong>，遵循两个设计原则：1）对于相同输出特征图尺寸，卷积层有相同个数的滤波器，2）如果特征图尺寸缩小一半，滤波器个数加倍以保持每个层的计算复杂度。通过<strong>步长为2的卷积</strong>来进行降采样。一共<strong>34个权重层</strong>。<br>需要指出，我们这个网络<code>与VGG相比，滤波器要少，复杂度要小</code>。<br><br>Residual Network 主要是在 上述的 plain network上加入 shortcut connections。<strong>ResNet的结构使得网络具有与学习恒等映射的能力，同时也具有学习其他映射的能力。因此ResNet的结构要优于传统的卷积网络（plain networks）结构。</strong><br><br>#### Experiments<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 3.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 6.png" style="zoom:70%"><br></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Tensorboard_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Tensorboard-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Tensorboard-Morvan/</id>
    <published>2018-12-01T14:08:52.000Z</published>
    <updated>2018-12-01T14:15:06.483Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensorflow) ➜  Morvan_Tensorflow tensorboard --logdir logs</span><br><span class="line">TensorBoard 1.11.0 at http://MacBook-Pro:6006 (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure><ul><li>Chrome</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://0.0.0.0:6006</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/</id>
    <published>2018-12-01T13:18:30.000Z</published>
    <updated>2018-12-01T14:15:38.172Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><p>Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/plt/</a></p><h2 id="Matplotlib简介"><a href="#Matplotlib简介" class="headerlink" title="Matplotlib简介"></a>Matplotlib简介</h2><h3 id="Matplotlib-安装"><a href="#Matplotlib-安装" class="headerlink" title="Matplotlib 安装"></a>Matplotlib 安装</h3><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><h3 id="figure-图像"><a href="#figure-图像" class="headerlink" title="figure 图像"></a>figure 图像</h3><h3 id="设置坐标轴"><a href="#设置坐标轴" class="headerlink" title="设置坐标轴"></a>设置坐标轴</h3><h3 id="Legend图例"><a href="#Legend图例" class="headerlink" title="Legend图例"></a>Legend图例</h3><h3 id="Annotation标注"><a href="#Annotation标注" class="headerlink" title="Annotation标注"></a>Annotation标注</h3><h3 id="tick能见度"><a href="#tick能见度" class="headerlink" title="tick能见度"></a>tick能见度</h3><h2 id="画图种类"><a href="#画图种类" class="headerlink" title="画图种类"></a>画图种类</h2><h3 id="Scatter-散点图"><a href="#Scatter-散点图" class="headerlink" title="Scatter 散点图"></a>Scatter 散点图</h3><h3 id="Bar-柱状图"><a href="#Bar-柱状图" class="headerlink" title="Bar 柱状图"></a>Bar 柱状图</h3><h3 id="Contours-等高线图"><a href="#Contours-等高线图" class="headerlink" title="Contours 等高线图"></a>Contours 等高线图</h3><h3 id="Image-图片"><a href="#Image-图片" class="headerlink" title="Image 图片"></a>Image 图片</h3><h3 id="3D图片"><a href="#3D图片" class="headerlink" title="3D图片"></a>3D图片</h3><h2 id="多图合并显示"><a href="#多图合并显示" class="headerlink" title="多图合并显示"></a>多图合并显示</h2><h3 id="Subplot-多合一显示"><a href="#Subplot-多合一显示" class="headerlink" title="Subplot 多合一显示"></a>Subplot 多合一显示</h3><h3 id="Subplot-分格显示"><a href="#Subplot-分格显示" class="headerlink" title="Subplot 分格显示"></a>Subplot 分格显示</h3><h3 id="图中图"><a href="#图中图" class="headerlink" title="图中图"></a>图中图</h3><h3 id="次坐标轴"><a href="#次坐标轴" class="headerlink" title="次坐标轴"></a>次坐标轴</h3><h2 id="动画"><a href="#动画" class="headerlink" title="动画"></a>动画</h2><h3 id="Animation动画"><a href="#Animation动画" class="headerlink" title="Animation动画"></a>Animation动画</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
&lt;p&gt;Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>numpy&amp;pandas_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/</id>
    <published>2018-12-01T12:10:48.000Z</published>
    <updated>2018-12-01T14:16:13.563Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><a id="more"></a><hr><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/</a></p><h3 id="Numpy-和-Pandas-安装"><a href="#Numpy-和-Pandas-安装" class="headerlink" title="Numpy 和 Pandas 安装"></a>Numpy 和 Pandas 安装</h3><h4 id="numpy-安装"><a href="#numpy-安装" class="headerlink" title="numpy 安装"></a>numpy 安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install numpy</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install numpy</span></span><br></pre></td></tr></table></figure><h4 id="pandas安装"><a href="#pandas安装" class="headerlink" title="pandas安装"></a>pandas安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install pandas</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install pandas</span></span><br></pre></td></tr></table></figure><h3 id="Numpy属性"><a href="#Numpy属性" class="headerlink" title="Numpy属性"></a>Numpy属性</h3><ul><li><code>ndim</code>：维度</li><li><code>shape</code>：行数和列数</li><li><code>size</code>：元素个数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#为了方便使用numpy 采用np简写</span></span><br><span class="line">array = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])  <span class="comment">#列表转化为矩阵</span></span><br><span class="line">print(array)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 2, 3],</span></span><br><span class="line"><span class="string">       [2, 3, 4]])</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">print(<span class="string">'number of dim:'</span>,array.ndim)  <span class="comment"># 维度</span></span><br><span class="line"><span class="comment"># number of dim: 2</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'shape :'</span>,array.shape)    <span class="comment"># 行数和列数</span></span><br><span class="line"><span class="comment"># shape : (2, 3)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'size:'</span>,array.size)   <span class="comment"># 元素个数</span></span><br><span class="line"><span class="comment"># size: 6</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-的创建array"><a href="#Numpy-的创建array" class="headerlink" title="Numpy 的创建array"></a>Numpy 的创建array</h3><ul><li>创建 array 有很多 <a href="https://docs.scipy.org/doc/numpy-dev/user/quickstart.html" target="_blank" rel="noopener">形式</a></li></ul><h4 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a><strong>关键字</strong></h4><ul><li><code>array</code>：创建数组</li><li><code>dtype</code>：指定数据类型</li><li><code>zeros</code>：创建数据全为0</li><li><code>ones</code>：创建数据全为1</li><li><code>empty</code>：创建数据接近0</li><li><code>arrange</code>：按指定范围创建数据</li><li><code>linspace</code>：创建线段</li></ul><h4 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>])  <span class="comment"># list 1d</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># [2 23 4]</span></span><br></pre></td></tr></table></figure><h4 id="指定数据-dtype"><a href="#指定数据-dtype" class="headerlink" title="指定数据 dtype"></a>指定数据 dtype</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int 64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int32</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float32</span></span><br></pre></td></tr></table></figure><h4 id="创建特定数据"><a href="#创建特定数据" class="headerlink" title="创建特定数据"></a>创建特定数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],[<span class="number">2</span>,<span class="number">32</span>,<span class="number">4</span>]])  <span class="comment"># 2d 矩阵 2行3列</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">[[ 2 23  4]</span></span><br><span class="line"><span class="string"> [ 2 32  4]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全零数组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据全为0，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全一数组, 同时也能指定这些特定数据的 dtype:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones((<span class="number">3</span>,<span class="number">4</span>),dtype = np.int)   <span class="comment"># 数据为1，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全空数组, 其实每个值都是接近于零的数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.empty((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据为empty，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  0.00000000e+000,   4.94065646e-324,   9.88131292e-324,   1.48219694e-323],</span></span><br><span class="line"><span class="string">       [  1.97626258e-323,   2.47032823e-323,   2.96439388e-323,   3.45845952e-323],</span></span><br><span class="line"><span class="string">       [  3.95252517e-323,   4.44659081e-323,   4.94065646e-323,   5.43472210e-323]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>arange</code> 创建连续数组:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>,<span class="number">20</span>,<span class="number">2</span>) <span class="comment"># 10-19 的数据，2步长</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([10, 12, 14, 16, 18])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>使用 <code>reshape</code> 改变数据的形状</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>,<span class="number">4</span>))    <span class="comment"># 3行4列，0到11</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">       [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">       [ 8,  9, 10, 11]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>linspace</code> 创建线段型数据:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>)    <span class="comment"># 开始端1，结束端10，且分割成20个数据，生成线段</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([  1.        ,   1.47368421,   1.94736842,   2.42105263,</span></span><br><span class="line"><span class="string">         2.89473684,   3.36842105,   3.84210526,   4.31578947,</span></span><br><span class="line"><span class="string">         4.78947368,   5.26315789,   5.73684211,   6.21052632,</span></span><br><span class="line"><span class="string">         6.68421053,   7.15789474,   7.63157895,   8.10526316,</span></span><br><span class="line"><span class="string">         8.57894737,   9.05263158,   9.52631579,  10.        ])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>同样也能进行 <code>reshape</code> 工作:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>).reshape((<span class="number">5</span>,<span class="number">4</span>)) <span class="comment"># 更改shape</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  1.        ,   1.47368421,   1.94736842,   2.42105263],</span></span><br><span class="line"><span class="string">       [  2.89473684,   3.36842105,   3.84210526,   4.31578947],</span></span><br><span class="line"><span class="string">       [  4.78947368,   5.26315789,   5.73684211,   6.21052632],</span></span><br><span class="line"><span class="string">       [  6.68421053,   7.15789474,   7.63157895,   8.10526316],</span></span><br><span class="line"><span class="string">       [  8.57894737,   9.05263158,   9.52631579,  10.        ]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-基础运算"><a href="#Numpy-基础运算" class="headerlink" title="Numpy 基础运算"></a>Numpy 基础运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.array([<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>])   <span class="comment"># array([10, 20, 30, 40])</span></span><br><span class="line">b=np.arange(<span class="number">4</span>) <span class="comment"># array([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line">c=a-b  <span class="comment"># array([10, 19, 28, 37])   矩阵的减法</span></span><br><span class="line">c=a+b   <span class="comment"># array([10, 21, 32, 43])矩阵的加法</span></span><br><span class="line">c=a*b   <span class="comment"># array([  0,  20,  60, 120])  矩阵的乘法</span></span><br><span class="line"></span><br><span class="line">c=b**<span class="number">2</span>  <span class="comment"># array([0, 1, 4, 9])  乘方</span></span><br><span class="line">c=<span class="number">10</span>*np.sin(a)  <span class="comment"># array([-5.44021111,  9.12945251, -9.88031624,  7.4511316 ]) 三角函数</span></span><br><span class="line">print(b&lt;<span class="number">3</span>)  <span class="comment"># array([ True,  True,  True, False], dtype=bool)  print()逻辑判断</span></span><br></pre></td></tr></table></figure><ul><li>对多行多维度的矩阵进行操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a=np.array([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">b=np.arange(<span class="number">4</span>).reshape((<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[1, 1],</span></span><br><span class="line"><span class="comment">#       [0, 1]])</span></span><br><span class="line"></span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># array([[0, 1],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line"></span><br><span class="line">c_dot = np.dot(a,b)     <span class="comment"># 矩阵乘法，即对应行乘对应列得到相应元素</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line">c_dot_2 = a.dot(b)<span class="comment"># 矩阵乘法(另一写法)</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[ 0.94692159,  0.20821798,  0.35339414,  0.2805278 ],</span></span><br><span class="line"><span class="comment">#       [ 0.04836775,  0.04023552,  0.44091941,  0.21665268]])</span></span><br><span class="line">np.sum(a)   <span class="comment"># 4.4043622002745959   对矩阵中所有元素进行求和</span></span><br><span class="line">np.min(a)   <span class="comment"># 0.23651223533671784  对矩阵中所有元素寻找最小值</span></span><br><span class="line">np.max(a)   <span class="comment"># 0.90438450240606416  对矩阵中所有元素寻找最大值</span></span><br><span class="line"></span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(<span class="string">"a ="</span>,a)</span><br><span class="line"><span class="comment"># a = [[ 0.23651224  0.41900661  0.84869417  0.46456022]</span></span><br><span class="line"><span class="comment"># [ 0.60771087  0.9043845   0.36603285  0.55746074]]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"sum ="</span>,np.sum(a,axis=<span class="number">1</span>))   <span class="comment"># 当axis的值为1的时候，将会以行作为查找单元</span></span><br><span class="line"><span class="comment"># sum = [ 1.96877324  2.43558896]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"min ="</span>,np.min(a,axis=<span class="number">0</span>))   <span class="comment"># 当axis的值为0的时候，将会以列作为查找单元</span></span><br><span class="line"><span class="comment"># min = [ 0.23651224  0.41900661  0.36603285  0.46456022]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"max ="</span>,np.max(a,axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># max = [ 0.84869417  0.9043845 ]</span></span><br></pre></td></tr></table></figure><ul><li>对应元素的<code>索引</code>也是非常重要的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">2</span>,<span class="number">14</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[ 2, 3, 4, 5]</span></span><br><span class="line"><span class="comment">#        [ 6, 7, 8, 9]</span></span><br><span class="line"><span class="comment">#        [10,11,12,13]])</span></span><br><span class="line">         </span><br><span class="line">print(np.argmin(A))    <span class="comment"># 0    求矩阵中最小元素的索引</span></span><br><span class="line">print(np.argmax(A))    <span class="comment"># 11   求矩阵中最大元素的索引</span></span><br><span class="line"></span><br><span class="line">print(np.mean(A))        <span class="comment"># 7.5  计算均值    </span></span><br><span class="line"><span class="comment"># print(A.mean())          # 7.5</span></span><br><span class="line">print(np.average(A))     <span class="comment"># 7.5</span></span><br><span class="line"></span><br><span class="line">print(A.median())       <span class="comment"># 7.5  求解中位数</span></span><br><span class="line"></span><br><span class="line">print(np.cumsum(A)) <span class="comment"># [2 5 9 14 20 27 35 44 54 65 77 90]   累加函数</span></span><br><span class="line"></span><br><span class="line">print(np.diff(A))    <span class="comment"># 累差运算</span></span><br><span class="line"><span class="comment"># [[1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]]</span></span><br><span class="line"></span><br><span class="line">print(np.nonzero(A))    <span class="comment"># 这个函数将所有非零元素的行与列坐标分割开，重构成两个分别关于行和列的矩阵。</span></span><br><span class="line"><span class="comment"># (array([0,0,0,0,1,1,1,1,2,2,2,2]),array([0,1,2,3,0,1,2,3,0,1,2,3]))</span></span><br><span class="line">B = np.array([[<span class="number">0</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">0</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">22</span>, <span class="number">0</span>, <span class="number">33</span>]])</span><br><span class="line">print(np.nonzero(B))<span class="comment">#遍历每一个元素，若其非0，则返回其行/列索引   第一(二)个array返回行(列)索引</span></span><br><span class="line"><span class="comment"># (array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([1, 2, 3, 0, 2, 3, 0, 1, 3]))</span></span><br></pre></td></tr></table></figure><ul><li>排序操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">14</span>,<span class="number">2</span>, <span class="number">-1</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[14, 13, 12, 11],</span></span><br><span class="line"><span class="comment">#       [10,  9,  8,  7],</span></span><br><span class="line"><span class="comment">#       [ 6,  5,  4,  3]])</span></span><br><span class="line"></span><br><span class="line">print(np.sort(A))    <span class="comment"># 仅针对每一行进行从小到大排序操作</span></span><br><span class="line"><span class="comment"># array([[11,12,13,14]</span></span><br><span class="line"><span class="comment">#        [ 7, 8, 9,10]</span></span><br><span class="line"><span class="comment">#        [ 3, 4, 5, 6]])</span></span><br></pre></td></tr></table></figure><ul><li>矩阵的转置有两种表示方法：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(np.transpose(A))    </span><br><span class="line">print(A.T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br></pre></td></tr></table></figure><ul><li>在Numpy中具有<code>clip(Array,Array_min,Array_max)</code>函数：将Array中大于Array_max的元素转换成Array_max，将Array中小于Array_min的元素转换成Array_min</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(A)</span><br><span class="line"><span class="comment"># array([[14,13,12,11]</span></span><br><span class="line"><span class="comment">#        [10, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 4, 3]])</span></span><br><span class="line"></span><br><span class="line">print(np.clip(A,<span class="number">5</span>,<span class="number">9</span>))    </span><br><span class="line"><span class="comment"># array([[ 9, 9, 9, 9]</span></span><br><span class="line"><span class="comment">#        [ 9, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 5, 5]])</span></span><br></pre></td></tr></table></figure><h3 id="Numpy索引"><a href="#Numpy索引" class="headerlink" title="Numpy索引"></a>Numpy索引</h3><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Communication-Technology-Basics-Experiment</title>
    <link href="http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/"/>
    <id>http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/</id>
    <published>2018-12-01T06:43:44.788Z</published>
    <updated>2018-12-01T08:02:06.310Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】通信技术基础上机</p><a id="more"></a><h3 id="基带编码"><a href="#基带编码" class="headerlink" title="基带编码"></a>基带编码</h3><h4 id="example"><a href="#example" class="headerlink" title="example"></a>example</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>];</span><br><span class="line">num=<span class="number">0</span>;</span><br><span class="line">yn = xn;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span> xn(<span class="built_in">i</span>)==<span class="number">1</span></span><br><span class="line">        num = num+<span class="number">1</span>;</span><br><span class="line">        yn(<span class="built_in">i</span>) = yn(<span class="built_in">i</span>)+ num;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-1</span> <span class="number">8</span>]);grid on</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/example.jpg"><br></center><h4 id="AMI码"><a href="#AMI码" class="headerlink" title="AMI码"></a>AMI码</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=+<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                   <span class="comment">% 以上部分完成AMI码编码</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/AMI.jpg"><br></center><h4 id="HDB3"><a href="#HDB3" class="headerlink" title="HDB3"></a>HDB3</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line"><span class="comment">% xn = [1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1];</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>   </span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line"><span class="comment">% HDB3编码 </span></span><br><span class="line">num=<span class="number">0</span>;  <span class="comment">% 连零计数器初始化 </span></span><br><span class="line">yh=yn;  <span class="comment">% 输出初始化 </span></span><br><span class="line"><span class="built_in">sign</span>=<span class="number">0</span>; <span class="comment">% 极性标志初始化为0 </span></span><br><span class="line">nonzero=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(yn)    </span><br><span class="line">    <span class="keyword">if</span> yn(k)==<span class="number">0</span>        </span><br><span class="line">        num=num+<span class="number">1</span>;  <span class="comment">% 连“0”个数计数        </span></span><br><span class="line">        <span class="keyword">if</span> num==<span class="number">4</span>   <span class="comment">% 如果4连“0”          </span></span><br><span class="line">            num=<span class="number">0</span>;    <span class="comment">% 计数器清零 </span></span><br><span class="line">            yh(k)= nonzero;              <span class="comment">% 让0000的最后一个0改变为与前一个非零符号相同极性的符号          </span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> yh(k)==<span class="built_in">sign</span>     <span class="comment">% 如果当前V符号与前一个V符号的极性相同             </span></span><br><span class="line">                yh(k)=<span class="number">-1</span>*yh(k); <span class="comment">% 则让当前V符号极性反转,以满足V符号间相互极性反转要求             </span></span><br><span class="line">                yh(k<span class="number">-3</span>)=yh(k);  <span class="comment">% 添加B符号,与V符号同极性     </span></span><br><span class="line">                       </span><br><span class="line">                 yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn))=<span class="number">-1</span>*yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn));   <span class="comment">% 并让后面的非零符号从V符号开始再交替变化          </span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">          <span class="built_in">sign</span>=yh(k);          <span class="comment">% 记录前一个V符号的极性</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        num=<span class="number">0</span>;                <span class="comment">% 当前输入为“1”则连“0”计数器清零   </span></span><br><span class="line">        nonzero = yn(k);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                         <span class="comment">% 编码完成</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yh);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/HDB3.jpg"><br></center><h4 id="Manchester"><a href="#Manchester" class="headerlink" title="Manchester"></a>Manchester</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">close all</span><br><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">t=<span class="number">0</span>:<span class="number">1</span>:<span class="number">2</span>*<span class="built_in">length</span>(xn)<span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span>(xn(<span class="built_in">i</span>)==<span class="number">1</span>)   <span class="comment">%manchester code "1"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">-1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span>           <span class="comment">%manchester code "0"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">stairs(t,yn);</span><br><span class="line">axis([<span class="number">0</span> length(yn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/Manchester.jpg"><br></center><h3 id="数字调制技术"><a href="#数字调制技术" class="headerlink" title="数字调制技术"></a>数字调制技术</h3><h4 id="DPSK"><a href="#DPSK" class="headerlink" title="DPSK"></a>DPSK</h4><p>参数设置Block Parameters <code>DPSK // DPSK_1(PPt)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">- Bernoulli Binary Generator   </span><br><span class="line">- Source of initial seed: Parameter</span><br><span class="line">- Initial seed: 50</span><br><span class="line">- Output data type: single</span><br><span class="line"></span><br><span class="line">- Differential Encoder</span><br><span class="line">- Initial conditions: 0.05</span><br><span class="line"></span><br><span class="line">- Unipolar to Bipolar Converter</span><br><span class="line">- M-ary number:2</span><br><span class="line">- Output data type:Same as input</span><br><span class="line"></span><br><span class="line">- Sine Wave </span><br><span class="line">- Amplitude: 2  // 1</span><br><span class="line">- Frequency(rad/sec):4*2*pi // 40*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Analog Filter Design</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter order:8 // 4</span><br><span class="line">- Lower passband edge frequency (rad/s): 2*pi // 2*2*pi</span><br><span class="line">- Upper passband edge frequency (rad/s): 10*pi // 7*2*pi</span><br><span class="line"></span><br><span class="line">- Transport Delay</span><br><span class="line">- Time delay: 0.318*pi</span><br><span class="line"></span><br><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:4</span><br><span class="line">- Passband edge frequency (rad/s): 2*2*pi  // 3*2*pi</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0.3</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h4 id="2FSK"><a href="#2FSK" class="headerlink" title="2FSK"></a>2FSK</h4><p>参数设置Block Parameters    <code>(文件参数) //(PPT参数)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 10*pi (与结果图Scope11一致) // 80</span><br><span class="line"></span><br><span class="line">- Analog Filter Design2</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 20*pi  // 20</span><br><span class="line"></span><br><span class="line">- Sine Wave3</span><br><span class="line">- Frequency(rad/sec):20*pi // 80*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Subtract</span><br><span class="line">- Icon shape:rectangular// round</span><br><span class="line">- List of signs:+-</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0 // 0.3(与结果图Scope15一致)</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h3 id="PCM-DM"><a href="#PCM-DM" class="headerlink" title="PCM_DM"></a>PCM_DM</h3><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clear;</span><br><span class="line">t=<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>),plot(t,a);title(<span class="string">'Original signal'</span>);</span><br><span class="line"></span><br><span class="line">ts=<span class="number">0.05</span>;</span><br><span class="line">t=<span class="number">0</span>:ts:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),stem(t,a);title(<span class="string">'Sampling signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_u,aquan8_u,code8_u]=u_pcm1(a,<span class="number">8</span>);  </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">3</span>),stem(t,aquan8_u);</span><br><span class="line">title(<span class="string">'Uniformly quantized signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_A,aquan8_A,code8_A]=A_pcm1(a,<span class="number">8</span>);   axis([<span class="number">0</span> <span class="number">4</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">4</span>),stem(t,aquan8_A);</span><br><span class="line">title(<span class="string">'A-law quantized signal'</span>);</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/PCM_DM_example.jpg"><br></center><h5 id="u-pcm1"><a href="#u-pcm1" class="headerlink" title="u_pcm1"></a>u_pcm1</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">u_pcm1</span><span class="params">(a,n)</span> </span></span><br><span class="line">amax=max(a);</span><br><span class="line">amin=min(a);</span><br><span class="line">delta=(amax-amin)/n;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n+<span class="number">1</span></span><br><span class="line">    m(<span class="built_in">i</span>)=amin+(<span class="built_in">i</span><span class="number">-1</span>)*delta;</span><br><span class="line"><span class="keyword">end</span><span class="comment">%%量化间隔</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n</span><br><span class="line">    q(<span class="built_in">i</span>)=(m(<span class="built_in">i</span>)+m(<span class="built_in">i</span>+<span class="number">1</span>))/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span>    </span><br><span class="line"><span class="comment">%量化值的计算 </span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n  </span><br><span class="line">    index=<span class="built_in">find</span>((q(<span class="built_in">i</span>)-delta/<span class="number">2</span> &lt;= a) &amp; (a &lt;= q(<span class="built_in">i</span>)+delta/<span class="number">2</span>)); <span class="comment">%%找到处于某个量化间隔的所有抽样点</span></span><br><span class="line">    aq(index)=q(<span class="built_in">i</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(index));  <span class="comment">%%利用qi作为该量化间隔的抽样值的量化值</span></span><br><span class="line">    q_index(<span class="built_in">find</span>((aq==q(<span class="built_in">i</span>))))=(<span class="built_in">i</span><span class="number">-1</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(<span class="built_in">find</span>(aq==q(<span class="built_in">i</span>)))); <span class="comment">%%得到量化索引</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">% %PCM编码——二进制编码</span></span><br><span class="line">code=dec2bin(q_index);</span><br><span class="line"></span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(a)/norm(a-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h5 id="A-pcm1"><a href="#A-pcm1" class="headerlink" title="A_pcm1"></a>A_pcm1</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">A_pcm1</span><span class="params">(x,n)</span> </span></span><br><span class="line">A=<span class="number">87.6</span>;</span><br><span class="line">[amax,amin,y]=A_compress(x,A);</span><br><span class="line"></span><br><span class="line">[sqnr,y_q,code]=u_pcm1(y,n);</span><br><span class="line">aq=A_expand(y,A);</span><br><span class="line">aq=aq*(amax-amin)/<span class="number">2</span>;</span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(x)/norm(x-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h6 id="A-compress"><a href="#A-compress" class="headerlink" title="A_compress"></a>A_compress</h6><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[amax,amin,y]</span> = <span class="title">A_compress</span><span class="params">(x,A)</span></span></span><br><span class="line">amax=max(x);</span><br><span class="line">amin=min(x);</span><br><span class="line">x=<span class="number">2</span>*x/(amax-amin);</span><br><span class="line">y=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(x));</span><br><span class="line"><span class="comment">%%A律压缩</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(x(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/A </span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h6 id="A-expand"><a href="#A-expand" class="headerlink" title="A_expand"></a>A_expand</h6><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">x</span>=<span class="title">A_expand</span><span class="params">(y,A)</span></span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(y)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(y(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/(<span class="number">1</span>+<span class="built_in">log</span>(A)); </span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))/A;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>)).*<span class="built_in">exp</span>(<span class="built_in">abs</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))<span class="number">-1</span>)/A;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h4 id="DM1"><a href="#DM1" class="headerlink" title="DM1"></a>DM1</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">% ch6example13prog1.m</span></span><br><span class="line"> clc;clear all</span><br><span class="line">Ts=<span class="number">1e-3</span>;                                <span class="comment">%采样间隔</span></span><br><span class="line">t=<span class="number">0</span>:Ts:<span class="number">20</span>*<span class="number">1e-3</span>;                           <span class="comment">%仿真时间序列</span></span><br><span class="line">x=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">50</span>*t)+<span class="number">0.5</span>*<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">150</span>*t);   <span class="comment">%信号</span></span><br><span class="line">delta=<span class="number">0.7</span>;                              <span class="comment">%量化阶距</span></span><br><span class="line">D(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                       <span class="comment">%预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)                       </span><br><span class="line">    e(k)=x(k)-D(k);  <span class="comment">%误差信号</span></span><br><span class="line">    <span class="keyword">if</span> e(k)&gt;=<span class="number">0</span></span><br><span class="line">        e_q(k)=delta;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        e_q(k)=-delta;</span><br><span class="line">    <span class="keyword">end</span>                <span class="comment">%量化器输出</span></span><br><span class="line">    D(k+<span class="number">1</span>)=e_q(k)+D(k);                 <span class="comment">%预测器输出</span></span><br><span class="line">    codeout(k)=(e_q(k)&gt;<span class="number">0</span>);              <span class="comment">%编码输出</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);plot(t,x,<span class="string">'-o'</span>);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);hold on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs(t,codeout);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">                                        <span class="comment">%解码端</span></span><br><span class="line">Dr(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                      <span class="comment">%解码端预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)</span><br><span class="line">    <span class="keyword">if</span> codeout(k)==<span class="number">0</span></span><br><span class="line">        eq(k)=-delta;</span><br><span class="line">    <span class="keyword">else</span> eq(k)=delta;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    xr(k)=eq(k)+Dr(k);</span><br><span class="line">    Dr(k+<span class="number">1</span>)=xr(k);                      <span class="comment">%延迟器状态更新</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs(t,xr);hold on;    <span class="comment">%解码输出</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);plot(t,x);               <span class="comment">%原信号</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/DM1.jpg"><br></center><h3 id="差错控制"><a href="#差错控制" class="headerlink" title="差错控制"></a>差错控制</h3><h4 id="CRC16"><a href="#CRC16" class="headerlink" title="CRC16"></a>CRC16</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% CRC 编码主程序</span></span><br><span class="line">clear;clc;close all;</span><br><span class="line">uncode_sequence=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">sequence_length = <span class="built_in">length</span>(uncode_sequence);            <span class="comment">% 得到原始信号长度</span></span><br><span class="line">crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">crc_length=<span class="built_in">length</span>(crc_ccitt)<span class="number">-1</span>;</span><br><span class="line">add_bit = <span class="built_in">zeros</span>(<span class="number">1</span>,crc_length);                                 <span class="comment">% 添加冗余比特位</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence add_bit];            <span class="comment">% 初始化输出检错码序列</span></span><br><span class="line">remainder_bits = [uncode_sequence add_bit];                     <span class="comment">% 初始化余数数组</span></span><br><span class="line"><span class="keyword">for</span> k = <span class="number">1</span>:sequence_length                 <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">    add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,sequence_length-k); <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">    register_bits = [crc_ccitt add_zeros];  <span class="comment">% 构造除数数组</span></span><br><span class="line">    <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>        <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">        register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    remainder_bits = bitxor(register_bits,remainder_bits); <span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">register_bits = crc_ccitt;                        <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">remainder_bits(<span class="number">1</span>) = [];                 <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence remainder_bits]    <span class="comment">% 生成余数序列的冗余位以叠加到编码序列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%%CRC解码</span></span><br><span class="line">error=randint(<span class="number">1</span>,<span class="built_in">length</span>(crc_coded_sequence));<span class="comment">%%信道误码</span></span><br><span class="line"><span class="comment">% error=round(1*rand(1,length(crc_coded_sequence)));%%信道误码    %若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">crc_coded_sequence=bitxor(crc_coded_sequence,error);<span class="comment">%%接收码组 </span></span><br><span class="line">sequence_length = <span class="built_in">length</span>(crc_coded_sequence);         <span class="comment">% 得到编码的长度</span></span><br><span class="line">original_sequence = crc_coded_sequence;                  <span class="comment">% 初始化输出序列 </span></span><br><span class="line">        crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">        remainder_bits = crc_coded_sequence;           <span class="comment">% 初始化余数数组</span></span><br><span class="line">        cycle_length = sequence_length-<span class="built_in">length</span>(crc_ccitt)+<span class="number">1</span>;  <span class="comment">% 计算长除法的循环周期        </span></span><br><span class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:cycle_length            <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">            add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,cycle_length-k);       <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">            register_bits = [crc_ccitt add_zeros];        <span class="comment">% 构造除数数组</span></span><br><span class="line">            <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>     <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">                register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            remainder_bits = bitxor(register_bits,remainder_bits);<span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">            register_bits = crc_ccitt;            <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">            remainder_bits(<span class="number">1</span>) = [];      <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">if</span> sum(remainder_bits) == <span class="number">0</span>       <span class="comment">% 传输码元中没有发生个错误</span></span><br><span class="line">            original_sequence = crc_coded_sequence(<span class="number">1</span>:cycle_length)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            err = <span class="number">1</span>                             <span class="comment">% 码元传输发生错误</span></span><br><span class="line">        <span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">err =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>若注释掉”信道误码”和”接受码组”，Result：</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">original_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="汉明码"><a href="#汉明码" class="headerlink" title="汉明码"></a>汉明码</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">clc;clear all;</span><br><span class="line">K=<span class="number">4</span>;</span><br><span class="line">N=<span class="number">7</span>;</span><br><span class="line">msg=randint(<span class="number">1</span>,K) <span class="comment">%%生成随机信息位   </span></span><br><span class="line"><span class="comment">% msg=round(1*rand(1,K)) %%生成随机信息位%若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">[H,G] = hammgen(N-K) <span class="comment">%%生成汉明码的生成矩阵和校验矩阵</span></span><br><span class="line">code=encode(msg,N,K,<span class="string">'linear/binary'</span>,G) <span class="comment">%%汉明码编码</span></span><br><span class="line">noise=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>];</span><br><span class="line">code_noise=bitxor(code,noise)</span><br><span class="line">rcv=decode(code_noise,N,K,<span class="string">'linear/binary'</span>,G)</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">msg =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">H =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">G =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code_noise =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">rcv =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">     </span><br><span class="line"># msg 与 rcv 保持一致即可</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】通信技术基础上机&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ADNI模态数据概念整理</title>
    <link href="http://yoursite.com/2018/11/30/ADNI%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2018/11/30/ADNI模态数据概念整理/</id>
    <published>2018-11-30T13:32:50.000Z</published>
    <updated>2018-11-30T13:57:42.874Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>最近需要了解ADNI（Alzheimer’s Disease Neuroimaging Initiative）数据集，刚在网站上注册和提交了<a href="https://ida.loni.usc.edu/services/Menu/IdaData.jsp?page=DATA&amp;subPage=AVAILABLE_DATA" target="_blank" rel="noopener">申请</a>（审核通过了才能下载数据集），审核时间大概是一周。暂时无法查看数据集内容，亦无法下载。无奈只好在再次回顾<a href="http://adni.loni.usc.edu/data-samples/data-types/" target="_blank" rel="noopener">ADNI Data Type</a> 相关说明。同时从同学处获取部分Nifti离线文件，并进行python读取文件数据。</p><h4 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h4><h5 id="Clinical-Data"><a href="#Clinical-Data" class="headerlink" title="Clinical Data"></a>Clinical Data</h5><p>ADNI临床数据集包括关于每个受试者的<code>临床信息</code>，包括招募，人口统计学，身体检查和认知评估数据。可以将整套临床数据作为逗号分隔值（CSV）文件批量下载。</p><p><img src="http://adni.loni.usc.edu/wp-content/uploads/2010/09/clinical-data-chart.png" style="zoom:60%"></p><ul><li><p>Demographics 人口统计学、Neurological Exam 神经系统检查、Screening Labs 筛选实验室 、Vital Signs 生命体征、Cognitive Assessments 认知评估、Biospecimen Collections 生物样本收集、 Medications 药物、Diagnostic Summary 诊断摘要、Lumbar Puncture 腰椎穿刺</p></li><li><p>Screening 筛选、Baseline 基线 、Month 3 、Month 6 、Month 12 、 Month 18 、Month 24 、Month36 、Month48 、Ongoing Annual Follow-up  当前进行的年度跟进</p></li></ul><h5 id="Gennetic-Data"><a href="#Gennetic-Data" class="headerlink" title="Gennetic Data"></a>Gennetic Data</h5><p>遗传因素在阿尔茨海默病中起重要作用。全基因组关联研究（<code>GWAS</code>）采用标记之间关联的测试，称为单核苷酸多态性（<code>SNP</code>）和感兴趣的表型。来自病例对照GWAS和其他类型的遗传关联研究的发现可以提供用于检查源自ADNI成像和其他生物标志物数据集的定量表型的目标。</p><p><code>APOE的4等位基因</code>是已知的AD最强大的遗传风险因素，如果拥有一个4等位基因的人患AD的风险增加了2- 3倍，那么如果有两个等位基因的人患AD的风险增加了12倍。</p><h5 id="MR-Image-Data"><a href="#MR-Image-Data" class="headerlink" title="MR Image Data"></a>MR Image Data</h5><p>MRI – <code>核磁共振成像</code>是根据有磁矩的原子核在磁场作用下，能产生能级间的跃迁的原理采用的技术。MRI对脑内低度星形胶质细胞瘤、神经节、神经胶质瘤、动静脉畸形和血肿等的诊断确认率极高。MRI能清楚地显示癫痫患者的脑萎缩，对脑实质和脑脊液的显示度极好。</p><p>原始，预处理和后处理图像文件，FMRI和DTI 这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/MRI.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>该项目将收集MRI（结构，扩散加权成像，灌注和静息状态序列）; 使用florbetapir F18（florbetapir）或florbetaben F18（florbetaben）的淀粉样蛋白PET; 18F-FDG-PET（FDG-PET）; CSF用于Aβ，tau，磷酸化tau（AKA磷酸化酶）和其他蛋白质; AV-1451 PET; 和遗传和尸检数据，以<code>确定这些生物标志物与基线临床状态和认知下降的关系</code>。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-47b425d8cdc1ff7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="PET-Image-Data"><a href="#PET-Image-Data" class="headerlink" title="PET Image Data"></a>PET Image Data</h5><p>正电子发射计算机断层扫描的大致方法是，将某种物质，一般是生物生命代谢中必须的物质，如：葡萄糖、蛋白质、核酸、脂肪酸，标记上短寿命的放射性核素（如18F，11C等），注入人体后，通过对于该物质在代谢中的聚集，来反映生命代谢活动的情况，从而达到诊断的目的。</p><p>其中：18F-FDG是指氟代脱氧葡萄糖，其完整的化学名称为2-氟-2-脱氧-D-葡萄糖，通常简称为FDG。葡萄糖是人体三大能源物质之一，将可以被PET探测并形成影像的的正电子核素18F标记在葡萄糖上。</p><p>原始，预处理和后处理图像文件，PIB（ADNI1），FDG（ADNI1 / GO / 2），FLORBETAPIR（ADNI GO / 2/3），FLORBETABEN（ADNI3）和TAU IMAGING（ADNI3）这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-1.png" alt="an overview of the PET data collected throughout the ADNI study" title="">                </div>                <div class="image-caption">an overview of the PET data collected throughout the ADNI study</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-Image-Data.png" alt="AVAILABLE IMAGE DATA" title="">                </div>                <div class="image-caption">AVAILABLE IMAGE DATA</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-508b820355abe639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="Biospecimen-Data"><a href="#Biospecimen-Data" class="headerlink" title="Biospecimen Data"></a>Biospecimen Data</h5><p>ADNI的目标之一是收集参与者的<code>血液</code>，<code>尿液</code>和<code>脑脊液（CSF）</code>等生物样本(Biospecimen Data)。鼓励有兴趣的调查员，无论是否与ADNI网站相关联，都可以申请使用这种有限的资源。但是，除非初步数据显示出明显优越的性能，否则不建议将ADNI样本用于技术开发或不同技术之间的比较。</p><p>此外，adni生物标记核心所执行的几项分析结果将在数据存档中提供如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- Homocysteine</span><br><span class="line">- Species of isoprostanes</span><br><span class="line">- CSF tau, sAPPβ levels, BACE levels, and enzyme activity</span><br><span class="line">- Plasma Aβ 40 and Aβ 42</span><br><span class="line">- Other promising CSF and plasma based on ongoing multiplex immunoassay studies and mass - spectrometry MRM studies</span><br></pre></td></tr></table></figure><h4 id="python-读取nifti数据"><a href="#python-读取nifti数据" class="headerlink" title="python 读取nifti数据"></a>python 读取nifti数据</h4><ul><li>使用nifti数据 23.6 MB   </li></ul><figure><br>    <img src="/2018/11/30/ADNI模态数据概念整理/nii_example.png" style="zoom:80%"><br></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># show the nii_data.shape</span></span><br><span class="line">nii_file = <span class="string">"ADNI_011_S_0010_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20061208114538147_S8800_I32270.nii"</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line">img = np.squeeze(img)</span><br><span class="line">print(<span class="string">"img.shape"</span>,img.shape) <span class="comment"># img.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.shape"</span>,data.shape) <span class="comment"># data.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.affine.shape"</span>,data.affine.shape)  <span class="comment"># data.affine.shape (4, 4)</span></span><br><span class="line"><span class="comment"># print(data.header) #数据头信息  输出信息于Result列出</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取slice信息生成图像</span></span><br><span class="line"><span class="comment"># 把slice数据生成图片的方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span><span class="params">(slices)</span>:</span></span><br><span class="line"></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">1</span>, len(slices))</span><br><span class="line">    <span class="keyword">for</span> i, slice <span class="keyword">in</span> enumerate(slices):</span><br><span class="line">        axes[i].imshow(slice.T, cmap=<span class="string">"gray"</span>, origin=<span class="string">"lower"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取nifti文件中的slice数据</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取单张slice数据</span></span><br><span class="line">slice_0 = img[<span class="number">26</span>, :, :]</span><br><span class="line">slice_1 = img[:, <span class="number">30</span>, :]</span><br><span class="line">slice_2 = img[:, :, <span class="number">16</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成图表</span></span><br><span class="line">show_img([slice_0, slice_1, slice_2])</span><br><span class="line">plt.suptitle(<span class="string">"show slice image"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">img.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.affine.shape (<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">&lt;class 'nibabel.nifti1.Nifti1Header'&gt; object, endian='&gt;'</span><br><span class="line">sizeof_hdr      : <span class="number">348</span></span><br><span class="line">data_type       : <span class="string">b''</span></span><br><span class="line">db_name         : <span class="string">b'011_S_0010'</span></span><br><span class="line">extents         : <span class="number">0</span></span><br><span class="line">session_error   : <span class="number">0</span></span><br><span class="line">regular         : <span class="string">b'r'</span></span><br><span class="line">dim_info        : <span class="number">0</span></span><br><span class="line">dim             : [  <span class="number">3</span> <span class="number">192</span> <span class="number">192</span> <span class="number">160</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>]</span><br><span class="line">intent_p1       : <span class="number">0.0</span></span><br><span class="line">intent_p2       : <span class="number">0.0</span></span><br><span class="line">intent_p3       : <span class="number">0.0</span></span><br><span class="line">intent_code     : none</span><br><span class="line">datatype        : float32</span><br><span class="line">bitpix          : <span class="number">32</span></span><br><span class="line">slice_start     : <span class="number">0</span></span><br><span class="line">pixdim          : [<span class="number">1.</span>        <span class="number">1.2447063</span> <span class="number">1.2507237</span> <span class="number">1.2010667</span> <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span></span><br><span class="line"> <span class="number">1.</span>       ]</span><br><span class="line">vox_offset      : <span class="number">0.0</span></span><br><span class="line">scl_slope       : nan</span><br><span class="line">scl_inter       : nan</span><br><span class="line">slice_end       : <span class="number">0</span></span><br><span class="line">slice_code      : unknown</span><br><span class="line">xyzt_units      : <span class="number">2</span></span><br><span class="line">cal_max         : <span class="number">0.0</span></span><br><span class="line">cal_min         : <span class="number">0.0</span></span><br><span class="line">slice_duration  : <span class="number">0.0</span></span><br><span class="line">toffset         : <span class="number">0.0</span></span><br><span class="line">glmax           : <span class="number">1721</span></span><br><span class="line">glmin           : <span class="number">0</span></span><br><span class="line">descrip         : <span class="string">b'MPR; GradWarp; B1 Correction; N3; Scaled'</span></span><br><span class="line">aux_file        : <span class="string">b'none'</span></span><br><span class="line">qform_code      : scanner</span><br><span class="line">sform_code      : unknown</span><br><span class="line">quatern_b       : <span class="number">0.70710677</span></span><br><span class="line">quatern_c       : <span class="number">-1.0713779e-09</span></span><br><span class="line">quatern_d       : <span class="number">-0.70710677</span></span><br><span class="line">qoffset_x       : <span class="number">94.87749</span></span><br><span class="line">qoffset_y       : <span class="number">165.8339</span></span><br><span class="line">qoffset_z       : <span class="number">115.27711</span></span><br><span class="line">srow_x          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_y          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_z          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">intent_name     : <span class="string">b''</span></span><br><span class="line">magic           : <span class="string">b'n+1'</span></span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/11/30/ADNI模态数据概念整理/show" alt="show slice image" title="slice">                </div>                <div class="image-caption">slice</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>VGG_Introduction</title>
    <link href="http://yoursite.com/2018/11/30/VGG_Introduction/"/>
    <id>http://yoursite.com/2018/11/30/VGG_Introduction/</id>
    <published>2018-11-30T07:13:36.000Z</published>
    <updated>2018-11-30T09:12:26.958Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>论文出处：<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/41423739" target="_blank" rel="noopener">一文读懂VGG网络</a>\VGG模型论文译文<a href="https://zhuanlan.zhihu.com/p/34851133" target="_blank" rel="noopener">(上)</a><a href="https://zhuanlan.zhihu.com/p/35516173" target="_blank" rel="noopener">(下)</a></p><h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>VGG16相比AlexNet的一个改进是<strong>采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）</strong>。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p><p>简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p><p>比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 $3\times(3^2C^2)= 27C^2$，如果直接使用7x7卷积核，其参数总量为  $7^2C^2 = 49C^2$，这里 C 指的是输入和输出的通道数。很明显，$27C^2$小于$49C^2$，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</p><p><strong>这里解释一下为什么使用2个3x3卷积核可以来代替5*5卷积核：</strong></p><p>5x5卷积看做一个小的全连接网络在5x5区域滑动，我们可以先用一个3x3的卷积滤波器卷积，然后再用一个全连接层连接这个3x3卷积输出，这个全连接层我们也可以看做一个3x3卷积层。这样我们就可以用两个3x3卷积级联（叠加）起来代替一个 5x5卷积。</p><center><br>    <img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Mini-network replacing the 5x5 convolutions.jpg" alt="missing"><br>    <figcaption>Mini-network replacing the 5x5 convolutions</figcaption><br></center><h5 id="VGG优缺点"><a href="#VGG优缺点" class="headerlink" title="VGG优缺点"></a><strong>VGG优缺点</strong></h5><p><strong>VGG优点</strong></p><ul><li>VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</li><li>几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：</li><li>验证了通过不断加深网络结构可以提升性能。</li></ul><p><strong>VGG缺点</strong></p><ul><li>VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！</li></ul><p>PS：有的文章称：发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</p><p>注：很多pretrained的方法就是使用VGG的model（主要是16和19），VGG相对其他的方法，参数空间很大，最终的model有500多m，AlexNet只有200m，GoogLeNet更少，所以train一个vgg模型通常要花费更长的时间，所幸有公开的pretrained model让我们很方便的使用。</p><hr><p>以下是论文的详细介绍，深入了解细节，有助于对其进行实现。</p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>在本文中，我们研究了大规模图像识别任务下卷积网络<code>深度</code>对其<code>预测准确率</code>的影响。 我们的主要贡献是使用具有非常小的（<code>3×3</code>）卷积滤波器的架构对<code>深度不断递增</code>的网络进行全面评估，结果表明通过将权重层深度推到<code>16-19层</code>可以在现有技术配置下（使准确率）实现显著提升。</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在本文中，我们解决了ConvNet架构设计的另一个重要方面 - 它的深度。 为此，我们修复了架构的其他参数，并通过添加更多卷积层来稳定增加网络深度，由于在所有层中都使用了非常小的（3×3）卷积滤波器，这是可行的。</p><h4 id="卷积网络配置"><a href="#卷积网络配置" class="headerlink" title="卷积网络配置"></a>卷积网络配置</h4><h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5><p>在训练期间，我们ConvNets的输入是固定尺寸的224×224 RGB图像。我们所做的<code>唯一预处理</code>是从每个像素中减去在训练集上计算的RGB均值。图像通过一叠卷积层，我们使用了感受野非常小的卷积核：<code>3×3</code>（这是左/右，上/下，中心点概念可捕获的最小尺寸）。在<code>其中一种</code>配置中，我们还使用<code>1×1</code>卷积滤波器，这可以看作是输入通道的线性变换（随后是非线性）。卷积步长固定为1个像素；卷积层的空间填充是指使得在卷积操作后保留原空间的分辨率，比如使用3×3 卷积核，就填充<strong>1</strong>个像素。空间池化是由五个最大池化层完成的，每个池化层前面都会有若干个卷积层（并非所有的卷积层后都使用最大池化层）。 最大池化是以2×2像素窗口上执行，步幅为<strong>2</strong>。</p><p>一堆卷积层（在不同的体系结构中具有不同的深度）之后是<code>三个完全连接（FC）层</code>：前两个具有4096个通道，第三个执行1000路ILSVRC分类，因此包含1000个通道（一个 为每个类）。 最后一层是<strong>soft-max</strong>层。 全连接层的配置在所有网络中都是相同的。</p><p><code>所有隐藏层都配备了ReLU激活函数</code>。 我们注意到我们的网络（除了一个网络）都没有包含局部响应归一化层（LRN）标准化（Krizhevsky et al。，2012）。 如第4部分所示，<code>这种标准化不会提升ILSVRC数据集的性能</code>，但会导致内存消耗和计算时间的增加。 在使用的情况下，LRN层的参数是（Krizhevsky et al。，2012）的参数</p><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://pic2.zhimg.com/v2-7a0f9391fbdab0f5c3e8c61693ebe205_r.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>本文中评估的ConvNet配置在表1中列出，每列一个。 我们将以他们的名字（A-E）来提及。 所有的配置都遵循2.1节中提到的通用设计，并且仅在深度上有所不同：从网络A中的11个权重层（<code>8个卷积层和3个全连接层</code>）到网络E中的19个权重层（<code>16个卷积层和3个全连接层</code>）。卷积层的宽度（<code>通道数量</code>）相当小，从第一层的64开始，然后在<code>每个最大池层后增加1倍</code>，直到达到512。在表2中，我们报告了每个配置的参数数目。 尽管深度很大，但我们网络的权重数量不会超过那些深度较浅、但卷积核和感受野宽度更大的网络。</p><ul><li>VGG16包含了16个隐藏层（13个卷积层和3个全连接层），如上图中的D列所示</li><li>VGG19包含了19个隐藏层（16个卷积层和3个全连接层），如上图中的E列所示</li></ul><p>VGG网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的max pooling。</p><hr><h5 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h5><p>我们整体都使用了非常小的<code>3x3卷积核</code>配合<code>步幅1</code>。显而易见的是，用两层的3x3卷积层组合（中间不包含池化层）所得到的感受野相当于一层的5x5卷积层的感受野；而三层这样的卷积层组合所得到的感受野相当于一层的7x7卷积核的感受野。那么，如果我们用三层3x3的卷积层组合来代替一层7x7卷积层，我们会得到什么呢？首先，我们并入了三个ReLU激活函数，而不是一个，这使决策功能的分辨力更强。 其次，我们减少参数的数量：假设三层3×3卷积层相叠的输入和输出都具有C个通道，则该叠层参数化为$3\times(3^2C^2)= 27C^2$个权重; 同时，一个7×7 卷积层需要$7^2C^2 = 49C^2$ 参数，参数增加81％。 这可以被看作是在7×7卷积中实施正规化， 迫使他们通过3×3卷积核进行分解（两者之间注入非线性）。</p><p>纳入1×1卷积核（配置C，表1）是一种增加决策函数的非线性而不影响卷积层感受野的方法。</p><p>Goodfellow等人（2014）将深度ConvNets（11个权重层）应用于街道号识别任务，并表明增加深度能获得更好的性能。 </p><h4 id="分类框架"><a href="#分类框架" class="headerlink" title="分类框架"></a>分类框架</h4><p>在本节中，我们将介绍ConvNet培训和评估的分类细节。</p><h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><p>ConvNet的训练过程<strong>基本上</strong>参照Krizhevsky等人（2012）（除了从多尺度训练图像中采集输入裁剪图像，如后文所述）。也就是说，训练是通过使用<code>小批量梯度下降</code>（基于反向传播（LeCun et al。，1989））的动量优化多项逻辑回归目标来实现的。 批量大小设置为<strong>256</strong>，动量为<strong>0.9</strong>。 训练通过权值衰减（L2惩罚系数设置为 $5 · 10^{−4}$ ）和前两个完全连接层（dropout设置为<strong>0.5</strong>）的dropout正则化来调整。 学习率最初设置为$10^{−2}$  ，然后在验证集精度停止改进时再降低10倍。 总的来说，学习率<strong>一共降低了3次</strong>，并且在<strong>370K个迭代</strong>（74代）后停止了学习。 我们推测，尽管与（Krizhevsky et al.，2012）相比，网络的参数数量更多，网络深度也更大，但能用<code>更少的迭代次数</code>来实现收敛，由于：（a）更大深度和更小卷积核所带来的隐式正则化；（b）某些图层的预初始化。</p><p>网络权重的初始化很重要，因为由于深度网络中的梯度不稳定，初始化不好可能会导致学习停滞。 为了避免这个问题，我们从训练配置A（表1）开始，这个网络足够浅，可以随机初始化进行训练。 然后，当训练更深的体系结构时，我们使用了<code>网络A的权值来初始化了前四个卷积层和最后三个完全连接的层，（中间层随机初始化）</code>。 我们没有降低预初始化图层的学习速率，允许它们在学习期间改变。 对于随机初始化（如有），我们从具有零均值和 $10^{−2}$ 方差的正态分布采样权重。 偏差初始化为零。 值得注意的是，在提交论文后，我们发现<code>可以使用Glorot＆Bengio（2010）的随机初始化程序在没有预先训练的情况下初始化权重</code>。</p><p>为了获得224×224固定大小的 ConvNet输入图像，他们从<code>重新缩放</code>的训练图像中<code>随机裁剪</code>（每个SGD迭代每个图像裁剪一次）。 为了进一步<strong>增强训练集</strong>，被裁剪的图像经过<code>随机水平翻转</code>和<code>随机RGB颜色偏移处理</code>（Krizhevsky et al.，2012）。 下面将介绍训练图像缩放。</p><p><strong>训练图像尺寸。</strong> 设S(the smallest side)是<strong>等比例缩放</strong>的训练图像的最小边，ConvNet基于这些图像的裁剪作为输入（我们也称S为训练尺度）。 虽然裁剪大小固定为224×224，但原则上S可以取不小于224的任何值：对于<strong>S = 224</strong>，裁剪图将捕获整幅图像统计数据，完全跨越训练图像的最小边; 对于<strong>S&gt;&gt;224</strong>，裁剪图将对应于图像的一小部分，包含一个小物体或一个物体部分。</p><p>我们考虑设定训练尺度S的两种方法。第一种方法是<code>固定S</code>，这对应于<code>单尺度训练</code>（注意采样作物中的图像内容仍然可以表示多尺度图像统计）。 在我们的实验中，我们评估了以两个固定尺度训练的模型：S = 256（已被广泛用于现有技术（Krizhevsky等，2012; Zeiler＆Fergus，2013; Sermanet等，2014））和S = 384。给定一个ConvNet配置，我们首先使用<strong>S = 256</strong>来训练网络。为了加速<strong>S = 384</strong>网络的训练，它被初始化为具有S = 256的预训练权重，并且我们使用较小的学习率初始值为 $10^{−3}$ 。</p><p>设定S的第二种方法是<code>多尺度训练</code>，其中通过从特定范围<code>[Smin，Smax]</code>（我们使用<strong>Smin = 256</strong>和<strong>Smax = 512</strong>）<code>随机采样S来单独重新调整每个训练图像</code>。 由于图像中的物体可能具有不同的大小，因此在训练时考虑到这一点是有益的。 这也可以看作是通过<strong>缩放抖动来增强训练集</strong>，其中单个模型被训练以识别多种类别的物体。 出于速度的原因，我们通过对具有相同配置的单尺度模型的所有层进行微调来训练多尺度模型，并使用固定的<strong>S = 384</strong>进行预训练。</p><h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><p>在测试时，给定一个训练有素的ConvNet和一个输入图像，它按以下方式分类。首先，将其等比例缩放到预定义的最小边，表示为Q（我们也将其称为测试尺度）。我们注意到，Q不一定等于训练尺度S（如我们将在第4部分中所示，<code>对每个S使用几个Q值可获得性能改进</code>）。然后，网络以类似于（Sermanet等人，2014）的方式被密集地应用在重新缩放的测试图像上。也就是说，<code>完全连接的层首先被转换成卷积层</code>（第一个FC层转为<strong>7×7</strong>的卷积层，后两个FC层转为<strong>1×1</strong> 卷积层）。然后将所得的全卷积网络应用于整个（<u>未裁剪的</u>）图像。其结果是一个<strong>类别得分映射</strong>，其类别数等于任务的目标分类数，以及一个可变的空间分辨率，取决于输入图像的大小。最后，为了获得固定大小的图像类别分数的向量，类别得分映射会被<u>空间平均（加总池化）</u>。我们还通过<strong>水平翻转图像来增强测试集</strong>；对原始图像和翻转图像的softmax分类概率进行<code>平均</code>以获得图像的最终分数。</p><p>由于卷积边界条件不同，<code>多裁剪图像评估</code>与<code>密集评估</code>是互补的：将ConvNet应用于裁剪图像时，卷积后的特征映射用零填充，而在密集评估的情况下，同一裁切图像的填充天然地来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获更多的上下文信息。</p><h5 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h5><p>实现源自公开发布的<code>C ++ Caffe工具箱</code>（Jia，2013）（2013年12月推出），但包含许多重大修改，使得我们能在装有<code>多个GPU</code>的单系统中执行训练和评估，以及能够对<code>多种规模的全尺寸（未裁剪）图像</code>（如上所述）进行训练和评估。与使用单个GPU相比，我们概念更简单的方案在现成的<code>4 GPU系统上已经提供了3.75倍的加速</code>。在配备四个NVIDIA Titan Black GPU的系统上，根据架构的不同，训练一个网络需要<strong>2-3周</strong>的时间。</p><h4 id="分类实验"><a href="#分类实验" class="headerlink" title="分类实验"></a>分类实验</h4><p>该数据集包括1000种分类的图像，并且被分成三组：训练集（1.3M张图像），验证集（50K张图像）和测试集（100K张标签被去除的图像）。</p><h5 id="单尺度评估"><a href="#单尺度评估" class="headerlink" title="单尺度评估"></a>单尺度评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet performance at a single test scale.jpg"></p><ul><li>虽然额外的非线性确实有帮助（C比B好），但使用感受野范围不少的卷积核（D比C好）捕获空间上下文也很重要。</li><li>带有小型卷积核的深网优于具有更大卷积核的浅网。</li><li>通过尺度抖动来增强训练集确实有助于捕获多尺度图像统计信息。</li></ul><h5 id="多尺度评估"><a href="#多尺度评估" class="headerlink" title="多尺度评估"></a>多尺度评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet performance at a multiple test scale.jpg"></p><h5 id="多裁切图像评估"><a href="#多裁切图像评估" class="headerlink" title="多裁切图像评估"></a>多裁切图像评估</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/ConvNet evaluation techniques comparison.jpg"> </p><ul><li>多裁切图像与密集评估，这两种方法确实是互补，因为它们的组合优于其中的每一种。</li></ul><h5 id="卷积网络融合"><a href="#卷积网络融合" class="headerlink" title="卷积网络融合"></a>卷积网络融合</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Multiple ConvNet fusion results.jpg"></p><h5 id="与当前最先进的技术相比较"><a href="#与当前最先进的技术相比较" class="headerlink" title="与当前最先进的技术相比较"></a>与当前最先进的技术相比较</h5><p><img src="https://captainzj.github.io/2018/11/30/VGG_Introduction/Comparison with the state of the art in ILSVRC classification.jpg"></p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>在这项工作中，我们评估了用于大规模图像分类的深层卷积网络（多达<code>19个权值层</code>）。 已经证明，<code>表示层的深度有利于分类准确性</code>，并且通过大幅增加网络深度便可以使用传统的ConvNet架构来实现ImageNet挑战数据集上的最新性能（LeCun等，1989; Krizhevsky等， 2012）。 在附录中，我们还展示了我们的模型能很好地<code>泛化应用</code>于其他的任务和数据集，不亚于甚至性能优于那些深度略浅、更复杂的识别流水线。 我们的结果再一次证实了视觉表示中<code>深度的重要性</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MachineLearningInAction_Code</title>
    <link href="http://yoursite.com/2018/11/26/MachineLearningInAction-Code/"/>
    <id>http://yoursite.com/2018/11/26/MachineLearningInAction-Code/</id>
    <published>2018-11-26T09:54:11.000Z</published>
    <updated>2018-11-27T11:23:20.893Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h3 id="Chapter13"><a href="#Chapter13" class="headerlink" title="Chapter13"></a><a href="http://ml.apachecn.org/mlia/pca/" target="_blank" rel="noopener">Chapter13</a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># datArr = [map(float,line) for line in stringArr]   #only support python2.x</span></span><br><span class="line">datArr = [[float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line] <span class="keyword">for</span> line <span class="keyword">in</span> stringArr] <span class="comment">#support python3.x</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在shell里输入python指令so stupid !!  Please use IDE,example 'PyCharm' </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pca</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat = pca.loadDataSet(<span class="string">'testSet.txt'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; shape(lowDMat) # support python2.x</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">1</span>)   <span class="comment"># (1000, 1)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>) <span class="comment"># (1000, 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat,reconMat=pca.pca(dataMat,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>) <span class="comment"># (1000, 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat.shape</span><br><span class="line">(<span class="number">1000</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">... </span>...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制降维后的数据reconMat和原始数据dataMat</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fig = plt.figure()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax.scatter(dataMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], dataMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],marker=<span class="string">'^'</span>,s=<span class="number">90</span>)</span><br><span class="line">&lt;matplotlib.collections.PathCollection object at <span class="number">0x11a142160</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ax.scatter(reconMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], reconMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],marker=<span class="string">'o'</span>,s=<span class="number">50</span>,c=<span class="string">'r'</span>)</span><br><span class="line">&lt;matplotlib.collections.PathCollection object at <span class="number">0x11a1424e0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat, reconMat = pca.pca(dataMat, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lowDMat</span><br><span class="line">matrix([[<span class="number">-2.51033597</span>,  <span class="number">0.15840394</span>],</span><br><span class="line">        [<span class="number">-2.86915379</span>,  <span class="number">0.5092619</span> ],</span><br><span class="line">        [ <span class="number">0.09741085</span>, <span class="number">-0.20728318</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">-0.50166225</span>, <span class="number">-0.62056456</span>],</span><br><span class="line">        [<span class="number">-0.05898712</span>, <span class="number">-0.02335614</span>],</span><br><span class="line">        [<span class="number">-0.18978714</span>, <span class="number">-1.37276015</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reconMat</span><br><span class="line">matrix([[<span class="number">10.235186</span>, <span class="number">11.321997</span>],</span><br><span class="line">        [<span class="number">10.122339</span>, <span class="number">11.810993</span>],</span><br><span class="line">        [ <span class="number">9.190236</span>,  <span class="number">8.904943</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">9.854922</span>,  <span class="number">9.201393</span>],</span><br><span class="line">        [ <span class="number">9.11458</span> ,  <span class="number">9.134215</span>],</span><br><span class="line">        [<span class="number">10.334899</span>,  <span class="number">8.543604</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat</span><br><span class="line">matrix([[<span class="number">10.235186</span>, <span class="number">11.321997</span>],</span><br><span class="line">        [<span class="number">10.122339</span>, <span class="number">11.810993</span>],</span><br><span class="line">        [ <span class="number">9.190236</span>,  <span class="number">8.904943</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">9.854922</span>,  <span class="number">9.201393</span>],</span><br><span class="line">        [ <span class="number">9.11458</span> ,  <span class="number">9.134215</span>],</span><br><span class="line">        [<span class="number">10.334899</span>,  <span class="number">8.543604</span>]])</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有剔除任何特征，那么重构之后的数据reconMat会和原始的数据dataMat重合</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pca</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataMat = pca.replaceNanWithMean()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>meanVals = mean(dataMat, axis = <span class="number">0</span>)  <span class="comment"># np.mean(dataMat, axis = 0)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>meanRemoved = dataMat - meanVals</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>covMat = cov(meanRemoved, rowvar = <span class="number">0</span>) <span class="comment"># covMat = np.cov(meanRemoved, rowvar = 0)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eigVals,eigVects = linalg.eig(mat(covMat)) <span class="comment"># np.linalg.eig(np.mat(covMat))</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eigVals</span><br><span class="line">array([ <span class="number">5.34151979e+07</span>,  <span class="number">2.17466719e+07</span>,  <span class="number">8.24837662e+06</span>,  <span class="number">2.07388086e+06</span>,</span><br><span class="line">        <span class="number">1.31540439e+06</span>,  <span class="number">4.67693557e+05</span>,  <span class="number">2.90863555e+05</span>,  <span class="number">2.83668601e+05</span>,</span><br><span class="line">        <span class="number">2.37155830e+05</span>,  <span class="number">2.08513836e+05</span>,  <span class="number">1.96098849e+05</span>,  <span class="number">1.86856549e+05</span>,</span><br><span class="line">        <span class="number">1.52422354e+05</span>,  <span class="number">1.13215032e+05</span>,  <span class="number">1.08493848e+05</span>,  <span class="number">1.02849533e+05</span>,</span><br><span class="line">        <span class="number">1.00166164e+05</span>,  <span class="number">8.33473762e+04</span>,  <span class="number">8.15850591e+04</span>,  <span class="number">7.76560524e+04</span>,</span><br><span class="line">        <span class="number">6.66060410e+04</span>,  <span class="number">6.52620058e+04</span>,  <span class="number">5.96776503e+04</span>,  <span class="number">5.16269933e+04</span>,</span><br><span class="line">        <span class="number">5.03324580e+04</span>,  <span class="number">4.54661746e+04</span>,  <span class="number">4.41914029e+04</span>,  <span class="number">4.15532551e+04</span>,</span><br><span class="line">        <span class="number">3.55294040e+04</span>,  <span class="number">3.31436743e+04</span>,  <span class="number">2.67385181e+04</span>,  <span class="number">1.47123429e+04</span>,</span><br><span class="line">        <span class="number">1.44089194e+04</span>,  <span class="number">1.09321187e+04</span>,  <span class="number">1.04841308e+04</span>,  <span class="number">9.48876548e+03</span>,</span><br><span class="line">        <span class="number">8.34665462e+03</span>,  <span class="number">7.22765535e+03</span>,  <span class="number">5.34196392e+03</span>,  <span class="number">4.95614671e+03</span>,</span><br><span class="line">        <span class="number">4.23060022e+03</span>,  <span class="number">4.10673182e+03</span>,  <span class="number">3.41199406e+03</span>,  <span class="number">3.24193522e+03</span>,</span><br><span class="line">        <span class="number">2.74523635e+03</span>,  <span class="number">2.35027999e+03</span>,  <span class="number">2.16835314e+03</span>,  <span class="number">1.86414157e+03</span>,</span><br><span class="line">        <span class="number">1.76741826e+03</span>,  <span class="number">1.70492093e+03</span>,  <span class="number">1.66199683e+03</span>,  <span class="number">1.53948465e+03</span>,</span><br><span class="line">        <span class="number">1.33096008e+03</span>,  <span class="number">1.25591691e+03</span>,  <span class="number">1.15509389e+03</span>,  <span class="number">1.12410108e+03</span>,</span><br><span class="line">        <span class="number">1.03213798e+03</span>,  <span class="number">1.00972093e+03</span>,  <span class="number">9.50542179e+02</span>,  <span class="number">9.09791361e+02</span>,</span><br><span class="line">        <span class="number">8.32001551e+02</span>,  <span class="number">8.08898242e+02</span>,  <span class="number">7.37343627e+02</span>,  <span class="number">6.87596830e+02</span>,</span><br><span class="line">        <span class="number">5.64452104e+02</span>,  <span class="number">5.51812250e+02</span>,  <span class="number">5.37209115e+02</span>,  <span class="number">4.93029995e+02</span>,</span><br><span class="line">        <span class="number">4.13720573e+02</span>,  <span class="number">3.90222119e+02</span>,  <span class="number">3.37288784e+02</span>,  <span class="number">3.27558605e+02</span>,</span><br><span class="line">        <span class="number">3.08869553e+02</span>,  <span class="number">2.46285839e+02</span>,  <span class="number">2.28893093e+02</span>,  <span class="number">1.96447852e+02</span>,</span><br><span class="line">        <span class="number">1.75559820e+02</span>,  <span class="number">1.65795169e+02</span>,  <span class="number">1.56428052e+02</span>,  <span class="number">1.39671194e+02</span>,</span><br><span class="line">        <span class="number">1.28662864e+02</span>,  <span class="number">1.15624070e+02</span>,  <span class="number">1.10318239e+02</span>,  <span class="number">1.08663541e+02</span>,</span><br><span class="line">        <span class="number">1.00695416e+02</span>,  <span class="number">9.80687852e+01</span>,  <span class="number">8.34968275e+01</span>,  <span class="number">7.53025397e+01</span>,</span><br><span class="line">        <span class="number">6.89260158e+01</span>,  <span class="number">6.67786503e+01</span>,  <span class="number">6.09412873e+01</span>,  <span class="number">5.30974002e+01</span>,</span><br><span class="line">        <span class="number">4.71797825e+01</span>,  <span class="number">4.50701108e+01</span>,  <span class="number">4.41349593e+01</span>,  <span class="number">4.03313416e+01</span>,</span><br><span class="line">        <span class="number">3.95741636e+01</span>,  <span class="number">3.74000035e+01</span>,  <span class="number">3.44211326e+01</span>,  <span class="number">3.30031584e+01</span>,</span><br><span class="line">        <span class="number">3.03317756e+01</span>,  <span class="number">2.88994580e+01</span>,  <span class="number">2.76478754e+01</span>,  <span class="number">2.57708695e+01</span>,</span><br><span class="line">        <span class="number">2.44506430e+01</span>,  <span class="number">2.31640106e+01</span>,  <span class="number">2.26956957e+01</span>,  <span class="number">2.16925102e+01</span>,</span><br><span class="line">        <span class="number">2.10114869e+01</span>,  <span class="number">2.00984697e+01</span>,  <span class="number">1.86489543e+01</span>,  <span class="number">1.83733216e+01</span>,</span><br><span class="line">        <span class="number">1.72517802e+01</span>,  <span class="number">1.60481189e+01</span>,  <span class="number">1.54406997e+01</span>,  <span class="number">1.48356499e+01</span>,</span><br><span class="line">        <span class="number">1.44273357e+01</span>,  <span class="number">1.42318192e+01</span>,  <span class="number">1.35592064e+01</span>,  <span class="number">1.30696836e+01</span>,</span><br><span class="line">        <span class="number">1.28193512e+01</span>,  <span class="number">1.22093626e+01</span>,  <span class="number">1.15228376e+01</span>,  <span class="number">1.12141738e+01</span>,</span><br><span class="line">        <span class="number">1.02585936e+01</span>,  <span class="number">9.86906139e+00</span>,  <span class="number">9.58794460e+00</span>,  <span class="number">9.41686288e+00</span>,</span><br><span class="line">        <span class="number">9.20276340e+00</span>,  <span class="number">8.63791398e+00</span>,  <span class="number">8.20622561e+00</span>,  <span class="number">8.01020114e+00</span>,</span><br><span class="line">        <span class="number">7.53391290e+00</span>,  <span class="number">7.33168361e+00</span>,  <span class="number">7.09960245e+00</span>,  <span class="number">7.02149364e+00</span>,</span><br><span class="line">        <span class="number">6.76557324e+00</span>,  <span class="number">6.34504733e+00</span>,  <span class="number">6.01919292e+00</span>,  <span class="number">5.81680918e+00</span>,</span><br><span class="line">        <span class="number">5.44653788e+00</span>,  <span class="number">5.12338463e+00</span>,  <span class="number">4.79593185e+00</span>,  <span class="number">4.47851795e+00</span>,</span><br><span class="line">        <span class="number">4.50369987e+00</span>,  <span class="number">4.27479386e+00</span>,  <span class="number">3.89124198e+00</span>,  <span class="number">3.56466892e+00</span>,</span><br><span class="line">        <span class="number">3.32248982e+00</span>,  <span class="number">2.97665360e+00</span>,  <span class="number">2.61425544e+00</span>,  <span class="number">2.31802829e+00</span>,</span><br><span class="line">        <span class="number">2.17171124e+00</span>,  <span class="number">1.99239284e+00</span>,  <span class="number">1.96616566e+00</span>,  <span class="number">1.88149281e+00</span>,</span><br><span class="line">        <span class="number">1.79228288e+00</span>,  <span class="number">1.71378363e+00</span>,  <span class="number">1.68028783e+00</span>,  <span class="number">1.60686268e+00</span>,</span><br><span class="line">        <span class="number">1.47158244e+00</span>,  <span class="number">1.40656712e+00</span>,  <span class="number">1.37808906e+00</span>,  <span class="number">1.27967672e+00</span>,</span><br><span class="line">        <span class="number">1.22803716e+00</span>,  <span class="number">1.18531109e+00</span>,  <span class="number">9.38857180e-01</span>,  <span class="number">9.18222054e-01</span>,</span><br><span class="line">        <span class="number">8.26265393e-01</span>,  <span class="number">7.96585842e-01</span>,  <span class="number">7.74597255e-01</span>,  <span class="number">7.14002770e-01</span>,</span><br><span class="line">        <span class="number">6.79457797e-01</span>,  <span class="number">6.37928310e-01</span>,  <span class="number">6.24646758e-01</span>,  <span class="number">5.34605353e-01</span>,</span><br><span class="line">        <span class="number">4.60658687e-01</span>,  <span class="number">4.24265893e-01</span>,  <span class="number">4.08634622e-01</span>,  <span class="number">3.70321764e-01</span>,</span><br><span class="line">        <span class="number">3.67016386e-01</span>,  <span class="number">3.35858033e-01</span>,  <span class="number">3.29780397e-01</span>,  <span class="number">2.94348753e-01</span>,</span><br><span class="line">        <span class="number">2.84154176e-01</span>,  <span class="number">2.72703994e-01</span>,  <span class="number">2.63265991e-01</span>,  <span class="number">2.45227786e-01</span>,</span><br><span class="line">        <span class="number">2.25805135e-01</span>,  <span class="number">2.22331919e-01</span>,  <span class="number">2.13514673e-01</span>,  <span class="number">1.93961935e-01</span>,</span><br><span class="line">        <span class="number">1.91647269e-01</span>,  <span class="number">1.83668491e-01</span>,  <span class="number">1.82518017e-01</span>,  <span class="number">1.65310922e-01</span>,</span><br><span class="line">        <span class="number">1.57447909e-01</span>,  <span class="number">1.51263974e-01</span>,  <span class="number">1.39427297e-01</span>,  <span class="number">1.32638882e-01</span>,</span><br><span class="line">        <span class="number">1.28000027e-01</span>,  <span class="number">1.13559952e-01</span>,  <span class="number">1.12576237e-01</span>,  <span class="number">1.08809771e-01</span>,</span><br><span class="line">        <span class="number">1.07136355e-01</span>,  <span class="number">8.60839655e-02</span>,  <span class="number">8.50467792e-02</span>,  <span class="number">8.29254355e-02</span>,</span><br><span class="line">        <span class="number">7.03701660e-02</span>,  <span class="number">6.44475619e-02</span>,  <span class="number">6.09866327e-02</span>,  <span class="number">6.05709478e-02</span>,</span><br><span class="line">        <span class="number">5.93963958e-02</span>,  <span class="number">5.22163549e-02</span>,  <span class="number">4.92729703e-02</span>,  <span class="number">4.80022983e-02</span>,</span><br><span class="line">        <span class="number">4.51487439e-02</span>,  <span class="number">4.30180504e-02</span>,  <span class="number">4.13368324e-02</span>,  <span class="number">4.03281604e-02</span>,</span><br><span class="line">        <span class="number">3.91576587e-02</span>,  <span class="number">3.54198873e-02</span>,  <span class="number">3.31199510e-02</span>,  <span class="number">3.13547234e-02</span>,</span><br><span class="line">        <span class="number">3.07226509e-02</span>,  <span class="number">2.98354196e-02</span>,  <span class="number">2.81949091e-02</span>,  <span class="number">2.49158051e-02</span>,</span><br><span class="line">        <span class="number">2.36374781e-02</span>,  <span class="number">2.28360210e-02</span>,  <span class="number">2.19602047e-02</span>,  <span class="number">2.00166957e-02</span>,</span><br><span class="line">        <span class="number">1.86597535e-02</span>,  <span class="number">1.80415918e-02</span>,  <span class="number">1.72261012e-02</span>,  <span class="number">1.60703860e-02</span>,</span><br><span class="line">        <span class="number">1.49566735e-02</span>,  <span class="number">1.40165444e-02</span>,  <span class="number">1.31296856e-02</span>,  <span class="number">1.21358005e-02</span>,</span><br><span class="line">        <span class="number">1.07166503e-02</span>,  <span class="number">1.01045695e-02</span>,  <span class="number">9.76055340e-03</span>,  <span class="number">9.16740926e-03</span>,</span><br><span class="line">        <span class="number">8.78108857e-03</span>,  <span class="number">8.67465278e-03</span>,  <span class="number">8.30918514e-03</span>,  <span class="number">8.05104488e-03</span>,</span><br><span class="line">        <span class="number">7.56152126e-03</span>,  <span class="number">7.31508852e-03</span>,  <span class="number">7.26347037e-03</span>,  <span class="number">6.65728354e-03</span>,</span><br><span class="line">        <span class="number">6.50769617e-03</span>,  <span class="number">6.28009879e-03</span>,  <span class="number">6.19160730e-03</span>,  <span class="number">5.64130272e-03</span>,</span><br><span class="line">        <span class="number">5.30195373e-03</span>,  <span class="number">5.07453702e-03</span>,  <span class="number">4.47372286e-03</span>,  <span class="number">4.32543895e-03</span>,</span><br><span class="line">        <span class="number">4.22006582e-03</span>,  <span class="number">3.97065729e-03</span>,  <span class="number">3.75292740e-03</span>,  <span class="number">3.64861290e-03</span>,</span><br><span class="line">        <span class="number">3.38915810e-03</span>,  <span class="number">3.27965962e-03</span>,  <span class="number">3.06633825e-03</span>,  <span class="number">2.99206786e-03</span>,</span><br><span class="line">        <span class="number">2.83586784e-03</span>,  <span class="number">2.74987243e-03</span>,  <span class="number">2.31066313e-03</span>,  <span class="number">2.26782347e-03</span>,</span><br><span class="line">        <span class="number">1.82206662e-03</span>,  <span class="number">1.74955624e-03</span>,  <span class="number">1.69305161e-03</span>,  <span class="number">1.66624597e-03</span>,</span><br><span class="line">        <span class="number">1.55346749e-03</span>,  <span class="number">1.51278404e-03</span>,  <span class="number">1.47296800e-03</span>,  <span class="number">1.33617458e-03</span>,</span><br><span class="line">        <span class="number">1.30517592e-03</span>,  <span class="number">1.24056353e-03</span>,  <span class="number">1.19823961e-03</span>,  <span class="number">1.14381059e-03</span>,</span><br><span class="line">        <span class="number">1.13027458e-03</span>,  <span class="number">1.11081803e-03</span>,  <span class="number">1.08359152e-03</span>,  <span class="number">1.03517496e-03</span>,</span><br><span class="line">        <span class="number">1.00164593e-03</span>,  <span class="number">9.50024604e-04</span>,  <span class="number">8.94981182e-04</span>,  <span class="number">8.74363843e-04</span>,</span><br><span class="line">        <span class="number">7.98497545e-04</span>,  <span class="number">7.51612220e-04</span>,  <span class="number">6.63964302e-04</span>,  <span class="number">6.21097646e-04</span>,</span><br><span class="line">        <span class="number">6.18098604e-04</span>,  <span class="number">5.72611403e-04</span>,  <span class="number">5.57509231e-04</span>,  <span class="number">5.47002381e-04</span>,</span><br><span class="line">        <span class="number">5.27195077e-04</span>,  <span class="number">5.11487997e-04</span>,  <span class="number">4.87787872e-04</span>,  <span class="number">4.74249071e-04</span>,</span><br><span class="line">        <span class="number">4.52367689e-04</span>,  <span class="number">4.24431101e-04</span>,  <span class="number">4.19119024e-04</span>,  <span class="number">3.72489906e-04</span>,</span><br><span class="line">        <span class="number">3.38125455e-04</span>,  <span class="number">3.34002144e-04</span>,  <span class="number">2.97951371e-04</span>,  <span class="number">2.84845901e-04</span>,</span><br><span class="line">        <span class="number">2.79038288e-04</span>,  <span class="number">2.77054476e-04</span>,  <span class="number">2.67962797e-04</span>,  <span class="number">2.54815126e-04</span>,</span><br><span class="line">        <span class="number">2.29230595e-04</span>,  <span class="number">1.99245436e-04</span>,  <span class="number">1.90381389e-04</span>,  <span class="number">1.84497913e-04</span>,</span><br><span class="line">        <span class="number">1.77415682e-04</span>,  <span class="number">1.68160613e-04</span>,  <span class="number">1.63992031e-04</span>,  <span class="number">1.58025553e-04</span>,</span><br><span class="line">        <span class="number">1.54226003e-04</span>,  <span class="number">1.40079892e-04</span>,  <span class="number">1.46097434e-04</span>,  <span class="number">1.46890640e-04</span>,</span><br><span class="line">        <span class="number">1.35736724e-04</span>,  <span class="number">9.90265098e-05</span>,  <span class="number">1.04252870e-04</span>,  <span class="number">1.16752515e-04</span>,</span><br><span class="line">        <span class="number">1.14080847e-04</span>,  <span class="number">1.22704035e-04</span>,  <span class="number">9.66039062e-05</span>,  <span class="number">9.60766570e-05</span>,</span><br><span class="line">        <span class="number">9.16166335e-05</span>,  <span class="number">9.07003478e-05</span>,  <span class="number">8.60212633e-05</span>,  <span class="number">8.32654024e-05</span>,</span><br><span class="line">        <span class="number">7.70526077e-05</span>,  <span class="number">7.36470020e-05</span>,  <span class="number">7.24998305e-05</span>,  <span class="number">6.80209910e-05</span>,</span><br><span class="line">        <span class="number">6.68682698e-05</span>,  <span class="number">6.14500420e-05</span>,  <span class="number">5.99843174e-05</span>,  <span class="number">5.49918003e-05</span>,</span><br><span class="line">        <span class="number">5.24646955e-05</span>,  <span class="number">5.13403849e-05</span>,  <span class="number">5.02336264e-05</span>,  <span class="number">4.89288507e-05</span>,</span><br><span class="line">        <span class="number">4.51104475e-05</span>,  <span class="number">4.29823765e-05</span>,  <span class="number">4.18869715e-05</span>,  <span class="number">4.14341562e-05</span>,</span><br><span class="line">        <span class="number">3.94822843e-05</span>,  <span class="number">3.80307292e-05</span>,  <span class="number">3.57776535e-05</span>,  <span class="number">3.43901591e-05</span>,</span><br><span class="line">        <span class="number">2.98089203e-05</span>,  <span class="number">2.72388358e-05</span>,  <span class="number">2.42608885e-05</span>,  <span class="number">2.30962279e-05</span>,</span><br><span class="line">        <span class="number">2.27807559e-05</span>,  <span class="number">2.14440814e-05</span>,  <span class="number">1.96208174e-05</span>,  <span class="number">1.91217363e-05</span>,</span><br><span class="line">        <span class="number">1.88276186e-05</span>,  <span class="number">1.66549051e-05</span>,  <span class="number">1.46846459e-05</span>,  <span class="number">1.39779892e-05</span>,</span><br><span class="line">        <span class="number">1.43753346e-05</span>,  <span class="number">1.21760519e-05</span>,  <span class="number">1.20295835e-05</span>,  <span class="number">1.13426750e-05</span>,</span><br><span class="line">        <span class="number">1.09258905e-05</span>,  <span class="number">1.02782991e-05</span>,  <span class="number">1.01021808e-05</span>,  <span class="number">9.72678794e-06</span>,</span><br><span class="line">        <span class="number">9.64538296e-06</span>,  <span class="number">9.23630205e-06</span>,  <span class="number">8.93991858e-06</span>,  <span class="number">8.34247982e-06</span>,</span><br><span class="line">        <span class="number">7.36188590e-06</span>,  <span class="number">7.20354827e-06</span>,  <span class="number">6.69282813e-06</span>,  <span class="number">6.49477814e-06</span>,</span><br><span class="line">        <span class="number">4.45482134e-06</span>,  <span class="number">4.65422046e-06</span>,  <span class="number">5.09342483e-06</span>,  <span class="number">5.31392220e-06</span>,</span><br><span class="line">        <span class="number">5.67034892e-06</span>,  <span class="number">5.91044556e-06</span>,  <span class="number">6.00244889e-06</span>,  <span class="number">4.11265577e-06</span>,</span><br><span class="line">        <span class="number">3.77558985e-06</span>,  <span class="number">3.65202836e-06</span>,  <span class="number">3.48065950e-06</span>,  <span class="number">2.78847699e-06</span>,</span><br><span class="line">        <span class="number">2.66299628e-06</span>,  <span class="number">2.57492503e-06</span>,  <span class="number">2.39210233e-06</span>,  <span class="number">2.06298821e-06</span>,</span><br><span class="line">        <span class="number">2.00824521e-06</span>,  <span class="number">1.76373602e-06</span>,  <span class="number">1.58273269e-06</span>,  <span class="number">1.32211395e-06</span>,</span><br><span class="line">        <span class="number">1.49813697e-06</span>,  <span class="number">1.42489429e-06</span>,  <span class="number">1.44003524e-06</span>,  <span class="number">1.10002716e-06</span>,</span><br><span class="line">        <span class="number">9.01008863e-07</span>,  <span class="number">8.49881106e-07</span>,  <span class="number">7.62521870e-07</span>,  <span class="number">6.57641103e-07</span>,</span><br><span class="line">        <span class="number">5.85636641e-07</span>,  <span class="number">5.33937361e-07</span>,  <span class="number">4.16077215e-07</span>,  <span class="number">3.33765858e-07</span>,</span><br><span class="line">        <span class="number">2.95575265e-07</span>,  <span class="number">2.54744632e-07</span>,  <span class="number">2.20144574e-07</span>,  <span class="number">1.86314525e-07</span>,</span><br><span class="line">        <span class="number">1.77370967e-07</span>,  <span class="number">1.54794344e-07</span>,  <span class="number">1.47331687e-07</span>,  <span class="number">1.39738552e-07</span>,</span><br><span class="line">        <span class="number">1.04110968e-07</span>,  <span class="number">1.00786519e-07</span>,  <span class="number">9.38635094e-08</span>,  <span class="number">9.10853310e-08</span>,</span><br><span class="line">        <span class="number">8.71546325e-08</span>,  <span class="number">7.48338889e-08</span>,  <span class="number">6.06817435e-08</span>,  <span class="number">5.66479200e-08</span>,</span><br><span class="line">        <span class="number">5.24576913e-08</span>,  <span class="number">4.57020648e-08</span>,  <span class="number">2.89942624e-08</span>,  <span class="number">2.60449421e-08</span>,</span><br><span class="line">        <span class="number">2.10987990e-08</span>,  <span class="number">2.17618741e-08</span>,  <span class="number">1.75542294e-08</span>,  <span class="number">1.34637025e-08</span>,</span><br><span class="line">        <span class="number">1.27167435e-08</span>,  <span class="number">1.23258201e-08</span>,  <span class="number">9.86367963e-09</span>,  <span class="number">1.04987513e-08</span>,</span><br><span class="line">        <span class="number">8.49423161e-09</span>,  <span class="number">9.33428155e-09</span>,  <span class="number">7.42190962e-09</span>,  <span class="number">6.84633796e-09</span>,</span><br><span class="line">        <span class="number">6.46870806e-09</span>,  <span class="number">5.76455817e-09</span>,  <span class="number">5.01138098e-09</span>,  <span class="number">3.48686453e-09</span>,</span><br><span class="line">        <span class="number">2.91267177e-09</span>,  <span class="number">2.77880628e-09</span>,  <span class="number">1.73093438e-09</span>,  <span class="number">1.42391194e-09</span>,</span><br><span class="line">        <span class="number">9.24975774e-10</span>,  <span class="number">1.16454971e-09</span>,  <span class="number">6.95073614e-10</span>,  <span class="number">1.11815884e-09</span>,</span><br><span class="line">        <span class="number">1.80003518e-10</span>,  <span class="number">1.97062415e-10</span>,  <span class="number">2.61936054e-10</span>,  <span class="number">6.13219223e-10</span>,</span><br><span class="line">        <span class="number">5.27584239e-10</span>, <span class="number">-2.16417104e-15</span>,  <span class="number">2.10627686e-15</span>,  <span class="number">6.25652286e-16</span>,</span><br><span class="line">       <span class="number">-1.69155643e-17</span>,  <span class="number">5.08498479e-19</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>,</span><br><span class="line">        <span class="number">0.00000000e+00</span>,  <span class="number">0.00000000e+00</span>])</span><br><span class="line"><span class="comment"># 发现超过20％的特征值都是0，意味着这些特征都是其他特征的副本，也就是说它们可以通过其他特征来表示，而本身并没有提供额外的信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataMat.shape (1567, 590)</span></span><br><span class="line"><span class="comment"># meanVals.shape (1, 590)</span></span><br><span class="line"><span class="comment"># meanRemoved.shape (1567, 590)</span></span><br><span class="line"><span class="comment"># covMat.shape (590, 590)</span></span><br><span class="line"><span class="comment"># eigVects.shape (590, 590)</span></span><br><span class="line"><span class="comment"># eigVals.shape (590,)</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 半导体制造数据</span></span><br><span class="line">http://archive.ics.uci.edu/ml/machine-learning-databases/secom/</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>DeepLearningwithKeras_Code</title>
    <link href="http://yoursite.com/2018/11/26/DeepLearningwithKeras-Code/"/>
    <id>http://yoursite.com/2018/11/26/DeepLearningwithKeras-Code/</id>
    <published>2018-11-26T02:44:25.000Z</published>
    <updated>2018-11-29T07:23:56.248Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><ul><li><p>keras_CIFAR10_simple</p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_0.png" alt=""></p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_1.png" alt=""></p><center class="half"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_modleAccuracy.png" width="300"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_simple_modleLoss.png" width="300"><br></center></li><li><p>keras_CIFAR10_V1</p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_run1.png" alt=""></p><p><img src="/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_run2.png" alt=""></p><center class="half"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_Accuracy.png" width="300"><br><img src="https://captainzj.github.io/2018/11/26/DeepLearningwithKeras-Code/keras_CIFAR10_V1_Loss.png" width="300"><br></center></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MachineLearning_Environment configuration</title>
    <link href="http://yoursite.com/2018/11/25/MachineLearning_EnvironmentConfiguration/"/>
    <id>http://yoursite.com/2018/11/25/MachineLearning_EnvironmentConfiguration/</id>
    <published>2018-11-25T11:13:41.000Z</published>
    <updated>2018-11-28T12:45:31.199Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h4><p><a href="http://www.cnblogs.com/harvey888/p/5465452.html" target="_blank" rel="noopener">Anaconda多环境多版本python配置指导</a></p><ul><li>更换镜像（<a href="https://www.jianshu.com/p/d54546ab315e" target="_blank" rel="noopener">Mac下通过Anaconda安装Tensorflow</a>）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加Anaconda的TUNA镜像</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置搜索时显示通道地址</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda config --<span class="built_in">set</span> show_channel_urls yes</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda install numpy   <span class="comment">#测试是否添加成功</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 之后会自动在用户根目录生成“.condarc”文件，可以在终端用 </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls -a </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令查看该文件，如果要删除镜像，直接删除“.condarc”文件即可： </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm .condarc</span></span><br></pre></td></tr></table></figure><ul><li>Mac Pycharm配置Anaconda环境</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- Command + ,</span><br><span class="line">- Project → Project Interpreter </span><br><span class="line">- 齿轮 → Add → System Interpreter </span><br><span class="line">- 齿轮 → <span class="string">'/Users/Captain/anaconda3/python.app/Contents/MacOS/python'</span></span><br></pre></td></tr></table></figure><p>#### </p><ul><li><p>shell 使用Anaconda的python</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> vim ~/.bash_profile</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Anaconda3</span></span><br><span class="line">export PATH=~/anaconda3/bin:$PATH  #若想使用系统自带的python版本，将此行注释即可</span><br></pre></td></tr></table></figure></li><li><p>Anaconda/env下 安装包路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/  <span class="comment">#keras</span></span></span><br></pre></td></tr></table></figure></li><li><p>anaconda_downgrade Failed</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">download low_version Anaconda</span><br></pre></td></tr></table></figure></li><li><p><a href="https://repo.anaconda.com/archive/" target="_blank" rel="noopener">Anaconda installer archive</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Anaconda2-5.3.0-MacOSX-x86_64.pkg  # 对应python3.6</span><br></pre></td></tr></table></figure></li></ul><h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><a href="https://www.tensorflow.org/versions/r1.1/install/install_mac" target="_blank" rel="noopener">TensorFlow on MacOS</a></p><ul><li><p>暂不支持python3.7</p></li><li><p>查看TensorFlow版本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tf.__version__</span><br><span class="line"><span class="string">'1.12.0'</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li><li><p>测试是否安装成功</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sess = tf.Session()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(sess.run(hello))</span><br><span class="line">Hello,TensorFlow!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- I tensorflow/core/platform/cpu_feature_guard.cc:<span class="number">140</span>] Your CPU supports instructions that this TensorFlow binary was <span class="keyword">not</span> compiled to use: AVX2 FMA</span><br></pre></td></tr></table></figure></li></ul><h4 id="Therno"><a href="#Therno" class="headerlink" title="Therno"></a>Therno</h4><ul><li><p>测试Therno</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> theano</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> theano.tensor <span class="keyword">as</span> T</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = T.dmatrix(<span class="string">'x'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="number">1</span>/(<span class="number">1</span>+T.exp(-x))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>logistic = theano.function([x],s)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>logistic([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">-1</span>,<span class="number">-2</span>]])</span><br><span class="line">array([[<span class="number">0.5</span>       , <span class="number">0.73105858</span>],</span><br><span class="line">       [<span class="number">0.26894142</span>, <span class="number">0.11920292</span>]])</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h4><ul><li><p>安装Keras</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install keras</span></span><br></pre></td></tr></table></figure></li><li><p>查看Keras版本号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> keras</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(keras.__version__)</span><br><span class="line"><span class="number">2.2</span><span class="number">.4</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>切换Keras后端backend</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建或打开如下Keras配置文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ~/.keras/keras.json</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认配置如下：  (将backend字段的值改为theano或者tensorflow，即可切换到相应的后端)</span></span><br><span class="line">&#123; </span><br><span class="line">    "floatx": "float32",</span><br><span class="line">    "epsilon": 1e-07,</span><br><span class="line">    "backend": "tensorflow", # "backend": "theano"</span><br><span class="line">    "image_data_format": "channels_last"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>离线下载cifar数据集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.通过源码\keras\datasets\cifar10.py可以看到文件下载地址:&apos;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz &apos;</span><br><span class="line">2.  通过源码keras\utils\data_utils.py可以看到下载后的文件保存至&apos;~/.keras/datasets/&quot;fname&quot;.tar.gz&apos;  (Anaconda 的env环境下的keras文件 保存路径亦如此)</span><br><span class="line"></span><br><span class="line">- 小结：</span><br><span class="line">手动下载数据集，然后移动到 ~\.keras\datasets目录下，并改名（包括后缀名）为cifar-10-batches-py.tar.gz，并且用到其他时依次类推。  注：&quot;改后缀名!!!&quot;</span><br></pre></td></tr></table></figure><ul><li>测试</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">print(y_train[:<span class="number">4</span>])</span><br></pre></td></tr></table></figure></li><li><p>downgrade Keras/upgrade keras</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> you can downgrade your keras with pip install keras==1.2.2 <span class="keyword">if</span> you don<span class="string">'t want to bother about keras 2 much. Otherwise, you have to write keras 2 go through the release notes and check the fresh API.</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install keras==1.2.2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> upgrade keras</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install --upgrade keras</span></span><br></pre></td></tr></table></figure></li><li><p>RunTime Error</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- TypeError: softmax() got an unexpected keyword argument <span class="string">'axis'</span></span><br><span class="line"> - pip install --upgrade keras==<span class="number">2.1</span>.<span class="number">3</span></span><br><span class="line">     </span><br><span class="line">- <span class="string">'python matplotlib framework under macosx'</span></span><br><span class="line">ImportError: Python is not installed as a framework. The Mac OS X backend will not be able to <span class="keyword">function</span> correctly <span class="keyword">if</span> Python is not installed as a framework. See the Python documentation <span class="keyword">for</span> more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or <span class="keyword">try</span> one of the other backends. <span class="keyword">If</span> you are using (Ana)Conda please install python.app and replace the use of <span class="string">'python'</span> with <span class="string">'pythonw'</span>. See <span class="string">'Working with Matplotlib on OSX'</span> <span class="keyword">in</span> the Matplotlib FAQ <span class="keyword">for</span> more information.</span><br><span class="line">- Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg</span><br></pre></td></tr></table></figure></li></ul><h4 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h4><ul><li><p>下载速度慢</p><ul><li><p>临时使用： <code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple &#39;packageName&#39;</code></p></li><li><p>永久修改，一劳永逸：<br>Linux下，修改 ~/.pip/pip.conf (没有就创建一个文件夹及文件。文件夹要加“.”表示隐藏文件夹) 内容如下:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure></li></ul></li><li><p>列出所有可升级的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip list --outdate</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>DataMining_Review_Assignment</title>
    <link href="http://yoursite.com/2018/11/24/DataMining-Review-Assignment/"/>
    <id>http://yoursite.com/2018/11/24/DataMining-Review-Assignment/</id>
    <published>2018-11-24T06:40:05.000Z</published>
    <updated>2018-11-25T08:11:09.607Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>​    决策树是一种机器学习的方法。决策树的生成算法有ID3, C4.5和C5.0等。决策树是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果。决策树是一种十分常用的监督学习分类方法，监管学习就是给出一堆样本，每个样本都有一组属性和一个分类结果，也就是分类结果已知，那么通过学习这些样本得到一个决策树，这个决策树能够对新的数据给出正确的分类。</p><p>​    这里通过一个简单的例子来说明决策树的构成思路：给出如下的一组数据，一共有五个样本，每个样本有’不浮出水面是否可以生存’，’是否有脚蹼’属性，最后判断这些样本是否是鱼类。最后一列给出了人工分类结果。</p><table><thead><tr><th style="text-align:center">序号ID</th><th style="text-align:center">不浮出水面是否可以生存No Surfacing?</th><th style="text-align:center">是否有脚蹼Flippers？</th><th style="text-align:center">是否为鱼类Fish？</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td><td style="text-align:center">是  Yes</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td><td style="text-align:center">否  No</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">否  No</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">否  No</td><td style="text-align:center">是  Yes</td><td style="text-align:center">否  No</td></tr></tbody></table><p>  <img src="/2018/11/24/DataMining-Review-Assignment/DecisionTree_exampleTree.png" alt="决策树范例"></p><h2 id="构建决策树"><a href="#构建决策树" class="headerlink" title="构建决策树"></a>构建决策树</h2><h3 id="决策树生成过程"><a href="#决策树生成过程" class="headerlink" title="决策树生成过程"></a>决策树生成过程</h3><ol><li><strong>特征选择</strong>：特征选择是指从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。</li><li><strong>决策树生成</strong>： 根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。 树结构来说，递归结构是最容易理解的方式。</li><li><strong>剪枝</strong>：决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合.剪枝技术有<code>预剪枝</code>和<code>后剪枝</code>两种.</li></ol><p>​    在非结束的条件下，首先选择出<code>合适的特征</code>，然后根据其分类。分类开始时，记录分类的特征到决策树中，然后在特征标签集中删除该特征，表示已经使用过该特征。<code>根据选中的特征将数据集分为若干个子数据集</code>，然后将子数据集作为参数<code>递归创建决策树</code>，最终生成一棵完整的决策树。</p><p>注：理想条件下，任何到达叶子节点的数据必然属于叶子结点的分类</p><h3 id="递归结束的条件"><a href="#递归结束的条件" class="headerlink" title="递归结束的条件"></a>递归结束的条件</h3><ul><li><p>每个分支下的所有实例都具有<code>相同的分类</code></p></li><li><p>程序遍历完所有划分数据集的<code>属性</code></p><p>遍历完全部属性，划分的数据有可能不全属于一个类，这个时候需要根据<strong>多数表决准则</strong>确定该子数据集的分类</p></li></ul><h3 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h3><ul><li>优点：决策树计算复杂度不高、便于使用、而且高效，决策树可处理具有不相关特征的数据、可很容易地构造出易于理解的规则，而规则通常易于解释和理解。</li><li>缺点：存在处理缺失数据时的困难、过度拟合以及忽略数据集中属性之间的相关性等问题。</li></ul><h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p><strong>特点</strong>：使用<code>信息增益</code>来选择特征，信息增益<code>大</code>的优先选择</p><p><strong>算法步骤</strong>：</p><p>1）初始化信息增益的阈值$ϵ$</p><p>2）判断样本是否为同一类输出$D_i$，如果是则返回单节点树$T$。标记类别为$D_i$</p><p>3）判断特征是否为空，如果是则返回单节点树🌲$T$，标记类别为样本中输出类别$D$实例数最多的类别</p><p>4）计算$A$中的各个特征（一共$n$个）对输出$D$的信息增益，选择信息增益最大的特征$A_g$</p><p>5）如果$A_g$的信息增益小于阈值$ϵ$，则返回单节点树🌲$T$，标记类别为样本中输出类别$D$实例数最多的类别</p><p>6）否则，按特征$A_g$的不同取值$A_{gi}$将对应的样本输出$D$分成不同的类别$D_i$。每个类别产生一个子节点。对应特征值为$A_{gi}$。返回增加了节点的树🌲$T$</p><p>7）对于所有的子节点，令$D=D_i$,$A=A−{A_g}$递归调用2-6步，得到子树🌲$T_i$并返回</p><p><strong>不足</strong>：</p><p>a）ID3没有考虑<code>连续特征</code>，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。</p><p>b）ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大（即<code>用信息增益作为标准容易偏向于取值较多的特征</code>）。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。如果校正这个问题呢？</p><p>c）ID3算法对于<code>缺失值</code>的情况没有做考虑</p><p>d) 没有考虑<code>过拟合</code>的问题</p><h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><p><strong>特点</strong>：采用<code>信息增益比</code>来选择特征，以减少信息增益容易选择特征值多的特征的问题</p><p><strong>算法思路</strong>：针对ID3算法的不足，加以改进</p><p>a）对于第一个问题，不能处理连续特征， C4.5的思路是将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为$a_1,a_2,…,a_m$,则C4.5取相邻两样本值的平均数，一共取得m-1个划分点，其中第i个划分点$T_i$表示为：$T_i=\frac{a_i+a_{i+1}}{2}$。对于这m-1个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。比如取到的增益最大的点为$a_t$，则小于$a_t$的值为$类别1$，大于$a_t$的值为$类别2$，这样我们就做到了连续特征的离散化。要注意的是，与离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。</p><p>b）对于第二个问题，信息增益作为标准容易偏向于取值较多的特征的问题。我们引入一个<code>信息增益比</code>的变量$I_R(D,A)$  (下文”相关概念”中有该变量的详细说明)。特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题。</p><p>c）对于第三个缺失值处理的问题，主要需要解决的是两个问题，一是在样本某些特征缺失的情况下<code>选择划分的属性</code>，二是选定了划分属性，对于在该属性上缺失特征的<code>样本处理</code>。</p><p>​    对于第一个子问题，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据$D_1$，另一部分是没有特征A的数据D2。然后对于没有缺失特征A的数据集$D_1$来和对应的A特征的各个特征值一起计算<code>加权重后的信息增益比</code>，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。</p><p>​    对于第二个子问题，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的<strong>权重</strong>按各个子节点样本的<strong>数量比例</strong>来分配。比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。</p><p>d）对于第4个问题，C4.5引入了正则化系数进行初步的剪枝。下文介绍CART算法时会详细讨论剪枝的思路。</p><p><strong>不足</strong>：</p><ul><li><p>由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。一般地，常采用”后剪枝加上交叉验证”选择最合适的决策树。</p></li><li><p>C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</p></li><li><p>C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</p></li><li><p>C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。</p></li></ul><h3 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h3><p><strong>特点</strong>：使用<code>基尼系数</code>来选择特征，简化模型（减少计算量）同时也不至于完全丢失熵模型的优点。</p><p><strong>对于连续特征和离散特征处理的改进</strong>：</p><ul><li>对于CART分类树<code>连续值</code>的处理问题，其思想和C4.5是相同的，都是将连续的特征离散化。唯一的区别在于在选择划分点时的度量方式不同，C4.5使用的是信息增益比，则CART分类树使用的是基尼系数。</li><li>对于CART分类树<code>离散值</code>的处理问题，采用的思路是不停的二分离散特征。如果某个特征A被选取建立决策树节点，它有A1,A2,A3三种类别，CART分类树会考虑把A分成${A_1}$和${A_2,A_3}$, ${A_2}$和${A_1,A_3}$,${A_3}$和${A_1,A_2}$三种情况，找到基尼系数最小的组合，比如${A_2}$和${A_1,A_3}$，然后建立二叉树节点，一个节点是$A2$对应的样本，另一个节点是${A1,A3}$对应的节点。同时，由于这次没有把特征A的取值完全分开，后面我们还有机会在子节点继续选择到特征A来划分A1和A3。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。</li></ul><p><strong>构建CART分类树的算法步骤</strong>：算法输入是训练集D，基尼系数的阈值，样本个数阈值；输出是决策树T；从根节点开始，用训练集递归的建立CART树。</p><p>1）对于当前节点的数据集为D，如果样本个数小于阈值或者没有特征，则返回决策子树，当前节点停止递归。</p><p>2）计算样本集D的基尼系数，如果基尼系数小于阈值，则返回决策树子树，当前节点停止递归。</p><p>3）计算当前节点现有的各个特征的各个特征值对数据集D的基尼系数，缺失值的处理和C4.5算法里描述的相同。</p><p>4）在计算出来的各个特征的各个特征值对数据集D的基尼系数中，选择基尼系数最小的特征A和对应的特征值a。根据这个最优特征和最优特征值，把数据集划分成两部分D1和D2，同时建立当前节点的左右节点，做节点的数据集D为D1，右节点的数据集D为D2.</p><p>5）对左右的子节点递归的调用1-4步，生成决策树。</p><p>对于生成的决策树做预测的时候，假如测试集里的样本A落到了某个叶子节点，而节点里有多个训练样本。则对于A的类别预测采用的是这个叶子节点里概率最大的类别（<strong>多数表决准则</strong>）。</p><p><strong>构建CART回归树算法</strong>：</p><p>​    CART回归树和CART分类树的建立算法大部分是类似的，所以这里我们只讨论CART回归树和CART分类树的建立算法不同的地方。</p><p>​    首先，我们要明白，什么是回归树，什么是分类树。两者的区别在于样本输出，如果样本输出是离散值，那么这是一颗分类树。如果果样本输出是连续值，那么那么这是一颗回归树。</p><p>​    除了概念的不同，CART回归树和CART分类树的建立和预测的区别主要有下面两点：</p><p>​    1)连续值的处理方法不同</p><p>​    2)决策树建立后做预测的方式不同。</p><p>​    对于连续值的处理，我们知道CART分类树采用的是用基尼系数的大小来度量特征的各个划分点的优劣情况。这比较适合分类模型，但是对于回归模型，我们使用了常见的<strong>和方差</strong>的度量方式，CART回归树的度量目标是，对于任意划分特征A，对应的任意划分点s两边划分成的数据集D1和D2，求出使D1和D2各自集合的<strong>均方差最小</strong>，同时D1和D2的<strong>均方差之和最小</strong>所对应的特征和特征值划分点。表达式为：<br>$$ \underbrace{min}_{A,s}\Bigg[\underbrace{min}_{c_1}\sum\limits_{x_i \in D_1(A,s)}(y_i - c_1)^2 + \underbrace{min}_{c_2}\sum\limits_{x_i \in D_2(A,s)}(y_i - c_2)^2\Bigg]$$ <br>其中，c1c1为D1数据集的样本输出均值，c2c2为D2数据集的样本输出均值。    </p><p>​    对于决策树建立后做预测的方式，上面讲到了CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来<code>预测输出结果</code>。</p><p>​    除了上面提到了以外，CART回归树和CART分类树的建立算法和预测没有什么区别。</p><h4 id="CART树算法的剪枝"><a href="#CART树算法的剪枝" class="headerlink" title="CART树算法的剪枝"></a>CART树算法的剪枝</h4><p>​    由于决策时算法很容易对训练集<code>过拟合</code>，而导致泛化能力差，为了解决这个问题，我们需要对CART树进行剪枝，即类似于线性回归的正则化，来增加决策树的泛化能力。但是，有很多的剪枝方法，我们应该这么选择呢？CART采用的办法是<code>后剪枝法</code>，即先生成决策树，然后产生所有可能的剪枝后的CART树，然后使用<code>交叉验证</code>来检验各种剪枝的效果，选择泛化能力最好的剪枝策略。</p><p>​    也就是说，CART树的剪枝算法可以概括为两步，第一步是从原始决策树生成<code>各种剪枝效果</code>的决策树，第二步是用交叉验证来检验剪枝后的预测能力，选择泛化预测能力最好的、剪枝后的树作为最终的CART树🌲。</p><p>​    首先我们看看剪枝的损失函数度量，在剪枝的过程中，对于任意的一刻子树$T$,其损失函数为：<br>$$ C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|$$ <br>其中，$α$为正则化参数，这和线性回归的正则化一样。$C(T_t)$为训练数据的预测误差，分类树是用基尼系数度量，回归树是均方差度量。$|T_t|$是子树T的叶子节点的数量。</p><p>​    当$α=0$时，即没有正则化，原始的生成的CART树即为最优子树。当$α=∞$时，即正则化强度达到最大，此时由原始的生成的CART树的根节点组成的单节点树为最优子树。当然，这是两种极端情况。一般来说，$α$越大，则剪枝剪的越厉害，生成的最优子树相比原生决策树就越偏小。对于固定的$α$，一定存在使损失函数$C_α(T)$最小的唯一子树。　　　　</p><p>​    看过剪枝的损失函数度量后，我们再来看看剪枝的思路，对于位于节点t的任意一颗子树$T_t$，如果没有剪枝，它的损失是<br>$$ C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|$$ <br>​    如果将其剪掉，仅仅保留根节点，则损失是<br>$$ C_{\alpha}(T) = C(T) + \alpha$$ <br>​    当$α=0$或者$α$很小时，$C_{\alpha}(T_t) &lt; C_{\alpha}(T)$ . 当$α$增大到一定的程度时，$C_{\alpha}(T_t) = C_{\alpha}(T)$ 。当$α$继续增大时不等式反向，也就是说，如果满足下式：$\alpha = \frac{C(T)-C(T_t)}{|T_t|-1}$，$T_t$和$T$有相同的损失函数，但是$T$节点更少，因此可以对子树$T_t$进行剪枝，也就是将它的子节点全部剪掉，变为一个叶子节点$T$。</p><p>​    最后我们看看CART树的交叉验证策略。上面我们讲到，可以计算出每个子树是否剪枝的阈值$α$，如果我们把所有的节点是否剪枝的值$α$都计算出来，然后分别针对不同的$α$所对应的剪枝后的最优子树做交叉验证。这样就可以选择一个最好的$α$，有了这个$α$，我们就可以用对应的最优子树作为最终结果。</p><p><strong>CART树的剪枝算法</strong>：</p><p>- 输入是CART树建立算法得到的原始决策树$T$</p><p>- 输出是最优决策子树$T_α$</p><p>1）初始化$α_{min}=∞$， 最优子树集合$ω={T}$。</p><p>2）从叶子节点开始自下而上计算各内部节点t的训练误差损失函数$C_α(T_t)$（回归树为均方差，分类树为基尼系数）, 叶子节点数$|T_t|$，以及正则化阈值$α=min{\frac{C(T)−C(T_t)}{|Tt|−1},α<em>{min}}$, 更新$α</em>{min}=α$</p><p>3) 得到所有节点的$α$值的集合M。</p><p>4）从M中选择最大的值$α_k$，自上而下的访问子树t的内部节点，如果$\frac{C(T)−C(T_t)}{|T_t|−1}≤α_k$时，进行剪枝。并决定叶节点t的值。如果是分类树，则是概率最高的类别，如果是回归树，则是所有样本输出的均值。这样得到$α_k$对应的最优子树$T_k$</p><p>5）最优子树集合$ω=ω∪T_k$， $M=M−{α_k}$。</p><p>6）如果M不为空，则回到步骤4。否则就已经得到了所有的可选最优子树集合$ω$.</p><p>7）采用交叉验证在$ω$选择最优子树$T_α$</p><p><strong>不足</strong>：</p><ul><li>无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1，这里不多介绍。</li><li>如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。</li></ul><h3 id="算法小结"><a href="#算法小结" class="headerlink" title="算法小结"></a>算法小结</h3><table><thead><tr><th>算法</th><th>支持模型</th><th>树结构</th><th>特征选择</th><th>连续值处理</th><th>缺失值处理</th><th>剪枝</th></tr></thead><tbody><tr><td>ID3</td><td>分类</td><td>多叉树</td><td>信息增益</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr><td>C4.5</td><td>分类</td><td>多叉树</td><td>信息增益比</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>CART</td><td>分类，回归</td><td>二叉树</td><td>基尼系数，均方差</td><td>支持</td><td>支持</td><td>支持</td></tr></tbody></table><h2 id="决策树相关概念"><a href="#决策树相关概念" class="headerlink" title="决策树相关概念"></a>决策树相关概念</h2><h3 id="信息熵-Entropy"><a href="#信息熵-Entropy" class="headerlink" title="信息熵 Entropy"></a>信息熵 Entropy</h3><ul><li><p>概念说明：熵表示混乱的程度，<strong>熵越大，越混乱</strong>，比如一杯浑浊水的熵就比一杯纯净的水熵大.</p></li><li><p>在信息论和概率统计中，设X是一个取有限个值的离散随机变量，其概率分布为：<br>$$   P(X=x_i)=p_i,i=1,2,3,..,n \tag{1}  $$ <br>则随机变量X的熵定义为：<br>$$   H(X)=-\sum _{i=1}^n p_i\log _2p_i\tag{2}  $$ <br>若$pi=0$，则规定$0log0=0$。需要说明的是，熵<code>只依赖于</code>$X$<code>的分布</code>，而不依赖于$X$的值.</p><ul><li><p>若$D:p_1=\frac{2}{5} \quad p_2=\frac{3}{5} $，则  $H(D)=-\left (-\frac {2}{5}\log _2 \frac {2}{5}-\frac {3}{5}\log _2\frac {3}{5}\right )=0.971$</p></li><li><p>推广：多个变量的联合熵，这里给出两个变量X和Y的<strong>联合熵</strong>表达式：<br>$$     H(X,Y) = -\sum\limits_{i=1}^{n}p(x_i,y_i)logp(x_i,y_i)    $$ </p></li></ul></li></ul><h3 id="条件熵-Conditional-Entropy"><a href="#条件熵-Conditional-Entropy" class="headerlink" title="条件熵 Conditional Entropy"></a>条件熵 Conditional Entropy</h3><ul><li><p>概念说明：条件熵 $H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性，定义为$X$给定条件下<code>Y</code>的条件概率分布的熵<code>对X的数学期望</code>。</p></li><li><p>条件熵的计算公式如下：<br>$$   H(Y|X)= -\sum\limits_{i=1}^{n}p(x_i,y_i)logp(y_i|x_i)=\sum _{i=1}^np(x_i)H(Y|X=x_i)\tag {3}  $$ <br>当熵和条件熵中的概率由<code>数据估计</code>得到时，所对应的熵与条件熵分别称为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</p></li></ul><h3 id="信息增益-Information-gain"><a href="#信息增益-Information-gain" class="headerlink" title="信息增益 Information gain"></a>信息增益 Information gain</h3><ul><li><p>概念说明：<strong>信息增益</strong>表示得知特征X的信息而使得类Y的信息的不确定性<code>减少的程度</code>。换一个角度解释一下，一杯浑浊的水$Y$，其熵为$H1$，现在将其中悬浮的一类物质$X$去除，这杯水的熵下降为$H2$，则物质$X$对于这杯水的信息增益就为$H1−H2$。</p></li><li><p>特征$X$对数据集$D$的信息增益记为$I(X,Y)$，计算公式如下：<br>$$   I(X,Y)=H(X)-H(X|Y) \tag {4}  $$ <br>其中$H(X|Y)$为特征X给定条件下$Y$的经验条件熵。</p></li><li><p>比较各个特征的信息增益，<code>选择信息增益最大的</code>作为分类的<code>最优特征</code>。</p><p><strong>ID3决策树在生成的过程中，根据信息增益来选择特征。</strong></p></li></ul><hr><p><strong>关系梳理</strong>：$H(X)$度量了X的不确定性，条件熵$H(X|Y)$度量了我们在知道$Y$以后$X$剩下的不确定性，$H(X)-H(X|Y)$为信息增益$I(X,Y)$</p><p><img src="/2018/11/24/DataMining-Review-Assignment/%E6%A6%82%E5%BF%B5%E5%9B%BE%E7%A4%BA.png" style="zoom:80%"></p><p>左边的椭圆代表$H(X)$,右边的椭圆代表$H(Y)$,中间重合的部分就是我们的互信息或者信息增益$I(X,Y)$, 左边的椭圆去掉重合部分就是$H(X|Y)$,右边的椭圆去掉重合部分就是$H(Y|X)$。两个椭圆的并就是$H(X,Y)$。</p><hr><h3 id="信息增益比-Information-gain-Ratio"><a href="#信息增益比-Information-gain-Ratio" class="headerlink" title="信息增益比 Information gain Ratio"></a>信息增益比 Information gain Ratio</h3><ul><li><p>引入目的：以信息增益作为划分训练数据集的特征，存在<code>偏向于选择取值较多</code>的特征的问题，使用<strong>信息增益比</strong>可以对这一问题进行校正。</p></li><li><p>概念说明：信息增益比是信息增益和特征熵的比值。</p></li><li><p>信息增益比计算公式如下：<br>$$   I_R(D,A)=\frac {I(A,D)}{H_A(D)} \tag {5}  $$ <br>其中$D$为样本特征输出的集合，$A$为样本特征，对于特征熵$H_A(D)$, 表达式如下：<br>$$   H_A(D)=-\sum _{i=1}^n\frac {|D_i|}{|D|}\log _2 \frac {|D_i|}{|D|}\tag {6}  $$ <br>特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题。</p></li><li><p>根据信息增益比，选择<code>数值最大的</code>作为分类的最优特征。</p><p><strong>C4.5决策树在生成的过程中，根据信息增益比来选择特征。</strong></p></li></ul><h3 id="基尼指数-GINI-index"><a href="#基尼指数-GINI-index" class="headerlink" title="基尼指数 GINI index"></a>基尼指数 GINI index</h3><ul><li><p>基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益(比)是相反的。</p></li><li><p>在分类问题中，假设有$K$个类别，第$k$个类别的概率为$p_k$, 则基尼系数的表达式为：<br>$$   Gini(p) = \sum\limits_{k=1}^{K}p_k(1-p_k) = 1- \sum\limits_{k=1}^{K}p_k^2  $$ <br>如果是<code>二类</code>分类问题，计算就更加简单了，如果属于第一个样本输出的概率是p，则基尼系数的表达式为：<br>$$   Gini(p) = 2p(1-p)  $$ <br>对于个给定的样本$D$,假设有$k$个类别, 第k个类别的数量为$C_k$,则样本$D$的基尼系数表达式为：<br>$$   Gini(D) = 1-\sum\limits_{k=1}^{K}(\frac{|C_k|}{|D|})^2  $$ <br>特别的，对于样本$D$,如果根据特征$A$的某个值$a$,把$D$分成$D_1$和$D_2$两部分，则在特征$A$的条件下，$D$的基尼系数表达式为：<br>$$   Gini(D,A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)  $$ <br>和熵模型的度量方式比，基尼系数对应的误差有多大呢？对于二类分类，基尼系数和熵之半的曲线如下：</p><p><img src="/2018/11/24/DataMining-Review-Assignment/GINIvsENTROPY.jpg" style="zoom:80%"></p><p>从上图可以看出，基尼系数和熵之半的曲线非常接近，仅仅在45度角附近误差稍大。因此，基尼系数可以做为熵模型的一个近似替代。而<strong>CART分类树算法就是使用的基尼系数来选择决策树的特征</strong>。同时，为了进一步简化，CART分类树算法每次仅仅对某个特征的值进行二分，而不是多分，这样CART分类树算法建立起来的是二叉树，而不是多叉树。这样一可以进一步简化基尼系数的计算，二可以建立一个更加优雅的二叉树模型。</p></li></ul><p>参考：<a href="https://blog.csdn.net/xuelabizp/article/details/50979469" target="_blank" rel="noopener">手把手生成决策树(dicision tree)</a>\决策树算法原理<a href="https://www.cnblogs.com/pinard/p/6050306.html" target="_blank" rel="noopener">(上)</a>、<a href="http://www.cnblogs.com/pinard/p/6053344.html" target="_blank" rel="noopener">(下)</a></p><p>阅读链接：<a href="">决策树(Decision Tree)：通俗易懂之介绍</a></p><h1 id="贝叶斯、SVM、ANN"><a href="#贝叶斯、SVM、ANN" class="headerlink" title="贝叶斯、SVM、ANN"></a>贝叶斯、SVM、ANN</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Arxiv_AD_with_Code</title>
    <link href="http://yoursite.com/2018/11/23/Arxiv_AD_with_Code/"/>
    <id>http://yoursite.com/2018/11/23/Arxiv_AD_with_Code/</id>
    <published>2018-11-23T14:04:50.000Z</published>
    <updated>2018-11-26T08:52:33.914Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="Alzheimer’s-Disease"><a href="#Alzheimer’s-Disease" class="headerlink" title="Alzheimer’s Disease"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease</a></h5><h5 id="Alzheimer’s-Disease-CNN"><a href="#Alzheimer’s-Disease-CNN" class="headerlink" title="Alzheimer’s Disease CNN"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+CNN&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease CNN</a></h5><ul><li><p><a href="https://arxiv.org/pdf/1808.02874.pdf" target="_blank" rel="noopener">Visualizing Convolutional Networks for MRI-based Diagnosis of Alzheimer’s Disease</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- We downloaded T1-weighted MPRAGE scans <span class="keyword">and</span> non- linearly registered all images to a <span class="number">1</span> mm isotropic ICBM template using <span class="string">'ANTs (http://stnava.github.io/ANTs/)'</span>, resulting <span class="keyword">in</span> volumes of <span class="number">193</span> × <span class="number">229</span> × <span class="number">193.</span></span><br><span class="line">- PyTorch implementations of all visualization methods will be made <span class="string">'available'</span> at http://github.com/jrieke/cnn-interpretability.</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1704.06033.pdf" target="_blank" rel="noopener">Predicting Cognitive Decline with Deep Learning of Brain Metabolism and Amyloid Imaging</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- This supervised learning are conducted by stochastic gradient descent (SGD) algorithm, the &apos;source code&apos; of which is distributed by MatConvNet (Version 1.0-beta 16).</span><br><span class="line">- Goodfellow IJ, Vinyals O, Saxe AM. Qualitatively characterizing neural network optimization problems. arXiv preprint arXiv:14126544 2014.</span><br><span class="line">-  Vedaldi A, Lenc K. MatConvNet: Convolutional neural networks for matlab. Proceedings of the 23rd Annual ACM Conference on Multimedia Conference; 2015: ACM: 689-692.</span><br></pre></td></tr></table></figure></li></ul><h5 id="Alzheimer’s-Disease-DeepLearning"><a href="#Alzheimer’s-Disease-DeepLearning" class="headerlink" title="Alzheimer’s Disease DeepLearning"></a><a href="https://arxiv.org/search/?query=Alzheimer%27s+Disease+Deep+Learning&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" target="_blank" rel="noopener">Alzheimer’s Disease DeepLearning</a></h5><ul><li><p><a href="https://arxiv.org/pdf/1807.10757.pdf" target="_blank" rel="noopener">A multi-contrast MRI approach to thalamus segmentation</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- The supervised learning <span class="keyword">and</span> convex segmentation steps of the algorithm were implemented <span class="keyword">in</span> MATLAB R2017b (The Mathworks Inc., Natick, MA, USA) <span class="keyword">and</span> are available at <span class="string">'https://github.com/veronicacorona/multicontrastSegmentation.git'</span>.</span><br><span class="line">- The dataset used <span class="keyword">in</span> this work <span class="keyword">and</span> the proposed supervised learning <span class="keyword">and</span> convex segmentation imple- mentations are available at <span class="string">'https://github.com/veronicacorona/multicontrastSegmentation.git'</span>.</span><br><span class="line">- Radio-frequency (RF) bias corrected [<span class="number">33</span>] T2∗-weighted magnitude images were affine co-registered to their corresponding bias-corrected MPRAGE volume using <span class="string">'ANTs (http://stnava.github.io/ ANTs/)'</span> [<span class="number">34</span>].</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1803.11550.pdf" target="_blank" rel="noopener">Multi-modal Disease Classification in Incomplete Datasets Using Geometric Matrix Completion</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- Hyperparameters were optimized using Hyperopt(<span class="string">'http://hyperopt.github.io/hyperopt/'</span>), through nested cross-validation, targeting classification loss (binary cross-entropy) on a hold-out validation set (<span class="number">10</span>% <span class="keyword">in</span> each fold of training data).</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1801.00880.pdf" target="_blank" rel="noopener">Deep convolutional neural networks for segmenting 3D in vivo multiphoton images of vasculature in Alzheimer disease mouse models</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- DeepVess <span class="keyword">is</span> freely available at <span class="string">'https://github.com/mhaft/DeepVess'</span> <span class="keyword">and</span> can be used immediately by researchers who use MPM <span class="keyword">for</span> vasculature imaging. </span><br><span class="line">- We hope the availability of our open source code <span class="keyword">and</span> reported results will facilitate <span class="keyword">and</span> motivate the adoption of this method by researchers <span class="keyword">and</span> practitioners.</span><br></pre></td></tr></table></figure></li><li><p><a href="https://arxiv.org/pdf/1711.11117.pdf" target="_blank" rel="noopener">Towards Alzheimer’s Disease Classification through Transfer Learning</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- Architecture models <span class="keyword">for</span> Tensor- Flow <span class="keyword">and</span> pre-trained weights were downloaded <span class="keyword">from</span> open source repositories of the models <span class="number">1</span>[<span class="string">'https://github.com/flyyufelix/cnn finetune'</span>].</span><br><span class="line">- For the Inception V4 model, stochastic gradient descent optimization <span class="keyword">with</span> a learning rate of <span class="number">0.0001</span> was used <span class="number">2</span>[Models, weights, dataset, <span class="keyword">and</span> code available at <span class="string">'https://github.com/ marciahon29/Ryerson MRP'</span>].</span><br><span class="line">- Keeping up <span class="keyword">with</span> the spirit of reproducible research, all our models, dataset, <span class="keyword">and</span> code can be accessed through the repository at: <span class="string">'https://github.com/marciahon29/Ryerson MRP'</span> .</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Numpy_Function</title>
    <link href="http://yoursite.com/2018/11/22/Numpy_Function/"/>
    <id>http://yoursite.com/2018/11/22/Numpy_Function/</id>
    <published>2018-11-22T14:25:41.000Z</published>
    <updated>2018-11-23T12:15:38.819Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="numpy-random-choice"><a href="#numpy-random-choice" class="headerlink" title="numpy.random.choice()"></a>numpy.random.choice()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">- numpy.random.choice(a, size=<span class="keyword">None</span>, replace=<span class="keyword">True</span>, p=<span class="keyword">None</span>)</span><br><span class="line">  - a: If an ndarray, a random sample <span class="keyword">is</span> generated <span class="keyword">from</span> its elements. </span><br><span class="line">       If an int, the random sample <span class="keyword">is</span> generated <span class="keyword">as</span> <span class="keyword">if</span> a was np.arange(n)  <span class="string">'a:[0..a)'</span></span><br><span class="line">  - size : int <span class="keyword">or</span> tuple of ints, optional<span class="string">"随机生成size个数"</span></span><br><span class="line">       If the given shape <span class="keyword">is</span>, e.g., (m, n, k), then m * n * k samples are drawn. </span><br><span class="line">  - replace : boolean, optional <span class="string">'生成数是否可重复 True:可重复  False:不可重复'</span></span><br><span class="line">             If you want only <span class="string">'unique'</span> samples then this should be false.</span><br><span class="line">  - p : <span class="number">1</span>-D array-like, optional <span class="string">'[0..a)中每个出现的概率[p_0 p_1 ...p_a)'</span></span><br><span class="line">        The probabilities associated <span class="keyword">with</span> each entry <span class="keyword">in</span> a. If <span class="keyword">not</span> given the sample assumes a uniform distribution(<span class="string">'均匀分布'</span>) over all entries <span class="keyword">in</span> a.</span><br><span class="line">        </span><br><span class="line">example:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">1</span>, <span class="number">3</span>)<span class="comment">#从[0]中随机生成3个数(默认replace=True 可重复)</span></span><br><span class="line">array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">2</span>, <span class="number">3</span>)<span class="comment">#从[0,1]中随机生成3个数(默认replace=True 可重复)</span></span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">3</span>, <span class="number">3</span>)<span class="comment">#从[0,1,2]中随机生成3个数(默认replace=True 可重复)</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">3</span>, <span class="number">3</span>, replace=<span class="keyword">False</span>) <span class="comment">#从[0，1，2]中随机生成3个不同(不重复)的数</span></span><br><span class="line">array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">5</span>, <span class="number">3</span>, replace=<span class="keyword">False</span>) <span class="comment">#从[0，1，2，3，4]中随机生成3个不同(不重复)的数</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.random.choice(<span class="number">5</span>, <span class="number">3</span>, p=[<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0.3</span>,<span class="number">0.6</span>,<span class="number">0</span>]) <span class="comment">#生成[0,1,2,3,4]的概率分别为[0.1,0,0.3,0.6,0]</span></span><br><span class="line">array([<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h4 id="numpy-argmax"><a href="#numpy-argmax" class="headerlink" title="numpy.argmax()"></a>numpy.argmax()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">- numpy.argmax(a, axis=<span class="keyword">None</span>, out=<span class="keyword">None</span>)</span><br><span class="line">  - a : (array_like)Input array.</span><br><span class="line">  - axis : (int, optional) By default, the index <span class="keyword">is</span> into the flattened array, otherwise along the specified axis.  <span class="string">'0为列 1为行'</span></span><br><span class="line">  - out : (array, optional) If provided, the result will be inserted into this array. It should be of the appropriate shape <span class="keyword">and</span> dtype.</span><br><span class="line">   </span><br><span class="line">  - Returns the <span class="string">'indices'</span> of the maximum values along an axis. 返回的是索引，并非值</span><br><span class="line">    </span><br><span class="line">examplpe:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a) <span class="comment">#flattened array[0,1,2,3,4,5]中最大值(5)索引为5</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a, axis=<span class="number">0</span>) <span class="comment">#第0列[0,3]中最大值(3)索引为1 第1列[1,4]中最大值(4)索引为1 第2列[2,5]中最大值(5)索引为1</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a, axis=<span class="number">1</span>) <span class="comment">#第0行[0,1,2]最大值[2]索引为2，第1行[3,4,5]最大值(5)索引为2</span></span><br><span class="line">array([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.arange(<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">1</span>] = <span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([<span class="number">0</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(b) <span class="comment"># Only the first occurrence is returned.</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">9</span>,<span class="number">8</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">array([[<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(c)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(c,axis=<span class="number">0</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(c,axis=<span class="number">1</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Assignment_Implement_Note</title>
    <link href="http://yoursite.com/2018/11/20/Assignment-Implement-Note/"/>
    <id>http://yoursite.com/2018/11/20/Assignment-Implement-Note/</id>
    <published>2018-11-20T11:10:14.000Z</published>
    <updated>2018-11-23T12:02:27.921Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h5 id="SVM-梯度计算"><a href="#SVM-梯度计算" class="headerlink" title="SVM 梯度计算"></a>SVM 梯度计算<div id="SVM 梯度计算"></div></h5><p><a href="https://captainzj.github.io/2018/10/18/CS231n-Lecture-SVM/#多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss" target="_blank" rel="noopener">SVM原理说明</a>/<a href="https://github.com/Captainzj/CS231n_Assignment/blob/master/assignment1/svm.ipynb" target="_blank" rel="noopener">效果演示</a>/<a href="https://github.com/Captainzj/CS231n_Assignment/blob/master/assignment1/cs231n/classifiers/linear_svm.py" target="_blank" rel="noopener">代码实现</a><br>$$<br>L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]<br>$$</p><p>$$ \left\{\begin{aligned}\nabla_{w_{y_i}} L_i = & -\left(\sum_{j \ne y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0)\right)x_i & j = y_i \\\nabla_{w_j} L_i = & 1(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i & j \ne y_i\end{aligned}\right.$$ <br>其中$\mathbb{1}$是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  dW = np.zeros(W.shape)  <span class="comment">#(3073, 10)</span></span><br><span class="line">  </span><br><span class="line">  num_classes = W.shape[<span class="number">1</span>] <span class="comment">#10</span></span><br><span class="line">  num_train = X.shape[<span class="number">0</span>]  <span class="comment">#500</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):  <span class="comment">#[0,500)</span></span><br><span class="line">    scores = X[i].dot(W)   <span class="comment">#矩阵乘法  (1,3073)*(3073,10)</span></span><br><span class="line">    correct_class_score = scores[y[i]] <span class="comment">#S_yi  该图像在正确标签上的得分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):</span><br><span class="line">      <span class="keyword">if</span> j == y[i]:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note: delta = 1  </span></span><br><span class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>: </span><br><span class="line">        loss += margin</span><br><span class="line">        dW[:, y[i]] -= X[i, :].T <span class="comment"># this is really a sum over j != y_i</span></span><br><span class="line">        dW[:, j] += X[i, :].T <span class="comment"># sums each contribution of the x_i's</span></span><br><span class="line">        </span><br><span class="line">  loss /= num_train</span><br><span class="line">  dW /= num_train</span><br><span class="line">  loss += <span class="number">0.5</span> *reg * np.sum(W * W) </span><br><span class="line">  dW += reg*W</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  dW = np.zeros(W.shape) <span class="comment"># dW.shape==(3073,500)</span></span><br><span class="line">  num_classes=W.shape[<span class="number">1</span>]</span><br><span class="line">  num_train=X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  scores=X.dot(W) <span class="comment">#(500,10) = (500,3073)*(3073,10)</span></span><br><span class="line">  scores_correct = scores[np.arange(num_train), y] <span class="comment">#(500,) scores_correct[i]=scores[i,y[i]]</span></span><br><span class="line">  scores_correct=np.reshape(scores_correct,(num_train,<span class="number">-1</span>))  <span class="comment">#(500,1) = (500,500*1/500)</span></span><br><span class="line">  margins=scores-scores_correct+<span class="number">1</span> <span class="comment">#delta=1  #scores.shape=(500,10)</span></span><br><span class="line">  margins=np.maximum(<span class="number">0</span>,margins)</span><br><span class="line">  margins[np.arange(num_train),y]=<span class="number">0</span></span><br><span class="line">  loss=np.sum(margins)/num_train</span><br><span class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># compute the gradient</span></span><br><span class="line">  margins[margins &gt; <span class="number">0</span>] = <span class="number">1</span>  <span class="comment">#margins中大于0的元素，数值赋为1;其余数值不变   shape==(500,10)</span></span><br><span class="line">  row_sum = np.sum(margins, axis=<span class="number">1</span>)                  <span class="comment"># 1 by N  (1行N列)</span></span><br><span class="line">  margins[np.arange(num_train), y] = -row_sum        <span class="comment">#margins[np.arange(num_train), y] 赋-row_sum前，值为0   shape==(500,)</span></span><br><span class="line">  <span class="comment">#print(margins)  ##necessary to understand</span></span><br><span class="line">  dW += np.dot(X.T, margins)/num_train + reg * W     <span class="comment"># D by C dW.shape==(3073，10) X.T.shape==(3073,500)  margins.shape==(500,10) </span></span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><ul><li>此处解释仅关注dW(即对权重的梯度计算) <code>np.dot(X.T, margins)</code>  </li></ul><p>$$ \underbrace{\underbrace{\begin{bmatrix}\overrightarrow{W_C}&\overrightarrow{W_D} &\overrightarrow{W_A}& \overrightarrow{W_B}\end{bmatrix}}_\text{可看作dW (D,C)}=\underbrace{\begin{bmatrix}\overrightarrow{X_c}&\overrightarrow{X_d}&\overrightarrow{X_a}&\overrightarrow{X_b}\end{bmatrix}}_\text{可看作X.T (D,N)}\underbrace{\begin{bmatrix}  1&1  &-9  &1 \\ 1 & 1 &  1&-9\\-9&  1&  1& 1\\  1&  -9&1  &1  \end{bmatrix}}_\text{可看作margins (N,C)}}_\text{可看作svm_loss_vectorized dW计算过程}=\underbrace{\begin{bmatrix}   \overrightarrow{X_a}+\overrightarrow{X_b}-9\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}-9\overrightarrow{X_d} &-9\overrightarrow{X_a}+\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}&\overrightarrow{X_a}-9\overrightarrow{X_b}+\overrightarrow{X_c}+\overrightarrow{X_d}   \end{bmatrix}}_\text{可看作svm_loss_naive dW计算过程}$$ </p><p>$margins.shape==scores.shape$    $-row_sum=-9 $</p><p>矩阵基本知识：<br>$$ (1)\begin{bmatrix}\overrightarrow{A}&\overrightarrow{B}  &\overrightarrow{C}  & \overrightarrow{D}\end{bmatrix}=\begin{bmatrix}\overrightarrow{a}&\overrightarrow{b}  &\overrightarrow{c}&\overrightarrow{d}\end{bmatrix}\begin{bmatrix} -9&  1&  1& 1\\  1&  -9&1  &1 \\  1&1  &-9  &1 \\ 1 & 1 &  1&-9 \end{bmatrix}=\begin{bmatrix} -9\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-9\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  & \overrightarrow{a}+\overrightarrow{b}-9\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-9\overrightarrow{d}  \end{bmatrix}$$ <br>$$ (2)\begin{bmatrix}\overrightarrow{C}&\overrightarrow{D} &\overrightarrow{A}& \overrightarrow{B}\end{bmatrix}=\begin{bmatrix}\overrightarrow{c}&\overrightarrow{d}&\overrightarrow{a}&\overrightarrow{b}\end{bmatrix}\begin{bmatrix}  1&1  &-9  &1 \\ 1 & 1 &  1&-9\\-9&  1&  1& 1\\  1&  -9&1  &1  \end{bmatrix}=\begin{bmatrix}   \overrightarrow{a}+\overrightarrow{b}-9\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-9\overrightarrow{d} &-9\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}&\overrightarrow{a}-9\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}   \end{bmatrix}$$ </p><p>$$ (3) \begin{bmatrix}\overrightarrow{A}\\\overrightarrow{B}\\\overrightarrow{C}\\\overrightarrow{D}\end{bmatrix}=\begin{bmatrix} -9&  1&  1& 1\\  1&  -9&1  &1 \\  1&1  &-9  &1 \\ 1 & 1 &  1&-9 \end{bmatrix}\begin{bmatrix}\overrightarrow{a}\\\overrightarrow{b}\\\overrightarrow{c}\\\overrightarrow{d}\end{bmatrix}=\begin{bmatrix}-9\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-9\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\ \overrightarrow{a}+\overrightarrow{b}-9\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-9\overrightarrow{d}  \end{bmatrix}$$ </p><p>$$ (4) \begin{bmatrix}\overrightarrow{C}\\\overrightarrow{D}\\\overrightarrow{A}\\\overrightarrow{B}\end{bmatrix}=\begin{bmatrix}   1&1  &-9  &1 \\ 1 & 1 &  1&-9 \\-9&  1&  1& 1\\  1&  -9&1  &1\end{bmatrix}\begin{bmatrix}\overrightarrow{c}\\\overrightarrow{d}\\\overrightarrow{a}\\\overrightarrow{b}\end{bmatrix}=\begin{bmatrix} \overrightarrow{a}+\overrightarrow{b}-9\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}-9\overrightarrow{d}\\-9\overrightarrow{a}+\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}\\\overrightarrow{a}-9\overrightarrow{b}+\overrightarrow{c}+\overrightarrow{d}  \end{bmatrix}$$ </p><ul><li>$C = A B $ 等价于 $C^T = B^T    A^T$</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>DataMining</title>
    <link href="http://yoursite.com/2018/11/20/dataMining/"/>
    <id>http://yoursite.com/2018/11/20/dataMining/</id>
    <published>2018-11-19T17:02:45.000Z</published>
    <updated>2018-11-23T11:31:01.119Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Data-Mining"><a href="#Data-Mining" class="headerlink" title="Data Mining"></a>Data Mining</h2><h3 id="Introduction-to-R"><a href="#Introduction-to-R" class="headerlink" title="Introduction to R"></a>Introduction to R</h3><ul><li>R语言概述</li><li>R语言数据类型</li><li>R语言数据管理</li><li>R语言绘图</li><li>R语言高级数据管理</li></ul><h3 id="Introduction-to-Data-Mining"><a href="#Introduction-to-Data-Mining" class="headerlink" title="Introduction to Data Mining"></a>Introduction to Data Mining</h3><ul><li>Know your data<ul><li>Data types</li><li>Statistical description of the data</li><li>Data visualization </li><li>Data similarity and dissimilarity</li></ul></li><li>Preprocess the data<ul><li>Cleaning the data</li><li>Integration the data</li><li>Reduction the data</li><li>Dimensionality reduction</li></ul></li><li>Some public datasets available</li></ul><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><ul><li><p>Classification: Basic Concepts </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- Supervision vs. Unsupervised Learning</span><br><span class="line">- Supervision (监督学习)：我们对输入样本经过模型训练后有明确的预期输出</span><br><span class="line">- Classification(分类)：想要预测的是离散值discrete(即标称型)</span><br><span class="line">- Regression(回归)：想要预测的是连续值nominal(即数值型)</span><br><span class="line">- Unsupervised(非监督学习)：我们对输入样本经过模型训练后得到什么输出完全没有预期</span><br></pre></td></tr></table></figure></li><li><p>Decision Tree Induction </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- Basic algorithm</span><br><span class="line">- 树以自上而下，递归，分而治之的方式构建</span><br><span class="line">- 所有的训练样例从根源开始分类</span><br><span class="line">- 根据所选属性递归分区示例</span><br><span class="line">- 在每个节点上，根据该节点上的训练样例以及启发式或统计度量（例如，信息增益）选择属性</span><br><span class="line">- Conditions for stopping partitioning</span><br><span class="line">- 给定节点的所有样本都属于同一个类</span><br><span class="line">- 没有剩余属性可用于进一步分区</span><br><span class="line">- 没有剩下的样例</span><br><span class="line">- Prediction</span><br><span class="line">- 采用多数投票对叶子进行分类</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 信息熵(Entropy) </span><br><span class="line">  - 定义：考虑该随机变量的所有可能取值，即所有可能发生事件所带来的信息量的期望</span><br><span class="line">  - 不确定性越大，熵越大</span><br><span class="line">- 条件熵(Conditional Entropy)</span><br><span class="line">  - 定义：另一个变量Y熵对X（条件）的期望</span><br><span class="line">- 信息增益(Information gain)</span><br><span class="line">- 增益率(Gain ratio)</span><br><span class="line">- 吉尼系数(Giniindex)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- Overfitting and Tree Pruning</span><br><span class="line">- Overfitting(过拟合):An induced tree may overfit the training data</span><br><span class="line">- Too many branches, some may reflect anomalies due to noise or outliers</span><br><span class="line">- Poor accuracy for unseen samples</span><br><span class="line">- Two approaches to avoid overfitting</span><br><span class="line">- Prepruning(预剪枝): Halt tree construction early ̵ do not split a node if this</span><br><span class="line">would result in the goodness measure falling below a threshold </span><br><span class="line">- Difficult to choose an appropriate threshold</span><br><span class="line">- Postpruning(后剪枝): Remove branches from a “fully grown” tree—get a sequence of progressively pruned trees</span><br><span class="line">- Use a set of data different from the training data to decide which is the “best pruned tree”</span><br></pre></td></tr></table></figure></li><li><p>Model Evaluation and Selection </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- Evaluation metrics</span><br><span class="line">- How can we measure accuracy? </span><br><span class="line">    - Other metrics to consider?</span><br><span class="line">- Use validation test set of class-labeled tuples instead of training set when assessing accuracy</span><br><span class="line">- Methods for estimating a classifier’s accuracy </span><br><span class="line">- Holdout method</span><br><span class="line">- Cross-validation</span><br><span class="line">- Bootstrap</span><br><span class="line">- Comparing classifiers: </span><br><span class="line">- ROC Curves</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Issues Affecting Model Selection</span><br><span class="line">- Accuracy</span><br><span class="line">- classifier accuracy: predicting class label</span><br><span class="line">- Speed</span><br><span class="line">- time to construct the model (training time)</span><br><span class="line">- time to use the model (classification/prediction time)</span><br><span class="line">- Robustness: handling noise and missing values</span><br><span class="line">- Scalability(可伸缩性): efficiency in disk-resident databases</span><br><span class="line">- Interpretability</span><br><span class="line">- understanding and insight provided by the model</span><br><span class="line">- Other measures, e.g., goodness of rules, such as decision tree size or compactness(紧凑性) of classification rules</span><br></pre></td></tr></table></figure></li><li><p>Techniques to Improve Classification Accuracy: Ensemble Methods </p></li><li><p>Bayes Classification Methods </p></li><li><p>Support Vector Machine (SVM)</p></li><li><p>Artificial Neural Network (ANN)</p></li><li><p>Summary </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">- Classification is a form of data analysis that extracts models describing important data classes.</span><br><span class="line">-  Effective and scalable(可扩展) methods have been developed for decision tree induction(归纳), Naive Bayesian classification, rule-based classification, and many other classification methods.</span><br><span class="line">- Evaluation metrics(指标) include: accuracy, sensitivity, specificity(特异性), precision(精确性), recall(召回率), F measure(度量), and Fß measure.</span><br><span class="line">- Stratified(分层) k-fold cross-validation is recommended for accuracy estimation. Bagging() and boosting() can be used to increase overall accuracy by learning and combining a series of individual(单独的) models.</span><br><span class="line">- Significance tests and ROC curves are useful for model selection. </span><br><span class="line">- There have been numerous comparisons of the different classification methods; the matter remains a research topic</span><br><span class="line">- No single method has been found to be superior over all others for all data sets(各方法各有千秋)</span><br><span class="line">- Issues such as accuracy, training time, robustness, scalability, and interpretability must be considered and can involve trade- offs(权衡), further complicating(复杂化) the quest for an overall superior method</span><br><span class="line">- Effective and advanced classification methods</span><br><span class="line">- Bayesian belief network (probabilistic概率 networks)</span><br><span class="line">- Backpropagation反向传播 (Neural networks)</span><br><span class="line">- Support Vector Machine (SVM)</span><br><span class="line">- Pattern-based classification</span><br><span class="line">- Other classification methods: lazy learners (KNN, case-based reasoning推理), genetic algorithms(遗传算法), rough set(粗糙集) and fuzzy set(模糊集) approaches</span><br><span class="line">- Additional Topics on Classification </span><br><span class="line">- Multiclass classification</span><br><span class="line">- Semi-supervised(半监督) classification </span><br><span class="line">    - Active learning(主动学习)</span><br><span class="line">- Transfer learning(迁移学习)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ADNI_Publications_digest</title>
    <link href="http://yoursite.com/2018/11/12/ADNI-Publications-digest/"/>
    <id>http://yoursite.com/2018/11/12/ADNI-Publications-digest/</id>
    <published>2018-11-12T06:16:06.000Z</published>
    <updated>2018-11-22T03:10:49.573Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>11</p><p><a href="http://adni.loni.usc.edu/adni-publications/Bayesian%20longitudinal%20low-rank%20regression%20models%20for%20imaging%20genetic%20data%20from%20longitudinal%20studies.pdf" target="_blank" rel="noopener">Bayesian longitudinal low-rank regression models for imaging genetic data from longitudinal studies</a><br>Z. H. Lu, Z. Khondker, J. G. Ibrahim, Y. Wang, H. Zhu and I. Alzheimer’s Disease Neuroimaging<br>Feature：开发了一个贝叶斯L2R2模型来确定纵向成像响应和协变量与成像遗传数据的关系</p><p>Result：我们应用L2R2模型来<strong>研究</strong>前10位单核苷酸多态性(SNPs)和前40位老年痴呆症相关基因的<strong>影响</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Structured%20and%20Sparse%20Canonical%20Correlation%20Analysis%20as%20a%20Brain-Wide%20Multi-Modal%20Data%20Fusion%20Approach.pdf" target="_blank" rel="noopener">Structured and Sparse Canonical Correlation Analysis as a Brain-Wide Multi-Modal Data Fusion Approach    </a><br>A. R. Mohammadi-Nejad, G. A. Hossein-Zadeh and H. Soltanian-Zadeh </p><p>Feature：提出了一种结构稀疏CCA (ssCCA)技术作为一种脑域多模态数据融合方法。</p><p>Result：ssCCA优于现有标准和正规化的基于CCA的融合方法。结果表明，所提出的无监督技术<strong>区分</strong>了AD患者的受试者过程与HC受试者之间的过渡模式。此外，我们还绘制了与AD患者相对于HC患者的解剖变化最相关的功能区域的脑图。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Normative%20morphometric%20data%20for%20cerebral%20cortical%20areas%20over%20the%20lifetime%20of%20the%20adult%20human%20brain.pdf" target="_blank" rel="noopener">Normative morphometric data for cerebral cortical areas over the lifetime of the adult human brain</a><br>O. Potvin, L. Dieumegarde, S. Duchesne and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：制定可以量化大脑异常的健康成人大脑皮层区域的<strong>规范数据</strong>，填补神经成像在此方面的不足。在健康成人的独立样本中验证了<strong>预测规范性数值</strong>的模型，显示了令人满意的验证R2。在轻度阿尔茨海默氏病和精神分裂症患者中，测量标准样本的偏差，并观察偏差的预期模式。</p><p><a href="http://adni.loni.usc.edu/adni-publications/High-resolution%20magnetic%20resonance%20imaging%20reveals%20nuclei%20of%20the%20human%20amygdala-%20manual%20segmentation%20to%20automatic%20atlas.pdf" target="_blank" rel="noopener">High-resolution magnetic resonance imaging reveals nuclei of the human amygdala: manual segmentation to automatic atlas</a><br>Z. M. Saygin, D. Kliemann, J. E. Iglesias, A. J. W. van der Kouwe, E. Boyd, M. Reuter, A. Stevens, K. Van Leemput, A. McKee, M. P. Frosch, B. Fischl, J. C. Augustinack and I. Alzheimer’s Disease Neuroimaging Feature：使用基于贝叶斯推理的atlas构建算法，使用高分辨率离体MRI数据<strong>自动分割</strong>可视化9个amygdala nuclei 的边界。提供了标准体内神经成像工具，能够自动将杏仁核划分成多个核，为神经成像研究人员提供探索人类杏仁核功能和连接的能力。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Independent%20value%20added%20by%20diffusion%20MRI%20for%20prediction%20of%20cognitive%20function%20in%20older%20adults.pdf" target="_blank" rel="noopener">Independent value added by diffusion MRI for prediction of cognitive function in older adults        </a><br>J. A. Scott, D. Tosun, M. N. Braskie, P. Maillard, P. M. Thompson, M. Weiner, C. DeCarli, O. T. Carmichael and Adni </p><p>Feature：<strong>预测老年人的认知功能</strong>. 确定通过扩散磁共振成像（dMRI）测量的白质微观结构能否提供关于认知障碍的老年人的基线水平或执行功能（EF）或记忆（MEM）变化的独立信息</p><p><a href="http://adni.loni.usc.edu/adni-publications/Opposing%20effects%20of%20progranulin%20deficiency%20on%20amyloid%20and%20tau%20pathologies%20via%20microglial%20TYROBP%20network.pdf" target="_blank" rel="noopener">Opposing effects of progranulin deficiency on amyloid and tau pathologies via microglial TYROBP network</a><br>H. Takahashi, Z. A. Klein, S. M. Bhagat, A. C. Kaufman, M. A. Kostylev, T. Ikezu, S. M. Strittmatter and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：探究缺乏颗粒体蛋白前体(PGRN)关于淀粉样蛋白和tau病理的<strong>反作用</strong>.揭示了GRN与AD的多维相互作用。PGRN缺乏会增加对Aβ的积累</p><p><a href="http://adni.loni.usc.edu/adni-publications/On%20the%20complexity%20of%20human%20neuroanatomy%20at%20the%20millimeter%20morphome%20scale-%20Developing%20codes%20and%20characterizing%20entropy%20indexed%20to%20spatial%20scale.pdf" target="_blank" rel="noopener">On the complexity of human neuroanatomy at the millimeter morphome scale: Developing codes and characterizing entropy indexed to spatial scale</a><br>D. J. Tward and M. I. Miller </p><p>Feature：我们通过使用来自阿尔茨海默病神经影像学计划的数据来训练多变量高斯先验模型，通过将它们与模板相关的微分变换来<strong>研究人脑中皮质下灰质结构的形状</strong>。这项工作代表了量化神经影像学研究可以提供疾病状态的信息量的第一步。</p><p><a href="http://adni.loni.usc.edu/adni-publications/jamaneurology_van_Maurik_2017_oi_170070.pdf" target="_blank" rel="noopener">Interpreting Biomarker Results in Individual Patients With Mild Cognitive Impairment in the Alzheimer’s Biomarkers in Daily Practice (ABIDE) Project</a><br>I. S. van Maurik, M. D. Zwan, B. M. Tijms, F. H. Bouwman, C. E. Teunissen, P. Scheltens, M. P. Wattjes, F. Barkhof, J. Berkhof, W. M. van der Flier and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：建立基于生物标志物的MCI患者未来<strong>AD痴呆预后模型</strong>。解释患有轻度认知障碍的个体患者的生物标志物结果，构建基于生物标记物的预测模型，帮助临床医生解释生物标记值并提供个性化的预测信息。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Generalized%20Scalar%20on%20Image%20Regression%20Models%20via%20Total%20Variation.pdf" target="_blank" rel="noopener">Generalized Scalar-on-Image Regression Models via Total Variation</a><br>X. Wang and H. Zhu </p><p>Feature：构建了一类基于总变差的广义标量图像回归模型(GSIRM-TV)，用于标量响应和存在标量协变量的<strong>成像预测器</strong>，可应用于从ADNI数据集获得的海马数据的分析。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Imaging-wide%20association%20study-%20Integrating%20imaging%20endophenotypes%20in%20GWAS.pdf" target="_blank" rel="noopener">Imaging-wide association study: Integrating imaging endophenotypes in GWAS</a><br>Z. Xu, C. Wu, W. Pan and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：提出了一种新的、强大的方法，称为全成像关联研究(image -wide association study, IWAS)，将成像内表型与GWAS相结合，以增强<strong>统计</strong>能力，并增强GWAS发现的生物学解释。所提出的IWAS是通用的，可以应用于其他的成像内表型，以及GWAS的个体水平或汇总关联数据。</p><p>12.</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20Novel%20Early%20Diagnosis%20System%20for%20Mild%20Cognitive%20Impairment%20Based%20on%20Local%20Region%20Analysis-%20A%20Pilot%20Study.pdf" target="_blank" rel="noopener">A Novel Early Diagnosis System for Mild Cognitive Impairment Based on Local Region Analysis: A Pilot Study</a><br>F. E. A. El-Gamal, M. M. Elmogy, M. Ghazal, A. Atwan, M. F. Casanova, G. N. Barnes, R. Keynton, A. S. El-Baz and A. Khalil </p><p>Feature：讨论了个性化MCI诊断系统，提出一种计算机辅助诊断（CAD）系统，其主要目标是提高<strong>诊断AD</strong>的准确性，特异性和敏感性</p><p><a href="http://adni.loni.usc.edu/adni-publications/Battaglini_et_al-2018-Human_Brain_Mapping.pdf" target="_blank" rel="noopener">SIENA-XL for improving the assessment of gray and white matter volume changes on brain MRI</a><br>M. Battaglini, M. Jenkinson, N. De Stefano and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：介绍了一种新的基于分段的纵向流水线SIENA-XL，可<strong>提高</strong>脑MRI上灰色和白色物质体积变化评估的<strong>精度</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Suresh_et_al-2018-Human_Brain_Mapping%20(1" target="_blank" rel="noopener">Factors influencing accuracy of cortical thickness in the diagnosis of Alzheimer’s disease</a>.pdf)<br>M. Belathur Suresh, B. Fischl, D. H. Salat and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：阐述影响诊断AD皮质厚度准确性的因素，有助于提高诊断<strong>分类</strong>的准确性</p><p>Result：通过检查一系列人口统计学，生物学和神经心理学数据来确定导致结构分类和临床诊断之间不匹配的因素，继发性病变（如WMH）影响与典型AD病理学重叠的区域的厚度值，从而影响分类的准确性。WMH体积增加，表明血管条件可能有助于皮质厚度测量的分类准确性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20spatio-temporal%20reference%20model%20of%20the%20aging%20brain.pdf" target="_blank" rel="noopener">A spatio-temporal reference model of the aging brain</a><br>W. Huizinga, D. H. J. Poot, M. W. Vernooij, G. V. Roshchupkin, E. E. Bron, M. A. Ikram, D. Rueckert, W. J. Niessen, S. Klein and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：开发由于正常衰老导致的大脑形态差异的时空模型，<strong>区分</strong>正常衰老和神经退行性疾病(AD)所产生的形态间<strong>差异</strong></p><p>Result：AD受试者和健康受试者之间的形态学差异可部分地通过加速衰老来解释</p><p><a href="http://adni.loni.usc.edu/adni-publications/Lee_et_al-2018-Statistics_in_Medicine.pdf" target="_blank" rel="noopener">Time-to-event data with time-varying biomarkers measured only at study entry, with applications to Alzheimer’s disease</a><br>C. Lee, R. A. Betensky and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：使用Cox回归模型对这些生物标记物轨迹关联到时间-事件将允许<strong>预测疾病进展</strong></p><p>Result：使用研究条目作为时间来源并将在研究进入时测量的时变协变量作为固定基线协变量进行处理，可以简化分析</p><p><a href="http://adni.loni.usc.edu/adni-publications/Cortical%20atrophy%20is%20associated%20with%20accelerate.pdf" target="_blank" rel="noopener">Cortical Atrophy is Associated with Accelerated Cognitive Decline in Mild Cognitive Impairment with Subsyndromal Depression</a><br>M. M. Gonzales, P. S. Insel, C. Nelson, D. Tosun, N. Mattsson, S. G. Mueller, Sacuiu, Bickford, W. Weiner and R. S. Mackin </p><p>Feature：<strong>研究</strong>轻度认知障碍（MCI）和慢性亚综合征性抑郁症（SSD）患者认知功能下降与皮质萎缩之间的<strong>关系</strong></p><p>Result：患有慢性SSD的个体可能代表MCI亚群，其非常容易受到加速认知衰退的影响，这种影响可能受额叶和前扣带萎缩的影响</p><p><a href="http://adni.loni.usc.edu/adni-publications/A%20Functional%20Varying-Coefficient%20Single%20Index.pdf" target="_blank" rel="noopener">A Functional Varying-Coefficient Single-Index Model for Functional Response Data</a><br>J. Li, C. Huang and H. Zhu </p><p>Feature：提出了一种新的功能变系数单指标模型（FVCSIM），可对一组感兴趣的协变量进行功能反应数据的回归分析，用于<strong>量化</strong>成像数据和感兴趣的临床变量之间的<strong>复杂关系</strong></p><p>Result：我们应用FVCSIM研究从阿尔茨海默病神经影像学倡议（ADNI）中获得的胼call体骨架上白质扩散的发展</p><p><a href="http://adni.loni.usc.edu/adni-publications/Gao_2016_PacSympBiocomput.pdf" target="_blank" rel="noopener">Adaptive Testing of SNP-Brain Functional Connectivity Association via a Modular Network Analysis</a><br>C. Gao, J. Kim and W. Pan </p><p>Feature：通过模块化网络分析自适应测试SNP-BRAIN功能连接关联，以识别脑功能网络中的模块结构</p><p>Result：我们将我们提出的方法应用于ADNI数据，以使用各种连通性测量来测试遗传变体与整个脑功能网络或其各种子组件之间的关联.发现了几个网络模块和APOE4基因变体之间联系的证据，APOE4基因变体是迄今为止阿尔茨海默病最重要的遗传风险因素.</p><p><a href="http://adni.loni.usc.edu/adni-publications/Biomarkers%20and%20Functional%20Decline%20in%20Prodromal.pdf" target="_blank" rel="noopener">Biomarkers and Functional Decline in Prodromal Alzheimer’s Disease.</a><br>C. Robb, C. Udeh-Momoh, S. Wagenpfeil, J. Schope, P. Alexopoulos, R. Perneczky and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：检测ADNI中生物标志物阳性和生物标志物阴性参与者之间的差异，以及这些差异是否代表了系统偏差</p><p>Result：基于ADNI的选择标准以及未来研究的设计，必须考虑生物标志物状态和疾病严重程度之间的潜在混淆，以确保前者(而非后者)是<strong>预测准确性</strong>的真正决定因素。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Ba_2017_Alzheimer&#39;s%20and%20dementia.pdf" target="_blank" rel="noopener">The prevalence and biomarkers’ characteristic of rapidly progressive Alzheimer’s disease from the Alzheimer’s Disease Neuroimaging Initiative database</a><br>M. Ba, X. Li, K. P. Ng, T. A. Pascoal, S. Mathotaarachchi, P. Rosa-Neto, S. Gauthier and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：探究快速进展性阿尔茨海默病(rpAD)的患病率和生物标志物特征，对<strong>识别</strong>临床高危rpAD具有预测价值</p><p>Result：发现rpAD通常存在于轻度AD中。脑代谢减退和p-tau/tau比值的降低可能在短期随访期间为rpAD提供潜在的临床差异值。</p><p>13</p><p><a href="http://adni.loni.usc.edu/adni-publications/Greenlaw_2016_arXiv.pdf" target="_blank" rel="noopener">A Bayesian Group Sparse Multi-Task Regression Model for Imaging Genetics</a><br>K. Greenlaw, E. Szefer, J. Graham, M. Lesperance, F. S. Nathoo and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：用于成像遗传学的贝叶斯群稀疏多任务回归模型，提供了可用于进行<strong>统计推断</strong>的技术，应用于神经影像学和遗传数据的分析，促使研究检查遗传变异对大脑结构的影响</p><p>Result：在将单核苷酸多态性与大脑影像学内表型联系起来时，将区间估计纳入单点估计之外的附加价值</p><p><a href="http://adni.loni.usc.edu/adni-publications/Li_2017_Alzheimer&#39;s%20and%20dementia%20A.D.A.M..pdf" target="_blank" rel="noopener">Age at injury is associated with the long-term cognitive outcome of traumatic brain injuries</a><br>W. Li, S. L. Risacher, T. W. McAllister, A. J. Saykin and A. s. D. N. Initiative </p><p>Feature：阐述 受伤年龄与创伤性脑损伤的长期认知结果有关 的回顾性调查报告</p><p><a href="http://adni.loni.usc.edu/adni-publications/Manning-2017-A%20Comparison%20of%20Accelerated%20and%20N.pdf" target="_blank" rel="noopener">A Comparison of Accelerated and Non-accelerated MRI Scans for Brain Volume and Boundary Shift Integral Measures of Volume Change: Evidence from the ADNI Dataset    </a><br>E. N. Manning, K. K. Leung, J. M. Nicholas, I. B. Malone, M. J. Cardoso, J. M. Schott, N. C. Fox, J. Barnes and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：评估加速MRI扫描代替非加速扫描是否影响对照组和轻度认知障碍和阿尔茨海默病患者的脑容量和萎缩率测量</p><p>Result：与非加速协议相比，使用加速扫描协议可以缩短采集时间，从而导致更少的扫描对由于运动伪影（可能影响BSI）而被排除在后续分析中，而不会显着改变绝对变化率或临床试验所需的样本量。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Autotaxin%20is%20Related%20to%20Metabolic%20Dysfunction.pdf" target="_blank" rel="noopener">Autotaxin is Related to Metabolic Dysfunction and Predicts Alzheimer’s Disease Outcomes</a><br>K. E. McLimans, A. A. Willette and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：自体分类素与代谢紊乱有关，可<strong>预测</strong>阿尔茨海默病的结果</p><p>Result： 自分泌运动因子水平在MCI和AD中显着升高，CSF自分泌运动因子可能是用于检查AD结果和风险的有用的代谢障碍生物标志物。</p><p>14</p><p><a href="http://adni.loni.usc.edu/adni-publications/Partovi-2017-Diagnostic%20performance%20of%20an%20auto.pdf" target="_blank" rel="noopener">Diagnostic performance of an automated analysis software for the diagnosis of Alzheimer’s dementia with 18F FDG PET        </a><br>S. Partovi, R. Yuh, S. Pirozzi, Z. Lu, S. Couturier, U. Grosse, M. D. Schluchter, A. Nelson, R. Jones, J. K. O’Donnell and P. Faulhaber </p><p>Feature：评估一种定量软件辅助方法的能力，以提高18F FDG PET对阿尔茨海默氏症的<strong>诊断准确性</strong></p><p>Result：基于定量体素的软件可能有助于经验丰富的18F FDG PET读者分析早发性AD</p><p><a href="http://adni.loni.usc.edu/adni-publications/Altered%20functional%20brain%20networks%20in%20amnestic%20mild%20cognitive%20impairment-%20a%20resting-state%20fMRI%20study.pdf" target="_blank" rel="noopener">Altered functional brain networks in amnestic mild cognitive impairment: a resting-state fMRI study</a><br>S. Cai, T. Chong, Y. Peng, W. Shen, J. Li, K. M. von Deneen and L. Huang </p><p>Feature：我们的目的是使用RS-fMRI技术探索aMCI患者中与记忆缺陷相关的异常静息状态网络RSN，用于研究aMCI的发病机制</p><p>Result：本研究的目的是探讨网络中这些roi之间的功能连通性，并探讨网络间的连通性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Application%20of%20Haralick%20texture%20features%20in%20brain%20[(18" target="_blank" rel="noopener">Application of Haralick texture features in brain (18)F-florbetapir positron emission tomography without reference region normalization        </a>F]-florbetapir%20positron%20emission%20tomography%20without%20reference%20region%20normalization.pdf)<br>D. L. Campbell, H. Kang and S. Shokouhi </p><p>Feature：Haralick特征可量化淀粉样蛋白PET放射性示踪剂摄取的空间特征，本研究的目的是计算不同诊断组中的几种HF并确定组间差异</p><p>Result：该技术可以改善AD药物试验中的受试者分层，并有助于纵向<strong>评估</strong>疾病进展和治疗效果，而没有与强度归一化相关的缺点</p><p><a href="http://adni.loni.usc.edu/adni-publications/Sparse%20shared%20structure%20based%20multi-task%20learning%20for%20MRI%20based%20Cognitive%20Performance%20prediction%20of%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Sparse shared structure based multi-task learning for MRI based Cognitive Performance prediction of Alzheimer’s disease        </a><br>P. Cao, X. Shan, D. Zhao, M. Huang and O. Zaiane </p><p>Feature：基于稀疏共享结构的多任务学习探索磁共振成像（MRI）和认知测量中存在的相关性</p><p>Result：证明了所提出的方法具有优于多种现有技术可比方法的优越性能，而且还<strong>识别</strong>与先验知识一致的认知相关MRI生物标志物</p><p><a href="http://adni.loni.usc.edu/adni-publications/Application%20of%20concordance%20probability%20estimate%20to%20predict%20conversion%20from%20mild%20cognitive%20impairment%20to%20Alzheimer%20s%20disease.pdf" target="_blank" rel="noopener">Application of concordance probability estimate to predict conversion from mild cognitive impairment to Alzheimer’s disease</a><br>X. Han, Y. Zhang, Y. Shao and A. s. D. N. Initiative </p><p>Feature：建立了Cox PH模型来<strong>预测</strong>从MCI到AD的转换，其中使用K指数评估预估准确性。</p><p><a href="http://adni.loni.usc.edu/adni-publications/Amyloidosis%20and%20neurodegeneration%20result%20in%20distinct%20structural%20connectivity%20patterns%20in%20mild%20cognitive%20impairment.pdf" target="_blank" rel="noopener">Amyloidosis and neurodegeneration result in distinct structural connectivity patterns in mild cognitive impairment</a><br>T. Jacquemont, F. De Vico Fallani, A. Bertrand, S. Epelbaum, A. Routier, B. Dubois, H. Hampel, S. Durrleman, O. Colliot and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：研究由淀粉样蛋白和神经变性生物标记物分层的MCI受试者亚组的结构连接体</p><p>Result：MCI亚组的连接组崩解模式在脑淀粉样蛋白和神经变性方面不同，展示了取决于生物标志物轮廓的网络改变的差异和相似之处</p><p><a href="http://adni.loni.usc.edu/adni-publications/Adaptive%20testing%20for%20multiple%20traits%20in%20a%20proportional%20odds%20model%20with%20applications%20to%20detect%20SNP-brain%20network%20associations.pdf" target="_blank" rel="noopener">Adaptive testing for multiple traits in a proportional odds model with applications to detect SNP-brain network associations        </a><br>J. Kim, W. Pan and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：提出一种在POM中结合检测SNP-brain网络的自适应关联测试模型，是一种灵活的统计检验来<strong>检测</strong>遗传由神经影像遗传学研究引起的多种性状的关联</p><p><a href="http://adni.loni.usc.edu/adni-publications/An%20Optimal%20Transportation%20based%20Univariate%20Neuroimaging%20Index.pdf" target="_blank" rel="noopener">An Optimal Transportation based Univariate Neuroimaging Index</a><br>L. Mi, W. Zhang, J. Zhang, Y. Fan, D. Goradia, K. Chen, E. M. Reiman, X. Gu and Y. Wang </p><p>Feature：一种基于单变量神经影像学指标的最优传输方法，用于数据集<strong>分类</strong></p><p>Result：在阿尔茨海默病患者和健康对照组之间的分类中，该方法在阿尔茨海默病疾病神经影像学倡议（ADNI）基线sMRI数据集上达到了82.30％的准确度，并且优于其他几个指数</p><p><a href="http://adni.loni.usc.edu/adni-publications/Predictive%20modelling%20using%20neuroimaging%20data%20in%20the%20presence%20of%20confounds.pdf" target="_blank" rel="noopener">Predictive modelling using neuroimaging data in the presence of confounds</a><br>A. Rao, J. M. Monteiro, J. Mourao-Miranda and I. Alzheimer’s Disease </p><p>Feature：讨论并评估了在神经影像学预测建模的背景下处理混杂的不同方法</p><p>Result：基线“仅图像”模型处理混淆时能给出更准确的<strong>预测</strong></p><p><a href="http://adni.loni.usc.edu/adni-publications/Targeted%20metabolomics%20and%20medication%20classification%20data%20from%20participants%20in%20the%20ADNI1%20cohort.pdf" target="_blank" rel="noopener">Targeted metabolomics and medication classification data from participants in the ADNI1 cohort</a><br>L. St John-Williams, C. Blach, J. B. Toledo, D. M. Rotroff, S. Kim, K. Klavins, R. Baillie, X. Han, S. Mahmoudiandehkordi, J. Jack, T. J. Massaro, J. E. Lucas, G. Louie, A. A. Motsinger-Reif, S. L. Risacher, I. Alzheimer’s Disease Neuroimaging, C. Alzheimer’s Disease Metabolomics, A. J. Saykin, G. Kastenmuller, M. Arnold, T. Koal, M. A. Moseley, L. M. Mangravite, M. A. Peters, J. D. Tenenbaum, J. W. Thompson and R. Kaddurah-Daouk </p><p>Feature：我们提供了使用AbsoluteIDQ-p180平台从199名对照组、356名轻度认知障碍和175名ADNI1受试者的血清中生成的定量代谢组学<strong>数据</strong>，以及用于<strong>数据预处理</strong>和<strong>药物分类</strong>以进行混淆纠正的管道。</p><p>Result：帮助发现与疾病和进展相关的代谢失败以及AD中一系列重要生理过程的生物标志物</p><p>15</p><p>151<a href="http://adni.loni.usc.edu/adni-publications/Deep%20ensemble%20learning%20of%20sparse%20regression%20models%20for%20brain%20disease%20diagnosis.pdf" target="_blank" rel="noopener">Deep ensemble learning of sparse regression models for brain disease diagnosis</a><br>H. I. Suk, S. W. Lee, D. Shen and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：脑疾病诊断的稀疏回归模型的深度集成学习，用于阿尔茨海默病/轻度认知障碍的<strong>诊断和预测</strong>.关于脑成像分析的研究见证了机器学习技术在计算机辅助干预脑疾病诊断中的核心作用</p><p>152<a href="http://adni.loni.usc.edu/adni-publications/Ventricular%20and%20Periventricular%20Anomalies%20in%20the%20Aging%20and%20Cognitively%20Impaired%20Brain.pdf" target="_blank" rel="noopener">Ventricular and Periventricular Anomalies in the Aging and Cognitively Impaired Brain</a><br>K. L. Todd, T. Brighton, E. S. Norton, S. Schick, W. Elkins, O. Pletnikova, R. H. Fortinsky, J. C. Troncoso, P. J. Molfese, S. M. Resnick, J. C. Conover and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：老化和认知受损大脑的心室和心室周异常.基于MRI的纵向研究为LV体积分析的使用提供支持，结合FLAIR PVH分析，用于<strong>识别和监测</strong>认知障碍与衰老</p><p>Result：分析了纵向结构磁共振成像（MRI）和受试者匹配的液体衰减反转恢复（FLAIR）MRI和脑室周围生物样本，以便在时间上映射心室扩张和相关的脑室周围水肿和房室管膜丢失的进展。实验结果揭示了与正常脑老化和认知障碍相关的病理生理学结果，并表明多因素分析最适合预测和监测认知衰退。</p><p>153<a href="http://adni.loni.usc.edu/adni-publications/Val66Met%20Polymorphism%20in%20BDNF%20Has%20No%20Sexual%20and%20APOE%20%CE%B54%20Status-Based%20Dimorphic%20Effects%20on%20Susceptibility%20to%20Alzheimer%E2%80%99s%20Disease-%20Evidence%20From%20an%20Updated%20Meta-Analysis%20of%20Case%E2%80%93Control%20Studies%20and%20High-Throughput%20Genotyping%20Cohorts.pdf" target="_blank" rel="noopener">Val66Met Polymorphism in BDNF Has No Sexual and APOE ε4 Status-Based Dimorphic Effects on Susceptibility to Alzheimer’s Disease: Evidence From an Updated Meta-Analysis of Case–Control Studies and High-Throughput Genotyping Cohorts</a><br>Q. Zhao, Shen, Zhao, L. Si, S. Jiang, Y. Qiu and A. s. D. N. Initiative </p><p>Feature：本次元分析的目的是通过引入年龄，性别和APOE e4作为混杂因素来<strong>重新检验</strong>BDNF的Val66Met与AD之间的关联，验证Val66Met是否仅在女性大脑衍生神经营养因子(BDNF)多态性表达对阿尔茨海默病(AD)的易感性</p><p>Result：我们显示Val66Met多态性与AD的易感性无关，并且没有基于性别或APOE e4状态的二态效应。我们的研究表明，混杂调整对于研究Val66Met甚至AD或AD相关性状的其他多态性是必要的</p><p>154<a href="http://adni.loni.usc.edu/adni-publications/Zhu2017_Article_DiscriminativeSelf-representat.pdf" target="_blank" rel="noopener">Discriminative self-representation sparse regression for neuroimaging-based alzheimer’s disease diagnosis</a><br>X. Zhu, H. I. Suk, S. W. Lee and D. Shen </p><p>Feature：基于神经影像的阿尔茨海默病<strong>诊断</strong>的判别自我表征稀疏回归，所选特征用于训练支持向量机以进行<strong>分类</strong></p><p>155<a href="http://adni.loni.usc.edu/adni-publications/Ensemble%20of%20random%20forests%20One%20vs.%20Rest%20classifiers%20for%20MCI%20and%20AD%20prediction%20using%20ANOVA%20cortical%20and%20subcortical%20feature%20selection%20and%20partial%20least%20squares.pdf" target="_blank" rel="noopener">Ensemble of random forests One vs. Rest classifiers for MCI and AD prediction using ANOVA cortical and subcortical feature selection and partial least squares        </a><br>J. Ramirez, J. M. Gorriz, A. Ortiz, F. J. Martinez-Murcia, F. Segovia, D. Salas-Gonzalez, D. Castillo-Barnes, I. A. Illan, C. G. Puntonet and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：使用ANOVA皮层和皮质下特征选择和偏最小二乘法的随机森林与Rest分类的集成，用于MCI和AD<strong>预测</strong></p><p>156<a href="http://adni.loni.usc.edu/adni-publications/Luo_2016_BBI.pdf" target="_blank" rel="noopener">Affect of APOE on information processing speed in non-demented elderly population: a preliminary structural MRI study</a><br>X. Luo, Y. Jiaerken, X. Yu, P. Huang, T. Qiu, Y. Jia, J. Sun, J. Zhou, M. Zhang and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：我们通过测量白质高信号（WMH），皮质灰质体积（GMV）和厚度的叶状分布来<strong>探索APOE</strong>相关IPS(信息处理速度)改变的神经基质</p><p>Result：（1）ε4携带者的WMH体积大于对照组，特别是额叶和顶叶; （2）顶叶WMH体积与IPS相关，尤其是ε4携带者。</p><p>157<a href="http://adni.loni.usc.edu/adni-publications/Geifman_2017_Alzheimer&#39;s%20research%20therapy.pdf" target="_blank" rel="noopener">Evidence for benefit of statins to modify cognitive decline and risk in Alzheimer’s disease    </a><br>N. Geifman, R. D. Brinton, R. P. Kennedy, L. S. Schneider and A. J. Butte </p><p>Feature：通过分析综合临床试验和前瞻性观察研究的数据集，研究他汀类药物在AD中可能的保护和<strong>治疗</strong>作用</p><p>Result：他汀类药物的使用可能使所有AD患者受益，这些患者在ApoE4纯合子中具有潜在更大的治疗效果</p><p>158<a href="http://adni.loni.usc.edu/adni-publications/Espinosa-2017-Cognitive%20Composites%20Domain%20Scor.pdf" target="_blank" rel="noopener">Cognitive Composites Domain Scores Related to Neuroimaging Biomarkers within Probable-Amnestic Mild Cognitive Impairment-Storage Subtype.    </a><br>A. Espinosa, M. Alegret, P. Pesini, S. Valero, A. Lafuente, M. Buendia, I. San Jose, M. Ibarria, M. A. Tejero, J. Gimenez, S. Ruiz, I. Hernandez, F. Pujadas, P. Martinez-Lage, J. Munuera, J. Arbizu, L. Tarraga, S. B. Hendrix, A. Ruiz, J. T. Becker, S. M. Landau, O. Sotolongo-Grau, M. Sarasa, M. Boada, A. B. S. Group and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：这项研究的目的是在Pr-aMCI-storage亚型患者中<strong>发现</strong>与神经影像学生物标志物最相关的优化认知复合(CCs)域得分</p><p>Result：延迟回忆是与前驱AD诊断相关的神经成像生物标志物最佳相关的CC域得分。</p><p>159<a href="http://adni.loni.usc.edu/adni-publications/Fiford-2017-White%20matter%20hyperintensities%20are.pdf" target="_blank" rel="noopener">White matter hyperintensities are associated with disproportionate progressive hippocampal atrophy: ASSOCIATION OF WMH WITH HIPPOCAMPAL ATROPHY</a><br>C. M. Fiford, E. N. Manning, J. W. Bartlett, D. M. Cash, I. B. Malone, G. R. Ridgway, M. Lehmann, K. K. Leung, C. H. Sudre, S. Ourselin, G. J. Biessels, O. T. Carmichael, N. C. Fox, M. J. Cardoso, J. Barnes and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：本研究调查了白质高信号（WMH）体积，脑脊液（CSF），阿尔茨海默病（AD）病理学标志物与脑和海马体积减少之间的关系</p><p>Result：白质增强与不成比例的进行性海马萎缩有关。在未痴呆的老年人中，血管损伤和AD病理学的共同作用是导致海马萎缩的主要原因。</p><p>160<a href="http://adni.loni.usc.edu/adni-publications/Functional%20Reserve_Experience%20Participating%20in.pdf" target="_blank" rel="noopener">Functional Reserve: Experience Participating in Instrumental Activities of Daily Living is Associated with Gender and Functional Independence in Mild Cognitive Impairment.        </a><br>C. Berezuk, K. K. Zakzanis, J. Ramirez, A. C. Ruocco, J. D. Edwards, B. L. Callahan, S. E. Black and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：研究男性和女性在MCI中的功能障碍方面的差异，并确定性别差异是否与潜在的功能储备有关</p><p>Result：虽然效果很小，男性性别与大量MCI患者的功能能力差异显着相关。此外，这一男性缺点可部分解释为该队列中男性的IADL经历较低。具有更多IADL经验的个体可能会发展出更大的功能储备，这可能会延迟或减缓MCI的功能下降。</p><p>16 </p><p>161<a href="http://adni.loni.usc.edu/adni-publications/LeeSH_2016_AlzDem.pdf" target="_blank" rel="noopener">Predicting progression from mild cognitive impairment to Alzheimer’s disease using longitudinalcallosal atrophy    </a><br>S. Minhas, A. Khanum, F. Riaz, S. A. Khan and A. Alvi<br>Feature：使用纵向胼a体萎缩<strong>预测</strong>从轻度认知障碍到阿尔茨海默病的进展</p><p>162<a href="http://adni.loni.usc.edu/adni-publications/Glozman_2017_Journal%20of%20Alzheimer&#39;s%20disease.pdf" target="_blank" rel="noopener">Shape-Attributes of Brain Structures as Biomarkers for Alzheimer’s Disease    </a><br>T. Glozman, J. Solomon, F. Pestilli, L. Guibas and I. Alzheimer’s Disease Neuroimaging<br>Feature：我们描述了一种基于大脑结构形状差异的两种类型痴呆<strong>分类</strong>的全自动框架。我们的框架对于确定阿尔茨海默病的发病敏感，在对MCIc与NC进行分类时达到高达88.13％的准确性，优于以前的方法。</p><p>163<a href="http://adni.loni.usc.edu/adni-publications/Mayo_2016_neuroimage%20clinical.pdf" target="_blank" rel="noopener">Longitudinal changes in microstructural white matter metrics in Alzheimer’s disease    </a><br>C. D. Mayo, E. L. Mazerolle, L. Ritchie, J. D. Fisk, J. R. Gawryluk and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病微观结构白质指标的纵向变化，对白质显微结构的敏感性是研究AD生物标志物的一个很有前途的途径。有助于早期<strong>诊断</strong>AD的症状前生物标志物</p><p>164<a href="http://adni.loni.usc.edu/adni-publications/Groupwise%20envelope%20models%20for%20imaging%20genetic.pdf" target="_blank" rel="noopener">Groupwise Envelope Models for Imaging Genetic Analysis </a><br>Y. Park, Z. Su and H. Zhu<br>Feature：本文的目的是开发用于多元线性回归的分组包络模型，以建立多变量响应和协变量之间的关联。可以显着提高测试和估计的效率，该模型在有效估计中的有效性</p><p>165<a href="http://adni.loni.usc.edu/adni-publications/Tanpitukpongse_2017_American%20Journal%20of%20neuroradiology.pdf" target="_blank" rel="noopener">Predictive Utility of Marketed Volumetric Software Tools in Subjects at Risk for Alzheimer Disease: Do Regions Outside the Hippocampus Matter?    </a><br>T. P. Tanpitukpongse, M. A. Mazurowski, J. Ikhena and J. R. Petrella<br>Feature：我们的目的是评估在两个商业上可用的脑容量软件包中个体与联合区域容量的预后有效性，以<strong>预测</strong>轻度认知障碍患者转化为阿尔茨海默病。</p><p>Result：将这些工具与人口统计学和其他生物标志物测量相结合，将海马体积作为唯一的体积生物标志物是合理的</p><p>166<a href="http://adni.loni.usc.edu/adni-publications/Moradi_2016_Neuroimagie%20clinical.pdf" target="_blank" rel="noopener">Rey’s Auditory Verbal Learning Test scores can be predicted from whole brain MRI in Alzheimer’s disease    </a><br>Moradi E1, Hallikainen I2, Hänninen T3, Tohka J4; Alzheimer’s Disease Neuroimaging Initiative<br>Feature：目的是通过机器学习的方法，基于结构磁共振成像(MRI)数据来综合研究RAVLT评分可预测的程度，以及寻找评估RAVLT评分最重要的大脑区域。可以基于观察到的或估计的RAVLT评分来<strong>预测</strong>MCI受试者在3年内转化为AD，其准确性与基于MRI的生物标志物相当。</p><p>explanation：Rey的听觉言语学习测验（RAVLT）是一种强大的神经心理学工具，用于测试情景记忆，广泛用于痴呆症和痴呆前症状的认知评估。</p><p>167<a href="http://adni.loni.usc.edu/adni-publications/Nho_2015_BMC%20medical%20genomics.pdf" target="_blank" rel="noopener">Association analysis of rare variants near the APOE region with CSF and neuroimaging biomarkers of Alzheimer’s disease    </a><br>K. Nho, S. Kim, E. Horgusluoglu, S. L. Risacher, L. Shen, D. Kim, S. Lee, T. Foroud, L. M. Shaw and J. Q. Trojanowski<br>Feature：APOE区域附近<code>罕见变异</code>和阿尔茨海默病神经影像<code>生物标志物</code>的关联分析,说明下一代测序和定量内表型在<strong>评估</strong>稀有变异体中的作用，这些变异体可能有助于解释AD和其他复杂疾病中缺失的遗传性。</p><p>Result：在调整APOE基因型后，跨越APOE区域的基因内的罕见变异与LOAD相关的CSFAβ1-42和神经成像生物标志物显着相关。</p><p>168<a href="http://adni.loni.usc.edu/adni-publications/Ower2018_Article_TemporalAssociationPatternsAnd.pdf" target="_blank" rel="noopener">Temporal association patterns and dynamics of amyloid-beta and tau in Alzheimer’s disease    </a><br>A. K. Ower, C. Hadjichrysanthou, L. Gras, J. Goudsmit, R. M. Anderson, F. de Wolf and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病中淀粉样蛋白-b和tau的时间关联模式和动态.生物标志物轨迹有助于对<strong>疾病进展</strong>进行无偏见，客观的评估。定量轨迹可能在临床试验设计中有用，因为它们可以更详细地了解旨在延缓生物疾病发展的治疗方法的有效性。</p><p>169<a href="http://adni.loni.usc.edu/adni-publications/Freesurfer%20cortical%20normative%20data%20for%20adults%20using%20Desikan-Killiany-Tourville%20and%20ex%20vivo%20protocols.pdf" target="_blank" rel="noopener">Freesurfer cortical normative data for adults using Desikan-Killiany-Tourville and ex vivo protocols    </a><br>O. Potvin, L. Dieumegarde, S. Duchesne and A. s. D. N. Initiative<br>Feature：我们根据年龄，性别，估计的颅内体积（eTIV）开发了FreeSurfer形态学估计皮质测量的规范数据，这些规范允许人们测量偏离个体正常性的程度，同时考虑影响这些估计的因素。我们的目的是为Desikan-Killianny-Tourville（DKT）和基于体外的标记方案制定类似的<code>标准值</code>，并检查这三种图册之间的<code>差异</code></p><p>objective：1.为DKT和离体标记方案制定规范值 2.描述标记协议之间预测模型的差异  3.确定在病理人群中使用标准Z分数时，地图集的选择是否会产生实质性差异</p><p>170<a href="http://adni.loni.usc.edu/adni-publications/Presotto2017_Article_ValidationOf18FFDG-PETSingle-S.pdf" target="_blank" rel="noopener">Validation of (18)F-FDG-PET Single-Subject Optimized SPM Procedure with Different PET Scanners    </a><br>L. Presotto, T. Ballarini, S. P. Caminiti, V. Bettinardi, L. Gianolli and D. Perani </p><p>Feature：用不同的PET扫描仪<strong>验证</strong>18F-FDG-PET单一主题优化的SPM程序,使用基于SPM软件包的优化方法可大大提高<strong>诊断准确性</strong>。</p><p>17</p><p>171<a href="http://adni.loni.usc.edu/adni-publications/Comparison%20of%20Cortical%20and%20Subcortical%20Measurements%20in%20Normal%20Older%20Adults%20across%20Databases%20and%20Software%20Packages.pdf" target="_blank" rel="noopener">Comparison of Cortical and Subcortical Measurements in Normal Older Adults across Databases and Software Packages    </a><br>S. Rane, A. Plassard, B. A. Landman, D. O. Claassen and M. J. Donahue<br>Feature：跨数据库和软件包的正常老年人的皮质和皮层下测量的比较，评估使用不同软件包获得的皮质下体积之间的<code>协议</code>.这项工作提供了一个结合ADNI和PPMI的成像<strong>数据</strong>，以提高统计能力，以及询问不同病理，如阿尔茨海默氏症和帕金森病的常见机制。</p><p>172<a href="http://adni.loni.usc.edu/adni-publications/Li2017_Article_BrainExplorerForConnectomicAna.pdf" target="_blank" rel="noopener">Brain explorer for connectomic analysis    </a><br>H. Li, S. Fang, J. A. Contreras, J. D. West, S. L. Risacher, Y. Wang, O. Sporns, A. J. Saykin, J. Goni, L. Shen and I. Alzheimer’s Disease Neuroimaging<br>Feature：我们通过在相同解剖结构的背景下结合科学和信息可视化技术，为脑成像数据开发了一种新的集成<strong>可视化</strong>解决方案.通过视觉探索，这种集成的解决方案可以帮助识别具有高度相关的功能激活及其激活模式的大脑区域。视觉检测分化特征还可能发现基于图像的脑疾病表型生物标志物。</p><p>173<a href="http://adni.loni.usc.edu/adni-publications/Dynamic%20predictions%20in%20Bayesian%20functional%20joint%20models%20for%20longitudinal%20and%20time-to-event%20data-%20An%20application%20to%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Dynamic predictions in Bayesian functional joint models for longitudinal and time-to-event data: An application to Alzheimer’s disease    </a><br>K. Li and S. Luo  (重复181)</p><p>Feature：贝叶斯功能关节模型中纵向和时间到事件数据的<strong>动态预测</strong>：阿尔茨海默病的应用.基于所收集的信息准确<strong>预测</strong>痴呆症的时间有助于医生监测患者的疾病进展并做出早期知情的医疗决策。</p><p>method：我们首先提出了一个功能性联合模型，以考虑联合建模框架中纵向和生存子模型中的功能预测器。然后，我们基于其标量和功能测量，开发用于参数估计的贝叶斯方法和用于预测受试者的未来结果轨迹和痴呆风险的动态预测框架。</p><p>174<a href="http://adni.loni.usc.edu/adni-publications/Frequency%20Specific%20Effects%20of%20ApoE%20epsilon4%20Allele%20on%20Resting-State%20Networks%20in%20Nondemented%20Elders.pdf" target="_blank" rel="noopener">Frequency Specific Effects of ApoE epsilon4 Allele on Resting-State Networks in Nondemented Elders    </a><br>Y. Liang, Z. Li, J. Wei, C. Li, X. Zhang and A. s. D. N. Initiative （重复182）</p><p>Feature：ApoEε4等位基因对非痴呆老年人休息状态网络的频率特异性影响，便于在早期寻找敏感且可靠的生物标志物</p><p>Method：我们应用静息状态功能磁共振成像（fMRI）来检查载脂蛋白E（ApoE）ε4等位基因对默认模式网络（DMN）和显着网络（SN）的功能连接性的影响。</p><p>Result：结果表明，在研究RSN功能连通性时，静息状态信号具有<code>频率依赖性</code>效应(越来越多的研究人员认为功能连接可能是频率特异性的)。</p><p>175<a href="http://adni.loni.usc.edu/adni-publications/Multifactorial%20causal%20model%20of%20brain%20(dis" target="_blank" rel="noopener">Multifactorial causal model of brain (dis) organization and therapeutic intervention: Application to Alzheimer’s disease    </a>%20organization%20and%20therapeutic%20intervention-%20Application%20to%20Alzheimer%E2%80%99s%20disease.pdf)<br>Y. Iturria-Medina, F. M. Carbonell, R. C. Sotero, F. Chouinard-Decorte, A. C. Evans and A. s. D. N. Initiative<br>Feature：在此，我们提出了一个大脑(dis)组织和治疗干预的时空多因素因果模型(MCM)，该模型解释了<code>局部因果交互作用</code>、通过物理大脑网络传播的效应、认知改变和最佳治疗干预的<strong>识别</strong>。可以解释进行性神经障碍的病理演变和实施多种介入策略的影响.</p><p>176<a href="http://adni.loni.usc.edu/adni-publications/Analysis%20of%20longitudinal%20diffusion-weighted%20images%20in%20healthy%20and%20pathological%20aging-%20An%20ADNI%20study.pdf" target="_blank" rel="noopener">Analysis of longitudinal diffusion-weighted images in healthy and pathological aging: An ADNI study    </a><br>F. Kruggel, F. Masaki, A. Solodkin and I. Alzheimer’s Disease Neuroimaging<br>Feature：通过将线性模型与线性混合效应模型进行交换来扩展纵向成像数据的模型,我们的分类器为可获得的生物标志物提供了有前途的功能，可以<strong>预测</strong>转变为阿尔茨海默病的风险。</p><p>177<a href="http://adni.loni.usc.edu/adni-publications/Prediction%20and%20classification%20of%20Alzheimer%20disease%20based%20on%20quantification%20of%20MRI%20deformation.pdf" target="_blank" rel="noopener">Prediction and classification of Alzheimer disease based on quantification of MRI deformation    </a><br>X. Long, L. Chen, C. Jiang, L. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：基于MRI变形量化的阿尔茨海默病<strong>预测</strong>与<strong>分类</strong>.我们提出了一种机器学习方法，用于区分健康老年人AD或轻度认知障碍（MCI）患者，并通过计算和分析组间大脑的区域形态差异来预测MCI患者的AD转换</p><p>178<a href="http://adni.loni.usc.edu/adni-publications/Automatic_Alzheimers_Disease_Recognition_from_MRI.pdf" target="_blank" rel="noopener">Automatic Alzheimer’s Disease Recognition from MRI Data Using Deep Learning Method    </a><br>S. Luo, X. Li and J. Li<br>Feature：利用深度学习方法从MRI数据中自动<strong>识别</strong>阿尔茨海默病</p><p>Measure：它描述了一种基于3D脑MRI深度学习的自动AD识别算法。该算法使用卷积神经网络（CNN）来实现AD识别。它的独特之处在于，在AD识别中将大脑的三维拓扑视为一个整体，从而获得准确的识别。实验表明，该算法具有较高的AD识别准确度，灵敏度为1，特异度为0.93。</p><p>179<a href="http://adni.loni.usc.edu/adni-publications/Maggipinto_2017_Phys._Med._Biol._62_2361.pdf" target="_blank" rel="noopener">DTI measurements for Alzheimer’s classification    </a><br>T. Maggipinto, R. Bellotti, N. Amoroso, D. Diacono, G. Donvito, E. Lella, A. Monaco, M. Antonella Scelsi and S. Tangaro<br>Feature：DTI可以深入了解白质微观结构的完整性，并在早期阶段<strong>识别</strong>出受阿尔茨海默病（AD）影响的白质区域。我们测量了特征选择偏差对分类性能的显着影响，对采用了有偏见的特征选择策略的DTI进行<strong>评估</strong></p><p>180<a href="http://adni.loni.usc.edu/adni-publications/Learning%20non-linear%20patch%20embeddings%20with%20neural%20networks%20for%20label%20fusion.pdf" target="_blank" rel="noopener">Learning non-linear patch embeddings with neural networks for label fusion    </a><br>G. Sanroma, O. M. Benkarim, G. Piella, O. Camara, G. Wu, D. Shen, J. D. Gispert, J. L. Molinuevo, M. A. Gonzalez Ballester and I. Alzheimer’s Disease Neuroimaging （重复185）</p><p>Feature：我们提出了一个使用神经网络计算补丁嵌入的框架，以增加PBLF中基于相似性的加权投票的判别能力，能够适应在<code>大脑结构分割</code>中更广泛的解剖变异性</p><p>18</p><p>181<a href="http://adni.loni.usc.edu/adni-publications/Dynamic%20predictions%20in%20Bayesian%20functional%20joint%20models%20for%20longitudinal%20and%20time-to-event%20data-%20An%20application%20to%20Alzheimer%E2%80%99s%20disease.pdf" target="_blank" rel="noopener">Dynamic predictions in Bayesian functional joint models for longitudinal and time-to-event data: An application to Alzheimer’s disease    </a><br>K. Li and S. Luo     （重复）</p><p>182<a href="http://adni.loni.usc.edu/adni-publications/Frequency%20Specific%20Effects%20of%20ApoE%20epsilon4%20Allele%20on%20Resting-State%20Networks%20in%20Nondemented%20Elders.pdf" target="_blank" rel="noopener">Frequency Specific Effects of ApoE epsilon4 Allele on Resting-State Networks in Nondemented Elders    </a><br>Y. Liang, Z. Li, J. Wei, C. Li, X. Zhang and A. s. D. N. Initiative （重复）</p><p>183<a href="http://adni.loni.usc.edu/adni-publications/Ueki_et_al-2017-Genetic_Epidemiology.pdf" target="_blank" rel="noopener">Detecting genetic association through shortest paths in a bidirected graph    </a><br>M. Ueki, Y. Kawasaki, G. Tamiya and I. for Alzheimer’s Disease Neuroimaging<br>Feature：提出了一种用于在多元回归模型中<strong>检测</strong>具有显着但弱的边际关联的隐藏SNP的新方法。</p><p>Result：所提出的方法可以检测LD隐藏的敏感性SNP，这些SNP未通过边际关联检验或现有的多变量方法检测到。当应用于阿尔茨海默病神经影像学倡议（ADNI）的真实GWAS数据时，我们的方法检测到两组SNP：一组在含有载脂蛋白E（APOE）基因的区域，另一组在接近信号素5A的区域（SEMA5A）基因。</p><p>184<a href="http://adni.loni.usc.edu/adni-publications/Automatic%20labeling%20of%20MR%20brain%20images%20through%20extensible%20learning%20and%20atlas%20forests.pdf" target="_blank" rel="noopener">Automatic labeling of MR brain images through extensible learning and atlas forests    </a><br>L. Xu, H. Liu, E. Song, M. Yan, R. Jin and C. C. Hung<br>Feature：通过可扩展学习和阿特拉斯森林自动标记MR脑图像，基于Multiatlas的方法因其简单性和鲁棒性而广泛应用于<strong>MR脑图像分割</strong>，该方法提供了极好的准确性。</p><p>185<a href="http://adni.loni.usc.edu/adni-publications/Learning%20non-linear%20patch%20embeddings%20with%20neural%20networks%20for%20label%20fusion.pdf" target="_blank" rel="noopener">Learning non-linear patch embeddings with neural networks for label fusion    </a><br>G. Sanroma, O. M. Benkarim, G. Piella, O. Camara, G. Wu, D. Shen, J. D. Gispert, J. L. Molinuevo, M. A. Gonzalez Ballester and I. Alzheimer’s Disease Neuroimaging （重复）</p><p>186<a href="http://adni.loni.usc.edu/adni-publications/Risk%20factors%20for%20amyloid%20positivity%20in%20older%20people%20reporting%20significant%20memory%20concern.pdf" target="_blank" rel="noopener">Risk factors for amyloid positivity in older people reporting significant memory concern    </a><br>J. Zhang, W. Zhou, R. M. Cassidy, H. Su, Y. Su, X. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：本研究的目的是确定报告主观认知能力下降（SCD）患者脑内淀粉样蛋白积聚的风险因素。识别这些风险因素将有助于更好地<strong>识别</strong>应该接受神经影像学研究以确认斑块存在并开始干预的患者，以及加强对阿尔茨海默病发病机制的研究。</p><p>187<a href="http://adni.loni.usc.edu/adni-publications/Differential%20Regional%20Distribution%20of%20Juxtacor.pdf" target="_blank" rel="noopener">Differential Regional Distribution of Juxtacortical White Matter Signal Abnormalities in Aging and Alzheimer’s Disease    </a><br>E. R. Lindemer, D. N. Greve, B. Fischl, J. C. Augustinack, D. H. Salat and I. Alzheimer’s Disease Neuroimaging（重复193）<br>Feature：老年人和阿尔茨海默病患者皮质白质信号异常WMSA的微分区域分布.</p><p>Objective：观察AD患者大脑中WMSA的空间分布模式是否与认知健康老化者不同</p><p>Result：结果表明WMSA是AD发展的重要病理组成部分</p><p>188<a href="http://adni.loni.usc.edu/adni-publications/Huang_2017_Alzheimer&#39;s%20and%20dementia%20T%20RCI.pdf" target="_blank" rel="noopener">Power analysis to detect treatment effects in longitudinal clinical trials for Alzheimer’s disease    </a><br>Z. Huang, G. Muniz-Terrera and B. D. M. Tom （重复194）<br>Feature：功效分析，以检测阿尔茨海默病纵向临床试验中的治疗效果</p><p>Conclusion：在设计临床试验时考虑组分评分的多变量/联合分布而不是单个综合评分的分布可以导致功效的增加和样本量的减少，以便在早期AD的临床试验中<strong>检测治疗效果</strong>。</p><p>189<a href="http://adni.loni.usc.edu/adni-publications/Battista-2017-Optimizing%20Neuropsychological%20As.pdf" target="_blank" rel="noopener">Optimizing Neuropsychological Assessments for Cognitive, Behavioral, and Functional Impairment Classification: A Machine Learning Study</a><br>Battista P1, Salvatore C1, Castiglioni I1<br>Feature：对认知、行为和功能障碍分类的神经心理学评估进行优化:机器学习研究，有助于用于<strong>分类和诊断</strong>AD的临床措施</p><p>Objective：评估机器学习在量化神经心理学评估过程中的潜力，并优化甚至减少用于对AD患者进行分类的神经心理学测试的数量，同样在损伤的早期阶段。</p><p>190<a href="http://adni.loni.usc.edu/adni-publications/Cortical%20atrophy%20is%20associated%20with%20accelerate.pdf" target="_blank" rel="noopener">Cortical Atrophy is Associated with Accelerated Cognitive Decline in Mild Cognitive Impairment with Subsyndromal Depression    </a><br>M. M. Gonzales, P. S. Insel, C. Nelson, D. Tosun, N. Mattsson, S. G. Mueller, Sacuiu, Bickford, W. Weiner and R. S. Mackin </p><p>Feature：<strong>研究</strong>轻度认知障碍（MCI）和慢性亚综合征性抑郁症（SSD）患者认知功能下降与皮质萎缩之间的<strong>关系</strong></p><p>Result：患有慢性SSD的个体可能代表MCI亚群，其非常容易受到加速认知衰退的影响，这种影响可能受额叶和前扣带萎缩的影响</p><p>19</p><p>191 A comparison of accurate automatic hippocampal segmentation methods    </p><p>URL：<code>http://adni.loni.usc.edu/adni-publications/Zandifar)%202017_neuroimaging.pdf</code></p><p>A. Zandifar, V. Fonov, P. Coupe, J. Pruessner, D. L. Collins and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：准确自动海马分割方法的比较</p><p>Method：比较了四种完全自动化的海马分割方法，它们与手动分割的一致性以及它们在临床环境中用作AD生物标志物的能力</p><p>Result：我们的研究表明，基于非线性补丁的纠错分割方法是最准确的自动分割方法，与手动分割最符合（= 0.894）</p><p>192<a href="http://adni.loni.usc.edu/adni-publications/Regional%2018F-Fluorodeoxyglucose%20Hypometabolism.pdf" target="_blank" rel="noopener">Regional 18F-Fluorodeoxyglucose Hypometabolism is Associated with Higher Apathy Scores Over Time in Early Alzheimer Disease</a><br>J. R. Gatchel, J. Donovan, J. Locascio, J. A. Becker, M. Rentz, A. Sperling, A. Johnson, A. Marshall and A. s. D. N. Initiative<br>Feature：研究了<code>冷漠</code>与区域18F-氟脱氧葡萄糖（FDG）代谢在认知正常，轻度认知障碍和来自阿尔茨海默病神经影像学倡议数据库的AD痴呆受试者之间的关联。研究AD蛋白病在冷漠发病机制中的潜在作用。有助于制定<strong>预防</strong>和治疗AD的策略</p><p>193<a href="http://adni.loni.usc.edu/adni-publications/Differential%20Regional%20Distribution%20of%20Juxtacor.pdf" target="_blank" rel="noopener">Differential Regional Distribution of Juxtacortical White Matter Signal Abnormalities in Aging and Alzheimer’s Disease    </a><br>E. R. Lindemer, D. N. Greve, B. Fischl, J. C. Augustinack, D. H. Salat and I. Alzheimer’s Disease Neuroimaging<br>Feature：（重复187）</p><p>194<a href="http://adni.loni.usc.edu/adni-publications/Huang_2017_Alzheimer&#39;s%20and%20dementia%20T%20RCI.pdf" target="_blank" rel="noopener">Power analysis to detect treatment effects in longitudinal clinical trials for Alzheimer’s disease    </a><br>Z. Huang, G. Muniz-Terrera and B. D. M. Tom （重复188）</p><p>195<a href="http://adni.loni.usc.edu/adni-publications/Plasma%20neurofilament%20light%20chain%20levels%20in%20Alz.pdf" target="_blank" rel="noopener">Plasma neurofilament light chain levels in Alzheimer’s disease.    </a><br>W. Zhou, J. Zhang, F. Ye, G. Xu, H. Su, Y. Su, X. Zhang and I. Alzheimer’s Disease Neuroimaging<br>Feature：阿尔茨海默病中的血浆神经丝轻链水平.检查了血浆NFL是否可能是AD的前驱和痴呆阶段的潜在生物标志物</p><p>Result：结果表明，血浆NFL水平可能不是诊断AD的前驱和痴呆阶段的有用生物标志物。</p><p>196<a href="http://adni.loni.usc.edu/adni-publications/Prediction%20of%20Conversion%20to%20Alzheimer_s%20Diseas.pdf" target="_blank" rel="noopener">Prediction of Conversion to Alzheimer’s Disease with Longitudinal Measures and Time-To-Event Data    </a><br>K. Li, W. Chan, R. S. Doody, J. Quinn, S. Luo and I. Alzheimer’s Disease Neuroimaging<br>Feature：通过纵向测量和事件发生时间数据<strong>预测</strong>阿尔茨海默病的转变</p><p>Objective：比较各种临床和生物标志物轨迹，以跟踪进展和预测从遗忘性轻度认知障碍到可能的AD的转换</p><p>Result：最强的预测因子是ADAS-Cog 13</p><p>Conclusion：除基线特征外，还可以通过纳入纵向变化信息来改善AD转换的预测。认知测量一直是重要的，并且通常比成像测量更强的<code>预测</code>因子。</p><p>197<a href="http://adni.loni.usc.edu/adni-publications/MRI-Based%20Classification%20Models%20in%20Prediction.pdf" target="_blank" rel="noopener">MRI-based classification models in prediction of mild cognitive impairment and dementia in late-life depression    </a><br>A. K. Lebedeva, E. Westman, T. Borza, M. K. Beyer, K. Engedal, D. Aarsland, G. Selbaek and A. K. Haberg<br>Feature：基于MRI的分类模型<code>预测</code>晚期抑郁症中的轻度认知障碍和痴呆</p><p>198<a href="http://adni.loni.usc.edu/adni-publications/Efficient%20Groupwise%20Registration%20for%20Brain%20MRI%20by%20Fast%20Initialization.pdf" target="_blank" rel="noopener">Efficient Groupwise Registration for Brain MRI by Fast Initialization    </a><br>P. Dong, X. Cao, J. Zhang, M. Kim, G. Wu and D. Shen<br>Feature：通过快速初始化测试<strong>图像的分组</strong>注册MRI，我们最终可以使用现有的分组注册方法来快速细化分组注册结果。与最先进的分组登记方法相比，ADNI数据集上的实验结果显示出显着提高的<code>计算效率</code>和竞争性配准精度。</p><p>199<a href="http://adni.loni.usc.edu/adni-publications/The%20interactive%20effect%20of%20demographic%20and%20clinical%20factors%20on%20hippocampal%20volume-%20A%20multicohort%20study%20on%201958%20cognitively%20normal%20individuals.pdf" target="_blank" rel="noopener">The interactive effect of demographic and clinical factors on hippocampal volume: A multicohort study on 1958 cognitively normal individuals    </a><br>D. Ferreira, O. Hansson, J. Barroso, Y. Molina, A. Machado, J. A. Hernandez-Cabrera, J. S. Muehlboeck, E. Stomrud, K. Nagga, O. Lindberg, D. Ames, G. Kalpouzos, L. Fratiglioni, L. Backman, C. Graff, P. Mecocci, B. Vellas, M. Tsolaki, I. Kloszewska, H. Soininen, S. Lovestone, H. Ahlstrom, L. Lind, E. M. Larsson, L. O. Wahlund, A. Simmons, E. Westman, f. t. A. s. D. N. I. the AddNeuroMed consortium, B. Australian Imaging and g. Lifestyle Study of Ageing research<br>Feature：人口统计学和临床因素对海马体积的交互影响：1958年认知正常个体的多项研究</p><p>200<a href="http://adni.loni.usc.edu/adni-publications/Left%20frontal%20cortex%20connectivity%20underlies%20cognitive%20reserve%20in%20prodromal%20Alzheimer%20disease.pdf" target="_blank" rel="noopener">Left frontal cortex connectivity underlies cognitive reserve in prodromal Alzheimer disease    </a><br>N. Franzmeier, M. Duering, M. Weiner, M. Dichgans, M. Ewers and I. Alzheimer’s Disease Neuroimaging </p><p>Feature：检测阿尔茨海默病（AD）左侧额叶皮质（LFC）的更高全局功能连接是否与更多年的教育（代理认知储备[CR]）相关，并减轻AD相关氟脱氧葡萄糖之间的关联（ FDG）-PET hypome-formolism和情节记忆。</p><p>Conclusion：较高的gLFC连接性是CR的功能性基质，有助于在早期AD中出现FDG-PET代谢减退时相对良好地维持情景记忆。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="ADNI" scheme="http://yoursite.com/categories/ADNI/"/>
    
    
  </entry>
  
  <entry>
    <title>系统集成项目管理知识点</title>
    <link href="http://yoursite.com/2018/11/03/%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E8%BD%AF%E8%80%83/"/>
    <id>http://yoursite.com/2018/11/03/系统集成项目管理软考/</id>
    <published>2018-11-03T04:43:04.000Z</published>
    <updated>2018-11-10T10:45:49.816Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h1 id="项目管理类"><a href="#项目管理类" class="headerlink" title="项目管理类"></a>项目管理类</h1><h2 id="项目立项"><a href="#项目立项" class="headerlink" title="项目立项"></a>项目立项</h2><h3 id="项目可行性研究"><a href="#项目可行性研究" class="headerlink" title="项目可行性研究"></a>项目可行性研究</h3><ul><li><p>可行性研究的步骤</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 机会研究</span><br><span class="line">2. 初步可行性研究</span><br><span class="line">3. 详细可行性研究</span><br><span class="line">- 小型项目可以不进行详细可行性研究</span><br><span class="line">4. 项目论证</span><br><span class="line">5. 项目评估</span><br><span class="line">- 项目评估由第三方进行</span><br><span class="line">- 决策的主要依据</span><br><span class="line">6. 项目可行性研究报告的编写、提交和获得批准</span><br></pre></td></tr></table></figure></li><li><p>甲方立项管理(解决项目的组织战略符合性问题)的四个阶段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. 项目识别</span><br><span class="line">2. 项目论证</span><br><span class="line">- 项目社会影响评价</span><br><span class="line">- 项目环境影响评价</span><br><span class="line">- 项目国民经济评价</span><br><span class="line">- 项目财务评价</span><br><span class="line">3. 投标</span><br><span class="line">4. 签订合同</span><br></pre></td></tr></table></figure></li><li><p>承建方(乙方)的项目管理步骤</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1. 项目机会识别</span><br><span class="line">2. 项目论证</span><br><span class="line">- 技术可行性分析</span><br><span class="line">    - 项目风险分析</span><br><span class="line">    - 人力资源配置分析</span><br><span class="line">    - 项目财务分析</span><br><span class="line">    - 对其他投标者的相关情况分析</span><br><span class="line">    </span><br><span class="line">    - 有效防范风险</span><br><span class="line">3. 投标</span><br></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">项目识别--乙方</span><br><span class="line">项目评估 -- 主管</span><br></pre></td></tr></table></figure></li><li><p>项目建议书(又称立项申请，由项目建设单位编写，非承建单位)包括的核心内容</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 项目的必要性</span><br><span class="line">2. 项目的市场预测</span><br><span class="line">3. 产品方案或服务的市场预测</span><br><span class="line">4. 项目建设必须的条件</span><br><span class="line">- 本期项目建设方案</span><br></pre></td></tr></table></figure></li><li><p>供应商项目内部立项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">内容：</span><br><span class="line">1. 项目资源估算</span><br><span class="line">2. 项目资源分配</span><br><span class="line">3. 准备项目任务书</span><br><span class="line">4. 任命项目经理</span><br><span class="line"></span><br><span class="line">作用:</span><br><span class="line">1. 分配资源</span><br><span class="line">2. 确定项目绩效目标</span><br><span class="line">3. 提升效率</span><br></pre></td></tr></table></figure></li></ul><h3 id="项目生命周期"><a href="#项目生命周期" class="headerlink" title="项目生命周期"></a>项目生命周期</h3><ul><li>项目临时性：明确的开始和结束时间</li></ul><h2 id="项目整体管理"><a href="#项目整体管理" class="headerlink" title="项目整体管理"></a>项目整体管理</h2><h2 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a>项目范围管理</h2><ul><li><p>项目范围管理过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 范围计划</span><br><span class="line">2. 范围定义</span><br><span class="line">3. 创建WBS</span><br><span class="line">4. 范围确认</span><br><span class="line">5. 范围控制</span><br></pre></td></tr></table></figure></li></ul><h3 id="制定范围管理计划"><a href="#制定范围管理计划" class="headerlink" title="制定范围管理计划"></a>制定范围管理计划</h3><h3 id="定义项目范围"><a href="#定义项目范围" class="headerlink" title="定义项目范围"></a>定义项目范围</h3><ul><li><p>范围说明书的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 项目合理性(资源需求)</span><br><span class="line">2. 项目目标</span><br><span class="line">3. 项目可交付成果清单</span><br></pre></td></tr></table></figure></li><li><p>工作说明书SOW </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">工作说明书(任务书)是对项目所要提供交付的产品或服务的叙述性的描述</span><br><span class="line">- 业务需求</span><br><span class="line">- 产品范围描述</span><br><span class="line">- 战略计划</span><br><span class="line">项目范围说明书则通过明确项目应该完成的工作而确定了项目的范围</span><br></pre></td></tr></table></figure></li></ul><h3 id="创建WBS"><a href="#创建WBS" class="headerlink" title="创建WBS"></a>创建WBS</h3><ul><li><p>工作包：WBS是最底层的工作单元</p></li><li><p>工作分解步骤</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 识别</span><br><span class="line">2. 分解</span><br><span class="line">3. 确认</span><br><span class="line">4. 核实</span><br></pre></td></tr></table></figure></li><li><p>WBS分解方法(逐层向下分解,渐进明细的)</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 生命周期为第一层，可交付物为第二层</span><br><span class="line">- 生命周期:&quot;需求分析、方案设计、实施准备、测试和验收&quot;(瀑布模型)</span><br><span class="line">- 重要的交付物为第一层</span><br><span class="line">- 子项目为第一层，再分解子项目的WBS</span><br></pre></td></tr></table></figure></li><li><p>WBS的制定需要<code>所有</code>项目干系人的参与，需要包括<code>100％</code>的工作内容</p></li></ul><h3 id="范围确认"><a href="#范围确认" class="headerlink" title="范围确认"></a>范围确认</h3><ul><li><p>范围确认(又称范围核实)：<code>正式验收并接受</code>已完成的项目可交付物的过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一般步骤：</span><br><span class="line">1. 确定需要进行确认范围的时间</span><br><span class="line">2. 识别确认范围需要哪些投入</span><br><span class="line">3. 确定范围正式被接受的标准和要素</span><br><span class="line">4. 确定确认范围会议的组织步骤</span><br><span class="line">5. 组织确认范围会议</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- 范围确认的对象不仅包括范围说明书，还包括项目管理计划和所有交付物</span><br><span class="line">- 范围确认的参加人员是客户和所有项目干系人，不仅限于项目组和质量管理员</span><br><span class="line">- 范围确认贯穿项目始终</span><br><span class="line">- 系统的终验报告作为范围确认证据</span><br><span class="line">- 用于范围确认的项目管理计划的组成部分包括如下范围基准</span><br><span class="line">- 项目范围说明书 - WBS - WBS词典(WBS的详细说明)    </span><br><span class="line">- 进行范围确认活动时应邀请客户参加</span><br><span class="line"></span><br><span class="line">范围确认与质量控制不同：</span><br><span class="line">前者是有关工作结果的接受问题；而后者是有关工作正确与否的问题。质量控制一般在范围确认之前完成.</span><br></pre></td></tr></table></figure></li><li><p>范围确认采用的方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 检查(有时也称审查、产品审查、审计、巡查)</span><br><span class="line">- 测量、审查与确认</span><br><span class="line">- 群体决策技术</span><br><span class="line">-一致同意 -大多数原则(超过50％) -相对多数原则 -独裁</span><br></pre></td></tr></table></figure></li><li><p>何时关注</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- 实际完成项目时间比计划提前</span><br></pre></td></tr></table></figure></li></ul><h3 id="控制项目范围"><a href="#控制项目范围" class="headerlink" title="控制项目范围"></a>控制项目范围</h3><ul><li><p>范围控制是监控项目状态 (如项目的<code>工作范围状态</code>和<code>产品范围状态</code>)，也是<code>控制变更</code>的过程</p><ul><li>变更影响分析由<code>项目经理</code>负责</li></ul></li><li><p>变更管理中 变更初审的目的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 确认变更的必要性</span><br><span class="line">- 格式校验、完整性校验，确保评估所需信息准备充分</span><br><span class="line">- 在干系人间 就提出供评估的变更信息达成共识</span><br></pre></td></tr></table></figure></li><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">控制变更，推荐纠正措施  属于 监督和控制过程组</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a>项目进度管理</h2><h3 id="活动排序"><a href="#活动排序" class="headerlink" title="活动排序"></a>活动排序</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出：</span><br><span class="line">- 项目进度网络图</span><br></pre></td></tr></table></figure><h3 id="活动资源估算"><a href="#活动资源估算" class="headerlink" title="活动资源估算"></a>活动资源估算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">方法：</span><br><span class="line">- 专家判断</span><br><span class="line">- 多方案分析：自制或者购买的决策</span><br><span class="line">- 出版的估算数据</span><br><span class="line">- 项目管理软件</span><br><span class="line">- 自下而上估算</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">- 资源分解结构</span><br><span class="line">- 请求的变更</span><br><span class="line">- 资源日历</span><br></pre></td></tr></table></figure><h3 id="项目历时估算"><a href="#项目历时估算" class="headerlink" title="项目历时估算"></a>项目历时估算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 主要方法和技术包括：专家判断、类比估算、参数估算、三点估算、后备估算</span><br><span class="line">- 三点估算能评估时间与概率的关系，可以用于风险评估，属于定量分析</span><br></pre></td></tr></table></figure><h3 id="控制进度计划"><a href="#控制进度计划" class="headerlink" title="控制进度计划"></a>控制进度计划</h3><ul><li><p>制定进度计划时可采用的工具与技术</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 关键路径法</span><br><span class="line">- 资源平衡技术 </span><br><span class="line">- 资源平滑技术</span><br><span class="line">- 活动只在其自由浮动时间和总浮动时间内延迟，不改变关键路径</span><br></pre></td></tr></table></figure></li><li><p>常用的历时估算方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 类比估算(未掌握全部细节)</span><br><span class="line">- 参数估算</span><br><span class="line">- 三点估算</span><br><span class="line">- 后备估算</span><br></pre></td></tr></table></figure></li><li><p>后备分析：以    <code>应急时间</code>、<code>时间储备</code>、<code>缓冲时间</code>为名称 增加时间</p></li><li>控制点：即里程碑. 关键路径<code>不能</code>包括所有项目进度控制点</li><li>项目进度表：横道图(gantt chart)</li><li>进度网络分析技术中的一种方法是<code>关键链法（经常改变关键路径，结合了确定性与随机性，常考）</code>、<code>关键路线法(正向与反向分析)</code></li></ul><h3 id="控制项目进度"><a href="#控制项目进度" class="headerlink" title="控制项目进度"></a>控制项目进度</h3><ul><li><p>压缩工期</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 投入更多的资源以加速活动进程(赶工)</span><br><span class="line">- 指派经验更丰富的人去完成或帮助完成项目工作</span><br><span class="line">- 减小活动范围或降低活动要求</span><br><span class="line">- 通过改进方法或技术提高生产效率</span><br><span class="line">- 快速跟进(并行工作)</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a>项目成本管理</h2><h3 id="估算项目成本"><a href="#估算项目成本" class="headerlink" title="估算项目成本"></a>估算项目成本</h3><h3 id="制定项目预算"><a href="#制定项目预算" class="headerlink" title="制定项目预算"></a>制定项目预算</h3><ul><li><p>挣值分析是成本控制的工具</p></li><li><p>成本预算的工具</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 参数估算</span><br><span class="line">- 资金限制平衡</span><br><span class="line">- 准备金分析</span><br></pre></td></tr></table></figure></li><li><p>成本分类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 直接成本：差旅费、工资</span><br><span class="line">- 间接成本：企业管理费、税金、福利、保卫费</span><br></pre></td></tr></table></figure></li></ul><h3 id="控制项目成本"><a href="#控制项目成本" class="headerlink" title="控制项目成本"></a>控制项目成本</h3><h3 id="绩效评估"><a href="#绩效评估" class="headerlink" title="绩效评估"></a>绩效评估</h3><ul><li><p>项目绩效就是搜集项目<code>所有基准数据</code>并向项目干系人提供绩效信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">收集材料：</span><br><span class="line">- 被评价项目资料清单</span><br><span class="line">- 项目绩效预测</span><br><span class="line">- 调查问卷</span><br></pre></td></tr></table></figure></li><li><p>项目评估包括</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 盈利要求</span><br><span class="line">2. 客户满意度要求</span><br><span class="line">3. 后续项目指标要求</span><br><span class="line">4. 内部满意度要求</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a>项目质量管理</h2><h3 id="质量度量"><a href="#质量度量" class="headerlink" title="质量度量"></a>质量度量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 软件产品的使用质量的质量属性：有效性、生产率、安全性、满意度</span><br><span class="line">- 质量特性：功能性、可靠性、易用性、效率、维护性、可移植性</span><br><span class="line">- 质量属性：精确性、完整性、可靠性、及时性、经济性、可验证性、安全性</span><br><span class="line">- 可靠性：故障次数 可用性：故障恢复时间</span><br><span class="line">- CMMI(软件能力成熟度模型)的过程改进目标：1.保证产品或服务质量 2.项目时间控制 3.用最低的成本</span><br></pre></td></tr></table></figure><h2 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a>项目人力资源管理</h2><ul><li><p>编制人力资源计划</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- 工具技术</span><br><span class="line">- 组织结构图和职位描述</span><br><span class="line">- 人力资源模板(可加快编制速度)</span><br><span class="line">- 非正式的人际网络</span><br><span class="line">- 组织理论</span><br><span class="line"></span><br><span class="line">- 描述工具</span><br><span class="line">- 工作分解结构</span><br><span class="line">- 组织分解结构(OBS)</span><br><span class="line">- 资源分解结构(RBS)</span><br><span class="line"></span><br><span class="line">- 每个工具包只有一个明确的责任人</span><br></pre></td></tr></table></figure></li><li><p>组建项目团队</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 生命周期：形成、震荡、正规、发挥(表现)、终止  </span><br><span class="line">- 项目团队加入新成员时，重新进入形成期</span><br><span class="line">- 方式：培训、扩展训练、认可和奖励</span><br></pre></td></tr></table></figure></li><li><p>管理项目团队</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 马斯洛需要层次理论：生理、安全、社会(团建活动)、自尊</span><br><span class="line">- 赫兹伯格的双因素理论：保健因素和激励因素</span><br><span class="line">- X-Y理论：x假定人性本恶 y假定人性本善</span><br><span class="line"></span><br><span class="line">- 责任分配矩阵 直观</span><br><span class="line"></span><br><span class="line">- 团队建设内容：1.一般管理技能 2.培训 3.团队建设活动 4.基本原则 5.同地办公</span><br><span class="line">- 项目组织结构：项目经理权利从小到大依次是职能型、弱矩阵型、平衡矩阵型、强矩阵型、项目型</span><br></pre></td></tr></table></figure></li><li><p>项目管理知识域</p></li></ul><h2 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a>项目沟通管理</h2><ul><li>沟通管理计划</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">编制过程：</span><br><span class="line">1. 确定干系人的沟通信息需求</span><br><span class="line">2. 描述信息收集和文件归档的机构</span><br><span class="line">3. 发送信息和重要信息的格式</span><br><span class="line"></span><br><span class="line">- 冲突管理</span><br><span class="line"></span><br><span class="line">- 主要内容</span><br><span class="line">- 项目干系人沟通要求</span><br><span class="line">- 对要发布信息的描述</span><br><span class="line">- 信息接收的个人或组织</span><br><span class="line">- 信息传达所需的技术或方法</span><br><span class="line">- 沟通频率</span><br><span class="line">- 上报过程</span><br><span class="line">- 随项目的进展对沟通管理计划更新与细化方法</span><br><span class="line">- 通用词语表</span><br></pre></td></tr></table></figure><ul><li><p>发布信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 项目状态/评审会议的主要目的：</span><br><span class="line">- 介绍项目进展情况</span><br><span class="line">- 项目是否偏离进度计划</span><br><span class="line">- 说明造成进度偏离计划的原因和预防计划</span><br><span class="line">- 汇报在项目执行中发现的问题及潜在的问题</span><br><span class="line">- 应引起客户或项目负责人注意的事项</span><br><span class="line"></span><br><span class="line">- 沟通(与上司沟通、与下属沟通、水平沟通)</span><br></pre></td></tr></table></figure></li><li><p>管理干系人</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 主要目的：避免项目干系人在项目管理中的严重分歧，促进干系人对项目的理解和支持</span><br><span class="line">- 沟通过程管理的最终目标是保障干系人之间的有效沟通</span><br><span class="line">- 干系人分析贯穿项目的始终</span><br></pre></td></tr></table></figure></li><li><p>冲突处理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 解决冲突的范畴</span><br><span class="line">- 强制</span><br><span class="line">- 妥协</span><br><span class="line">- 撤退</span><br><span class="line">- 合作(得到大多数人都同意)</span><br><span class="line">- 问题解决(公开讨论，直至选择出一套最佳方案)</span><br><span class="line">- 求同存异 </span><br><span class="line">- 问题解决应该聚焦现在，而不是过去</span><br></pre></td></tr></table></figure></li><li><p>沟通方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 引导技术</span><br><span class="line">- 头脑风暴</span><br><span class="line">- 冲突处理</span><br><span class="line">- 问题解决</span><br><span class="line">- 会议管理</span><br><span class="line">- 控制沟通的技术和方法</span><br><span class="line">- 信息管理系统</span><br><span class="line">- 专家判断</span><br><span class="line">- 会议</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a>项目风险管理</h2><ul><li><p>风险识别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 输入：企业环境因素、组织过程资产、项目范围说明书、风险管理计划、项目管理计划</span><br><span class="line">- 输出：风险识别单</span><br><span class="line">- 方法：德尔菲技术(专家判断、大多数原则)、SWOT分析</span><br></pre></td></tr></table></figure></li><li><p>定性风险分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 工具和技术(概率)</span><br><span class="line">- 风险概率及影响评估</span><br><span class="line">- 概率及影响矩阵</span><br><span class="line">- 风险数据质量评估</span><br><span class="line">- 风险种类</span><br><span class="line">- 风险紧急度评估</span><br></pre></td></tr></table></figure></li><li><p>定量风险分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">工作成果：</span><br><span class="line">- 项目的概率分析</span><br><span class="line">- 实现成本和时间目标的概率</span><br><span class="line">- 量化风险优先级清单</span><br><span class="line">- 定量风险分析结果的趋势</span><br><span class="line"></span><br><span class="line">技术方法：</span><br><span class="line">- 表示技术：概率分布、专家判断、风险信息访谈</span><br><span class="line">- 建模技术：灵敏度分析、期望货币值分析、决策树分析、建模仿真</span><br></pre></td></tr></table></figure></li><li><p>制定风险应对计划</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 检查措施</span><br><span class="line">- 缺陷补救措施：对 在质量审查和审核过程中发现的缺陷 制定的修复和消除影响的措施</span><br><span class="line">- 预防措施：消除潜在不良影响，降低风险发生的可能性而需要的措施  (常考)</span><br><span class="line">- 纠正措施：消除 已发现的不合格的情况 所采取的措施</span><br></pre></td></tr></table></figure></li><li><p>监控项目风险</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 工具和技术</span><br><span class="line">- 风险再评估</span><br><span class="line">- 风险审计：检查并记录</span><br><span class="line">- 偏差和趋势分析</span><br><span class="line">- 技术绩效测量</span><br><span class="line">- 储备分析</span><br><span class="line">- 会议</span><br><span class="line"></span><br><span class="line">- 风险不能消除</span><br></pre></td></tr></table></figure></li></ul><h2 id="项目采购和合同管理"><a href="#项目采购和合同管理" class="headerlink" title="项目采购和合同管理"></a>项目采购和合同管理</h2><ul><li><p>询价</p></li><li><p>招标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- 信息邀请书RFI(Request For Information)</span><br><span class="line">  投标邀请书IFB(Invitation for bid)</span><br><span class="line">  报价邀请书RFQ(Request For Quotation)</span><br><span class="line">  建议邀请书RFP(Request For Proposal)：征求潜在供应商建议的文件</span><br><span class="line"></span><br><span class="line">- 集成商在招标阶段的工作顺序</span><br><span class="line">1.研读招标公告</span><br><span class="line">2.编制投标文件</span><br><span class="line">3.提交投标文件</span><br><span class="line">4.参与开标过程</span><br><span class="line">- 合同价款应为中标者的投标价</span><br></pre></td></tr></table></figure></li><li><p>采购管理</p></li><li><p>合同管理</p></li><li><p>合同违约管理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 索赔的性质属于经济补偿，并非惩罚</span><br><span class="line">- 在索赔事项发生后28天后，向监理工程师提出索赔意向通知</span><br><span class="line">- 承建单位严重违约的，可部分或全部终止合同，并采取善后措施</span><br></pre></td></tr></table></figure></li><li><p>项目收尾</p></li></ul><h2 id="文档与配置管理"><a href="#文档与配置管理" class="headerlink" title="文档与配置管理"></a>文档与配置管理</h2><h2 id="需求管理"><a href="#需求管理" class="headerlink" title="需求管理"></a>需求管理</h2><h2 id="项目管理高级知识"><a href="#项目管理高级知识" class="headerlink" title="项目管理高级知识"></a>项目管理高级知识</h2><h3 id="大型及复杂项目管理"><a href="#大型及复杂项目管理" class="headerlink" title="大型及复杂项目管理"></a>大型及复杂项目管理</h3><h3 id="信息系统工程监理"><a href="#信息系统工程监理" class="headerlink" title="信息系统工程监理"></a>信息系统工程监理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- 信息系统工程监理遵循&quot;四控、三管、一协调&quot;</span><br><span class="line">- 四控</span><br><span class="line">- 质量控制</span><br><span class="line">- 进度控制</span><br><span class="line">- 投资控制</span><br><span class="line">- 变更控制</span><br><span class="line">- 三管</span><br><span class="line">    - 合同管理</span><br><span class="line">    - 信息管理</span><br><span class="line">    - 安全管理</span><br><span class="line">- 一协调</span><br><span class="line">- 在信息系统工程实施过程中协调有关单位及人员间的工作关系</span><br></pre></td></tr></table></figure><h1 id="信息系统类"><a href="#信息系统类" class="headerlink" title="信息系统类"></a>信息系统类</h1><h2 id="IT信息化知识"><a href="#IT信息化知识" class="headerlink" title="IT信息化知识"></a>IT信息化知识</h2><h3 id="企业信息化"><a href="#企业信息化" class="headerlink" title="企业信息化"></a>企业信息化</h3><ul><li><p>企业信息化结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 产品层</span><br><span class="line">- 作业层</span><br><span class="line">- 管理层</span><br><span class="line">- 决策层</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- CRM(客户关系管理)</span><br><span class="line">- 自动化的销售、客户服务和市场营销</span><br><span class="line">- 以客户为中心</span><br><span class="line">- ERP(企业资源计划)</span><br><span class="line">- 企业可以根据自身的情况灵活地选择和集成模块</span><br><span class="line">- SCM(供应链管理)</span><br><span class="line">- 把正确数量的商品在正确的时间配送到正确的地点的一套管理方法，有效控制各种信息流、资金流和物流</span><br><span class="line">- 最重要的评价指标：客户满意度</span><br></pre></td></tr></table></figure></li><li><p>客户数据</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 描述性数据：客户的基本信息</span><br><span class="line">- 促销性数据：企业为客户提供的产品和服务的历史数据(客服人员建议、广告数据等)</span><br><span class="line">- 交易性数据：客户对企业的回馈信息(历史购买记录、投诉数据、客户建议等)</span><br></pre></td></tr></table></figure></li><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- ssl通信协议用于保护电子商务交易中的敏感数据</span><br></pre></td></tr></table></figure></li></ul><h3 id="系统运维管理"><a href="#系统运维管理" class="headerlink" title="系统运维管理"></a>系统运维管理</h3><ul><li><p>IT运维管理内容</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1. 设备管理</span><br><span class="line">2. 应用服务</span><br><span class="line">3. 数据存储</span><br><span class="line">4. 业务</span><br><span class="line">5. 目录内容</span><br><span class="line">6. 资源资产</span><br><span class="line">7. 信息安全</span><br><span class="line">8. 日常活动</span><br><span class="line"></span><br><span class="line">- 对系统进行升级改造属于 开发 ，不属于运维</span><br><span class="line"></span><br><span class="line">系统运维分类：</span><br><span class="line">- 更正性维护</span><br><span class="line">- 适应性维护</span><br><span class="line">- 完善性维护</span><br><span class="line">- 预防性维护</span><br></pre></td></tr></table></figure></li><li><p>IT服务</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- 核心要素：人员(正确选人)、过程(正确做事)、技术(高效做事)和资源(保障做事)</span><br><span class="line">- 生命周期：</span><br><span class="line">- 规划设计</span><br><span class="line">- 部署实施</span><br><span class="line">- 服务运营</span><br><span class="line">- 持续改进</span><br><span class="line">- 监督管理</span><br></pre></td></tr></table></figure></li><li><p>一般公认信息系统审计准则：职业准则、ISACA公告、职业道德规范</p></li></ul><h3 id="系统集成企业资质"><a href="#系统集成企业资质" class="headerlink" title="系统集成企业资质"></a>系统集成企业资质</h3><ul><li><p>系统集成主要包括<code>设备系统集成</code>和<code>应用系统集成</code></p></li><li><p>我国信息系统服务管理的主要内容：计算机信息系统<code>集成单位</code>资质管理、信息系统<code>项目经理</code>资格管理、信息系统<code>工程监理单位</code>资质管理、信息系统<code>工程监理人员</code>资质管理</p></li><li><p>项目集成项目成功实施的保障：<code>管理</code>和<code>商务</code></p></li><li><p>资质企业要求</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">人才要求:</span><br><span class="line">一级：具有计算机信息系统集成项目经理人数不少于25人，其中高级项目经理人数不少于8名</span><br><span class="line">二级：具有计算机信息系统集成项目经理人数不少于18人，其中高级项目经理人数不少于4名</span><br><span class="line">三级：具有计算机信息系统集成项目经理人数不少于6人，其中高级项目经理人数不少于1名</span><br><span class="line">四级：具有计算机信息系统集成项目经理人数不少于2人</span><br><span class="line"></span><br><span class="line">收入比例要求：</span><br><span class="line">一级：近三年的系统集成收入总额占营业收入总额的比例不低于70％</span><br><span class="line">二级：近三年的系统集成收入总额占营业收入总额的比例不低于60％</span><br><span class="line">三级：近三年的系统集成收入总额占营业收入总额的比例不低于50％</span><br><span class="line"></span><br><span class="line">注册资金:</span><br><span class="line">一级：不少于5000万元</span><br><span class="line">二级：不少于3000万元</span><br><span class="line">三级：不少于500万元</span><br><span class="line">四级：不少于30万元</span><br></pre></td></tr></table></figure></li></ul><h3 id="云服务"><a href="#云服务" class="headerlink" title="云服务"></a>云服务</h3><ul><li><p>云计算的服务形式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- Iaas(基础设施即服务)：向用户提供计算机(物理机和虚拟机)、存储空间等基本计算资源</span><br><span class="line">- Paas(平台即服务)：将软件研发的平台作为一种服务(如数据库管理系统、Web应用系统)</span><br><span class="line">- SaaS(软件即服务)：用户租用基于Web的软件来管理企业经营活动</span><br></pre></td></tr></table></figure></li><li><p>混合云：将公有云(使用计算资源，解决访问量暴增的情况)与私有云(存放数据，安全)进行混合和匹配</p></li></ul><h3 id="移动互联网"><a href="#移动互联网" class="headerlink" title="移动互联网"></a>移动互联网</h3><ul><li><p>物流信息技术主要包括条码技术、RFID技术、EDI技术、GPS技术和GIS技术</p></li><li><p>物联网</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">从架构上分为：</span><br><span class="line">- 感知层：负责信息采集和物物之间信息传输</span><br><span class="line">- 网络层：对采集的数据进行编码认证和传输</span><br><span class="line">- 应用层：结合行业信息化需求</span><br></pre></td></tr></table></figure></li></ul><h3 id="商业智能BI"><a href="#商业智能BI" class="headerlink" title="商业智能BI"></a>商业智能BI</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- 基本体系结构：数据仓库、联机分析处理、数据挖掘</span><br><span class="line">- 主要功能</span><br><span class="line">- 数据仓库(数据存储和访问)</span><br><span class="line">- 数据ETL(数据的抽取、转换和加载)</span><br><span class="line">- 数据统计输出(统计报表的设计和展示)</span><br><span class="line">- 分析功能</span><br><span class="line">- 实现层次</span><br><span class="line">- 数据报表</span><br><span class="line">- 多维数据分析</span><br><span class="line">- 数据挖掘</span><br></pre></td></tr></table></figure><ul><li><p>other</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- 智能制造&quot;炼金术&quot;:信息物理系统CPS</span><br><span class="line">- 智能城市</span><br><span class="line">- 数据及服务支撑层(关键技术：SOA、海量数据汇聚与存储、数据融合与处理、智能挖掘分析、协同分析)</span><br><span class="line">- 中国制造2025 新一代信息技术产业</span><br><span class="line">- 集成电路及专用装备</span><br><span class="line">- 信息通信设备</span><br><span class="line">- 操作系统及工业软件</span><br></pre></td></tr></table></figure></li></ul><h2 id="信息系统基础"><a href="#信息系统基础" class="headerlink" title="信息系统基础"></a>信息系统基础</h2><h3 id="软件工程"><a href="#软件工程" class="headerlink" title="软件工程"></a>软件工程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">- 软件规模估算方法</span><br><span class="line">- 德尔菲法</span><br><span class="line">- 软件设计方法</span><br><span class="line">- V模型方法</span><br><span class="line">- 开发：需求分析 → 概要设计 → 详细设计 → 编码测试</span><br><span class="line">- 测试：验收测试 ← 系统测试 ← 集成测试 ← 单元测试</span><br><span class="line">- 原型法(反复修改来实现用户的最终系统需求)</span><br><span class="line">- 用例设计</span><br><span class="line">- 软件开发模型</span><br><span class="line">- 瀑布模型(适用于需求明确或很少变更单的项目,结构化分析与设计)</span><br><span class="line">- 螺旋模型(瀑布模型+快速原型模型)</span><br><span class="line">- 每次迭代的活动依次是 制定计划、风险分析、实施工程、客户评估</span><br><span class="line">- 软件文档的质量等级</span><br><span class="line">- 最低限度文档</span><br><span class="line">- 内部文档</span><br><span class="line">- 工作文档</span><br><span class="line">- 正式文档</span><br></pre></td></tr></table></figure><h3 id="ruan’jian"><a href="#ruan’jian" class="headerlink" title="ruan’jian"></a>ruan’jian</h3><h1 id="专题类"><a href="#专题类" class="headerlink" title="专题类"></a>专题类</h1><h2 id="计算题"><a href="#计算题" class="headerlink" title="计算题"></a>计算题</h2><ul><li><p>三点估算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 平均时间：(best + 4*average + worst)/6</span><br><span class="line">- 正态分布，期望值两边+-1个标准差的范围内，曲线下面积约占总面积的68％</span><br><span class="line">+-2个标准差的范围内，曲线下面积约占总面积的95％</span><br><span class="line">+-3个标准差的范围内，曲线下面积约占总面积的99％</span><br><span class="line">- 标准差 (最坏-最好)/6</span><br></pre></td></tr></table></figure></li><li><p>挣值估算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- PV:一切按计划 该时间点所需花费</span><br><span class="line">- EV:以实际进度为准 该时间段所完成的工作量 计划中所需花费 (按实际进度 计划本该花费)</span><br><span class="line">- AC:实际情况 进行到该时间点 的已支出花费</span><br><span class="line">- CV：EV-AC (计算费用偏差)</span><br><span class="line">- SV: EV-PV(计算进度偏差)</span><br><span class="line">- CPI：EV/AC (成本绩效)</span><br><span class="line">- SPI：EV/PV (进度绩效)</span><br><span class="line">- 完成尚需估算ETC </span><br><span class="line">- (非典型) ETC = BAC-EV</span><br><span class="line">- (典型) ETC = (BAC-EV)/CPI</span><br><span class="line">- 完工估计EAC=AC+ETC</span><br></pre></td></tr></table></figure></li><li><p>运筹统计</p></li><li><p>关键路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">历时最长的路径</span><br></pre></td></tr></table></figure></li><li><p>期望货币值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 预期收益EMV = 概率*期望</span><br><span class="line">- 常结合决策数分析</span><br></pre></td></tr></table></figure></li><li><p>投资回收期</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给你n年时间，你只需要pt年就收回成本了</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><ul><li><p>配置管理的目标：为了系统地控制配置变更，在系统的整个生命周期中维持配置的完整性和可综合性，而标识系统在不同时间点上配置的管理。</p></li><li><p>配置管理的主要活动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1. 制定配置管理计划</span><br><span class="line">2. 配置标识</span><br><span class="line">3. 配置控制</span><br><span class="line">4. 配置状态报告</span><br><span class="line">5. 配置审计</span><br><span class="line">-配置审计也称配置审核或配置评价，包括功能配置审计和物理配置审计，分别用以验证当前配置项的一致性和完整性。其 实施 主要是为了确保项目配置管理的有效性，体现项目配置的最根本要求---不允许出现任何混乱现象.</span><br><span class="line">   1. 变更申请</span><br><span class="line">   2. 变更评估</span><br><span class="line">   3. 通告评估结果</span><br><span class="line">   4. 变更实施</span><br><span class="line">   5. 变更验证与确认</span><br><span class="line">   6. 变更的发布</span><br><span class="line">   7. 基于配置库的变更控制</span><br><span class="line">6. 发布管理和交付</span><br></pre></td></tr></table></figure></li><li><p>配置库的分类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 开发库：也称动态库、程序员库或工作库</span><br><span class="line">- 受控库：也称主库，包含当前的基线加上对基线的变更</span><br><span class="line">- 产品库：也称静态库、发行库、软件仓库，包含已发布使用的各种基线的存档</span><br><span class="line"></span><br><span class="line">配置库应该区分开发库和受控库，否则处于已发布状态的项目是不可能被随意修改配置项的.</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置控制委员会-Configuration-Control-Board-CCB"><a href="#配置控制委员会-Configuration-Control-Board-CCB" class="headerlink" title="配置控制委员会(Configuration Control Board,CCB)"></a>配置控制委员会(Configuration Control Board,CCB)</h3><h3 id="配置管理员-Configuration-Management-Officer-CMO"><a href="#配置管理员-Configuration-Management-Officer-CMO" class="headerlink" title="配置管理员(Configuration Management Officer,CMO)"></a>配置管理员(Configuration Management Officer,CMO)</h3><ul><li>编写配置管理计划</li><li>建立和维护<code>配置管理系统</code></li><li>建立和维护<code>配置库</code></li><li>配置项识别</li><li>建立和管理<code>基线</code></li><li><code>版本管理</code>和配置控制</li><li>配置状态报告</li><li>配置审计</li><li>发布管理和交付</li><li>对项目成员进行<code>配置管理培训</code></li></ul><h2 id="合同管理"><a href="#合同管理" class="headerlink" title="合同管理"></a>合同管理</h2><h3 id="合同分类"><a href="#合同分类" class="headerlink" title="合同分类"></a>合同分类</h3><ul><li><p>按项目付款方式划分的合同分类</p><ol><li>总价合同：又称固定价格合同，是指在合同中确定一个完成项目的总价，承包人据此完成项目全部合同内容的合同。承包人(集成商)承担了需求变更等方面带来的风险。—-对甲方有利</li><li>成本补偿合同：甲方承担项目实际发生的一切费用，因此也承担了项目的全部风险。—-对甲方不利</li><li>工料合同： 成本补偿合同+总价合同  </li></ol></li><li><p>合同支付条款，应该规定以下3方面的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 支付货款的条件</span><br><span class="line">- 结算支付的方式</span><br><span class="line">- 拒付货款，发包方有权部分或全部拒付货款</span><br></pre></td></tr></table></figure></li></ul><h2 id="采购管理"><a href="#采购管理" class="headerlink" title="采购管理"></a>采购管理</h2><ol><li><p>编制采购管理计划</p><ul><li>按照自制/外购的判断因素进行评估</li><li>采购计划应提交公司高层领导审批</li></ul></li><li><p>实施采购</p><ul><li>不能以报价最低作为选择乙方的依据(进行充分调研，了解调研采购产品的市场价格，以及潜在供应商的资信情况)</li><li>选择标准 应对集成商的经验和业绩(资质和声誉) 做出要求</li><li>双方签订合同时应确定明确的需求(就产品的型号、质量进行约定，约定合同交付物必要的质量检验和付款条件的把控)</li></ul></li><li>控制采购<ul><li>有效管理合同的执行(遇到问题，不能推卸责任)</li></ul></li><li>结束采购</li></ol><h2 id="质量管理"><a href="#质量管理" class="headerlink" title="质量管理"></a>质量管理</h2><ul><li><p>质量管理的主要活动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 规划质量管理</span><br><span class="line">2. 实施质量保证</span><br><span class="line">3. 质量控制</span><br><span class="line"></span><br><span class="line">- 质量管理计划制定和实施过程中需要注意：</span><br><span class="line">- 明确质量管理相关各方职责</span><br><span class="line">- 质量管理计划应该由项目经理带领项目组一起完成，并应组织相关人员进行评审，最后需要有效执行</span><br><span class="line">- 明确质量保证(QA)人员的职责</span><br><span class="line">- 区分质量保证和质量控制</span><br></pre></td></tr></table></figure></li><li><p>QA的主要工作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 制定质量管理计划</span><br><span class="line">- 按照计划实施质量管理活动</span><br><span class="line">- 发现问题要记录和沟通直至问题解决</span><br><span class="line">- 定期提交质量报告</span><br><span class="line">- 为项目组人员提供质量方面的培训</span><br></pre></td></tr></table></figure></li><li><p>设计评审会议</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">应该由项目经理组织，QA也可以组织</span><br><span class="line">- 项目经理对整个项目负责(包括质量)，设计评审是保证质量的常见方式</span><br><span class="line">- QA如果有丰富的技术背景，也可以组织设计评审</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="软考" scheme="http://yoursite.com/tags/%E8%BD%AF%E8%80%83/"/>
    
  </entry>
  
</feed>
