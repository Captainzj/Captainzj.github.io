<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Go Further</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-12-31T14:12:45.590Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>CaptainSE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>visdom_Tutorial</title>
    <link href="http://yoursite.com/2018/12/31/visdom-Tutorial/"/>
    <id>http://yoursite.com/2018/12/31/visdom-Tutorial/</id>
    <published>2018-12-31T12:32:33.000Z</published>
    <updated>2018-12-31T14:12:45.590Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>Github linkage: <a href="https://github.com/facebookresearch" target="_blank" rel="noopener">facebookresearch</a>/<a href="https://github.com/facebookresearch/visdom" target="_blank" rel="noopener">visdom</a></p><ul><li><p>Install</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Install Python server and client，如果您使用python的话，装这一个就可以了。</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install visdom</span></span><br></pre></td></tr></table></figure></li><li><p>Usage</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> visdom</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> or (The visdom <span class="built_in">command</span> is equivalent to running python -m visdom.server)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> python -m visdom.server</span></span><br></pre></td></tr></table></figure><blockquote><p>If the above does not work, try using an SSH tunnel to your server by adding the following line to your local <code>~/.ssh/config</code>: <code>LocalForward 127.0.0.1:8097 127.0.0.1:8097</code></p></blockquote></li></ul><p><a href="https://cdn.rawgit.com/plotly/plotly.js/master/dist/plotly.min.js" target="_blank" rel="noopener">https://cdn.rawgit.com/plotly/plotly.js/master/dist/plotly.min.js</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Classification with Pre-trained Model</title>
    <link href="http://yoursite.com/2018/12/31/Classification-with-Pretrained-Model/"/>
    <id>http://yoursite.com/2018/12/31/Classification-with-Pretrained-Model/</id>
    <published>2018-12-31T06:53:44.000Z</published>
    <updated>2018-12-31T07:19:37.924Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>参考：</p><ul><li><a href="https://blog.csdn.net/u010165147/article/details/72829969" target="_blank" rel="noopener">使用pytorch预训练模型分类与特征提取</a></li><li><a href="https://blog.csdn.net/geek_of_csdn/article/details/84343971#comments" target="_blank" rel="noopener">Pytorch：利用预训练好的VGG16网络提取图片特征</a></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable </span><br><span class="line"><span class="keyword">import</span> torch.cuda</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"> </span><br><span class="line">img_to_tensor = transforms.ToTensor()</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">()</span>:</span></span><br><span class="line">    resmodel=models.resnet34(pretrained=<span class="keyword">True</span>)</span><br><span class="line">    resmodel.cuda()<span class="comment">#将模型从CPU发送到GPU,如果没有GPU则删除该行</span></span><br><span class="line">    <span class="keyword">return</span> resmodel</span><br><span class="line"> </span><br><span class="line"><span class="comment">#分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(resmodel,imgpath)</span>:</span></span><br><span class="line">    resmodel.eval()<span class="comment">#必需，否则预测结果是错误的</span></span><br><span class="line">    </span><br><span class="line">    img=Image.open(imgpath)</span><br><span class="line">    img=img.resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">    tensor=img_to_tensor(img)</span><br><span class="line">    </span><br><span class="line">    tensor=tensor.resize_(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    tensor=tensor.cuda()<span class="comment">#将数据发送到GPU，数据和模型在同一个设备上运行</span></span><br><span class="line">            </span><br><span class="line">    result=resmodel(Variable(tensor))</span><br><span class="line">    result_npy=result.data.cpu().numpy()<span class="comment">#将结果传到CPU，并转换为numpy格式</span></span><br><span class="line">    max_index=np.argmax(result_npy[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> max_index</span><br><span class="line">    </span><br><span class="line"><span class="comment">#特征提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_feature</span><span class="params">(resmodel,imgpath)</span>:</span></span><br><span class="line">    resmodel.fc=torch.nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line">    resmodel.eval()</span><br><span class="line">    </span><br><span class="line">    img=Image.open(imgpath)</span><br><span class="line">    img=img.resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">    tensor=img_to_tensor(img)</span><br><span class="line">    </span><br><span class="line">    tensor=tensor.resize_(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    tensor=tensor.cuda()</span><br><span class="line">            </span><br><span class="line">    result=resmodel(Variable(tensor))</span><br><span class="line">    result_npy=result.data.cpu().numpy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result_npy[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    model=make_model()</span><br><span class="line">    imgpath=<span class="string">'path_to_img/xxx.jpg'</span> <span class="comment"># imgpath='ILSVRC2012_val_00001101.JPEG' 此时图片与该代码文件放在同一目录下</span></span><br><span class="line">    <span class="keyword">print</span> inference(model,imgpath)</span><br><span class="line">    <span class="keyword">print</span> extract_feature(model, imgpath)</span><br></pre></td></tr></table></figure><p>注：</p><ul><li><p>关于使用的img</p><p>img.jpg是随便找的一张图，要求是3通道的（RGB，不能是黑白的，如果是黑白的要自己拓展成3通道）.建议先看下这里的文章：<a href="https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c" target="_blank" rel="noopener">https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c</a>。另外，建议不要用pytorch提供的vgg模型来提取特征，效果不是很好，最好是通过别的框架的，例如keras提供的vgg模型来提取特征，保存为文件之后再调用pytorch</p></li><li><p><code>#分类</code> 的返回值max_index</p><p>index为0～999的值，0对应n01440764，1对应n01443537，是一个映射表参考：<a href="https://blog.csdn.net/u010165147/article/details/72848497" target="_blank" rel="noopener">https://blog.csdn.net/u010165147/article/details/72848497</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>torchvision_pretrainedModel</title>
    <link href="http://yoursite.com/2018/12/28/torchvision-pretrainedModel/"/>
    <id>http://yoursite.com/2018/12/28/torchvision-pretrainedModel/</id>
    <published>2018-12-28T08:09:59.000Z</published>
    <updated>2018-12-31T07:16:32.881Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>关于“Save &amp;&amp; Load Model” 可参见<a href="https://captainzj.github.io/2018/12/28/Pytorch-Save-Load-Model/" target="_blank" rel="noopener">说明</a>.</p><h3 id="直接加载预训练模型"><a href="#直接加载预训练模型" class="headerlink" title="直接加载预训练模型"></a>直接加载预训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">model = torchvision.models.densenet169(pretrained=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><strong>Save model</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.save(model.state_dict(),<span class="string">'model.pth'</span>)</span><br></pre></td></tr></table></figure><h4 id="View-model-params"><a href="#View-model-params" class="headerlink" title="View model params "></a><strong>View model params </strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pretrained_dict = model.state_dict()  <span class="comment"># densenet169</span></span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> pretrained_dict.items():</span><br><span class="line">    print(k,v.size())    <span class="comment">#打印网络中的变量名</span></span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features.conv0.weight torch.Size([<span class="number">64</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line">features.norm0.weight torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.bias torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.running_mean torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.running_var torch.Size([<span class="number">64</span>])</span><br><span class="line">features.norm0.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.norm1.weight torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.bias torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.running_mean torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.running_var torch.Size([<span class="number">64</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer1.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer1.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.weight torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.bias torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.running_mean torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.running_var torch.Size([<span class="number">96</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer2.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">96</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer2.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer2.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer3.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer3.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer3.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.weight torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.bias torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.running_mean torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.running_var torch.Size([<span class="number">160</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer4.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">160</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer4.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer4.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.weight torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.bias torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.running_mean torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.running_var torch.Size([<span class="number">192</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer5.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">192</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer5.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer5.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.weight torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.bias torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.running_mean torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.running_var torch.Size([<span class="number">224</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm1.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer6.conv1.weight torch.Size([<span class="number">128</span>, <span class="number">224</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.weight torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.bias torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.running_mean torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.running_var torch.Size([<span class="number">128</span>])</span><br><span class="line">features.denseblock1.denselayer6.norm2.num_batches_tracked torch.Size([])</span><br><span class="line">features.denseblock1.denselayer6.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.transition1.norm.weight torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.bias torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.running_mean torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.running_var torch.Size([<span class="number">256</span>])</span><br><span class="line">features.transition1.norm.num_batches_tracked torch.Size([])</span><br><span class="line">features.transition1.conv.weight torch.Size([<span class="number">128</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">.... </span><br><span class="line">features.denseblock4.denselayer32.conv2.weight torch.Size([<span class="number">32</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">features.norm5.weight torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.bias torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.running_mean torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.running_var torch.Size([<span class="number">1664</span>])</span><br><span class="line">features.norm5.num_batches_tracked torch.Size([])</span><br><span class="line">classifier.weight torch.Size([<span class="number">1000</span>, <span class="number">1664</span>])</span><br><span class="line">classifier.bias torch.Size([<span class="number">1000</span>])</span><br></pre></td></tr></table></figure><h4 id="View-model-structure"><a href="#View-model-structure" class="headerlink" title="View model structure"></a>View model structure</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = torch.nn.Sequential(*list(model.children())[:]) <span class="comment"># densenet169</span></span><br><span class="line">print(feature)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Sequential(</span><br><span class="line">    (conv0): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">    (norm0): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">    (relu0): ReLU(inplace)</span><br><span class="line">    (pool0): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (denseblock1): _DenseBlock(</span><br><span class="line">      (denselayer1): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">      (denselayer2): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">  ... ...</span><br><span class="line">        (denselayer32): _DenseLayer(</span><br><span class="line">        (norm1): BatchNorm2d(<span class="number">1632</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu1): ReLU(inplace)</span><br><span class="line">        (conv1): Conv2d(<span class="number">1632</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">        (norm2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">        (relu2): ReLU(inplace)</span><br><span class="line">        (conv2): Conv2d(<span class="number">128</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (norm5): BatchNorm2d(<span class="number">1664</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">1664</span>, out_features=<span class="number">1000</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>基本上可以看出总体分为两个部分，这两个部分对应的名字可以用<code>print(model._modules.keys())</code>查询到：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查询结果</span></span><br><span class="line">odict_keys([<span class="string">'features'</span>, <span class="string">'classifier'</span>])</span><br></pre></td></tr></table></figure><p>之后可以直接用<code>model.features</code>直接只调用features部分，直接将分类部分抛弃掉。</p><h3 id="加载部分预训练模型"><a href="#加载部分预训练模型" class="headerlink" title="加载部分预训练模型"></a>加载部分预训练模型</h3><p>其实大多数时候我们需要根据我们的任务调节我们的模型，所以很难保证模型和公开的模型完全一样，但是预训练模型的参数确实有助于提高训练的准确率，为了结合二者的优点，就需要我们加载部分预训练模型。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载model，model是自己定义好的模型</span></span><br><span class="line">resnet50 = models.resnet50(pretrained=<span class="keyword">True</span>) </span><br><span class="line">model =Net(...) </span><br><span class="line"> </span><br><span class="line"><span class="comment">#读取参数 </span></span><br><span class="line">pretrained_dict =resnet50.state_dict()  </span><br><span class="line">model_dict = model.state_dict() </span><br><span class="line"> </span><br><span class="line"><span class="comment">#将pretrained_dict里不属于model_dict的键剔除掉,筛选符合自定义模型的键</span></span><br><span class="line">pretrained_dict =  &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125; </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更新现有的model_dict </span></span><br><span class="line">model_dict.update(pretrained_dict) <span class="comment"># update</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 加载我们真正需要的state_dict </span></span><br><span class="line">model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure><p>因为需要剔除原模型中不匹配的键，也就是层的名字，所以我们的新模型改变了的层需要和原模型对应层的名字不一样，比如：resnet最后一层的名字是fc(PyTorch中)，那么我们修改过的resnet的最后一层就不能取这个名字，可以叫fc_</p><h3 id="简单预训练"><a href="#简单预训练" class="headerlink" title="简单预训练"></a>简单预训练</h3><p>我们先从torchvision中调用基本模型，加载预训练模型，然后，重点来了，<strong>将其中的层直接替换为我们需要的层即可</strong>：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resnet = torchvision.models.resnet152(pretrained=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 原本为1000类，改为10类</span></span><br><span class="line">resnet.fc = torch.nn.Linear(<span class="number">2048</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>其中使用了pretrained参数，会直接加载预训练模型，内部实现和前文提到的加载预训练的方法一样。因为是先加载的预训练参数，相当于模型中已经有参数了，所以替换掉最后一层即可。OK！</p><h3 id="使用预训练模型分类与特征提取"><a href="#使用预训练模型分类与特征提取" class="headerlink" title="使用预训练模型分类与特征提取"></a>使用预训练模型分类与特征提取</h3><p># <strong>To  Completed</strong></p><p><strong>Reference：</strong></p><ul><li><p><a href="https://zhuanlan.zhihu.com/p/25980324" target="_blank" rel="noopener">PyTorch预训练[知乎]</a></p></li><li><p><a href="https://blog.csdn.net/u010165147/article/details/72829969" target="_blank" rel="noopener">使用pytorch预训练模型分类与特征提取</a></p></li><li><a href="https://blog.csdn.net/Geek_of_CSDN/article/details/84343971" target="_blank" rel="noopener">Pytorch：利用预训练好的VGG16网络提取图片特征</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch_Save&amp;Load_Model</title>
    <link href="http://yoursite.com/2018/12/28/Pytorch-Save-Load-Model/"/>
    <id>http://yoursite.com/2018/12/28/Pytorch-Save-Load-Model/</id>
    <published>2018-12-28T07:33:53.000Z</published>
    <updated>2018-12-28T08:10:49.283Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="方法一-推荐"><a href="#方法一-推荐" class="headerlink" title="方法一(推荐)"></a>方法一(推荐)</h2><p>第一种方法也是官方推荐的方法，只保存和恢复模型中的参数。</p><h3 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(the_model.state_dict(), PATH)</span><br></pre></td></tr></table></figure><h3 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">the_model = TheModelClass(*args, **kwargs)</span><br><span class="line">the_model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>使用这种方法，我们需要自己导入模型的结构信息。</p><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>使用这种方法，将会保存模型的参数和结构信息。</p><h3 id="保存-1"><a href="#保存-1" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(the_model, PATH)</span><br></pre></td></tr></table></figure><h3 id="恢复-1"><a href="#恢复-1" class="headerlink" title="恢复"></a>恢复</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">the_model = torch.load(PATH)</span><br></pre></td></tr></table></figure><h2 id="一个相对完整的例子"><a href="#一个相对完整的例子" class="headerlink" title="一个相对完整的例子"></a>一个相对完整的例子</h2><h3 id="save"><a href="#save" class="headerlink" title="save"></a>save</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(&#123;</span><br><span class="line">            <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,</span><br><span class="line">            <span class="string">'arch'</span>: args.arch,</span><br><span class="line">            <span class="string">'state_dict'</span>: model.state_dict(),</span><br><span class="line">            <span class="string">'best_prec1'</span>: best_prec1,</span><br><span class="line">        &#125;, <span class="string">'checkpoint.tar'</span> )</span><br></pre></td></tr></table></figure><h3 id="load"><a href="#load" class="headerlink" title="load"></a>load</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.resume:</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(args.resume):</span><br><span class="line">            print(<span class="string">"=&gt; loading checkpoint '&#123;&#125;'"</span>.format(args.resume))</span><br><span class="line">            checkpoint = torch.load(args.resume)</span><br><span class="line">            args.start_epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">            best_prec1 = checkpoint[<span class="string">'best_prec1'</span>]</span><br><span class="line">            model.load_state_dict(checkpoint[<span class="string">'state_dict'</span>])</span><br><span class="line">            print(<span class="string">"=&gt; loaded checkpoint '&#123;&#125;' (epoch &#123;&#125;)"</span></span><br><span class="line">                  .format(args.evaluate, checkpoint[<span class="string">'epoch'</span>]))</span><br></pre></td></tr></table></figure><h2 id="获取模型中某些层的参数"><a href="#获取模型中某些层的参数" class="headerlink" title="获取模型中某些层的参数"></a>获取模型中某些层的参数</h2><h3 id="model-state-dict"><a href="#model-state-dict" class="headerlink" title="model.state_dict()"></a>model.state_dict()</h3><p>对于恢复的模型，如果我们想查看某些层的参数，可以：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个网络</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">                  (<span class="string">'conv1'</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">                  (<span class="string">'relu1'</span>, nn.ReLU()),</span><br><span class="line">                  (<span class="string">'conv2'</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">                  (<span class="string">'relu2'</span>, nn.ReLU())</span><br><span class="line">                ]))</span><br><span class="line"><span class="comment"># 打印网络的结构</span></span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Sequential (</span><br><span class="line">  (conv1): Conv2d(<span class="number">1</span>, <span class="number">20</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu1): ReLU ()</span><br><span class="line">  (conv2): Conv2d(<span class="number">20</span>, <span class="number">64</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu2): ReLU ()</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>如果我们想获取conv1的weight和bias：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params=model.state_dict() </span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> params.items():</span><br><span class="line">    print(k)    <span class="comment">#打印网络中的变量名</span></span><br><span class="line"></span><br><span class="line">print(params[<span class="string">'conv1.weight'</span>])   <span class="comment">#打印conv1的weight.size()</span></span><br><span class="line">print(params[<span class="string">'conv1.bias'</span>])   <span class="comment">#打印conv1的bias.size()</span></span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv1.weight</span><br><span class="line">conv1.bias</span><br><span class="line">conv2.weight</span><br><span class="line">conv2.bias</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">torch.Size([<span class="number">20</span>])</span><br></pre></td></tr></table></figure><h3 id="model-named-parameters"><a href="#model-named-parameters" class="headerlink" title="model.named_parameters()"></a>model.named_parameters()</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = list(model.named_parameters())</span><br><span class="line">(name, param) = params[<span class="number">0</span>]</span><br><span class="line">print(name)</span><br><span class="line">print(param.grad)</span><br><span class="line">print(<span class="string">'-------------------------------------------------'</span>) </span><br><span class="line">(name1, param1) = params[<span class="number">1</span>]</span><br><span class="line">print(name1)</span><br><span class="line">print(param1.grad)</span><br><span class="line">print(<span class="string">'----------------------------------------------------'</span>)</span><br><span class="line">(name2, param2) = params[<span class="number">2</span>]</span><br><span class="line">print(name2) </span><br><span class="line">print(param2.grad)</span><br><span class="line">print(<span class="string">'----------------------------------------------------'</span>)</span><br><span class="line">(name3, param3) = params[<span class="number">3</span>]</span><br><span class="line">print(name3) </span><br><span class="line">print(param3.grad)</span><br></pre></td></tr></table></figure><p>Out:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv1.weight</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">-------------------------------------------------</span><br><span class="line">conv1.bias</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">----------------------------------------------------</span><br><span class="line">conv2.weight</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line">----------------------------------------------------</span><br><span class="line">conv2.bias</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure><p>参考：</p><ul><li><p><a href="https://www.pytorchtutorial.com/pytorch-note5-save-and-restore-models/" target="_blank" rel="noopener">PyTorch 学习笔记（五）：存储和恢复模型并查看参数</a></p></li><li><p><a href="https://blog.csdn.net/appleml/article/details/81000301" target="_blank" rel="noopener">pytorch查看网络中的参数</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Spectral_Clustering</title>
    <link href="http://yoursite.com/2018/12/28/Spectral-Clustering/"/>
    <id>http://yoursite.com/2018/12/28/Spectral-Clustering/</id>
    <published>2018-12-28T03:50:46.000Z</published>
    <updated>2018-12-28T03:54:40.120Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><br></p><div class="row">    <embed src="谱聚类.pdf" width="100%" height="550" type="application/pdf"></div><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>聚类综述</title>
    <link href="http://yoursite.com/2018/12/28/%E8%81%9A%E7%B1%BB%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2018/12/28/聚类综述/</id>
    <published>2018-12-28T03:23:11.000Z</published>
    <updated>2018-12-28T03:37:04.165Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p><br></p><div class="row">    <embed src="聚类综述.pdf" width="100%" height="550" type="application/pdf"></div><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>医学数据格式</title>
    <link href="http://yoursite.com/2018/12/27/Medical-Data-Format/"/>
    <id>http://yoursite.com/2018/12/27/Medical-Data-Format/</id>
    <published>2018-12-27T09:08:13.000Z</published>
    <updated>2018-12-27T11:56:24.036Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>ToRead：</p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_12" target="_blank" rel="noopener">Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></p><p><a href="http://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007/978-3-319-59050-9_47" target="_blank" rel="noopener">Unsupervised Domain Adaptation in Brain Lesion Segmentation with Adversarial Networks</a></p><p>Paper：</p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=2ahUKEwjXyObB2r_fAhXjRt8KHROrC5cQFjABegQIAxAB&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1702.05747&amp;usg=AOvVaw3kBlBAYVhnDhZxU1aBbgxG" target="_blank" rel="noopener">A Survey on Deep Learning in Medical Image Analysis</a></p><table><thead><tr><th>数据格式</th><th>含义（字段）</th><th>头部-&gt; 内容</th></tr></thead><tbody><tr><td>DICOM</td><td></td><td></td></tr><tr><td>nii</td><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><table><thead><tr><th>数据</th><th>Kind</th><th>knowledge point + theory</th></tr></thead><tbody><tr><td>MRI</td><td>T1\T2\Flair</td><td>区别， 各自针对的内容</td></tr><tr><td>CT</td><td>腹部CT\胸部\全身CT</td><td>扫描方式</td></tr><tr><td>PET</td><td></td></tr></tbody></table><h2 id="医学图像数据类型"><a href="#医学图像数据类型" class="headerlink" title="医学图像数据类型"></a>医学图像数据类型</h2><h3 id="MRI"><a href="#MRI" class="headerlink" title="MRI"></a>MRI</h3><h3 id="CT"><a href="#CT" class="headerlink" title="CT"></a>CT</h3><h3 id="PET"><a href="#PET" class="headerlink" title="PET"></a>PET</h3><h2 id="医学图像数据格式"><a href="#医学图像数据格式" class="headerlink" title="医学图像数据格式"></a>医学图像数据格式</h2><h3 id="DICOM"><a href="#DICOM" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>医学图像采用数字成像和通信（DICOM）作为存储和交换医学图像数据的标准解决方案。这个标准的第一个版本是在1985年发布的。发展到现在，该方案有了一些改变。该标准使用文件格式和通信协议。</p><p><strong>文件格式</strong> - 所有患者医疗图像都以DICOM文件格式保存。除了其他图像相关数据（例如用于拍摄图像的设备以及医疗处理的一些背景）之外，该格式具有关于患者的PHI（受保护的健康信息），例如姓名，性别，年龄。医学影像设备创建DICOM文件。医生使用DICOM查看器，可显示DICOM图像的计算机软件应用程序，读取和诊断图像中的发现。</p><p><strong>通信协议</strong> - DICOM通信协议用于搜索档案中的成像研究，并将成像研究恢复到工作站以显示。连接到医院网络的所有医疗成像应用程序都使用DICOM协议来交换信息，主要是DICOM图像，还包括患者和手术信息。还有更先进的网络命令，用于控制和跟踪治疗，调度程序，报告状态，分担医生和成像设备之间的工作量。关于DICOM标准细节，在这里推荐一个很好的博客<a href="http://link.zhihu.com/?target=http%3A//dicomiseasy.blogspot.com" target="_blank" rel="noopener">http://dicomiseasy.blogspot.com</a></p><h4 id="分析DICOM图像"><a href="#分析DICOM图像" class="headerlink" title="分析DICOM图像"></a><strong>分析DICOM图像</strong></h4><ul><li><strong>了解DICOM 格式数据</strong></li></ul><p>CT扫描的测量单位是Hounsfield单位（HU），它是放射性强度的量度。 仔细校准CT扫描仪以准确测量。 关于这方面的详细了解可以在这里到。<a href="https://web.archive.org/web/20070926231241/http://www.intl.elsevierhealth.com/e-books/pdf/940.pdf" target="_blank" rel="noopener">Introduction to CT physics</a></p><p>每个像素被分配一个数值（CT值），它是相应体素中所有衰减值的平均值。 将这个数字与水的衰减值进行比较，并在戈弗雷·豪斯菲尔德爵士（Sir Godfrey Hounsfield）之后以胡恩斯菲尔德单位（Hounsfield units，HU）的任意单位的比例显示。</p><ul><li><p>获得DICOM 数据库</p><ul><li>kaggle competitions and Datasets</li><li>Dicom Library</li><li>Osirix Datasets</li><li>Visible Human Datasets</li><li><p>The Zubal Phantom</p></li><li><p>杜克大学他们有公开的数据集</p></li></ul></li></ul><h3 id="nii"><a href="#nii" class="headerlink" title="nii"></a>nii</h3><h2 id="Matlab-python-医学工具包"><a href="#Matlab-python-医学工具包" class="headerlink" title="Matlab/python 医学工具包"></a>Matlab/python 医学工具包</h2><h3 id="DICOM-1"><a href="#DICOM-1" class="headerlink" title="DICOM"></a>DICOM</h3><h4 id="python-package"><a href="#python-package" class="headerlink" title="python package"></a>python package</h4><ul><li><strong>pydiocm</strong></li></ul><h2 id="浏览image数据工具"><a href="#浏览image数据工具" class="headerlink" title="浏览image数据工具"></a>浏览image数据工具</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/30915590" target="_blank" rel="noopener">医学图像处理与深度学习[知乎]</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深度学习之PyTorch实战计算机视觉</title>
    <link href="http://yoursite.com/2018/12/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8BPyTorch%E5%AE%9E%E6%88%98%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    <id>http://yoursite.com/2018/12/17/深度学习之PyTorch实战计算机视觉/</id>
    <published>2018-12-17T03:46:57.000Z</published>
    <updated>2018-12-17T05:50:00.292Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="第6章-PyTorch基础"><a href="#第6章-PyTorch基础" class="headerlink" title="第6章 PyTorch基础"></a>第6章 PyTorch基础</h4><ul><li><p><strong>Why PyTorch</strong></p><p>pytorch可以说是torch的python版，然后增加了很多新的特性。pytorch在编写模型的时候最大的特点就是利用autograd技术来实现<code>自动求导</code>，也就是不需要我们再去麻烦地写一些反向的计算函数，这点上继承了torch。<a href="https://oldpan.me/archives/pytorch-torch-relation" target="_blank" rel="noopener">浅谈Pytorch与Torch的关系</a></p></li><li><p><strong>pytorch document</strong></p><p>Link：<a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></p></li></ul><h4 id="第7章-迁移学习"><a href="#第7章-迁移学习" class="headerlink" title="第7章 迁移学习"></a>第7章 迁移学习</h4><p>如果我们用这么多资源训练的模型能够<code>解决同一类问题</code>，那么模型的性价比会提高很多，这就促使使用迁移模型解决同 一类问题的方法出现 。因为该方法的出现，我们通过对 一个训练好的模型进行细微调整，就能将其应用到相似的问题中，最后还能取得很好的效果 ; 另外，对于原始数据较少的问题，我们也能够通过采用迁移模型进行有效解决 ，所以，如果能够选取合适的迁移学习方法，则会对解决我们所面临的问题有很大的帮助 。</p><h4 id="第8章-图像风格迁移实战"><a href="#第8章-图像风格迁移实战" class="headerlink" title="第8章 图像风格迁移实战"></a>第8章 图像风格迁移实战</h4><center class="third"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/cat.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/2-style1.jpg" width="200"><br><img src="/2018/12/17/深度学习之PyTorch实战计算机视觉/y-output.jpg" width="200"><br></center><h4 id="第9章-多模型融合"><a href="#第9章-多模型融合" class="headerlink" title="第9章 多模型融合"></a>第9章 多模型融合</h4><blockquote><p>“集百家之所长”  </p></blockquote><ul><li><p><strong>结果融合法</strong></p><p>通用理论：各个模型的输出结果的差异性越高 ， 多模型融合的效果就会越好 。</p><ul><li><p>结果多数表决</p></li><li><p>结果直接平均</p><p>融合各模型的平均预测水平，<code>弥补个别模型的明显劣势</code>，预防过拟合和欠拟合的发生</p><p>评价：虽然在总体的准确率上有所提升，但在单个数据的预测能力上并不优秀</p></li><li><p>结果加权平均</p><p>评价：调节各个模型的权重参数对最后的融合模型的结果影响较大。 所以在使用权重平均的过程中，我们需要<code>不断尝试</code>使用不同的权重值组合，以达到多模型融合的最优解决方案 。</p></li></ul></li></ul><h4 id="第10章-循环神经网络"><a href="#第10章-循环神经网络" class="headerlink" title="第10章 循环神经网络"></a>第10章 循环神经网络</h4><p>在循环神经网络中循环单元可以随意控制输入数据及输出数据的数量，具有非常大的灵活性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://deeplearning4j.org/images/guide/rnn_masking_2.png" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>循环神经网络的网络简化模型，通过不断地对自身的网络结构进行复制来构造不同的循环神经网络模型。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>将上图展开，</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn" title="">                </div>                <div class="image-caption">Image result for rnn</div>            </figure><p>虽然循环神经网络已经能够很好地对输入的序列数据进行处理 ，是不能进行长期记忆，其带来的影响就是如果近期输入的数据发生了变化，则会对当前的输出结果产生重大影响 。 为了避免这种情况的出现，研究者开发了 LSTM ( Long Short Term Memory)类型 的循环神经网络模型 。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for rnn lstm" title="">                </div>                <div class="image-caption">Image result for rnn lstm</div>            </figure><h4 id="第11章-自动编码器"><a href="#第11章-自动编码器" class="headerlink" title="第11章 自动编码器"></a>第11章 自动编码器</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="data:image/png;base64,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" alt="Image result for autoEncoder" title="">                </div>                <div class="image-caption">Image result for autoEncoder</div>            </figure><p>自动编码器模型的最大用途就是实现输入数据的清洗，比如去除输入数据中的噪声数据、对输入数据的某些关键特征进行增强和放大，等等 。 举一个比较简单的例子，假设我们现在有一些被打上了马赛克的图片需要进行除码处理，这时就可以通过自动编码器模型来解决这个 问题 。 其实可以将这个除码的过程看作对数据进行除噪的过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>PyTorch_Docs</title>
    <link href="http://yoursite.com/2018/12/15/PyTorch-Package/"/>
    <id>http://yoursite.com/2018/12/15/PyTorch-Package/</id>
    <published>2018-12-15T12:22:24.000Z</published>
    <updated>2018-12-24T05:01:31.838Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><h4 id="torch-Tensor-view"><a href="#torch-Tensor-view" class="headerlink" title="torch.Tensor.view"></a>torch.Tensor.view</h4><p><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view" target="_blank" rel="noopener"><code>view</code>(*<em>shape</em>) → Tensor</a> Returns a new tensor with the same data as the <code>self</code> tensor but of a different <code>shape</code>.</p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.view(<span class="number">16</span>)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred(推导) from other dimensions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>])  <span class="comment"># 2 = (4*4)/8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=x.view(<span class="number">2</span>,<span class="number">-1</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>]) <span class="comment"># 8 = (4*4)/2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=x.view(<span class="number">4</span>,<span class="number">-1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>]) <span class="comment"># 4 = (4*4)/4</span></span><br></pre></td></tr></table></figure><ul><li><strong>Parameters:</strong> <strong>shape</strong> (<em>torch.Size</em> <em>or</em> <em>int…</em>) – the desired size</li></ul><h4 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h4><p><a href="https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops" target="_blank" rel="noopener">Docs</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)  <span class="comment"># dim:0 按列级联(排成一列)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">1</span>)  <span class="comment"># dim:1 按行级联(排成一行)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>, <span class="number">-1.0969</span>, <span class="number">-0.4614</span>,  <span class="number">0.6580</span>,</span><br><span class="line">         <span class="number">-1.0969</span>, <span class="number">-0.4614</span>],</span><br><span class="line">        [<span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>, <span class="number">-0.5790</span>,  <span class="number">0.1497</span>, <span class="number">-0.1034</span>,</span><br><span class="line">         <span class="number">-0.5790</span>,  <span class="number">0.1497</span>]])</span><br></pre></td></tr></table></figure><h2 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h2><h3 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h3><h4 id="torch-nn-Module"><a href="#torch-nn-Module" class="headerlink" title="torch.nn.Module"></a>torch.nn.Module</h4><h5 id="forward-input"><a href="#forward-input" class="headerlink" title="forward(*input)"></a>forward(*<em>input</em>)</h5><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward" target="_blank" rel="noopener"><code>forward</code>(*<em>input</em>)</a>  Defines the computation performed at every call.</p><h4 id="torch-nn-Sequential"><a href="#torch-nn-Sequential" class="headerlink" title="torch.nn.Sequential"></a>torch.nn.Sequential</h4><p><a href="https://pytorch.org/docs/stable/nn.html#sequential" target="_blank" rel="noopener">torch.nn.Sequential</a> 类是 torch.nn 中的一种序列容器，通过在容器中嵌套各种实现神经网络中具体功能相关的类，来完成对神 经网络模型 的搭建，最主要的是，<code>参数会按照我们定义好的序列自动传递下去</code>。我们可以将嵌套在容器中的各个部分看作各种不同的模块，这些模块可以自由组合。模块的加入 一般有两种方式 ， 一种是<strong>直接嵌套</strong>，另 一 种是以 <strong>orderdict</strong> 有序字典的方式进行传入，这两种方式的唯一区别是，使用后者搭建的模型的每个模块都有我们自定义的名字 ， 而前者默认使用从零开始的数字序列作为每个模块的名字。</p><h3 id="Convolution-Layers"><a href="#Convolution-Layers" class="headerlink" title="Convolution Layers"></a>Convolution Layers</h3><center><br>    <img src="/2018/12/15/PyTorch-Package/channel.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/SimpleCNN.png" width="600"><br></center><center><br><img src="/2018/12/15/PyTorch-Package/LinearSize.png" width="600"><br></center><p><a href="https://www.youtube.com/watch?v=LgFNRIFxuUo" target="_blank" rel="noopener">PyTorch Lecture 10: Basic CNN</a></p><h4 id="torch-nn-Conv1d"><a href="#torch-nn-Conv1d" class="headerlink" title="torch.nn.Conv1d"></a>torch.nn.Conv1d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv1d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv1d(<span class="number">16</span>,  , <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">24</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$ (N, C_{\text{in}}, L)$  —  $\text{input.size :} (20, 16, 50)$</li><li><p>$ (N, C_{\text{out}}, L_{\text{out}})$ — $\text{output.size :} (20,  33, 24)$ </p><ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation}<br>\times (\text{kernel_size} - 1) - 1}{\text{stride}} + 1\right\rfloor \Rightarrow  24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size)}$.</p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) –the learnable bias of the module of shape $\text{(out_channels)}$.</li></ul><h4 id="torch-nn-Conv2d"><a href="#torch-nn-Conv2d" class="headerlink" title="torch.nn.Conv2d"></a>torch.nn.Conv2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnconv2din95channels-out95channels-kernel95size-stride1-padding0-dilation1-groups1-biastrue" target="_blank" rel="noopener">文档说明</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>) <span class="comment"># (in_channels, out_channels, kernel_size, stride)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding and dilation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">26</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, H_{in}, W_{in})$  — $\text{input.size :} (20, 16, 50, 100)$</li><li>$(N, C_{out}, H_{out}, W_{out})$ — $\text{output.size :} (20, 33, 26, 100)$<ul><li>$C_{\text{out}}  \text{ : out_channels}$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor  \Rightarrow 26  = \left\lfloor\frac{50  + 2 \times 4- 3<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 100 =  \left\lfloor\frac{100  + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape $\text{(out_channels, in_channels, kernel_size[0], kernel_size[1])}$.</li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h4 id="torch-nn-Conv3d"><a href="#torch-nn-Conv3d" class="headerlink" title="torch.nn.Conv3d"></a>torch.nn.Conv3d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#conv3d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">33</span>, <span class="number">8</span>, <span class="number">50</span>, <span class="number">99</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">33</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C_{in}, D_{in}, H_{in}, W_{in})$  — $\text{input.size :}20, 16, 10, 50, 100)$</li><li><p>$(N, C_{out}, D_{out}, H_{out}, W_{out})$  — $\text{output.size :} (20, 33, 8, 50, 99)$ </p><ul><li>$H_{out} = \left\lfloor\frac{H{in} + 2 \times \text{padding}[1] - \text{dilation}[1]<br>\times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor \<br>\Rightarrow 50 =  \left\lfloor\frac{50 + 2 \times 2 - 1<br>\times (5- 1) - 1}{1} + 1\right\rfloor$</li><li>$D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0]<br>\times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor \\Rightarrow 8 =  \left\lfloor\frac{10 + 2 \times 4 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor$</li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2]<br>\times (\text{kernel_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor \\Rightarrow 99 = \left\lfloor\frac{100 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul></li><li><p><strong>weight</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable weights of the module of shape$\text{ (out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2])}$ </p></li><li><strong>bias</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>Tensor</em></a>) – the learnable bias of the module of shape $\text{(out_channels)}$. </li></ul><h3 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h3><h4 id="torch-nn-MaxPool2d"><a href="#torch-nn-MaxPool2d" class="headerlink" title="torch.nn.MaxPool2d"></a>torch.nn.MaxPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#maxpool2d" target="_blank" rel="noopener">Docs</a>  <a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#class-torchnnmaxpool2dkernel95size-stridenone-padding0-dilation1-return95indicesfalse-ceil95modefalse" target="_blank" rel="noopener">文档说明</a></p><p>Applies a 2D max pooling over an input signal composed of several input planes.</p><p>In the simplest case, the output value of the layer with input size$(N, C, H, W)​$, output $(N, C, H_{out}, W_{out})​$ and <code>kernel_size</code> $(kH, kW)​$can be precisely described as:</p><p>$\begin{aligned}<br>out(N_i, C_j, h, w) ={} &amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \text{input}(N_i, C_j, \text{stride[0]} \times h + m,<br>\text{stride[1]} \times w + n)<br>\end{aligned}$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li><p>$(N, C, H_{in}, W_{in})$ — $\text{input.size:}(20, 16, 50, 32) $</p></li><li><p>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</p></li><li><p>$H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]}<br>\times (\text{kernel_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor \\Rightarrow 24 = \left\lfloor\frac{50 + 2 \times 0 - 1<br>\times (3 - 1) - 1}{2} + 1\right\rfloor $</p></li><li>$W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]}<br>\times (\text{kernel_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor \ \Rightarrow 31 = \left\lfloor\frac{32 + 2 \times 0 - 1<br>\times (2 - 1) - 1}{1} + 1\right\rfloor$</li></ul><h4 id="torch-nn-AvgPool2d"><a href="#torch-nn-AvgPool2d" class="headerlink" title="torch.nn.AvgPool2d"></a>torch.nn.AvgPool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#avgpool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">31</span>])</span><br></pre></td></tr></table></figure><ul><li>$(N, C, H_{in}, W_{in})$ — $\text{input.size: } (20, 16, 50, 32)$</li><li>$(N, C, H_{out}, W_{out})$ — $\text{output.size: } (20, 16, 24, 31)$</li><li>$H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] -<br>\text{kernel_size}[0]}{\text{stride}[0]} + 1\right\rfloor \Rightarrow 24 = \left\lfloor\frac{50  + 2 \times 0 -<br>3}{2} + 1\right\rfloor$</li><li><p>$W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] -<br>\text{kernel_size}[1]}{\text{stride}[1]} + 1\right\rfloor \Rightarrow 31 = \left\lfloor\frac{32  + 2 \times 0 -<br>2}{1} + 1\right\rfloor$</p></li><li><p><strong><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#dropout-layers" target="_blank" rel="noopener">torch.nn.Dropout</a></strong> torch.nn.Dropout 类用于防止卷积神经网络在训练的过程中发生过拟合 ， 其工作原理简单来说就是在模型训练的过程中，以一定的随机概率将卷积神经网络模型的部分参数归零(“丢弃”)， 以达到减少相邻两层神经连接的目的。</p></li></ul><h3 id="Non-Linear-Activations"><a href="#Non-Linear-Activations" class="headerlink" title="Non-Linear Activations"></a>Non-Linear Activations</h3><h4 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h4><p><a href="https://pytorch.org/docs/stable/nn.html#relu" target="_blank" rel="noopener">Docs</a></p><center><br>    <img src="https://pytorch.org/docs/stable/_images/ReLU.png" width="400"><br></center><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.ReLU()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.7526</span>, <span class="number">0.9017</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([<span class="number">-0.5070</span>, <span class="number">0.4540</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">0.0000</span>, <span class="number">0.4540</span>])</span><br></pre></td></tr></table></figure><ul><li>Input:$(N, <em>)$ where </em> means, any number of additional dimensions</li><li>Output: $(N, *)$, same shape as the input</li></ul><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><h4 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h4><p><a href="https://pytorch.org/docs/stable/nn.html#linear" target="_blank" rel="noopener">Docs</a></p><p>Applies a linear transformation to the incoming data: $y = xA^T + b$</p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Linear(<span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">128</span>, <span class="number">20</span>)  <span class="comment"># (N,∗,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(output.size())</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">30</span>])   <span class="comment"># (N,∗,out_features)</span></span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[<span class="number">-0.8833</span>,  <span class="number">0.1130</span>,  <span class="number">0.0446</span>,  ..., <span class="number">-0.2786</span>,  <span class="number">2.0762</span>,  <span class="number">0.6139</span>],</span><br><span class="line">        [<span class="number">-0.9236</span>,  <span class="number">3.1720</span>, <span class="number">-0.9857</span>,  ...,  <span class="number">0.1017</span>, <span class="number">-0.4042</span>, <span class="number">-0.1072</span>],</span><br><span class="line">        [ <span class="number">0.0153</span>,  <span class="number">0.8800</span>, <span class="number">-0.6031</span>,  ..., <span class="number">-0.2836</span>,  <span class="number">0.7584</span>, <span class="number">-2.3324</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.9628</span>, <span class="number">-0.3177</span>, <span class="number">-0.7577</span>,  ...,  <span class="number">0.2819</span>,  <span class="number">0.9684</span>, <span class="number">-1.8474</span>],</span><br><span class="line">        [ <span class="number">0.3380</span>,  <span class="number">1.0946</span>, <span class="number">-1.3399</span>,  ..., <span class="number">-0.0043</span>, <span class="number">-0.9811</span>,  <span class="number">0.3067</span>],</span><br><span class="line">        [ <span class="number">0.6834</span>,  <span class="number">0.5804</span>, <span class="number">-0.8192</span>,  ...,  <span class="number">1.2167</span>,  <span class="number">1.3583</span>, <span class="number">-1.5123</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">1.0747</span>,  <span class="number">1.2864</span>,  <span class="number">0.6512</span>,  ...,  <span class="number">0.1053</span>, <span class="number">-0.0487</span>, <span class="number">-0.1705</span>],</span><br><span class="line">        [ <span class="number">0.2707</span>, <span class="number">-0.7018</span>, <span class="number">-0.4553</span>,  ..., <span class="number">-0.2100</span>, <span class="number">-0.3003</span>,  <span class="number">1.0038</span>],</span><br><span class="line">        [ <span class="number">0.1943</span>, <span class="number">-0.3070</span>, <span class="number">-0.3651</span>,  ...,  <span class="number">1.1940</span>, <span class="number">-0.2991</span>,  <span class="number">0.0455</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.4118</span>, <span class="number">-0.3984</span>,  <span class="number">0.2089</span>,  ...,  <span class="number">0.7984</span>, <span class="number">-0.6598</span>,  <span class="number">0.2150</span>],</span><br><span class="line">        [<span class="number">-0.1639</span>, <span class="number">-1.5081</span>, <span class="number">-0.4011</span>,  ...,  <span class="number">0.9673</span>,  <span class="number">0.3524</span>,  <span class="number">0.0993</span>],</span><br><span class="line">        [ <span class="number">0.5961</span>, <span class="number">-0.4150</span>, <span class="number">-0.1207</span>,  ...,  <span class="number">0.3189</span>, <span class="number">-0.0829</span>,  <span class="number">0.5195</span>]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.weight.size()</span><br><span class="line">torch.Size([<span class="number">30</span>, <span class="number">20</span>])  <span class="comment"># (out_features,in_features)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.bias.size()</span><br><span class="line">torch.Size([<span class="number">30</span>])   <span class="comment">#  (out_features)</span></span><br></pre></td></tr></table></figure><h3 id="NormalizationLayers"><a href="#NormalizationLayers" class="headerlink" title="NormalizationLayers"></a>NormalizationLayers</h3><p><a href="https://www.youtube.com/watch?v=NGO0oxdz-zs" target="_blank" rel="noopener">Batch Normalization 批标准化 (PyTorch tutorial 神经网络 教学)</a> </p><p><a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)_Morvan</a>让数值保持在激活函数的有效区间，可避免梯度消失。Batch Normalization (BN) 就被添加在每一个全连接和激励函数之间.</p><p><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">深度学习中 Batch Normalization为什么效果好？</a> </p><h4 id="BatchNorm2d"><a href="#BatchNorm2d" class="headerlink" title="BatchNorm2d"></a>BatchNorm2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#batchnorm2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>])  <span class="comment">#  (same shape as input）</span></span><br></pre></td></tr></table></figure><h3 id="Dropout-Layers"><a href="#Dropout-Layers" class="headerlink" title="Dropout Layers"></a>Dropout Layers</h3><h4 id="torch-nn-Dropout"><a href="#torch-nn-Dropout" class="headerlink" title="torch.nn.Dropout"></a>torch.nn.Dropout</h4><p><a href="https://pytorch.org/docs/stable/nn.html#dropout" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">20</span>, <span class="number">16</span>])  <span class="comment">#  Output is of the same shape as input</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input</span><br><span class="line">tensor([[ <span class="number">1.7224</span>,  <span class="number">1.3201</span>, <span class="number">-0.8480</span>],</span><br><span class="line">        [ <span class="number">1.8960</span>, <span class="number">-0.1245</span>,  <span class="number">0.6991</span>],</span><br><span class="line">        [ <span class="number">1.1756</span>,  <span class="number">0.2378</span>,  <span class="number">1.4059</span>],</span><br><span class="line">        [ <span class="number">0.2427</span>,  <span class="number">0.2278</span>, <span class="number">-0.7612</span>],</span><br><span class="line">        [<span class="number">-0.8882</span>,  <span class="number">0.2088</span>,  <span class="number">1.5004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([[ <span class="number">2.1530</span>,  <span class="number">1.6501</span>, <span class="number">-1.0601</span>],</span><br><span class="line">        [ <span class="number">2.3700</span>, <span class="number">-0.1556</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">1.4694</span>,  <span class="number">0.2972</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.3034</span>,  <span class="number">0.0000</span>, <span class="number">-0.9515</span>],</span><br><span class="line">        [<span class="number">-0.0000</span>,  <span class="number">0.2610</span>,  <span class="number">1.8755</span>]])</span><br></pre></td></tr></table></figure><h3 id="torch-nn-init"><a href="#torch-nn-init" class="headerlink" title="torch.nn.init"></a>torch.nn.init</h3><h4 id="torch-nn-init-kaiming-uniform"><a href="#torch-nn-init-kaiming-uniform" class="headerlink" title="torch.nn.init.kaiming_uniform_"></a>torch.nn.init.kaiming_uniform_</h4><p><a href="https://pytorch.org/docs/stable/nn.html?highlight=nn.init#torch.nn.init.kaiming_normal_" target="_blank" rel="noopener">Docs</a></p><h2 id="torch-nn-functional"><a href="#torch-nn-functional" class="headerlink" title="torch.nn.functional"></a>torch.nn.functional</h2><h3 id="Pooling-functions"><a href="#Pooling-functions" class="headerlink" title="Pooling functions"></a>Pooling functions</h3><h4 id="adaptive-avg-pool2d"><a href="#adaptive-avg-pool2d" class="headerlink" title="adaptive_avg_pool2d"></a>adaptive_avg_pool2d</h4><p><a href="https://pytorch.org/docs/stable/nn.html#adaptive-avg-pool2d" target="_blank" rel="noopener">Docs</a></p><p><strong>Examples:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 5x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d((<span class="number">5</span>,<span class="number">7</span>))  <span class="comment"># output_size – (H, W) </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 7x7 (square)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d(<span class="number">7</span>)  <span class="comment"># a single H for a square image H x H</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># target output size of 10x7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool2d((<span class="keyword">None</span>, <span class="number">7</span>))  <span class="comment"># None, which means the size will be the same as that of the input.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.size()</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">10</span>, <span class="number">7</span>])</span><br></pre></td></tr></table></figure><h4 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h4><ul><li><p><strong>torchvision.transforms.Resize:</strong>用于对载入的图片数据按我们需求的大小进行缩放。 传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列， 其中 ， h 代表高度， w 代表宽度，但是如果使用的是 一 个整型数据，那么表示缩放的宽度和高度都是这个整型数据的值 。 </p></li><li><p><strong>torchvision.transforms.Scale</strong>: 用于对载入的图片数据按我 们 需求的大小进 行缩 放，用法和 torchvision.transforms.Resize类似。 </p></li><li><p><strong>torchvision.transforms.CenterCrop:</strong>用 于对载入的图片以图片中心为参考点 ， 按我们需要的大小进行裁剪 。传递给这个类 的参数可以是一个整型数据 ，也可以 是一个类似 于( h,w)的序列 。 </p></li><li><p><strong>torchvision.transforms.RandomCrop:</strong> 用于对载入的图片按我们需要的大小进行随机裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于$ (h,w)$的序列。 </p></li><li><p><strong>torchvision.transforms.RandomHorizontaIFlip:</strong> 用于对载入的图片按随机概率进行水平翻转。我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则使用 默认的概率值 0.5。</p></li><li><p><strong>torchvision.transforms.RandomVerticalFlip:</strong> 用于对载入的图片按随机概率进行垂直翻转。 我们可以通过传递给这个类的参数自定义随机概率 ，如果没有定义 ，则 使用默 认的概率值 0.5。 </p></li><li><p><strong>torchvision.transforms.ToTensor:</strong> 用于对载入的图片数据进行类型转换 ， 将之前构成 PIL 图片的数据转换成 Tensor数据类型的变量 ，让 PyTorch 能够对其进行计算和处理。 </p></li><li><p><strong>torchvision.transforms.ToPILlmage:</strong> 用于将 Tensor变量的数据转换成 PIL 图片数据， 主要是为了方便图片内容的显示。</p></li></ul><h2 id="torch-utils-model-zoo"><a href="#torch-utils-model-zoo" class="headerlink" title="torch.utils.model_zoo"></a>torch.utils.model_zoo</h2><p><a href="https://pytorch.org/docs/stable/model_zoo.html#module-torch.utils.model_zoo" target="_blank" rel="noopener">torch.utils.model_zoo.load_url</a></p><p><strong>Example:</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>state_dict = torch.utils.model_zoo.load_url(<span class="string">'https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GraduationDesign</title>
    <link href="http://yoursite.com/2018/12/13/GraduationDesign/"/>
    <id>http://yoursite.com/2018/12/13/GraduationDesign/</id>
    <published>2018-12-13T09:51:23.000Z</published>
    <updated>2018-12-21T07:04:46.434Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h4 id="毕设要求"><a href="#毕设要求" class="headerlink" title="毕设要求"></a>毕设要求</h4><table><thead><tr><th>课题名称</th><th>基于densenet的图像分类算法研究与实现</th></tr></thead><tbody><tr><td>课题简介</td><td>随着深度学习网络越来越深，架构越来越复杂，解决反向传播时梯度消失的问题也越来越严重。densenetdensenet的每一层都和损失函数的梯度以及原始输入直接相连，用更少的参数减轻了反向梯度消失，可以令网络规模更大。该课题研究基于densenet的图像分类算法，提高分类效率。</td></tr></tbody></table><h4 id="代码调研"><a href="#代码调研" class="headerlink" title="代码调研"></a>代码调研</h4><ul><li><p><a href="https://blog.csdn.net/mdjxy63/article/details/76401145" target="_blank" rel="noopener">DenseNet的使用</a></p><p>Github link: <a href="https://github.com/liuzhuang13/DenseNetCaffe" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNetCaffe</a>  <strong>Star 243</strong></p></li><li><p><a href="https://blog.csdn.net/u014380165/article/details/75142664" target="_blank" rel="noopener">DenseNet算法详解</a></p><p>代码的github链接：<a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet</a>    <strong>Star 3090</strong><br>MXNet版本代码（有ImageNet预训练模型）: <a href="https://github.com/miraclewkf/DenseNet" target="_blank" rel="noopener">https://github.com/miraclewkf/DenseNet</a>    <strong>Star 41</strong></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/28190802" target="_blank" rel="noopener">Densely Connected Convolutional Networks》论文笔记</a></p><p><a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet</a>   <strong>Star 3090</strong></p></li><li><p>pytorch官方已经提供了Resnet、densenet的实现代码及权重文件</p></li><li><p><a href="https://www.leiphone.com/news/201708/0MNOwwfvWiAu43WO.html" target="_blank" rel="noopener">CVPR 2017最佳论文作者解读</a></p><p><a href="https://github.com/gaohuang/MSDNet" target="_blank" rel="noopener"> https://github.com/gaohuang/MSDNet</a>  <strong>Star 351</strong></p><p>代码参见：</p><p>Torch implementation: <a href="https://github.com/liuzhuang13/DenseNet/tree/master/models" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet/tree/master/models</a>    <strong>Star 3090</strong></p><p>PyTorch implementation: <a href="https://github.com/gpleiss/efficient_densenet_pytorch" target="_blank" rel="noopener">https://github.com/gpleiss/efficient_densenet_pytorch</a>    <strong>Star 771</strong></p><p>MxNet implementation: <a href="https://github.com/taineleau/efficient_densenet_mxnet" target="_blank" rel="noopener">https://github.com/taineleau/efficient_densenet_mxnet</a>    </p><p>Caffe implementation: <a href="https://github.com/Tongcheng/DN_CaffeScript" target="_blank" rel="noopener">https://github.com/Tongcheng/DN_CaffeScript</a>    <strong>Star 123</strong></p></li></ul><h4 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h4><ul><li>Torch implementation: <a href="https://github.com/liuzhuang13/DenseNet/tree/master/models" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet/tree/master/models</a>    <strong>Star 3090</strong></li><li>PyTorch <a href="https://blog.csdn.net/u014380165/article/details/79119664" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/79119664</a></li></ul><p><a href="https://pytorch.org/docs/master/torchvision/models.html" target="_blank" rel="noopener">https://pytorch.org/docs/master/torchvision/models.html</a></p><ul><li><p><a href="https://www.ctolib.com/article/wiki/34431" target="_blank" rel="noopener">DenseNet的一个PyTorch实现</a></p></li><li><p><a href="https://www.jianshu.com/p/9e5d68369a38" target="_blank" rel="noopener">Pytorch 使用预训练模型</a></p></li></ul><p>Q: pytorch.model.densenet 使用</p><h4 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h4><ul><li><p>_DenseLayer  命名方式_</p><p>$\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t$</p></li></ul><table><thead><tr><th style="text-align:center">model version</th><th style="text-align:center">num_init_features</th><th style="text-align:center">growth_rate</th><th style="text-align:center">block_config</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet121</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 24, 16)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet169</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 32, 32)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet201</a></td><td style="text-align:center">64</td><td style="text-align:center">32</td><td style="text-align:center">(6, 12, 48, 32)</td></tr><tr><td style="text-align:center"><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">densenet161</a></td><td style="text-align:center">96</td><td style="text-align:center">48</td><td style="text-align:center">(6, 12, 36, 24)</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>白话深度学习与TensorFlow_笔记</title>
    <link href="http://yoursite.com/2018/12/12/%E7%99%BD%E8%AF%9D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8ETensorFlow-%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/12/12/白话深度学习与TensorFlow-笔记/</id>
    <published>2018-12-12T09:32:42.000Z</published>
    <updated>2018-12-17T06:24:01.592Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读说明】这本书适合零基础的初学者</p><a id="more"></a><h4 id="第5章-手写板功能"><a href="#第5章-手写板功能" class="headerlink" title="第5章 手写板功能"></a>第5章 手写板功能</h4><ul><li><p>手写识别</p><p>Github Link：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p><p>文件目录：<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist</a></p></li></ul><h4 id="第6章-卷积神经网络"><a href="#第6章-卷积神经网络" class="headerlink" title="第6章 卷积神经网络"></a>第6章 卷积神经网络</h4><ul><li><p><strong>卷积</strong></p><center><br><img src="https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-59-29-pm.png?w=748" style="zoom:80%"><br></center></li><li><p><strong>卷积核</strong> </p><center><br>    <img src="https://www.oreilly.com/library/view/neural-networks-with/9781788397872/assets/2009c470-759a-4fb7-a1a3-982c4bae841c.png" style="zoom:30%"><br></center></li></ul><ul><li><p><strong>池化层 Pooling Layer</strong></p><blockquote><p>池化层的作用实际上对 Feature Map 所做的数据处理又进行了一次所谓的池化处理。常见的池化层处理有两种方式:一种叫 Max Pooling，一种叫 Mean Pooling (也叫 Average Pooling)</p></blockquote><center><br>    <img src="https://i.stack.imgur.com/bhXRN.png" style="zoom:60%"><br></center></li></ul><h4 id="第7章-综合问题"><a href="#第7章-综合问题" class="headerlink" title="第7章 综合问题"></a>第7章 综合问题</h4><ul><li><p><strong>ReLU 函数 Activation Function</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/ReLU.png"><br></center><p><strong>优点：</strong></p><p>其一 ，在第一象限中<code>不会有明显的梯度消失问题</code>，因为导数恒为 1，而 w 在初始化的 时候也是有大有小，连乘的时候不会轻易出现很小或者很大的数值，这就是一个非常好的 特性了 。 </p><p>其二，由于导数为 1，所以求解它的导数要比求解 Sigmoid 函数的导数<code>时间代价要小</code> 一些.</p><blockquote><p>因而现在的工程人员在近几年的网络中都喜欢大量使用 ReLU 函数 。 在笔者的工程经验中也是至少 80% 以上的工程都是倾向于优先使用 ReLU 函数作为激励函数的 。 </p></blockquote></li><li><p><strong>归一化 normalization</strong></p><blockquote><p>统一“单位”，让模型对各参数数值变化的敏感程度保持一致，“没有偏见”</p></blockquote></li><li><p><strong>正则化 regulization</strong></p><blockquote><p>防止过拟合，提高泛化能力</p></blockquote></li><li><p><strong>超参数 hyper parameter</strong></p><blockquote><p>不能通过算法学习到的参数，例如 K-Means 算法中的簇数 N，还有就是像在深度学习中涉及的学习率 $\eta $</p></blockquote></li><li><p><strong>Dropout</strong></p><blockquote><p>在一轮训练阶段丢弃一部分网络节点 。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</span><br></pre></td></tr></table></figure></li></ul><h4 id="第8章-循环神经网络"><a href="#第8章-循环神经网络" class="headerlink" title="第8章 循环神经网络"></a>第8章 循环神经网络</h4><ul><li><p><strong><a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">隐马尔可夫模型</a></strong></p><center><br>    <img src="data:image/png;base64,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"><br></center></li></ul><blockquote><p>马尔可夫链的核心是说，在给定当前知识或信息的情况下，观察对象过去的历史状态对于<br>将来的预测来说预测是无关的 。 也可以说，在观察一个系统变化的时候，它下一个状态(第<br>n+l个状态)如何的概率只需要观察和统计<code>当前状态</code>(第n个状态)即可以正确得出。</p></blockquote><ul><li><p><strong>RNN 和 BPTT 算法</strong></p><center><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/BPTT.png" style="zoom:50%"><br></center></li><li><p><strong>LSTM算法</strong></p><center><br>    <img src="data:image/png;base64,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" style="zoom:150%"><br></center></li><li><p><strong>聊天机器人</strong></p><p>Github链接：<a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener">https://github.com/Conchylicultor/DeepQA</a></p><p>issue:</p><ul><li><p>OK <a href="https://github.com/Conchylicultor/DeepQA/issues/68" target="_blank" rel="noopener">Error about BasicLSTMCell </a></p></li><li><p>After using Nicholas C.’s pre-trained model ,<code>still not work</code>.</p><p>To resolve  <a href="https://github.com/Conchylicultor/DeepQA/issues/149" target="_blank" rel="noopener">WARNING: Restoring previous model</a></p><ul><li><p>I think the pretrained model is not work</p></li><li><p><a href="https://mcastedu-my.sharepoint.com/personal/nicholas_cutajar_a100636_mcast_edu_mt/Documents/Forms/All.aspx?slrid=ba91ab9e-d04d-7000-6ce2-3d1610bc6c24&amp;FolderCTID=0x012000ACF25C8BFBFE2F4A85CE16FF1E3C2BBC&amp;id=%2Fpersonal%2Fnicholas_cutajar_a100636_mcast_edu_mt%2FDocuments%2FDeepQA%20-%20Pre%20Trained%20Models" target="_blank" rel="noopener">N C</a></p></li></ul></li></ul></li></ul><h4 id="第9章-深度残差网络"><a href="#第9章-深度残差网络" class="headerlink" title="第9章 深度残差网络"></a>第9章 深度残差网络</h4><p>Github Link：</p><p><a href="https://github.com/ry/tensorflow-resnet" target="_blank" rel="noopener">https://github.com/ry/tensorflow-resnet</a></p><p><a href="https://github.com/raghakot/keras-resnet" target="_blank" rel="noopener">https://github.com/raghakot/keras-resnet</a></p><p><a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">https://github.com/KaimingHe/deep-residual-networks</a></p><h4 id="第10章-受限玻尔兹曼机"><a href="#第10章-受限玻尔兹曼机" class="headerlink" title="第10章 受限玻尔兹曼机"></a>第10章 受限玻尔兹曼机</h4><p><a href="https://github.com/meownoid/tensorfow-rbm" target="_blank" rel="noopener">https://github.com/meownoid/tensorfow-rbm</a>  解码器(autodecoder)</p><p><a href="https://github.com/Cospel/rbm-ae-tf" target="_blank" rel="noopener">https://github.com/Cospel/rbm-ae-tf</a> 降维工具</p><h4 id="第11章-强化学习"><a href="#第11章-强化学习" class="headerlink" title="第11章 强化学习"></a>第11章 强化学习</h4><ul><li><p><strong><a href="http://gym.openai.com/" target="_blank" rel="noopener">OpenAI Gym</a></strong></p><p>Github Link：<a href="https://github.com/openai/gym" target="_blank" rel="noopener">https://github.com/openai/gym</a></p></li><li><p><strong>Playing Atari with Deep Reinforcement Learning</strong></p><p>Github Link：<a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" target="_blank" rel="noopener">https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner</a></p></li></ul><h4 id="第12章-对抗学习"><a href="#第12章-对抗学习" class="headerlink" title="第12章 对抗学习"></a>第12章 对抗学习</h4><ul><li><p><strong>DCGAN</strong></p><p>Github Link：<a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">https://github.com/carpedm20/DCGAN-tensorflow</a></p></li></ul><h4 id="第13章-有趣的深度学习应用"><a href="#第13章-有趣的深度学习应用" class="headerlink" title="第13章 有趣的深度学习应用"></a>第13章 有趣的深度学习应用</h4><ul><li><p>人脸识别</p><p>GIthub link：<a href="https://github.com/davidsandberg/facenet" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet</a></p><p>LFW datasets: <a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p></li><li><p>作诗姬</p><p>Github link：<a href="https://github.com/XingxingZhang/rnnpg" target="_blank" rel="noopener">https://github.com/XingxingZhang/rnnpg</a></p></li><li><p>VGG</p><p>Github link：<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python neural_style.py --content &lt;content file&gt; --styles &lt;style file&gt; --output &lt;output file&gt;</span><br><span class="line"></span><br><span class="line">Example:</span><br><span class="line">python neural_style.py –content examples/cat.jpg –styles examples/2-style1.jpg –output y-output.jpg</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(tensorflow) ➜  neural-style-master python neural_style.py --content examples/cat.jpg --styles examples/2-style1.jpg --output y-output.jpg --network imagenet-vgg-verydeep-19.mat</span><br><span class="line">Optimization started...</span><br><span class="line">Iteration    1/1000</span><br><span class="line">Iteration    2/1000 (16 sec elapsed, 4 hr 26 min remaining)</span><br><span class="line">Iteration    3/1000 (30 sec elapsed, 4 hr 10 min remaining)</span><br><span class="line">Iteration    4/1000 (43 sec elapsed, 4 hr 0 min remaining)</span><br><span class="line">Iteration    5/1000 (55 sec elapsed, 3 hr 50 min remaining)</span><br><span class="line">...</span><br><span class="line">Iteration  999/1000 (3 hr 22 min elapsed, 24 sec remaining)</span><br><span class="line">Iteration 1000/1000 (3 hr 23 min elapsed, 12 sec remaining)</span><br><span class="line">content loss: 796114</span><br><span class="line">  style loss: 234885</span><br><span class="line">     tv loss: 44175.5</span><br><span class="line">  total loss: 1.07517e+06</span><br></pre></td></tr></table></figure><center class="third"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/cat.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/2-style1.jpg" width="200"><br>    <img src="/2018/12/12/白话深度学习与TensorFlow-笔记/y-output.jpg" width="200"><br></center></li></ul><h4 id="Other-Concepts"><a href="#Other-Concepts" class="headerlink" title="Other Concepts"></a>Other Concepts</h4><ul><li><p><strong>VC维 Vapnik-Chervonenkis Dimension</strong></p><blockquote><p>H的VC维表示为VC(H) ，指能够被H分散的最大集合的大小。若H能分散任意大小的集合，那么VC(H)为无穷大。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读说明】这本书适合零基础的初学者&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>软件过程与项目管理</title>
    <link href="http://yoursite.com/2018/12/10/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2018/12/10/软件过程与项目管理/</id>
    <published>2018-12-10T11:02:40.000Z</published>
    <updated>2018-12-10T12:23:08.557Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><h3 id="Introduction-to-Project-Management"><a href="#Introduction-to-Project-Management" class="headerlink" title="Introduction to Project Management"></a>Introduction to Project Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-c0568a46ba885ed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="The-Project-Management-and-Information-Technology-Context"><a href="#The-Project-Management-and-Information-Technology-Context" class="headerlink" title="The Project Management and Information Technology Context"></a>The Project Management and Information Technology Context</h3><h3 id="The-Project-Management-Process-Groups"><a href="#The-Project-Management-Process-Groups" class="headerlink" title="The Project Management Process Groups"></a>The Project Management Process Groups</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Initiating processes - 启动过程</span><br><span class="line">Planning processes - 计划过程</span><br><span class="line">Executing processes - 执行过程组</span><br><span class="line">Monitoring and controlling processes- 监控过程</span><br><span class="line">Closing processes -闭合过程</span><br></pre></td></tr></table></figure><h3 id="Project-Integration-Management"><a href="#Project-Integration-Management" class="headerlink" title="Project Integration Management"></a>Project Integration Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-0ea7fa98a3c3eb4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Scope-Management"><a href="#Project-Scope-Management" class="headerlink" title="Project Scope Management"></a>Project Scope Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a0e80e3077f6b3c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Schedule-Management"><a href="#Project-Schedule-Management" class="headerlink" title="Project Schedule Management"></a>Project Schedule Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-34622539853a259b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Cost-Management"><a href="#Project-Cost-Management" class="headerlink" title="Project Cost Management"></a>Project Cost Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-cc09a65d92af001a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="630"><br></center><center><br>        <img src="https://upload-images.jianshu.io/upload_images/5267500-0170a5c22ef465af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"><br></center><h3 id="Project-Quality-Management"><a href="#Project-Quality-Management" class="headerlink" title="Project Quality Management"></a>Project Quality Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-6ee33da505abded3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Resource-Management"><a href="#Project-Resource-Management" class="headerlink" title="Project Resource Management"></a>Project Resource Management</h3><center><br><img src="https://upload-images.jianshu.io/upload_images/5267500-7374cb810a56778a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Communications-Management"><a href="#Project-Communications-Management" class="headerlink" title="Project Communications Management"></a>Project Communications Management</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-e1777f730d2a1f31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h3 id="Project-Risk-Management"><a href="#Project-Risk-Management" class="headerlink" title="Project Risk Management"></a>Project Risk Management</h3><h4 id="processes"><a href="#processes" class="headerlink" title="processes"></a>processes</h4><ol><li><p><strong>Planning risk management:</strong> deciding how to approach and plan the risk management activities for the project 决定如何处理和规划项目的风险管理活动</p><ul><li>The project team should review project documents as well as corporate risk management <code>policies</code>, <code>risk categories</code>,<code>lessons-learned</code> reports from past projects, and<code>templates</code> for creating a risk management plan</li></ul></li><li><p><strong>Identifying risks</strong>: determining which risks are likely to affect a project and documenting the characteristics of each 确定哪些风险可能影响项目并记录每个风险的特征</p><ul><li>tools and techniques <ul><li>Brainstorming</li><li>The Delphi Technique: 专家小组；匿名输入；书面答复</li><li>Interviewing</li><li>SWOT analysis: Strengths,weaknesses, opportunities, and threats</li></ul></li><li>Output<ul><li>Risk Register </li></ul></li></ul></li><li><p><strong>Performing qualitative risk analysis</strong>: prioritizing risks based on their probability and impact of occurrence 根据风险的概率和发生的影响确定风险的优先级</p><ul><li>tools and techniques <ul><li>Probability/impact matrixes</li><li>The Top Ten Risk Item Tracking</li><li>Expert judgment</li></ul></li></ul></li><li><p><strong>Performing quantitative risk analysis</strong>: numerically estimating the effects of risks on project objectives 数字估算风险对项目目标的影响</p><ul><li>Main techniques <ul><li>Decision tree analysis 决策树分析  EMV(Expected Monetary Value )</li><li>Simulation 模拟   <strong>Monte Carlo analysis</strong></li><li>Sensitivity analysis 敏感性分析</li></ul></li></ul></li><li><p><strong>Planning risk responses</strong>: taking steps to enhance opportunities and reduce threats to meeting project objectives  采取措施增加机会并减少对实现项目目标的威胁</p><ul><li><p>Negative</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-401c059f77196a16.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="500"><br></center></li><li><p>Positive</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-d40395b0292ca1c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="300"><br></center></li></ul></li><li><p><strong>Implementing risk responses</strong>: implementing the risk response plans  实施风险应对计划</p></li><li><p><strong>Monitoring risk</strong>: monitoring identified and residual risks, identifying new risks, carrying out risk response plans, and evaluating the effectiveness of risk strategies throughout the life of the project 监控已识别和剩余风险，识别新风险，执行风险应对计划，并在项目的整个生命周期内评估风险策略的有效性</p></li></ol><ul><li>Main output of this process is a <code>risk management plan</code></li></ul><h3 id="PROJECT-PROCUREMENT-MANAGEMENT"><a href="#PROJECT-PROCUREMENT-MANAGEMENT" class="headerlink" title="PROJECT PROCUREMENT MANAGEMENT"></a>PROJECT PROCUREMENT MANAGEMENT</h3><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-141f7fc025e82374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><h4 id="Types-of-outsourcing"><a href="#Types-of-outsourcing" class="headerlink" title="Types of outsourcing"></a>Types of outsourcing</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Local outsourcing</span><br><span class="line">- Offshore outsourcing</span><br><span class="line">- Nearshore outsourcing</span><br></pre></td></tr></table></figure><h4 id="Types-of-Contracts"><a href="#Types-of-Contracts" class="headerlink" title="Types of Contracts"></a>Types of Contracts</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 'Fixed price' or lump sum contracts: involve a fixed total price for a well-defined product or service   #卖家不利</span><br><span class="line">- `Point of Total Assumption` (PTA): cost at which the contractor assumes total responsibility for each additional dollar of contract cost</span><br><span class="line">- 'Fixed Price' / Lump Sum / Firm Fixed Price : Risk is on the seller</span><br><span class="line">- Fixed Price with Economic Price Adjustment Contracts ('FP-EPA'): 旨在保护买方和卖方免受其无法控制的外部条件的影响。 如`通货膨胀变化`，或成本增加。</span><br><span class="line">- Fixed Price Incentive Fee ('FPIF') 固定价格激励: 根据卖家表现支付额外奖励，例如更快/更便宜/更好,比如 项目早期每月完成一次，向卖方支付额外的10,000美元</span><br><span class="line">- Fixed Price Award Fee ('FPAF')固定价格奖励: 买方根据业绩支付固定价格和奖励金额（奖金）</span><br><span class="line"></span><br><span class="line">- 'Cost-reimbursable' contracts: involve payment to the seller for direct and indirect costs   #买家不利</span><br><span class="line">- Cost plus incentive fee, cost plus fixed fee, and cost plus percentage of costs</span><br><span class="line">- Cost + Fee (CPF)/ Cost Plus Percentage of Costs ('CPPC') :涉及向卖方支付已完成工作所产生的`所有合法实际费用`，以及费用的百分比。</span><br><span class="line">- Cost Plus Fixed Fee.('CPFF'). 成本加固定费用</span><br><span class="line">- Cost Plus Incentive Fee ('CPIF'). 成本加奖励</span><br><span class="line">- Cost Plus Award Fee ('CPAF'). 成本加奖励费</span><br><span class="line"></span><br><span class="line">- 'Time and material' contracts: hybrid of both fixed price and cost reimbursable contracts  用于在授予合同时`无法确定工作量`的服务工作 例如: 合同=每天1美元加上每线性木材5美元的材料</span><br><span class="line"></span><br><span class="line">- 'Unit price' contracts: require the buyer to pay the seller a predetermined amount per unit of service</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-91e6cc7316e81548.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ContractRisk.png" title="">                </div>                <div class="image-caption">ContractRisk.png</div>            </figure><h3 id="PROJECT-STAKEHOLDER-MANAGEMENT"><a href="#PROJECT-STAKEHOLDER-MANAGEMENT" class="headerlink" title="PROJECT STAKEHOLDER MANAGEMENT"></a>PROJECT STAKEHOLDER MANAGEMENT</h3><h4 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h4><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-f52bfa58c3aa23aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="600"><br></center><ol><li><p><strong>Identifying stakeholders</strong>: identifying everyone involved in the project or affected by it, and determining the best ways to manage relationships with them.</p><ul><li><p>output: <code>stakeholder register</code> includes basic information on stakeholders</p><center><br>    <img src="https://upload-images.jianshu.io/upload_images/5267500-a78cfe957aaaa2b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width=""><br></center><ul><li><p><strong>Identification information</strong>: stakeholders’ names, positions, locations, roles in the project, and contact information</p></li><li><p><strong>Assessment information</strong>: stakeholders’ major requirements and expectations, potential influences, and phases of the project in which stakeholders have the most interest</p></li><li><p><strong>Stakeholder classification</strong>: is the stakeholder internal or external to the organization? Is the stakeholder a supporter of the project or resistant to it?</p></li></ul></li></ul></li><li><p><strong>Planning stakeholder management</strong>: determining strategies to effectively engage stakeholders in project decisions and activities based on their needs, interests, and potential impact.</p><ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Managing stakeholder engagement:</strong> communicating and working with project stakeholders to satisfy their needs and expectations, resolving issues, and fostering engagement in project decisions and activities<ul><li>output: <code>stakeholder engagement plan</code></li></ul></li><li><strong>Monitoring stakeholder engagement</strong>:monitoring stakeholder relationships and adjusting plans and strategies for engaging stakeholders as needed<ul><li>Outputs: <code>work performance information</code>, <code>change requests</code>, <code>project management plan updates</code>, and <code>project documents updates</code>.</li></ul></li></ol><h2 id="Exam"><a href="#Exam" class="headerlink" title="Exam"></a>Exam</h2><h3 id="考后说明"><a href="#考后说明" class="headerlink" title="考后说明"></a>考后说明</h3><ul><li><strong>True or False</strong>： 只要理解<a href="#知识点啊~朋友们">知识点</a>部分的内容，就够了，不必去记忆。考卷的”False”很明显</li><li><strong>Single choice</strong>：刷一遍题库，对题目有印象就行。考试都是原题，选项次序都不变</li><li><strong>Fill in the blanks</strong>：刷一遍题库，考试都是原题</li><li><strong>Writing</strong>：still 背题库，<strong>默写</strong>式答题</li></ul><blockquote><p><strong>Summary：</strong> 此门课程难点还是 前期完成的项目本身  笔试部分则是”记到便是赚到“  (2018.12.10)</p></blockquote><h3 id="知识点啊-朋友们"><a href="#知识点啊-朋友们" class="headerlink" title="知识点啊~朋友们"></a>知识点啊~朋友们</h3><h4 id="项目管理简介"><a href="#项目管理简介" class="headerlink" title="项目管理简介"></a>项目管理简介</h4><p>1.<code>项目</code>与运营不同，因为它们在达到目标或项目终止时<code>结束</code>。<br>2.使用<code>渐进式细化</code>开发项目。项目通常在开始时被广泛定义，随着时间的推移，项目的具体细节变得更加清晰。因此，应该<code>逐步开发</code>项目。</p><p>3.一个项目涉及<code>不确定性</code>。每个项目都是独一无二的，因此有时很难明确定义目标，估计完成所需的时间，或确定需要多少费用。这种不确定性是项目管理如此具有挑战性的主要原因之一。<br>4.管理<code>三重约束</code>涉及在项目的范围，时间和成本目标之间进行权衡。经验丰富的项目经理知道必须决定三重约束的哪个方面最重要。<br>5.<code>利益相关者</code>是参与或受项目活动影响的人，包括项目发起人，项目团队，支持人员，客户，用户，供应商，甚至是项目的反对者。<br>6.<code>项目管理知识领域</code>描述了项目经理必须发展的关键能力。<code>项目采购管理</code>涉及从执行组织外部为项目获取或采购商品和服务。<br>7.<code>项目经理</code>不仅<code>负责</code>项目成果的交付。他们是<code>负责</code>这些项目开发的产品和流程成功的变革推动者。</p><p>8.<code>IT项目经理</code>必须愿意发展不仅仅是他们的<code>技术技能</code>，才能成为富有成效的团队成员和成功的项目经理。每个人，无论他们多么技术，都应该培养<code>商业和软技能</code>。</p><h4 id="项目管理和信息技术背景"><a href="#项目管理和信息技术背景" class="headerlink" title="项目管理和信息技术背景"></a>项目管理和信息技术背景</h4><p>1.使用<code>系统方法</code>对于成功的项目管理至关重要。如果高层管理人员和项目经理要了解项目与整个组织的关系，他们必须<code>遵循</code>系统理念。<br>2.矩阵组织的<code>项目经理</code>有来自<code>各个职能领域的工作人员</code>从事项目工作。<br>3.<code>组织文化</code>非常强大，许多人认为许多公司问题的根本原因不在于组织结构或员工;他们在文化中。<br>4.在围绕团体或团队而不是个人组织工作活动的组织中，项目工作最为成功。强调团队工作的<code>组织文化</code>最适合管理项目。<br>5.在项目生命周期的<code>早期阶段</code>，资源需求通常最低，不确定性水平最高。在<code>后期阶段</code>对项目进行重大改变要昂贵得多。<br>6.由于组织通常会在项目<code>持续时投入更多资金</code>，因此应在每个阶段之后进行<code>管理评审</code>，以评估进度，潜在成功以及与组织目标的持续兼容性。<br>7.<code>虚拟团队</code>是一群使用通信技术在时间和空间边界上一起工作的人。团队成员可能都在同一个国家的同一家公司工作，或者他们可能包括员工以及独立顾问，供应商，甚至志愿者，他们提供来自全球的专业知识。</p><h4 id="项目管理流程组"><a href="#项目管理流程组" class="headerlink" title="项目管理流程组"></a>项目管理流程组</h4><p>1.<code>启动流程</code>包括定义和授权项目或项目阶段。启动过程在项目的<code>每个阶段</code>进行。<br>2.<code>启动和关闭任务通常是最短的</code>（分别在项目或阶段的开始和结束时），并且它们需要最少的资源和时间。<br>3.<code>监控和控制流程</code>与所有其他项目管理流程组<code>重叠</code>，因为可以随时进行更改。<br>4.<code>敏捷</code>是一种适应性产品生命周期，当可交付成果具有<code>高度变化</code>和<code>高交付频率</code>时使用。<br>5.六西格玛项目使用两种主要方法：<code>DMAIC</code>（定义，测量，分析，改进和控制）用于改进现有业务流程，并使用<code>DMADV</code>（定义，测量，分析，设计和验证）创建新产品或流程设计，以实现可预测的，无缺陷的性能。<br>6.<code>启动会议</code>是在项目开始时举行的会议，以便利益相关者可以相互见面，审查项目的目标，并讨论未来的计划。启动会议通常在<code>业务案例和项目章程完成后</code>举行，但可以根据需要提前举行。</p><p>7.<code>WBS</code>是项目管理中非常重要的工具，因为它为决定如何开展工作提供了基础。 WBS还为<code>创建项目进度表</code>和<code>执行挣值管理</code>提供了基础，用于<code>衡量和预测项目绩效</code>。<br>8.因为<code>Scrum</code>暗示团队成员是由ScrumMaster指导的<code>自我导向组</code>，所以<code>团队合同不是必需的</code>。<br>9.燃尽图表(<code>burndown chart</code>)显示了每天冲刺中<code>剩余的累积工作量</code>。<br>10.<code>冲刺审查</code>是团队向产品所有者展示冲刺期间<code>完成的内容</code>的会议。</p><p>11.Scrum框架中<code>监控和控制</code>的两个主要项目是<code>每日Scrum</code>和<code>冲刺审查</code>。<br>12.<code>结账流程</code>包括正式接受项目或项目阶段并有效结束。作为阶段或项目的一部分，<code>管理活动</code>（例如归档项目文件，结束合同，记录经验教训以及接受正式接受交付的工作）通常涉及此流程组。</p><h4 id="项目集成管理"><a href="#项目集成管理" class="headerlink" title="项目集成管理"></a>项目集成管理</h4><p>1.<code>界面管理</code>涉及识别和管理项目各个元素之间的<code>交互点</code>。<br>2.<code>项目集成管理包括界面管理</code>，涉及识别和管理项目各个元素之间的交互点。随着项目涉及的人数增加，<code>接口数量可能呈指数级增长</code>。<br>3.有些人喜欢使用<code>思维导图</code>进行SWOT分析，这种技术使用从核心思想辐射出来的分支来构建思想和想法。<br>4.许多信息系统被归类为<code>“战略性”</code>，因为它们直接支持<code>关键业务战略</code>。例如，信息系统可以帮助组织支持作为低成本生产者的战略。<br>5.随着项目的进展，组织必须<code>重新评估</code>每个项目的需求，资金和意愿，以确定是否应该继续，重新定义或终止项目。<br>6.由于要求和期望不明确，许多项目都失败了，所以从<code>项目章程</code>开始就很有意义。<br>7.<code>项目管理计划</code>不仅仅是甘特图。</p><h4 id="项目范围管理"><a href="#项目范围管理" class="headerlink" title="项目范围管理"></a><a href="#第5章 - 项目范围管理">项目范围管理</a></h4><p>1.<code>范围基准</code>包括已批准的项目范围声明及其关联的WBS和WBS字典。</p><p>2.<code>WBS的主要目的</code>是定义完成项目所需的所有工作。<br>3.<code>工作包</code>是WBS最低级别的任务。它表示项目经理监视和控制的工作级别。<br>4.创建一个好的WBS非常<code>困难</code>。为此，您必须了解项目及其范围，并纳入利益相关方的需求和知识。<br>5.执行任务executing task在项目之间<code>变化最大</code>，但其他项目管理过程组下的许多任务对于所有项目都是类似的。<br>6.创建一个好的WBS及其WBS字典的基本原则是，<code>一个工作单元应该只出现在WBS中的一个地方</code>。<br>7.即使项目范围相当明确，许多IT项目仍然存在<code>范围蔓延</code> - 项目范围越来越大的趋势。许多IT项目因范围蔓延而失败。</p><h4 id="项目进度管理"><a href="#项目进度管理" class="headerlink" title="项目进度管理"></a><a href="#第6章 - 项目进度管理">项目进度管理</a></h4><p>1.<code>活动或任务</code>是通常在工作分解结构（WBS）上找到的工作要素，其具有预期的持续时间，成本和资源要求。<br>2.在项目进度管理中，定义活动的<code>主要输出</code>是活动列表，活动属性，里程碑列表和项目管理计划更新。<br>3.<code>项目进度表</code>从发起项目的基本文件中发展而来。<code>项目章程</code>经常提到计划的项目开始和结束日期，作为更详细的计划的起点。<br>4.<code>时间表管理计划</code>包括有关报告格式的信息。此信息描述了项目所需的计划报告的格式和频率。此外，它还包括有关流程描述的信息，并描述了如何执行所有计划管理流程。<br>5.项目的<code>里程碑</code>是一个重要事件，通常<code>没有持续时间</code>。通常需要多次活动和大量工作来完成里程碑，但里程碑本身就像是帮助识别必要活动的<code>标记</code>。<br>6.<code>依赖关系</code>或关系涉及项目活动或任务的<code>顺序</code>。确定活动之间的这些关系或依赖关系对于开发和管理项目进度表具有重大影响。<br>7.<code>网络图</code>是显示<code>活动排序</code>的首选技术。网络图是项目活动及其排序之间逻辑关系的示意图。<br>8.网络图是项目活动及其排序之间逻辑关系的示意图。网络图中的箭头表示活动顺序或任务之间的关系。<br>9.当两个或多个节点在单个节点之前时发生<code>合并</code>。另一方面，当两个或多个活动跟随单个节点时发生<code>突发</code>。<br>10.<code>甘特图</code>提供了一种标准格式，用于通过以日历形式列出项目活动及其相应的开始和结束日期来显示项目进度信息。在甘特图中，黑色菱形符号代表了一个里程碑<br>11.<code>跟踪甘特图</code>基于项目任务完成的工作百分比或实际开始和结束日期。它允许项目经理<code>监控</code>各个任务和整个项目的进度。<br>12.在<code>关键路径分析</code>中，几个任务在项目上并行完成，大多数项目通过网络图有多条路径。包含关键任务的最长路径或路径是驱动项目完成日期的原因。<br>13.<code>crashing</code>的主要优点是缩短了完成项目所需的时间。主要缺点是它通常会增加项目总成本。<br>14.<code>关键链调度</code>是一种在创建项目计划时考虑有限资源的方法，并包含用于保护项目完成日期的<code>缓冲区</code>。它假设资源不是多任务或至少最小化多任务处理。</p><h4 id="项目成本管理"><a href="#项目成本管理" class="headerlink" title="项目成本管理"></a><a href="#第7章 - 项目成本管理">项目成本管理</a></h4><p>1.<code>超支</code>是实际成本超过估计值的额外百分比或金额。<br>2.<code>现金流量分析</code>是确定项目的估计年度成本和收益以及由此产生的年度现金流量的一种方法。项目经理必须进行现金流量分析以<code>确定净现值</code>。<br>3.<code>沉没成本</code>是过去花费的钱。在决定投资或继续投资哪些项目时，不应包括沉没成本。<br>4.<code>管理储备</code>允许未来<code>不可预测</code>的情况。例如，如果项目经理生病了两周或者一个重要的供应商停业，可以留出管理储备来支付由此产生的费用。<br>5.<code>估算</code>通常在项目的<code>不同阶段进行</code>，随着时间的推移应该变得更加准确。<br>6.<code>类似的估计</code>需要大量的专家判断，并且通常比其他技术成本更低。但是，它也不太准确。<br>7.项目<code>成本估算不准确</code>的原因之一是<code>人类偏向于低估</code>。因此，项目经理和高层管理人员必须审核估算并提出重要问题，以确保估算不会有偏差<br>8.方差和指数的公式以<code>EV</code>（赢得值）开头。通过从EV中减去实际成本或计划值来计算差异，并且通过将EV除以实际成本或计划值来计算指数。<br>9.如果<code>CPI</code>小于1或小于100％，则该项目超出预算。另一方面，如果CPI大于1％或超过100％，则项目预算可控。</p><h4 id="项目质量管理"><a href="#项目质量管理" class="headerlink" title="项目质量管理"></a><a href="#第8章 - 项目质量管理">项目质量管理</a></h4><p>1.<code>实验设计</code>是一种有助于确定哪些变量对过程总体结果影响最大的技术。您还可以将实验设计应用于<code>项目管理问题</code>，例如成本和进度权衡。<br>2.<code>可靠性</code>是指产品或服务在正常条件下按<strong>预期</strong>运行的能力。<br>3.所有项目利益相关方必须<strong>共同努力</strong>，以<code>平衡项目</code>的质量，范围，时间和成本方面。但是，<code>项目经理最终负责</code>其项目的质量管理。<br>4.<code>接受决定确定</code>作为项目一部分生产的产品或服务是否将被接受或拒绝。如果他们被接受，他们被认为是<strong>经过验证的可交付成果</strong>。<br>5.<code>运行图表</code>显示过程随时间变化的<strong>历史和模式</strong>。它是一个折线图，显示按发生顺序绘制的数据点。<br>6.<code>测试</code>需要在系统开发生命周期的几乎<code>每个阶段进行</code>，而不仅仅是在组织发布或将产品交给客户之前。<br>7.在全面质量控制中，产品质量比生产率更重要，工人可以在<code>出现质量问题时停止生产</code>。<br>8.符合要求意味着项目的流程和产品<code>符合书面规范</code>。例如，如果项目范围声明要求交付100台具有特定处理器和内存的计算机，则可以轻松检查是否已交付合适的计算机。</p><h4 id="项目人力资源管理"><a href="#项目人力资源管理" class="headerlink" title="项目人力资源管理"></a><a href="#第9章 - 项目资源管理">项目人力资源管理</a></h4><p>1.<code>马斯洛的需求层次</code>表明人们的行为受到一系列需求的<code>指导或激励</code>。<br>2.根据赫兹伯格的说法，<code>激励者</code>，如更高的工资，更多的监督，或更有吸引力的工作环境，将激励工人做更多的工作。他提到导致工作满意度的因素作为激励因素和可能导致不满意的因素作为卫生因素。<br>3.需要制度权力或社会<code>权力的人</code>希望组织其他人来推进组织的目标。<br>4.相信<code>X理论</code>的人认为工人在可能的情况下不喜欢和避免工作，因此管理者必须使用<strong>强制，威胁和各种控制方案</strong>让工人做出足够的努力来实现目标。他们认为普通工人希望被指导并且更愿意避免责任，没有什么野心，并且希望安全高于一切。</p><p>5.Thamhain和Wilemon发现，当项目经理过于依赖权力，金钱或惩罚来影响人们时，项目更有可能失败。当项目经理使用<code>工作挑战和专业知识来影响人们</code>时，项目更有可能成功。<br>6.<code>合法的权力</code>使人们根据权威的地位做事。这种权力类似于权威的影响基础。<br>7.如OBS中所述，责任分配矩阵（<code>RAM</code>）将WBS中描述的项目工作映射到负责执行工作的人员。<br>8.<code>资源调配</code>可以减少项目人员和会计部门的问题。劳动力水平和人力资源的增加和减少往往会产生<code>额外的工作和混乱</code>。<br>9.<code>平滑模式</code>是项目经理强调或避免差异领域并强调协议领域的模式。这种方法也称为适应性，当关系具有高度重要性且任务不重要时，最好使用这种方法。</p><h4 id="项目沟通管理"><a href="#项目沟通管理" class="headerlink" title="项目沟通管理"></a><a href="#第10章 - 项目沟通管理">项目沟通管理</a></h4><p>1.举行会议的准则之一是确定是否可以<code>避免会议</code>。如果有更好的方法来实现手头的目标，就不要开会。<br>2.项目经理经常将所有<code>经验教训</code>报告中的信息合并到项目总结报告中。<br>3.提高组织的沟通能力需要组织中的<code>文化变革</code>，这需要花费大量时间，努力工作和耐心。<br>4.要使项目取得成功，每个项目团队成员都需要这<code>两种技能</code>，并需要通过正规教育和在职培训不断开发这些技能。<br>5.<code>地理位置和文化背景影响项目沟通的复杂性</code>。如果项目利益相关者在不同的国家，通常很难或不可能在正常工作时间内安排双向沟通的时间。<br>6.<strong>项目沟通管理</strong>涉及包含影响项目中开发的产品或服务的关键性能特征的<code>详细技术信息</code>。记录可能影响产品性能的<code>技术规范</code>的任何<strong>变更</strong>甚至更为重要。<br>7.沟通的一个重要方面是<code>参与项目的人数</code>。随着数量的增加，通信的复杂性也会增加，因为人们可以通过更多的渠道或途径进行交流。随着团队规模的增加，沟通变得更加复杂。</p><h4 id="项目风险管理"><a href="#项目风险管理" class="headerlink" title="项目风险管理"></a><a href="第11章 - 项目风险管理">项目风险管理</a></h4><p>1.项目风险管理<code>涉及</code>了解项目可能出现的潜在问题以及它们如何阻碍项目成功。但是，也有积极的风险或机会，可以为项目带来良好的结果。<br>2.<code>寻求风险的人</code>更喜欢更不确定的结果，并且通常愿意支付惩罚来承担风险。<br>3.项目风险管理的第一步是通过<code>执行风险管理计划</code>来决定如何处理特定项目的知识领域。<br>4.<code>应急计划</code>是预定义的行动，如果发生已识别的风险事件，项目团队将采取这些行动。<br>5.<code>头脑风暴</code>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<code>德尔菲技术</code>是一种基于对未来事件的独立和匿名输入的系统化交互式预测程序。<br>6.项目经理可以绘制风险对<code>概率/影响矩阵或图表</code>的概率和影响，其中列出了风险发生的相对概率和风险发生的相对影响。<br>7.<code>十大风险项目跟踪</code>是一种定性风险分析工具。<br>8.已识别的风险可能<code>无法实现</code>，或者其发生或丧失的可能性可能会<code>减少</code>。</p><h4 id="项目采购管理"><a href="#项目采购管理" class="headerlink" title="项目采购管理"></a><a href="#第12章-项目采购管理">项目采购管理</a></h4><p>1.提供采购服务的组织或个人称为<code>供应商</code>。供应商也称为供应商，承包商，分包商或销售商。<br>2.在外包时，组织应谨慎保护可能在供应商手中易受攻击的<code>战略信息</code>。<br>3.计划采购涉及通过使用组织外部的产品或服务来确定最佳地满足哪些项目需求。如果不需要从组织外部购买产品或服务，则<code>不需要进一步的采购管理</code>。<br>4.成本可偿还合同通常包括费用，例如利润百分比或达到或超过选定项目目标的激励。与固定价格合同相比，买方通过<code>成本可偿还合同</code>承担更多风险。<br>5.<code>固定价格（FFP）</code>合约对买方的风险最小，其次是<code>固定价格激励费（FPIF）</code>合约。<br>6.制造或购买分析涉及估算提供产品或服务的内部成本，并将估算与外包成本进行<code>比较</code>。<br>7.如果公司使用设备20天，他们最好<code>租赁</code>，总费用为10,000美元（20 x 500美元）。 10,000美元的购买成本将增加2,000美元的运营成本（20 x 100美元）。<br>8.评估投标的关键因素，特别是涉及IT的项目，是投标人<code>过去的业绩记录</code>。检查性能记录和参考可以<code>降低</code>选择跟踪记录不佳的供应商的<code>风险</code>。<br>9.控制采购可确保卖方的<code>业绩符合合同要求</code>。合同关系是一种法律关系，这意味着它受州和联邦合同法的约束。</p><h4 id="项目利益相关者管理"><a href="#项目利益相关者管理" class="headerlink" title="项目利益相关者管理"></a>项目利益相关者管理</h4><p>1.与通信和人力资源管理相关的许多概念也<code>适用</code>于利益相关者管理，但需要开展<code>独特的活动</code>以实现良好的利益相关者管理。<br>2.<code>识别</code>利益相关者涉及识别参与项目或受其影响的每个人，并确定<code>管理</code>与他们之间关系的最佳方式。该过程的主要输出是<code>利益相关者登记</code>。<br>3.内部项目利益相关者通常<code>包括</code>项目发起人，项目团队，支持人员和项目的内部客户。其他内部利益相关者包括高层管理人员，其他职能经理和其他项目经理，因为组织资源有限。<br>4.由于员工流动，合作伙伴关系和其他事件，利益相关者可能在项目期间发生<code>变化</code>。<br>5.领先的利益相关者是了解项目及其潜在影响并积极参与<code>帮助项目成功</code>的人<br>6.项目经理必须了解并与各利益相关方合作;因此，他们应该专门讨论如何使用各种沟通方法及其人际关系和管理技能来<code>吸引利益相关者</code>。<br>7.您无法控制利益相关者，但您可以<code>监控干系人的参与程度</code>。参与涉及对话，人们寻求理解和解决共同关心的问题。<br>8.应邀请主要利益攸关方积极<code>参加启动会议</code>，而不仅仅是参加会议。项目经理应该强调，会议<code>期望进行对话</code>，包括利益相关者喜欢的文本或任何沟通方式。</p><h3 id="填空题"><a href="#填空题" class="headerlink" title="填空题"></a>填空题</h3><h4 id="第4章-项目集成管理"><a href="#第4章-项目集成管理" class="headerlink" title="第4章 - 项目集成管理"></a>第4章 - 项目集成管理</h4><ol><li>____涉及通过分析优势和劣势，研究机会和威胁，预测未来趋势以及预测新产品和服务的需求来确定长期目标。<br>答案：战略规划</li><li>____涉及分析公司的优势，劣势，机会和威胁，并用于协助战略规划。<br>答案：SWOT分析</li><li>____是一种技术，它使用从核心思想辐射出来的分支来构建思想和想法。<br>答案：思维导图</li><li>____指的是改善组织的机会。<br>答案：机遇</li><li>____是从效益中减去项目成本然后除以成本的结果。<br>答案：投资回报率（ROI）</li><li>____是一种工具，它提供了一个基于许多标准选择项目的系统过程。<br>答案：加权评分模型</li><li>____是记录的起点，测量或观察，以便可以用于将来的比较。变化。<br>答案：基线</li><li>____涉及在整个项目生命周期中识别，评估和管理变更。<br>答案：综合变更控制</li></ol><h4 id="第5章-项目范围管理"><a href="#第5章-项目范围管理" class="headerlink" title="第5章 - 项目范围管理"></a>第5章 - 项目范围管理</h4><ol><li>____创建涉及将主要项目可交付成果细分为更小，更易于管理的组件。<br>答案：工作分解结构（WBS）</li><li>____是指“项目必须满足的条件或能力，或者在产品，服务或结果中出现以满足协议或其他正式规定的条件或能力。”<br>答案：要求</li><li>____包括已批准的项目范围声明及其关联的WBS和WBS字典。<br>答案：范围基线</li><li>工作包是WBS的____级任务。<br>答案：最低</li><li>____在创建WBS的方法中，团队成员首先确定尽可能多的与项目相关的特定任务。<br>答案：自下而上</li><li>____是一种技术，它使用从核心思想中散发出来的分支来构建创建WBS时的思想和想法。<br>答案：思维导图</li><li>____是项目范围越来越大的趋势。<br>答案：范围蔓延</li><li>____执行范围验证的主要工具是和小组决策制定技术。<br>答案：检查</li><li>____涉及开发系统的工作副本或系统的某些方面。<br>答案：原型设计</li></ol><h4 id="第6章-项目进度管理"><a href="#第6章-项目进度管理" class="headerlink" title="第6章 - 项目进度管理"></a>第6章 - 项目进度管理</h4><ol><li>____是完成任务所需的工作日或工作小时数。<br>答案：努力</li><li>在项目进度表中，灵活性最小的变量是____。<br>答案：时间</li><li>____涉及确保及时完成项目所需的过程。<br>答案：项目进度管理</li><li>____是要列入项目进度表的活动的表格。<br>答案：活动清单</li><li>____是项目活动及其排序之间逻辑关系的示意图。<br>答案：网络图</li><li>在____关系中，“from”活动必须在“to”活动完成之前开始。<br>答案：从头到尾</li><li>____没有持续时间和资源，但偶尔需要在AOA网络图上显示活动之间的逻辑关系。<br>答案：虚拟活动</li></ol><h4 id="第7章-项目成本管理"><a href="#第7章-项目成本管理" class="headerlink" title="第7章 - 项目成本管理"></a>第7章 - 项目成本管理</h4><ol><li>____过程的主要成果是活动成本估算，估算基础和项目文件更新。<br>答案：成本估算</li><li>____流程的主要成果是成本绩效基准，项目资金要求和项目文件更新。<br>答案：成本预算</li><li>____理论指出，当重复生产许多物品时，随着生产更多单位，这些物品的单位成本会以规律的方式减少。<br>答案：学习曲线</li><li>____估算是在项目的早期阶段或甚至在项目正式启动之前完成的。<br>答案：粗略的数量级（ROM）</li><li>____是项目经理用来衡量和监控成本绩效的分阶段预算。<br>答案：成本基准</li></ol><h4 id="第8章-项目质量管理"><a href="#第8章-项目质量管理" class="headerlink" title="第8章 - 项目质量管理"></a>第8章 - 项目质量管理</h4><ol><li>____这个词意味着产品可以按照预期使用。<br>答案：适合使用</li><li>____是一种质量计划技术，有助于确定哪些变量对过程的总体结果影响最大。<br>答案：实验设计</li><li>____图表将有关质量问题的投诉追溯到负责任的生产操作。<br>答案：因果关系<br>鱼刺<br>石川</li><li>Watts S. Humphrey将____定义为在交付程序之前必须更改的任何内容。<br>答案：软件缺陷</li><li>____是一个公司部门的非监督人员和工作领导小组，他们自愿组织如何提高部门工作效率的小组研究。<br>答案：质量圈子</li><li>____意味着对失败负责或不满足质量期望。<br>答案：不合格的成本</li><li>Genichi Taguchi的____方法着重于通过用科学探究替代试错法来消除缺陷。<br>答案：稳健的设计</li></ol><h4 id="第9章-项目资源管理"><a href="#第9章-项目资源管理" class="headerlink" title="第9章 - 项目资源管理"></a>第9章 - 项目资源管理</h4><ol><li>根据马斯洛的说法，只有满足____需求后，个人才能满足增长需求。<br>答案：缺陷</li><li>赫茨伯格称之为导致工作满意度的因素____。<br>答案：激励者</li><li>____是整体等于其各部分之和的概念。<br>答案：协同作用</li><li>____正在倾听，意图理解。<br>答案：移情倾听</li><li>____是和谐，一致，一致或亲和的关系，对沟通很重要。<br>答案：交流</li><li>____根据所需的详细程度将工作分配给负责任和执行的组织，团队或个人。<br>答案：责任分配矩阵（RAM）</li><li>____是一种特定类型的组织结构图，显示哪些组织单位负责哪些工作项。<br>答案：OBS（组织分解结构）</li></ol><h4 id="第10章-项目沟通管理"><a href="#第10章-项目沟通管理" class="headerlink" title="第10章 - 项目沟通管理"></a>第10章 - 项目沟通管理</h4><ol><li><p>许多信息技术专业人员在<strong>_</strong>项目中工作，他们从未与项目赞助商，其他团队成员或其他项目利益相关者会面。<br>答案：虚拟</p></li><li><p>____分析包括信息的联系人，信息到期时以及信息的首选格式等信息。<br>答案：利益相关方沟通</p></li><li>在试图评估项目利益相关者的承诺时，<strong>_</strong>会议或网络会议可能是最合适的媒介。<br>答案：面对面</li><li>控制通信的主要目标是确保整个____的最佳信息流。<br>答案：项目生命周期</li><li>所有会议必须有____和预期结果。<br>答案：目的</li><li>____强制会议组织者计划会议，并让潜在参与者有机会决定是否需要参加。<br>答案：议程</li></ol><h4 id="第11章-项目风险管理"><a href="#第11章-项目风险管理" class="headerlink" title="第11章 - 项目风险管理"></a>第11章 - 项目风险管理</h4><ol><li>项目<strong>_</strong>是一种不确定性，可能对实现项目目标产生负面或正面影响。<br>答案：风险</li><li>是从潜在收益中获得的满足或愉悦的数量。<br>答案：风险效用</li><li>是项目潜在风险类别的等级。<br>答案：风险分解结构</li><li>是一种技术，通过这种技术，一个小组试图通过自发地和没有判断地积累思想来产生想法或找到特定问题的解决方案。<br>答案：头脑风暴</li><li>是包含各种风险管理流程结果的文件。<br>答案：风险登记</li><li>是风险事件概率和风险事件货币价值的乘积。<br>答案：EMV<br>预期的货币价值<br>预期货币价值（EMV）<br>EMV（预期货币价值）</li><li>风险是在实施所有应对策略后仍然存在的风险。<br>答案：剩余</li></ol><h4 id="第12章-项目采购管理"><a href="#第12章-项目采购管理" class="headerlink" title="第12章-项目采购管理"></a>第12章-项目采购管理</h4><ol><li>____是指从外部来源获取商品和/或服务的过程。<br>答案：采购</li><li>____是一项具有相互约束力的协议，规定卖方有义务提供指定的产品或服务，并规定买方有义务支付这些产品或服务。<br>答案：合同</li><li>____决定是指组织决定在组织内部制造某些产品或执行某些服务是否符合其最佳利益，或者是否最好从外部组织购买。<br>答案：制造或购买</li><li>____合同包括由于通货膨胀等条件的变化而对合同价格进行预定义的最终调整的特殊规定。<br>答案：固定价格与经济价格调整（FP-EPA），固定价格与经济，价格调整，FP-EPA</li><li>____合同是固定价格和成本可偿还合同的混合体。<br>答案：时间和材料（T＆M），时间和材料，T＆M</li><li>____是允许买方或供应商终止合同的合同条款。<br>答案：终止条款</li><li>____是卖方在满足买方需求时采用不同方法编制的文件。<br>答案：提案</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GooLeNet</title>
    <link href="http://yoursite.com/2018/12/07/GooLeNet/"/>
    <id>http://yoursite.com/2018/12/07/GooLeNet/</id>
    <published>2018-12-07T02:44:09.000Z</published>
    <updated>2018-12-11T12:40:45.132Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】未完待续</p><a id="more"></a><p>参考链接：<a href="https://blog.csdn.net/shuzfan/article/details/50738394#googlenet-inception-v2" target="_blank" rel="noopener">GoogLeNet系列解读</a>、<a href="https://blog.csdn.net/qq_31531635/article/details/72232651" target="_blank" rel="noopener">深度学习之GoogLeNet解读</a>、<a href="https://www.jianshu.com/p/33197e469414" target="_blank" rel="noopener">GoogLeNet的心路历程</a></p><p>ToRead：<a href="https://blog.csdn.net/docrazy5351/article/details/78993269" target="_blank" rel="noopener">深入理解GoogLeNet结构</a></p><h2 id="GoogLeNet-Incepetion-V1"><a href="#GoogLeNet-Incepetion-V1" class="headerlink" title="GoogLeNet Incepetion V1"></a>GoogLeNet Incepetion <a href="https://www.jianshu.com/p/a2ad00eddbd5" target="_blank" rel="noopener">V1</a></h2><p>GoogLeNet, 一个22层的深度网络，2014年ILSVRC挑战赛冠军，将Top5 的错误率降低到6.67%。这是一种 类似于 <strong>网中网（Network In Network）</strong>的结构，即原来的结点也是一个网络。</p><p>这是GoogLeNet的最早版本，出现在2014年的《<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Going deeper with convolutions</a>》。之所以名为“GoogLeNet”而非“GoogleNet”,文章说是为了向早期的LeNet致敬。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>深度学习以及神经网络快速发展，人们不再只关注更给力的硬件、更大的数据集、更大的模型，而是更在意新的idea、新的算法以及模型的改进。</p><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生<strong>过拟合</strong>也会大大<strong>增加计算量</strong>。</p><p>文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献1表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。<strong>这点表明臃肿的稀疏网络可能被不失性能地简化。</strong> 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。</p><p>早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了<code>随机稀疏连接</code>。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。</p><p>所以，现在的问题是有没有一种方法，<strong>既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能</strong>。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。</p><h3 id="Architectural-Details"><a href="#Architectural-Details" class="headerlink" title="Architectural Details"></a>Architectural Details</h3><p>Inception 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。<br>作者首先提出下图这样的基本结构： </p><center><br>    <img src="/2018/12/07/GooLeNet/V1_Figure2(a).jpg" style="zoom:60%"><br></center><p>对上图做以下说明：<br>1 . 采用不同大小的卷积核意味着不同大小的感受野，最后拼接<code>意味着不同尺度特征的融合</code>；<br>2 . 之所以卷积核大小采用1、3和5，主要是<code>为了方便对齐</code>。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以<code>直接拼接</code>在一起了；<br>3 . 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。<br>4 . 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p><p><strong>但是，使用5x5的卷积核仍然会带来巨大的计算量</strong>。 为此，文章借鉴NIN，采用<code>1x1卷积核来进行降维</code>。<br>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。<a href="https://blog.csdn.net/capecape/article/details/78296796#4维度计算" target="_blank" rel="noopener">详细的降维计算过程</a></p><p>具体改进后的Inception Module如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure2(b).jpg" style="zoom:60%"><br></center><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p>GoogLeNet的整体结构如下图：</p><center><br><img src="/2018/12/07/GooLeNet/GooLeNet.jpg" style="zoom:60%"><br></center><p>对上图做如下说明：<br>1 . 显然GoogLeNet采用了模块化的结构，方便增添和修改；<br>2 . 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；<br>3 . 虽然移除了全连接，但是网络中依然使用了Dropout ;<br>4 . 为了<code>避免梯度消失</code>，网络额外增加了2个辅助的softmax（average pooling）用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</p><p>下图是一个比较清晰的结构图：</p><center><br><img src="/2018/12/07/GooLeNet/V1_Figure3.jpg" style="zoom:60%"><br></center><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>GoogLeNet是谷歌团队为了参加ILSVRC 2014比赛而精心准备的，为了达到最佳的性能，除了使用上述的网络结构外，还做了大量的辅助工作：包括训练多个model求平均、裁剪不同尺度的图像做多次验证等等。详细的这些可以参看文章的实验部分。</p><p>本文的主要想法其实是想通过<code>构建密集的块结构来近似最优的稀疏结构</code>，从而达到<code>提高性能而又不大量增加计算量</code>的目的。GoogleNet的caffemodel大小约50M，但性能却很优异。</p><h2 id="GoogLeNet-Inception-V2"><a href="#GoogLeNet-Inception-V2" class="headerlink" title="GoogLeNet Inception V2"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/4270f5acc066" target="_blank" rel="noopener">V2</a></h2><ul><li><a href="https://link.jianshu.com?t=http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>，top5 error 4.8%</li></ul><p>这篇文章做出的贡献不是一般的大，它提出了Batch Normalization（BN），以至于网上关于它的介绍铺天盖地，但中文优秀原创没几个，都是转载来转载去，挑几个好的比如：<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/u012816943/article/details/51691868" target="_blank" rel="noopener"><strong>这个</strong></a>、<a href="https://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="noopener"><strong>这个</strong></a>。</p><h2 id="GoogLeNet-Inception-v3"><a href="#GoogLeNet-Inception-v3" class="headerlink" title="GoogLeNet Inception v3"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/0cc42b8e6d25" target="_blank" rel="noopener">v3</a></h2><p>GoogLeNet凭借其优秀的表现，得到了很多研究人员的学习和使用，因此Google团队又对其进行了进一步发掘改进，产生了升级版本的GoogLeNet。这一节介绍的版本记为V2，文章为：《<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a>》。</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>14年以来，构建更深的网络逐渐成为主流，但是模型的变大也使计算效率越来越低。这里，文章试图找到一种方法在<strong>扩大网络的同时又尽可能地发挥计算性能</strong>。</p><p>首先，GoogLeNet V1出现的同期，性能与之接近的大概只有VGGNet了，并且二者在图像分类之外的很多领域都得到了成功的应用。但是相比之下，GoogLeNet的计算效率明显高于VGGNet，大约只有500万参数，只相当于Alexnet的1/12(GoogLeNet的caffemodel大约50M，VGGNet的caffemodel则要超过600M)。</p><p>GoogLeNet的表现很好，但是，如果想要通过简单地放大Inception结构来构建更大的网络，则会立即提高计算消耗。此外，在V1版本中，文章也没给出有关构建Inception结构注意事项的清晰描述。因此，在文章中作者<strong>首先给出了一些已经被证明有效的用于放大网络的通用准则和优化方法</strong>。这些准则和方法适用但不局限于Inception结构。</p><h3 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h3><p>下面的准则来源于大量的实验，因此包含一定的推测，但实际证明基本都是有效的。</p><p><strong>1 . 避免表达瓶颈，特别是在网络靠前的地方</strong>。 信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。<br>另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）</p><p><strong>2 . 高维特征更易处理</strong>。 高维特征更易区分，会加快训练。</p><p><strong>3. 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息</strong>。 比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。</p><p><strong>4 . 平衡网络的宽度与深度</strong>。</p><p>上述的这些并不能直接用来提高网络质量，而<code>仅用来在大环境下作指导</code>。</p><h3 id="Factorizing-Convolutions-with-Large-Filter-Size"><a href="#Factorizing-Convolutions-with-Large-Filter-Size" class="headerlink" title="Factorizing Convolutions with Large Filter Size"></a>Factorizing Convolutions with Large Filter Size</h3><p>大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。为此，作者提出可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量)如下图： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure1.jpg" style="zoom:80%"><br></center><p>然后就会有2个疑问：</p><p><strong>1 . 这种替代会造成表达能力的下降吗？</strong><br>后面有大量实验可以表明<code>不会造成表达缺失</code>；</p><p><strong>2 . 3x3卷积之后还要再加激活吗？ </strong><br>作者也做了对比试验，表明添加非线性激活会提高性能。</p><p>从上面来看，大卷积核完全可以由一系列的3x3卷积核来替代，那能不能分解的更小一点呢。文章考虑了 <strong>nx1</strong> 卷积核。<br>如下图所示的取代3x3卷积： </p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure3.jpg" style="zoom:80%"><br></center><p>于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，作者发现<strong>在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好</strong>。（对于mxm大小的feature map,建议m在12到20之间）。</p><p>总结如下图：</p><center><br><img src="/2018/12/07/GooLeNet/V2_Figure4_5_6.jpg" style="zoom:80%"><br></center><p><strong>(1)</strong> 图4是GoogLeNet V1中使用的Inception结构；</p><p><strong>(2)</strong> 图5是用3x3卷积序列来代替大卷积核；</p><p><strong>(3)</strong> 图6是用nx1卷积来代替大卷积核，这里设定n=7来应对17x17大小的feature map。该结构被正式用在GoogLeNet V2中。</p><h2 id="GoogLeNet-Inception-v4"><a href="#GoogLeNet-Inception-v4" class="headerlink" title="GoogLeNet Inception v4"></a>GoogLeNet Inception <a href="https://www.jianshu.com/p/e0464e8d6db4" target="_blank" rel="noopener">v4</a></h2><ul><li><a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1602.07261" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>，top5 error 3.08%</li></ul><p>Szegedy读了此<a href="https://link.jianshu.com/?t=http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener"><strong>论文</strong></a>后，蹦出了结合GoogLeNet与Residual Connections的奇思妙想，于是就有了上面那篇论文，主要贡献如下：</p><ul><li>1、在Inception v3的基础上发明了Inception v4，v4比v3更加复杂，复杂到不可思议</li><li>2、结合ResNet与GoogLeNet，发明了Inception-ResNet-v1、Inception-ResNet-v2，其中Inception-ResNet-v2效果非常好，但相比ResNet，Inception-ResNet-v2的复杂度非常惊人，跟Inception v4差不多</li><li>3、加入了Residual Connections以后，网络的训练速度加快了</li><li>4、在网络复杂度相近的情况下，Inception-ResNet-v2略优于Inception-v4</li><li>5、Residual Connections貌似只能加速网络收敛，真正提高网络精度的是“<strong>更大的网络规模</strong>”</li></ul><p>以上就是Inception v4论文的主要贡献了，没有什么创新，只是在前人的基础上修修补补、移花接木，但这篇文章工作量不小，需要花费大量时间训练作者提出的3种网络。</p><blockquote><p>至此，GoogLeNet四篇相关论文就介绍完了，纵观GoogLeNet的发展历程，Szegedy为我们提供了许多可以借鉴的网络设计方法，比如Inception结构、非对称卷积、Batch Normalization、取消全连层……等等。就连Szegedy本人，也汲取了ResNet的精髓，合体两种网络设计出了Inception-ResNet。所以多读论文，多学习别人的idea，是非常重要的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】未完待续&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://yoursite.com/categories/DeepLearning/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>DenseNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/03/DenseNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/03/DenseNet-Introduction/</id>
    <published>2018-12-03T08:39:14.000Z</published>
    <updated>2018-12-03T15:26:59.184Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>原文链接：<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">Densely Connected Convolutional Netwroks</a></p><p>译文链接：<a href="https://zhuanlan.zhihu.com/p/31647627" target="_blank" rel="noopener">DenseNet论文翻译及pytorch实现解析（上）</a>、<a href="https://blog.csdn.net/tumi678/article/details/78667966" target="_blank" rel="noopener">Densely Connected Convolutional Networks翻译</a></p><p>参考链接：<a href="https://blog.csdn.net/u014380165/article/details/75142664" target="_blank" rel="noopener">DenseNet算法详解(ToRead  评价最高)</a>、<a href="https://zhuanlan.zhihu.com/p/28190802" target="_blank" rel="noopener">《Densely Connected Convolutional Networks》论文笔记（精而简）</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络（简明）</a>、<a href="https://www.leiphone.com/news/201708/0MNOwwfvWiAu43WO.html" target="_blank" rel="noopener">DenseNet 的“what”、“why”和“how”(思路清晰)</a>、<a href="https://zhuanlan.zhihu.com/p/43057737" target="_blank" rel="noopener">DenseNet详解(图解清晰)</a></p><p>ToRead：<a href="https://blog.csdn.net/Bryan__/article/details/77337109" target="_blank" rel="noopener">DenseNet 简介(数学说明)</a>、<a href="https://zhuanlan.zhihu.com/p/37189203" target="_blank" rel="noopener">DenseNet：比ResNet更优的CNN模型(形象细致)</a></p><p><strong>DenseNet的优点</strong>：</p><ul><li>减轻梯度消失的问题；</li><li>加强了特征的<code>传导</code>和<code>利用</code>；</li><li>减少了参数量（与ResNet相比，在实现同等准确率的条件下，DenseNet的参数量要小于ResNet）</li><li>减少了计算量</li></ul><h4 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h4><h5 id="Dense-block"><a href="#Dense-block" class="headerlink" title="Dense block"></a><strong>Dense block</strong></h5><p>​    网络的每一层都直接与其前面层相连（可以直接将梯度从后层传向前层），实现<code>特征的重复利用</code>，这就使得网络更加“参数高效”。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure1.jpg" style="zoom:80%"><br></center><h5 id="Transition-layer"><a href="#Transition-layer" class="headerlink" title="Transition layer"></a><strong>Transition layer</strong></h5><p>​    该层位于两个dense block之间，由conv层和pooling层组成。之前说过，在一个dense block里，空间维度是保持不变的，为了能进行下采样，故而在两个dense block之间插入transition layer，进一步减少特征图的数量，提升模型的紧凑程度。</p><h5 id="Growth-rate"><a href="#Growth-rate" class="headerlink" title="Growth rate"></a><strong>Growth rate</strong></h5><p>​    论文里涉及到growth rate这个概念。它指的是一个dense block里各个层输出feature maps的通道数，在同一个dense block里bn-relu-conv输出的通道数都是一样的。如上图，它的growth rate=4。一般，为了不使网络变得太宽，以及增加参数的利用效率，growth rate一般不会设得太大。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table1.jpg"><br></center><h5 id="Bottleneck-layers"><a href="#Bottleneck-layers" class="headerlink" title="Bottleneck layers "></a><strong>Bottleneck layers </strong></h5><p>​    在一个dense block里，尽管每层输出的通道数并不大（growth rate一般不会设得很大），但是输入是由前面层的feature maps串接起来的，所以输入的通道数会很大。为了提高计算效率，作者<code>引进1*1 conv层作为bottleneck layer，放置在每层的前面，用来降低通道数(减小参数量)</code>。带有bottleneck layer的DenseNet被称为DenseNet-B。</p><h5 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a><strong>Compression</strong></h5><p>​    如果transition layer对上一个dense block进行了通道数的降维（即压缩），则称这类DenseNet为    <code>DenseNet-C</code>。同时使用了bottleneck layer和compression的DenseNet称为<code>DenseNet-BC</code>。</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure4_left.png"><br></center><p>上图是DenseNet和它的几种变体进行parameter efficiency 的比较，可以看出在实现同等accuracy的条件下，DenseNet-BC所用的参数量最少，实现最大的parameter efficiency。</p><hr><p>完整的DenseNet网络结构：</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Figure2.png"><br>    <figcaption>Figure 2</figcaption><br></center><p>上图是由三个dense block组成的，两个block之间的conv+pool为transition layer。dense block3后面的pooling是global average pooling，然后再接一个全连接层+softmax。</p><hr><h4 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><strong>算法分析</strong></h4><h5 id="Model-compactness"><a href="#Model-compactness" class="headerlink" title="Model compactness"></a>Model compactness</h5><p>由于DenseNet对输入进行cat操作,一个直观的影响就是每一层学到的feature map都能被之后所有层直接使用,这使得特征可以在整个网络中重用,也使得模型更加简洁.</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure4.jpg"><br></center><p>从上图中我们可以看出DenseNet的参数效率:左图包含了对多种DenseNet结构参数和最终性能的统计,我们可以看出当模型实现相同的test error时,原始的DenseNet往往要比DenseNet-BC拥有2-3倍的参数量.中间图为DenseNet-BC与ResNet的对比,在相同的模型精度下,DenseNet-BC只需要ResNet约三分之一的参数数量.右图为1001层超过10M参数量的ResNet与100层只有0.8M参数量的DenseNet-BC在训练时的对比,虽然他们在约相同的训练epoch时收敛,但DenseNet-BC却只需要ResNet不足十分之一的参数量.</p><h5 id="Implicit-Deep-Supervision"><a href="#Implicit-Deep-Supervision" class="headerlink" title="Implicit Deep Supervision"></a>Implicit Deep Supervision</h5><p>解释DenseNet为何拥有如此高性能的另一个原因是网络中的每一层不仅接受了原始网络中来自loss的监督,同时由于存在多个bypass与shortcut,网络的监督是多样的.Deep supervision的优势同样在deeply-supervised nets (DSN)中也被证实.(DSN中每一个Hidden layer都有一个分类器,强迫其学习一些有区分度的特征).与DSN不同的是,DenseNet拥有单一的loss function, 模型构造和梯度计算更加简易.</p><h5 id="Feature-Reuse"><a href="#Feature-Reuse" class="headerlink" title="Feature Reuse"></a>Feature Reuse</h5><p>在设计初,DenseNet便被设计成让一层网络可以使用所有之前层网络feature map的网络结构,为了探索feature的复用情况,作者进行了相关实验.作者训练的L=40,K=12的DenseNet,对于任意Denseblock中的所有卷积层,计算之前某层feature map在该层权重的绝对值平均数.这一平均数表明了这一层对于之前某一层feature的利用率,下图为由该平均数绘制出的热力图:</p><center><br><img src="/2018/12/03/DenseNet-Introduction/Figure5.jpg" style="zoom:60%"><br></center><p>从图中我们可以得出以下结论:</p><p>a) 一些较早层提取出的特征仍可能被较深层直接使用<br>b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征<br>c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,即Compression的必要性.<br>d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生.</p><h4 id="实现结果"><a href="#实现结果" class="headerlink" title="实现结果"></a>实现结果</h4><p>作者在多个benchmark数据集上训练了多种DenseNet模型,并与state-of-art的模型(主要是ResNet和其变种)对比:</p><center><br>    <img src="/2018/12/03/DenseNet-Introduction/Table2.jpg"><br></center><p>由上表我们可以看出,DenseNet只需要较小的Growth rate(12,24)便可以实现state-of-art的性能,结合了Bottleneck和Compression的DenseNet-BC具有远小于ResNet及其变种的参数数量,且无论DenseNet或者DenseNet-BC,都在原始数据集和增广数据集上实现了超越ResNet的性能.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ResNet_Introduction</title>
    <link href="http://yoursite.com/2018/12/02/ResNet-Introduction/"/>
    <id>http://yoursite.com/2018/12/02/ResNet-Introduction/</id>
    <published>2018-12-02T11:03:11.000Z</published>
    <updated>2018-12-03T14:35:38.115Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>论文出处：<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>译文链接：<a href="http://blog.csdn.net/wspba/article/details/57074389" target="_blank" rel="noopener">http://blog.csdn.net/wspba/article/details/57074389</a></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/32085715" target="_blank" rel="noopener">ResNet学习笔记</a>、<a href="https://www.jianshu.com/p/46d76bd56766" target="_blank" rel="noopener">深度详解ResNet及其六大变体</a>、<a href="https://www.jianshu.com/p/e58437f39f65" target="_blank" rel="noopener">残差网络ResNet笔记</a>、<a href="https://zhuanlan.zhihu.com/p/30756859" target="_blank" rel="noopener">残差系列网络</a></p><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>随着CNN网络的发展，尤其的VGG网络的提出，大家发现网络的层数是一个关键因素，貌似越深的网络效果越好。但是<code>随着网络层数的增加，问题也随之而来</code>。</p><p>首先出现的问题是<strong>梯度消失/梯度爆炸</strong>，这就导致训练难以收敛。<code>归一初始化</code>（normalized initialization）和<code>中间归一化</code>（intermediate normalization）在很大程度上解决了这一问题，它使得数十层的网络在反向传播的随机梯度下降（SGD）上能够收敛。</p><p>当深层网络能够收敛时，一个<strong>退化</strong>问题又出现了：随着网络深度的增加，准确率达到饱和然后迅速退化。意外的是，这种退化<strong>并不是由过拟合造成的</strong>，并且在一个合理的深度模型中增加更多的层却导致了<strong>更高的错误率</strong>。<strong>Fig.1</strong>展示了一个典型的例子：</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 1.jpg" style="zoom:80%"><br></center><br>对于更深的模型，这有一种通过构建的解决方案：<strong>恒等映射identity mapping</strong>(所谓的恒等映射，即输入$x$经过某一个函数（设为$G(x)$）作用输出还是$x$本身，即$G(x)=x$)，来构建增加的层，而其它层直接从浅层模型中复制而来。这个构建的解决方案也表明了，一个更深的模型不应当产生比它的浅层版本更高的训练错误率。但是，<strong>相关的实验结果说明传统的网络（”plain” networks）很难去学习恒等映射</strong>，即会出现因为深度增加而导致性能下降的问题（即使采用了恒等映射方法）。<br><br>#### Identity Mapping by Shortcuts<br><br>本文中，我们提出了一种<strong>深度残差学习</strong>框架来解决这种因为深度增加而导致性能下降的问题。<br>我们假设$F(x)$代表某个只包含有两三层的block的映射函数， $x$ 是block的输入，$F(x)$ 是block的输出。假设他们具有相同的维度。在训练的过程中我们希望能够通过修改网络中的 $w$ 和 $b$ 去拟合一个理想的 $\mathcal{H}(x)$ (从输入到输出的一个理想的映射函数)。也就是我们的目标是修改 $\mathcal{F}(x)$ 中的 $w$ 和 $b$ 逼近 $\mathcal{H}(x)$ 。<br>如果我们改变思路，用$\mathcal{F}(x)$  来逼近$\mathcal{H}(x)-x$，那么我们最终得到bolck的输出$\mathcal{H}(x)$就由 $\mathcal{F}(x)$ 变为$\mathcal{F}(x)+x$ （这里的加指的是对应位置上的元素相加，也就是element-wise addition），这里的直接将输入连接到输出的结构也称为shortcut。 这里我们假设优化残差映射$\mathcal{F}({x})$比优化原来的映射 $\mathcal{H}({x})$容易。<br><br>- 改变前目标： 训练$\mathcal{F}(x)$ 逼近 $\mathcal{H}(x)$<br>- 改变后目标：训练 $\mathcal{F}(x)$ 逼近$\mathcal{H}(x)-x$   (即 $\mathcal{F}(x)+x$ 逼近$\mathcal{H}(x)$)<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 2.1.jpg" style="zoom:80%"><br></center><br>左边的original block需要调整其内部参数，使得输入的x经过卷积操作后最终输出的F(x)等于x，即实现了恒等映射F(x)=x，等号左边是block的输出，右边是block的输入。但是这种结构的卷积网络很难调整其参数完美地实现F(x)=x。再看右边的Res block。因为shortcut的引入，整个block的输出变成了F(x)+x，block的输入还是x。此时网络需要调整其内部参数使得F(x)+x=x，也就是直接令其内部的所有参数为0，使得F(x)=0，F(x)+x=x就变成了0+x = x，等号左边是block的输出，右边是block的输入。输出等于输入，即<strong>完美地完成了恒等映射</strong>。因此使用ResNet结构搭建的深度网络至少与浅层网络具有相同的拟合能力，不会出现之前的网络退化问题。<br><br>——<br><br><br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/Figure 2.png" style="zoom:40%"><br></center><br><strong>We consider a building block defined as</strong>：  $\begin{equation} {y}= \mathcal{F}({x}, {W_{i}}) + W_{s}{x}. \end{equation}$<br><br><br>#### Shortcut的三种方式<br><br>由于ResNet要求 $F(x)$与 $x$ 的维度大小要一致才能够相加，因此在$F(x)$ 与$x$ 维度不相同时就需要对$x$的维度做调整，文章中提出了三种调整的方式：<br><br>1. 如果 $x$ 的维度增加，就使用0来填充增加出来的维度（A方式）<br>2. 如果 $x$ 的维度增加，使用线性变换来增加多出来的维度，在程序里表现为使用一个1x1的卷积核进行调整维度（B方式）<br>3. 对于所有的shortcut，都使用线性变换，也就是1x1的卷积（C方式）<br><br>由下面的实验结果可以，分析ABC这三种方式。A方式采用0填充.，完全不存在任何的残差学习能力。B方式与C方式相比，错误率略高。但是B方式的模型复杂度要远低于C方式，因此，作者最终在所有的网络中采用方式B。B方式在 $x$ 的维度与$F(x)$的维度相同时，直接用 $x$ 加上 $F(x)$，在 $x$ 的维度与 $F(x)$的维度不同时，才采用1x1的卷积层对 $x$ 的维度进行调整。<br><br>——<br><br>#### 对ResNet的解读<br><br><center><br>    <img src="/2018/12/02/ResNet-Introduction/shortcuts_1.png" style="zoom:80%"><br></center><p>ResNet架构有很多独立有效路径（或者说残差网络其实是很多并行子网络的组合），而且大部分路径在移除了部分层之后会保持完整无损。相反，VGG网络只有一个有效路径，因此移除一个层都会对它的唯一路径的性能产生极大的影响。</p><center><br>    <img src="/2018/12/02/ResNet-Introduction/distribution of path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/gradient magnitude per path length.png" width="200"><br>    <img src="/2018/12/02/ResNet-Introduction/total gradient magnitude per path length.png" width="200"><br></center><p>图(左)大部分的路径都流经了19到35个残差块。为了得到路径长度k的梯度幅度，作者们首先向网络输入了一批数据，然后任意采样了k个残差块。当反向传递梯度时，他们仅将采样的残差块通过权重层进行传递。图(中)表示随着路径长度的增加，梯度幅度会迅速下降。我们现在可以将每一路径长度与其期望的梯度大小相乘，看每一路径长度在训练中起到多大的作用，就像图(右)。</p><p>令人惊讶的是，大多分布都来自于9到18的路径长度，但它们都只包含少量的总路径（或者说ResNet是由大多数中度网络和一小部分浅度网络和深度网络组成的，说明虽然表面上ResNet网络很深，但是其实起实际作用的网络层数并没有很深。），如图(左)。这是一个非常有趣的发现，因为这暗示着<code>ResNet无法解决过长路径的梯度消失问题</code>，<strong>ResNet的成功实际上源自于它缩短了它的有效路径(effective path)的长度</strong>。</p><p> Stochastic depth通过在训练期间随机丢弃层来改善深度残留网络的训练。这表明并不是所有的层都是需要的，并且强调在深度（剩余）网络中存在大量的冗余。</p><hr><h4 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h4><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 3.png" style="zoom:40%"><br></center><br>Plain Network 主要是受 VGG 网络启发，主要采用<strong>3*3滤波器</strong>，遵循两个设计原则：1）对于相同输出特征图尺寸，卷积层有相同个数的滤波器，2）如果特征图尺寸缩小一半，滤波器个数加倍以保持每个层的计算复杂度。通过<strong>步长为2的卷积</strong>来进行降采样。一共<strong>34个权重层</strong>。<br>需要指出，我们这个网络<code>与VGG相比，滤波器要少，复杂度要小</code>。<br><br>Residual Network 主要是在 上述的 plain network上加入 shortcut connections。<strong>ResNet的结构使得网络具有与学习恒等映射的能力，同时也具有学习其他映射的能力。因此ResNet的结构要优于传统的卷积网络（plain networks）结构。</strong><br><br>#### Experiments<br><br><center><br><img src="/2018/12/02/ResNet-Introduction/Figure 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 3.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 4.png" style="zoom:70%"><br></center><center><br><img src="/2018/12/02/ResNet-Introduction/Table 6.png" style="zoom:70%"><br></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Tensorboard_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Tensorboard-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Tensorboard-Morvan/</id>
    <published>2018-12-01T14:08:52.000Z</published>
    <updated>2018-12-01T14:15:06.483Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(tensorflow) ➜  Morvan_Tensorflow tensorboard --logdir logs</span><br><span class="line">TensorBoard 1.11.0 at http://MacBook-Pro:6006 (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure><ul><li>Chrome</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://0.0.0.0:6006</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/Matplotlib-Python3-Morvan/</id>
    <published>2018-12-01T13:18:30.000Z</published>
    <updated>2018-12-01T14:15:38.172Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><p>Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。</p><a id="more"></a><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/plt/</a></p><h2 id="Matplotlib简介"><a href="#Matplotlib简介" class="headerlink" title="Matplotlib简介"></a>Matplotlib简介</h2><h3 id="Matplotlib-安装"><a href="#Matplotlib-安装" class="headerlink" title="Matplotlib 安装"></a>Matplotlib 安装</h3><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><h3 id="figure-图像"><a href="#figure-图像" class="headerlink" title="figure 图像"></a>figure 图像</h3><h3 id="设置坐标轴"><a href="#设置坐标轴" class="headerlink" title="设置坐标轴"></a>设置坐标轴</h3><h3 id="Legend图例"><a href="#Legend图例" class="headerlink" title="Legend图例"></a>Legend图例</h3><h3 id="Annotation标注"><a href="#Annotation标注" class="headerlink" title="Annotation标注"></a>Annotation标注</h3><h3 id="tick能见度"><a href="#tick能见度" class="headerlink" title="tick能见度"></a>tick能见度</h3><h2 id="画图种类"><a href="#画图种类" class="headerlink" title="画图种类"></a>画图种类</h2><h3 id="Scatter-散点图"><a href="#Scatter-散点图" class="headerlink" title="Scatter 散点图"></a>Scatter 散点图</h3><h3 id="Bar-柱状图"><a href="#Bar-柱状图" class="headerlink" title="Bar 柱状图"></a>Bar 柱状图</h3><h3 id="Contours-等高线图"><a href="#Contours-等高线图" class="headerlink" title="Contours 等高线图"></a>Contours 等高线图</h3><h3 id="Image-图片"><a href="#Image-图片" class="headerlink" title="Image 图片"></a>Image 图片</h3><h3 id="3D图片"><a href="#3D图片" class="headerlink" title="3D图片"></a>3D图片</h3><h2 id="多图合并显示"><a href="#多图合并显示" class="headerlink" title="多图合并显示"></a>多图合并显示</h2><h3 id="Subplot-多合一显示"><a href="#Subplot-多合一显示" class="headerlink" title="Subplot 多合一显示"></a>Subplot 多合一显示</h3><h3 id="Subplot-分格显示"><a href="#Subplot-分格显示" class="headerlink" title="Subplot 分格显示"></a>Subplot 分格显示</h3><h3 id="图中图"><a href="#图中图" class="headerlink" title="图中图"></a>图中图</h3><h3 id="次坐标轴"><a href="#次坐标轴" class="headerlink" title="次坐标轴"></a>次坐标轴</h3><h2 id="动画"><a href="#动画" class="headerlink" title="动画"></a>动画</h2><h3 id="Animation动画"><a href="#Animation动画" class="headerlink" title="Animation动画"></a>Animation动画</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
&lt;p&gt;Matplotlib 是一个非常强大的 Python 画图工具，它能帮你画出美丽的线图、散点图、等高线图、条形图、柱状图、3D图形，甚至是图形动画等等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>numpy&amp;pandas_Python3_Morvan</title>
    <link href="http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/"/>
    <id>http://yoursite.com/2018/12/01/numpy-pandas-Python3-Morvan/</id>
    <published>2018-12-01T12:10:48.000Z</published>
    <updated>2018-12-01T14:16:13.563Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】Not Completed……</p><a id="more"></a><hr><p>链接：<a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/</a></p><h3 id="Numpy-和-Pandas-安装"><a href="#Numpy-和-Pandas-安装" class="headerlink" title="Numpy 和 Pandas 安装"></a>Numpy 和 Pandas 安装</h3><h4 id="numpy-安装"><a href="#numpy-安装" class="headerlink" title="numpy 安装"></a>numpy 安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install numpy</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install numpy</span></span><br></pre></td></tr></table></figure><h4 id="pandas安装"><a href="#pandas安装" class="headerlink" title="pandas安装"></a>pandas安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 3+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip3 install pandas</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 python 2+:</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install pandas</span></span><br></pre></td></tr></table></figure><h3 id="Numpy属性"><a href="#Numpy属性" class="headerlink" title="Numpy属性"></a>Numpy属性</h3><ul><li><code>ndim</code>：维度</li><li><code>shape</code>：行数和列数</li><li><code>size</code>：元素个数</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#为了方便使用numpy 采用np简写</span></span><br><span class="line">array = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])  <span class="comment">#列表转化为矩阵</span></span><br><span class="line">print(array)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 2, 3],</span></span><br><span class="line"><span class="string">       [2, 3, 4]])</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">print(<span class="string">'number of dim:'</span>,array.ndim)  <span class="comment"># 维度</span></span><br><span class="line"><span class="comment"># number of dim: 2</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'shape :'</span>,array.shape)    <span class="comment"># 行数和列数</span></span><br><span class="line"><span class="comment"># shape : (2, 3)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'size:'</span>,array.size)   <span class="comment"># 元素个数</span></span><br><span class="line"><span class="comment"># size: 6</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-的创建array"><a href="#Numpy-的创建array" class="headerlink" title="Numpy 的创建array"></a>Numpy 的创建array</h3><ul><li>创建 array 有很多 <a href="https://docs.scipy.org/doc/numpy-dev/user/quickstart.html" target="_blank" rel="noopener">形式</a></li></ul><h4 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a><strong>关键字</strong></h4><ul><li><code>array</code>：创建数组</li><li><code>dtype</code>：指定数据类型</li><li><code>zeros</code>：创建数据全为0</li><li><code>ones</code>：创建数据全为1</li><li><code>empty</code>：创建数据接近0</li><li><code>arrange</code>：按指定范围创建数据</li><li><code>linspace</code>：创建线段</li></ul><h4 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>])  <span class="comment"># list 1d</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># [2 23 4]</span></span><br></pre></td></tr></table></figure><h4 id="指定数据-dtype"><a href="#指定数据-dtype" class="headerlink" title="指定数据 dtype"></a>指定数据 dtype</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int 64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.int32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># int32</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float64</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">print(a.dtype)</span><br><span class="line"><span class="comment"># float32</span></span><br></pre></td></tr></table></figure><h4 id="创建特定数据"><a href="#创建特定数据" class="headerlink" title="创建特定数据"></a>创建特定数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">2</span>,<span class="number">23</span>,<span class="number">4</span>],[<span class="number">2</span>,<span class="number">32</span>,<span class="number">4</span>]])  <span class="comment"># 2d 矩阵 2行3列</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">[[ 2 23  4]</span></span><br><span class="line"><span class="string"> [ 2 32  4]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全零数组</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据全为0，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.],</span></span><br><span class="line"><span class="string">       [ 0.,  0.,  0.,  0.]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全一数组, 同时也能指定这些特定数据的 dtype:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.ones((<span class="number">3</span>,<span class="number">4</span>),dtype = np.int)   <span class="comment"># 数据为1，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1],</span></span><br><span class="line"><span class="string">       [1, 1, 1, 1]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>创建全空数组, 其实每个值都是接近于零的数:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.empty((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 数据为empty，3行4列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  0.00000000e+000,   4.94065646e-324,   9.88131292e-324,   1.48219694e-323],</span></span><br><span class="line"><span class="string">       [  1.97626258e-323,   2.47032823e-323,   2.96439388e-323,   3.45845952e-323],</span></span><br><span class="line"><span class="string">       [  3.95252517e-323,   4.44659081e-323,   4.94065646e-323,   5.43472210e-323]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>arange</code> 创建连续数组:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>,<span class="number">20</span>,<span class="number">2</span>) <span class="comment"># 10-19 的数据，2步长</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([10, 12, 14, 16, 18])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>使用 <code>reshape</code> 改变数据的形状</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>,<span class="number">4</span>))    <span class="comment"># 3行4列，0到11</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">       [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">       [ 8,  9, 10, 11]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>用 <code>linspace</code> 创建线段型数据:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>)    <span class="comment"># 开始端1，结束端10，且分割成20个数据，生成线段</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([  1.        ,   1.47368421,   1.94736842,   2.42105263,</span></span><br><span class="line"><span class="string">         2.89473684,   3.36842105,   3.84210526,   4.31578947,</span></span><br><span class="line"><span class="string">         4.78947368,   5.26315789,   5.73684211,   6.21052632,</span></span><br><span class="line"><span class="string">         6.68421053,   7.15789474,   7.63157895,   8.10526316,</span></span><br><span class="line"><span class="string">         8.57894737,   9.05263158,   9.52631579,  10.        ])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>同样也能进行 <code>reshape</code> 工作:</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">20</span>).reshape((<span class="number">5</span>,<span class="number">4</span>)) <span class="comment"># 更改shape</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">array([[  1.        ,   1.47368421,   1.94736842,   2.42105263],</span></span><br><span class="line"><span class="string">       [  2.89473684,   3.36842105,   3.84210526,   4.31578947],</span></span><br><span class="line"><span class="string">       [  4.78947368,   5.26315789,   5.73684211,   6.21052632],</span></span><br><span class="line"><span class="string">       [  6.68421053,   7.15789474,   7.63157895,   8.10526316],</span></span><br><span class="line"><span class="string">       [  8.57894737,   9.05263158,   9.52631579,  10.        ]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="Numpy-基础运算"><a href="#Numpy-基础运算" class="headerlink" title="Numpy 基础运算"></a>Numpy 基础运算</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.array([<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>])   <span class="comment"># array([10, 20, 30, 40])</span></span><br><span class="line">b=np.arange(<span class="number">4</span>) <span class="comment"># array([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line">c=a-b  <span class="comment"># array([10, 19, 28, 37])   矩阵的减法</span></span><br><span class="line">c=a+b   <span class="comment"># array([10, 21, 32, 43])矩阵的加法</span></span><br><span class="line">c=a*b   <span class="comment"># array([  0,  20,  60, 120])  矩阵的乘法</span></span><br><span class="line"></span><br><span class="line">c=b**<span class="number">2</span>  <span class="comment"># array([0, 1, 4, 9])  乘方</span></span><br><span class="line">c=<span class="number">10</span>*np.sin(a)  <span class="comment"># array([-5.44021111,  9.12945251, -9.88031624,  7.4511316 ]) 三角函数</span></span><br><span class="line">print(b&lt;<span class="number">3</span>)  <span class="comment"># array([ True,  True,  True, False], dtype=bool)  print()逻辑判断</span></span><br></pre></td></tr></table></figure><ul><li>对多行多维度的矩阵进行操作</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=np.array([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">b=np.arange(<span class="number">4</span>).reshape((<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[1, 1],</span></span><br><span class="line"><span class="comment">#       [0, 1]])</span></span><br><span class="line"></span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># array([[0, 1],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line"></span><br><span class="line">c_dot = np.dot(a,b)     <span class="comment"># 矩阵乘法，即对应行乘对应列得到相应元素</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br><span class="line">c_dot_2 = a.dot(b)<span class="comment"># 矩阵乘法(另一写法)</span></span><br><span class="line"><span class="comment"># array([[2, 4],</span></span><br><span class="line"><span class="comment">#       [2, 3]])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># array([[ 0.94692159,  0.20821798,  0.35339414,  0.2805278 ],</span></span><br><span class="line"><span class="comment">#       [ 0.04836775,  0.04023552,  0.44091941,  0.21665268]])</span></span><br><span class="line">np.sum(a)   <span class="comment"># 4.4043622002745959   对矩阵中所有元素进行求和</span></span><br><span class="line">np.min(a)   <span class="comment"># 0.23651223533671784  对矩阵中所有元素寻找最小值</span></span><br><span class="line">np.max(a)   <span class="comment"># 0.90438450240606416  对矩阵中所有元素寻找最大值</span></span><br><span class="line"></span><br><span class="line">a=np.random.random((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(<span class="string">"a ="</span>,a)</span><br><span class="line"><span class="comment"># a = [[ 0.23651224  0.41900661  0.84869417  0.46456022]</span></span><br><span class="line"><span class="comment"># [ 0.60771087  0.9043845   0.36603285  0.55746074]]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"sum ="</span>,np.sum(a,axis=<span class="number">1</span>))   <span class="comment"># 当axis的值为1的时候，将会以行作为查找单元</span></span><br><span class="line"><span class="comment"># sum = [ 1.96877324  2.43558896]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"min ="</span>,np.min(a,axis=<span class="number">0</span>))   <span class="comment"># 当axis的值为0的时候，将会以列作为查找单元</span></span><br><span class="line"><span class="comment"># min = [ 0.23651224  0.41900661  0.36603285  0.46456022]</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"max ="</span>,np.max(a,axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># max = [ 0.84869417  0.9043845 ]</span></span><br></pre></td></tr></table></figure><ul><li>对应元素的<code>索引</code>也是非常重要的</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">2</span>,<span class="number">14</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[ 2, 3, 4, 5]</span></span><br><span class="line"><span class="comment">#        [ 6, 7, 8, 9]</span></span><br><span class="line"><span class="comment">#        [10,11,12,13]])</span></span><br><span class="line">         </span><br><span class="line">print(np.argmin(A))    <span class="comment"># 0    求矩阵中最小元素的索引</span></span><br><span class="line">print(np.argmax(A))    <span class="comment"># 11   求矩阵中最大元素的索引</span></span><br><span class="line"></span><br><span class="line">print(np.mean(A))        <span class="comment"># 7.5  计算均值    </span></span><br><span class="line"><span class="comment"># print(A.mean())          # 7.5</span></span><br><span class="line">print(np.average(A))     <span class="comment"># 7.5</span></span><br><span class="line"></span><br><span class="line">print(A.median())       <span class="comment"># 7.5  求解中位数</span></span><br><span class="line"></span><br><span class="line">print(np.cumsum(A)) <span class="comment"># [2 5 9 14 20 27 35 44 54 65 77 90]   累加函数</span></span><br><span class="line"></span><br><span class="line">print(np.diff(A))    <span class="comment"># 累差运算</span></span><br><span class="line"><span class="comment"># [[1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1]]</span></span><br><span class="line"></span><br><span class="line">print(np.nonzero(A))    <span class="comment"># 这个函数将所有非零元素的行与列坐标分割开，重构成两个分别关于行和列的矩阵。</span></span><br><span class="line"><span class="comment"># (array([0,0,0,0,1,1,1,1,2,2,2,2]),array([0,1,2,3,0,1,2,3,0,1,2,3]))</span></span><br><span class="line">B = np.array([[<span class="number">0</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">0</span>, <span class="number">22</span>, <span class="number">33</span>],[<span class="number">11</span>, <span class="number">22</span>, <span class="number">0</span>, <span class="number">33</span>]])</span><br><span class="line">print(np.nonzero(B))<span class="comment">#遍历每一个元素，若其非0，则返回其行/列索引   第一(二)个array返回行(列)索引</span></span><br><span class="line"><span class="comment"># (array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([1, 2, 3, 0, 2, 3, 0, 1, 3]))</span></span><br></pre></td></tr></table></figure><ul><li>排序操作</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">14</span>,<span class="number">2</span>, <span class="number">-1</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># array([[14, 13, 12, 11],</span></span><br><span class="line"><span class="comment">#       [10,  9,  8,  7],</span></span><br><span class="line"><span class="comment">#       [ 6,  5,  4,  3]])</span></span><br><span class="line"></span><br><span class="line">print(np.sort(A))    <span class="comment"># 仅针对每一行进行从小到大排序操作</span></span><br><span class="line"><span class="comment"># array([[11,12,13,14]</span></span><br><span class="line"><span class="comment">#        [ 7, 8, 9,10]</span></span><br><span class="line"><span class="comment">#        [ 3, 4, 5, 6]])</span></span><br></pre></td></tr></table></figure><ul><li>矩阵的转置有两种表示方法：</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(np.transpose(A))    </span><br><span class="line">print(A.T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br><span class="line"><span class="comment"># array([[14,10, 6]</span></span><br><span class="line"><span class="comment">#        [13, 9, 5]</span></span><br><span class="line"><span class="comment">#        [12, 8, 4]</span></span><br><span class="line"><span class="comment">#        [11, 7, 3]])</span></span><br></pre></td></tr></table></figure><ul><li>在Numpy中具有<code>clip(Array,Array_min,Array_max)</code>函数：将Array中大于Array_max的元素转换成Array_max，将Array中小于Array_min的元素转换成Array_min</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(A)</span><br><span class="line"><span class="comment"># array([[14,13,12,11]</span></span><br><span class="line"><span class="comment">#        [10, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 4, 3]])</span></span><br><span class="line"></span><br><span class="line">print(np.clip(A,<span class="number">5</span>,<span class="number">9</span>))    </span><br><span class="line"><span class="comment"># array([[ 9, 9, 9, 9]</span></span><br><span class="line"><span class="comment">#        [ 9, 9, 8, 7]</span></span><br><span class="line"><span class="comment">#        [ 6, 5, 5, 5]])</span></span><br></pre></td></tr></table></figure><h3 id="Numpy索引"><a href="#Numpy索引" class="headerlink" title="Numpy索引"></a>Numpy索引</h3><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-5-np-indexing/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】Not Completed……&lt;/p&gt;
    
    </summary>
    
    
      <category term="Morvan" scheme="http://yoursite.com/tags/Morvan/"/>
    
  </entry>
  
  <entry>
    <title>Communication-Technology-Basics-Experiment</title>
    <link href="http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/"/>
    <id>http://yoursite.com/2018/12/01/Communication-Technology-Basics-Experiment/</id>
    <published>2018-12-01T06:43:44.788Z</published>
    <updated>2018-12-01T08:02:06.310Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】通信技术基础上机</p><a id="more"></a><h3 id="基带编码"><a href="#基带编码" class="headerlink" title="基带编码"></a>基带编码</h3><h4 id="example"><a href="#example" class="headerlink" title="example"></a>example</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>];</span><br><span class="line">num=<span class="number">0</span>;</span><br><span class="line">yn = xn;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span> xn(<span class="built_in">i</span>)==<span class="number">1</span></span><br><span class="line">        num = num+<span class="number">1</span>;</span><br><span class="line">        yn(<span class="built_in">i</span>) = yn(<span class="built_in">i</span>)+ num;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-1</span> <span class="number">8</span>]);grid on</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/example.jpg"><br></center><h4 id="AMI码"><a href="#AMI码" class="headerlink" title="AMI码"></a>AMI码</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=+<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                   <span class="comment">% 以上部分完成AMI码编码</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/AMI.jpg"><br></center><h4 id="HDB3"><a href="#HDB3" class="headerlink" title="HDB3"></a>HDB3</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">xn=[<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>];<span class="comment">% 输入单极性码</span></span><br><span class="line"><span class="comment">% xn = [1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1];</span></span><br><span class="line">yn=xn;<span class="comment">% 输出yn初始化</span></span><br><span class="line">num=<span class="number">0</span>;<span class="comment">% 计数器初始化</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">   <span class="keyword">if</span> xn(k)==<span class="number">1</span></span><br><span class="line">      num=num+<span class="number">1</span>;                <span class="comment">% "1"计数器</span></span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">mod</span>(num,<span class="number">2</span>)==<span class="number">1</span> <span class="comment">% 奇数个1时输出-1,进行极性交替</span></span><br><span class="line">              yn(k)=<span class="number">-1</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">              yn(k)=<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">end</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>   </span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br><span class="line"><span class="comment">% HDB3编码 </span></span><br><span class="line">num=<span class="number">0</span>;  <span class="comment">% 连零计数器初始化 </span></span><br><span class="line">yh=yn;  <span class="comment">% 输出初始化 </span></span><br><span class="line"><span class="built_in">sign</span>=<span class="number">0</span>; <span class="comment">% 极性标志初始化为0 </span></span><br><span class="line">nonzero=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(yn)    </span><br><span class="line">    <span class="keyword">if</span> yn(k)==<span class="number">0</span>        </span><br><span class="line">        num=num+<span class="number">1</span>;  <span class="comment">% 连“0”个数计数        </span></span><br><span class="line">        <span class="keyword">if</span> num==<span class="number">4</span>   <span class="comment">% 如果4连“0”          </span></span><br><span class="line">            num=<span class="number">0</span>;    <span class="comment">% 计数器清零 </span></span><br><span class="line">            yh(k)= nonzero;              <span class="comment">% 让0000的最后一个0改变为与前一个非零符号相同极性的符号          </span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> yh(k)==<span class="built_in">sign</span>     <span class="comment">% 如果当前V符号与前一个V符号的极性相同             </span></span><br><span class="line">                yh(k)=<span class="number">-1</span>*yh(k); <span class="comment">% 则让当前V符号极性反转,以满足V符号间相互极性反转要求             </span></span><br><span class="line">                yh(k<span class="number">-3</span>)=yh(k);  <span class="comment">% 添加B符号,与V符号同极性     </span></span><br><span class="line">                       </span><br><span class="line">                 yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn))=<span class="number">-1</span>*yh(k+<span class="number">1</span>:<span class="built_in">length</span>(yn));   <span class="comment">% 并让后面的非零符号从V符号开始再交替变化          </span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">          <span class="built_in">sign</span>=yh(k);          <span class="comment">% 记录前一个V符号的极性</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        num=<span class="number">0</span>;                <span class="comment">% 当前输入为“1”则连“0”计数器清零   </span></span><br><span class="line">        nonzero = yn(k);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span>                         <span class="comment">% 编码完成</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],yh);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]); grid on;</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/HDB3.jpg"><br></center><h4 id="Manchester"><a href="#Manchester" class="headerlink" title="Manchester"></a>Manchester</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear all</span><br><span class="line">close all</span><br><span class="line">xn=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">t=<span class="number">0</span>:<span class="number">1</span>:<span class="number">2</span>*<span class="built_in">length</span>(xn)<span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(xn)</span><br><span class="line">    <span class="keyword">if</span>(xn(<span class="built_in">i</span>)==<span class="number">1</span>)   <span class="comment">%manchester code "1"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">-1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span>           <span class="comment">%manchester code "0"</span></span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>)=<span class="number">1</span>;</span><br><span class="line">            yn(<span class="number">2</span>*<span class="built_in">i</span>)=<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);stairs([<span class="number">0</span>:length(xn)<span class="number">-1</span>],xn);axis([<span class="number">0</span> length(xn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">stairs(t,yn);</span><br><span class="line">axis([<span class="number">0</span> length(yn) <span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line"> grid on;</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br><img src="/2018/12/01/Communication-Technology-Basics-Experiment/Manchester.jpg"><br></center><h3 id="数字调制技术"><a href="#数字调制技术" class="headerlink" title="数字调制技术"></a>数字调制技术</h3><h4 id="DPSK"><a href="#DPSK" class="headerlink" title="DPSK"></a>DPSK</h4><p>参数设置Block Parameters <code>DPSK // DPSK_1(PPt)</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Bernoulli Binary Generator   </span><br><span class="line">- Source of initial seed: Parameter</span><br><span class="line">- Initial seed: 50</span><br><span class="line">- Output data type: single</span><br><span class="line"></span><br><span class="line">- Differential Encoder</span><br><span class="line">- Initial conditions: 0.05</span><br><span class="line"></span><br><span class="line">- Unipolar to Bipolar Converter</span><br><span class="line">- M-ary number:2</span><br><span class="line">- Output data type:Same as input</span><br><span class="line"></span><br><span class="line">- Sine Wave </span><br><span class="line">- Amplitude: 2  // 1</span><br><span class="line">- Frequency(rad/sec):4*2*pi // 40*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Analog Filter Design</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter order:8 // 4</span><br><span class="line">- Lower passband edge frequency (rad/s): 2*pi // 2*2*pi</span><br><span class="line">- Upper passband edge frequency (rad/s): 10*pi // 7*2*pi</span><br><span class="line"></span><br><span class="line">- Transport Delay</span><br><span class="line">- Time delay: 0.318*pi</span><br><span class="line"></span><br><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:4</span><br><span class="line">- Passband edge frequency (rad/s): 2*2*pi  // 3*2*pi</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0.3</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h4 id="2FSK"><a href="#2FSK" class="headerlink" title="2FSK"></a>2FSK</h4><p>参数设置Block Parameters    <code>(文件参数) //(PPT参数)</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Analog Filter Design1</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 10*pi (与结果图Scope11一致) // 80</span><br><span class="line"></span><br><span class="line">- Analog Filter Design2</span><br><span class="line">- Design method:Butterworth</span><br><span class="line">- Filter type: Lowpass</span><br><span class="line">- Filter order:8</span><br><span class="line">- Passband edge frequency (rad/s): 20*pi  // 20</span><br><span class="line"></span><br><span class="line">- Sine Wave3</span><br><span class="line">- Frequency(rad/sec):20*pi // 80*pi</span><br><span class="line">- Sample time:1/500// 1/1000</span><br><span class="line"></span><br><span class="line">- Subtract</span><br><span class="line">- Icon shape:rectangular// round</span><br><span class="line">- List of signs:+-</span><br><span class="line"></span><br><span class="line">- Switch</span><br><span class="line">- Criteria for passing first input: u2 &gt;= Threshold</span><br><span class="line">- Threshold: 0 // 0.3(与结果图Scope15一致)</span><br><span class="line">- Enable zero crossing detection (√)</span><br></pre></td></tr></table></figure><h3 id="PCM-DM"><a href="#PCM-DM" class="headerlink" title="PCM_DM"></a>PCM_DM</h3><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear;</span><br><span class="line">t=<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>),plot(t,a);title(<span class="string">'Original signal'</span>);</span><br><span class="line"></span><br><span class="line">ts=<span class="number">0.05</span>;</span><br><span class="line">t=<span class="number">0</span>:ts:<span class="number">4</span>;</span><br><span class="line">a=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*t)+<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">5</span>*t); </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),stem(t,a);title(<span class="string">'Sampling signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_u,aquan8_u,code8_u]=u_pcm1(a,<span class="number">8</span>);  </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">3</span>),stem(t,aquan8_u);</span><br><span class="line">title(<span class="string">'Uniformly quantized signal'</span>);</span><br><span class="line"></span><br><span class="line">[sqnr8_A,aquan8_A,code8_A]=A_pcm1(a,<span class="number">8</span>);   axis([<span class="number">0</span> <span class="number">4</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">4</span>),stem(t,aquan8_A);</span><br><span class="line">title(<span class="string">'A-law quantized signal'</span>);</span><br></pre></td></tr></table></figure><p><strong>Result:</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/PCM_DM_example.jpg"><br></center><h5 id="u-pcm1"><a href="#u-pcm1" class="headerlink" title="u_pcm1"></a>u_pcm1</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">u_pcm1</span><span class="params">(a,n)</span> </span></span><br><span class="line">amax=max(a);</span><br><span class="line">amin=min(a);</span><br><span class="line">delta=(amax-amin)/n;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n+<span class="number">1</span></span><br><span class="line">    m(<span class="built_in">i</span>)=amin+(<span class="built_in">i</span><span class="number">-1</span>)*delta;</span><br><span class="line"><span class="keyword">end</span><span class="comment">%%量化间隔</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n</span><br><span class="line">    q(<span class="built_in">i</span>)=(m(<span class="built_in">i</span>)+m(<span class="built_in">i</span>+<span class="number">1</span>))/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span>    </span><br><span class="line"><span class="comment">%量化值的计算 </span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n  </span><br><span class="line">    index=<span class="built_in">find</span>((q(<span class="built_in">i</span>)-delta/<span class="number">2</span> &lt;= a) &amp; (a &lt;= q(<span class="built_in">i</span>)+delta/<span class="number">2</span>)); <span class="comment">%%找到处于某个量化间隔的所有抽样点</span></span><br><span class="line">    aq(index)=q(<span class="built_in">i</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(index));  <span class="comment">%%利用qi作为该量化间隔的抽样值的量化值</span></span><br><span class="line">    q_index(<span class="built_in">find</span>((aq==q(<span class="built_in">i</span>))))=(<span class="built_in">i</span><span class="number">-1</span>).*<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(<span class="built_in">find</span>(aq==q(<span class="built_in">i</span>)))); <span class="comment">%%得到量化索引</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">% %PCM编码——二进制编码</span></span><br><span class="line">code=dec2bin(q_index);</span><br><span class="line"></span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(a)/norm(a-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h5 id="A-pcm1"><a href="#A-pcm1" class="headerlink" title="A_pcm1"></a>A_pcm1</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[sqnr,aq,code]</span>=<span class="title">A_pcm1</span><span class="params">(x,n)</span> </span></span><br><span class="line">A=<span class="number">87.6</span>;</span><br><span class="line">[amax,amin,y]=A_compress(x,A);</span><br><span class="line"></span><br><span class="line">[sqnr,y_q,code]=u_pcm1(y,n);</span><br><span class="line">aq=A_expand(y,A);</span><br><span class="line">aq=aq*(amax-amin)/<span class="number">2</span>;</span><br><span class="line"> <span class="comment">%SQNR的计算</span></span><br><span class="line">sqnr=<span class="number">20</span>*<span class="built_in">log10</span>(norm(x)/norm(x-aq)); <span class="comment">%norm(a)求a的均方根值</span></span><br></pre></td></tr></table></figure><h6 id="A-compress"><a href="#A-compress" class="headerlink" title="A_compress"></a>A_compress</h6><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[amax,amin,y]</span> = <span class="title">A_compress</span><span class="params">(x,A)</span></span></span><br><span class="line">amax=max(x);</span><br><span class="line">amin=min(x);</span><br><span class="line">x=<span class="number">2</span>*x/(amax-amin);</span><br><span class="line">y=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(x));</span><br><span class="line"><span class="comment">%%A律压缩</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(x(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/A </span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        y(<span class="built_in">i</span>)=<span class="built_in">sign</span>(x(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A*<span class="built_in">abs</span>(x(<span class="built_in">i</span>))))/(<span class="number">1</span>+<span class="built_in">log</span>(A));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h6 id="A-expand"><a href="#A-expand" class="headerlink" title="A_expand"></a>A_expand</h6><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">x</span>=<span class="title">A_expand</span><span class="params">(y,A)</span></span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(y)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(y(<span class="built_in">i</span>))&lt;=<span class="number">1</span>/(<span class="number">1</span>+<span class="built_in">log</span>(A)); </span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))/A;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        x(<span class="built_in">i</span>)=<span class="built_in">sign</span>(y(<span class="built_in">i</span>)).*<span class="built_in">exp</span>(<span class="built_in">abs</span>(y(<span class="built_in">i</span>))*(<span class="number">1</span>+<span class="built_in">log</span>(A))<span class="number">-1</span>)/A;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h4 id="DM1"><a href="#DM1" class="headerlink" title="DM1"></a>DM1</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"> <span class="comment">% ch6example13prog1.m</span></span><br><span class="line"> clc;clear all</span><br><span class="line">Ts=<span class="number">1e-3</span>;                                <span class="comment">%采样间隔</span></span><br><span class="line">t=<span class="number">0</span>:Ts:<span class="number">20</span>*<span class="number">1e-3</span>;                           <span class="comment">%仿真时间序列</span></span><br><span class="line">x=<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">50</span>*t)+<span class="number">0.5</span>*<span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">150</span>*t);   <span class="comment">%信号</span></span><br><span class="line">delta=<span class="number">0.7</span>;                              <span class="comment">%量化阶距</span></span><br><span class="line">D(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                       <span class="comment">%预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)                       </span><br><span class="line">    e(k)=x(k)-D(k);  <span class="comment">%误差信号</span></span><br><span class="line">    <span class="keyword">if</span> e(k)&gt;=<span class="number">0</span></span><br><span class="line">        e_q(k)=delta;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        e_q(k)=-delta;</span><br><span class="line">    <span class="keyword">end</span>                <span class="comment">%量化器输出</span></span><br><span class="line">    D(k+<span class="number">1</span>)=e_q(k)+D(k);                 <span class="comment">%预测器输出</span></span><br><span class="line">    codeout(k)=(e_q(k)&gt;<span class="number">0</span>);              <span class="comment">%编码输出</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>);plot(t,x,<span class="string">'-o'</span>);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);hold on;</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>);stairs(t,codeout);axis([<span class="number">0</span> <span class="number">20</span>*<span class="number">1e-3</span>,<span class="number">-2</span> <span class="number">2</span>]);</span><br><span class="line">                                        <span class="comment">%解码端</span></span><br><span class="line">Dr(<span class="number">1</span>+<span class="built_in">length</span>(t))=<span class="number">0</span>;                      <span class="comment">%解码端预测器初始状态</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">length</span>(t)</span><br><span class="line">    <span class="keyword">if</span> codeout(k)==<span class="number">0</span></span><br><span class="line">        eq(k)=-delta;</span><br><span class="line">    <span class="keyword">else</span> eq(k)=delta;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    xr(k)=eq(k)+Dr(k);</span><br><span class="line">    Dr(k+<span class="number">1</span>)=xr(k);                      <span class="comment">%延迟器状态更新</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);stairs(t,xr);hold on;    <span class="comment">%解码输出</span></span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>);plot(t,x);               <span class="comment">%原信号</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><center><br>    <img src="/2018/12/01/Communication-Technology-Basics-Experiment/DM1.jpg"><br></center><h3 id="差错控制"><a href="#差错控制" class="headerlink" title="差错控制"></a>差错控制</h3><h4 id="CRC16"><a href="#CRC16" class="headerlink" title="CRC16"></a>CRC16</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% CRC 编码主程序</span></span><br><span class="line">clear;clc;close all;</span><br><span class="line">uncode_sequence=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">sequence_length = <span class="built_in">length</span>(uncode_sequence);            <span class="comment">% 得到原始信号长度</span></span><br><span class="line">crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">crc_length=<span class="built_in">length</span>(crc_ccitt)<span class="number">-1</span>;</span><br><span class="line">add_bit = <span class="built_in">zeros</span>(<span class="number">1</span>,crc_length);                                 <span class="comment">% 添加冗余比特位</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence add_bit];            <span class="comment">% 初始化输出检错码序列</span></span><br><span class="line">remainder_bits = [uncode_sequence add_bit];                     <span class="comment">% 初始化余数数组</span></span><br><span class="line"><span class="keyword">for</span> k = <span class="number">1</span>:sequence_length                 <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">    add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,sequence_length-k); <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">    register_bits = [crc_ccitt add_zeros];  <span class="comment">% 构造除数数组</span></span><br><span class="line">    <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>        <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">        register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    remainder_bits = bitxor(register_bits,remainder_bits); <span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">register_bits = crc_ccitt;                        <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">remainder_bits(<span class="number">1</span>) = [];                 <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">crc_coded_sequence = [uncode_sequence remainder_bits]    <span class="comment">% 生成余数序列的冗余位以叠加到编码序列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%%CRC解码</span></span><br><span class="line">error=randint(<span class="number">1</span>,<span class="built_in">length</span>(crc_coded_sequence));<span class="comment">%%信道误码</span></span><br><span class="line"><span class="comment">% error=round(1*rand(1,length(crc_coded_sequence)));%%信道误码    %若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">crc_coded_sequence=bitxor(crc_coded_sequence,error);<span class="comment">%%接收码组 </span></span><br><span class="line">sequence_length = <span class="built_in">length</span>(crc_coded_sequence);         <span class="comment">% 得到编码的长度</span></span><br><span class="line">original_sequence = crc_coded_sequence;                  <span class="comment">% 初始化输出序列 </span></span><br><span class="line">        crc_ccitt=[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">        remainder_bits = crc_coded_sequence;           <span class="comment">% 初始化余数数组</span></span><br><span class="line">        cycle_length = sequence_length-<span class="built_in">length</span>(crc_ccitt)+<span class="number">1</span>;  <span class="comment">% 计算长除法的循环周期        </span></span><br><span class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:cycle_length            <span class="comment">% 开始循环计算长除得到最终余数</span></span><br><span class="line">            add_zeros = <span class="built_in">zeros</span>(<span class="number">1</span>,cycle_length-k);       <span class="comment">% 加入冗余位参与模2运算</span></span><br><span class="line">            register_bits = [crc_ccitt add_zeros];        <span class="comment">% 构造除数数组</span></span><br><span class="line">            <span class="keyword">if</span> remainder_bits(<span class="number">1</span>) == <span class="number">0</span>     <span class="comment">% 被除数第一位为0则将除数所有位置0</span></span><br><span class="line">                register_bits = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">length</span>(register_bits));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            remainder_bits = bitxor(register_bits,remainder_bits);<span class="comment">% 将除数与被除数进行异或操作</span></span><br><span class="line">            register_bits = crc_ccitt;            <span class="comment">% 将寄存器恢复为除数数组</span></span><br><span class="line">            remainder_bits(<span class="number">1</span>) = [];      <span class="comment">% 去除模2后得到的被除数的第1位</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">if</span> sum(remainder_bits) == <span class="number">0</span>       <span class="comment">% 传输码元中没有发生个错误</span></span><br><span class="line">            original_sequence = crc_coded_sequence(<span class="number">1</span>:cycle_length)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            err = <span class="number">1</span>                             <span class="comment">% 码元传输发生错误</span></span><br><span class="line">        <span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">err =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>若注释掉”信道误码”和”接受码组”，Result：</strong></p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">uncode_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">crc_coded_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">original_sequence =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="汉明码"><a href="#汉明码" class="headerlink" title="汉明码"></a>汉明码</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clc;clear all;</span><br><span class="line">K=<span class="number">4</span>;</span><br><span class="line">N=<span class="number">7</span>;</span><br><span class="line">msg=randint(<span class="number">1</span>,K) <span class="comment">%%生成随机信息位   </span></span><br><span class="line"><span class="comment">% msg=round(1*rand(1,K)) %%生成随机信息位%若matlab版本不支持randint()函数，则以此行替换</span></span><br><span class="line">[H,G] = hammgen(N-K) <span class="comment">%%生成汉明码的生成矩阵和校验矩阵</span></span><br><span class="line">code=encode(msg,N,K,<span class="string">'linear/binary'</span>,G) <span class="comment">%%汉明码编码</span></span><br><span class="line">noise=[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>];</span><br><span class="line">code_noise=bitxor(code,noise)</span><br><span class="line">rcv=decode(code_noise,N,K,<span class="string">'linear/binary'</span>,G)</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">msg =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">H =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">G =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">code_noise =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"></span><br><span class="line">rcv =</span><br><span class="line"></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">     </span><br><span class="line"># msg 与 rcv 保持一致即可</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】通信技术基础上机&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ADNI模态数据概念整理</title>
    <link href="http://yoursite.com/2018/11/30/ADNI%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2018/11/30/ADNI模态数据概念整理/</id>
    <published>2018-11-30T13:32:50.000Z</published>
    <updated>2018-11-30T13:57:42.874Z</updated>
    
    <content type="html"><![CDATA[<p>【阅读时间】XXX min XXX words<br>【阅读内容】……</p><a id="more"></a><p>最近需要了解ADNI（Alzheimer’s Disease Neuroimaging Initiative）数据集，刚在网站上注册和提交了<a href="https://ida.loni.usc.edu/services/Menu/IdaData.jsp?page=DATA&amp;subPage=AVAILABLE_DATA" target="_blank" rel="noopener">申请</a>（审核通过了才能下载数据集），审核时间大概是一周。暂时无法查看数据集内容，亦无法下载。无奈只好在再次回顾<a href="http://adni.loni.usc.edu/data-samples/data-types/" target="_blank" rel="noopener">ADNI Data Type</a> 相关说明。同时从同学处获取部分Nifti离线文件，并进行python读取文件数据。</p><h4 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h4><h5 id="Clinical-Data"><a href="#Clinical-Data" class="headerlink" title="Clinical Data"></a>Clinical Data</h5><p>ADNI临床数据集包括关于每个受试者的<code>临床信息</code>，包括招募，人口统计学，身体检查和认知评估数据。可以将整套临床数据作为逗号分隔值（CSV）文件批量下载。</p><p><img src="http://adni.loni.usc.edu/wp-content/uploads/2010/09/clinical-data-chart.png" style="zoom:60%"></p><ul><li><p>Demographics 人口统计学、Neurological Exam 神经系统检查、Screening Labs 筛选实验室 、Vital Signs 生命体征、Cognitive Assessments 认知评估、Biospecimen Collections 生物样本收集、 Medications 药物、Diagnostic Summary 诊断摘要、Lumbar Puncture 腰椎穿刺</p></li><li><p>Screening 筛选、Baseline 基线 、Month 3 、Month 6 、Month 12 、 Month 18 、Month 24 、Month36 、Month48 、Ongoing Annual Follow-up  当前进行的年度跟进</p></li></ul><h5 id="Gennetic-Data"><a href="#Gennetic-Data" class="headerlink" title="Gennetic Data"></a>Gennetic Data</h5><p>遗传因素在阿尔茨海默病中起重要作用。全基因组关联研究（<code>GWAS</code>）采用标记之间关联的测试，称为单核苷酸多态性（<code>SNP</code>）和感兴趣的表型。来自病例对照GWAS和其他类型的遗传关联研究的发现可以提供用于检查源自ADNI成像和其他生物标志物数据集的定量表型的目标。</p><p><code>APOE的4等位基因</code>是已知的AD最强大的遗传风险因素，如果拥有一个4等位基因的人患AD的风险增加了2- 3倍，那么如果有两个等位基因的人患AD的风险增加了12倍。</p><h5 id="MR-Image-Data"><a href="#MR-Image-Data" class="headerlink" title="MR Image Data"></a>MR Image Data</h5><p>MRI – <code>核磁共振成像</code>是根据有磁矩的原子核在磁场作用下，能产生能级间的跃迁的原理采用的技术。MRI对脑内低度星形胶质细胞瘤、神经节、神经胶质瘤、动静脉畸形和血肿等的诊断确认率极高。MRI能清楚地显示癫痫患者的脑萎缩，对脑实质和脑脊液的显示度极好。</p><p>原始，预处理和后处理图像文件，FMRI和DTI 这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/MRI.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>该项目将收集MRI（结构，扩散加权成像，灌注和静息状态序列）; 使用florbetapir F18（florbetapir）或florbetaben F18（florbetaben）的淀粉样蛋白PET; 18F-FDG-PET（FDG-PET）; CSF用于Aβ，tau，磷酸化tau（AKA磷酸化酶）和其他蛋白质; AV-1451 PET; 和遗传和尸检数据，以<code>确定这些生物标志物与基线临床状态和认知下降的关系</code>。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-47b425d8cdc1ff7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="PET-Image-Data"><a href="#PET-Image-Data" class="headerlink" title="PET Image Data"></a>PET Image Data</h5><p>正电子发射计算机断层扫描的大致方法是，将某种物质，一般是生物生命代谢中必须的物质，如：葡萄糖、蛋白质、核酸、脂肪酸，标记上短寿命的放射性核素（如18F，11C等），注入人体后，通过对于该物质在代谢中的聚集，来反映生命代谢活动的情况，从而达到诊断的目的。</p><p>其中：18F-FDG是指氟代脱氧葡萄糖，其完整的化学名称为2-氟-2-脱氧-D-葡萄糖，通常简称为FDG。葡萄糖是人体三大能源物质之一，将可以被PET探测并形成影像的的正电子核素18F标记在葡萄糖上。</p><p>原始，预处理和后处理图像文件，PIB（ADNI1），FDG（ADNI1 / GO / 2），FLORBETAPIR（ADNI GO / 2/3），FLORBETABEN（ADNI3）和TAU IMAGING（ADNI3）这些图像的收集对于满足ADNI开发生物标记物以追踪阿尔茨海默病的进展和潜在病理学变化的目标至关重要。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-1.png" alt="an overview of the PET data collected throughout the ADNI study" title="">                </div>                <div class="image-caption">an overview of the PET data collected throughout the ADNI study</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://adni.loni.usc.edu/wp-content/uploads/2012/08/PET-Image-Data.png" alt="AVAILABLE IMAGE DATA" title="">                </div>                <div class="image-caption">AVAILABLE IMAGE DATA</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://upload-images.jianshu.io/upload_images/5267500-508b820355abe639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h5 id="Biospecimen-Data"><a href="#Biospecimen-Data" class="headerlink" title="Biospecimen Data"></a>Biospecimen Data</h5><p>ADNI的目标之一是收集参与者的<code>血液</code>，<code>尿液</code>和<code>脑脊液（CSF）</code>等生物样本(Biospecimen Data)。鼓励有兴趣的调查员，无论是否与ADNI网站相关联，都可以申请使用这种有限的资源。但是，除非初步数据显示出明显优越的性能，否则不建议将ADNI样本用于技术开发或不同技术之间的比较。</p><p>此外，adni生物标记核心所执行的几项分析结果将在数据存档中提供如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Homocysteine</span><br><span class="line">- Species of isoprostanes</span><br><span class="line">- CSF tau, sAPPβ levels, BACE levels, and enzyme activity</span><br><span class="line">- Plasma Aβ 40 and Aβ 42</span><br><span class="line">- Other promising CSF and plasma based on ongoing multiplex immunoassay studies and mass - spectrometry MRM studies</span><br></pre></td></tr></table></figure><h4 id="python-读取nifti数据"><a href="#python-读取nifti数据" class="headerlink" title="python 读取nifti数据"></a>python 读取nifti数据</h4><ul><li>使用nifti数据 23.6 MB   </li></ul><figure><br>    <img src="/2018/11/30/ADNI模态数据概念整理/nii_example.png" style="zoom:80%"><br></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># show the nii_data.shape</span></span><br><span class="line">nii_file = <span class="string">"ADNI_011_S_0010_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20061208114538147_S8800_I32270.nii"</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line">img = np.squeeze(img)</span><br><span class="line">print(<span class="string">"img.shape"</span>,img.shape) <span class="comment"># img.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.shape"</span>,data.shape) <span class="comment"># data.shape (192, 192, 160)</span></span><br><span class="line">print(<span class="string">"data.affine.shape"</span>,data.affine.shape)  <span class="comment"># data.affine.shape (4, 4)</span></span><br><span class="line"><span class="comment"># print(data.header) #数据头信息  输出信息于Result列出</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取slice信息生成图像</span></span><br><span class="line"><span class="comment"># 把slice数据生成图片的方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span><span class="params">(slices)</span>:</span></span><br><span class="line"></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">1</span>, len(slices))</span><br><span class="line">    <span class="keyword">for</span> i, slice <span class="keyword">in</span> enumerate(slices):</span><br><span class="line">        axes[i].imshow(slice.T, cmap=<span class="string">"gray"</span>, origin=<span class="string">"lower"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取nifti文件中的slice数据</span></span><br><span class="line">data = nib.load(nii_file)</span><br><span class="line">img = data.get_fdata()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取单张slice数据</span></span><br><span class="line">slice_0 = img[<span class="number">26</span>, :, :]</span><br><span class="line">slice_1 = img[:, <span class="number">30</span>, :]</span><br><span class="line">slice_2 = img[:, :, <span class="number">16</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成图表</span></span><br><span class="line">show_img([slice_0, slice_1, slice_2])</span><br><span class="line">plt.suptitle(<span class="string">"show slice image"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><strong>Result：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.shape (<span class="number">192</span>, <span class="number">192</span>, <span class="number">160</span>)</span><br><span class="line">data.affine.shape (<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">&lt;class 'nibabel.nifti1.Nifti1Header'&gt; object, endian='&gt;'</span><br><span class="line">sizeof_hdr      : <span class="number">348</span></span><br><span class="line">data_type       : <span class="string">b''</span></span><br><span class="line">db_name         : <span class="string">b'011_S_0010'</span></span><br><span class="line">extents         : <span class="number">0</span></span><br><span class="line">session_error   : <span class="number">0</span></span><br><span class="line">regular         : <span class="string">b'r'</span></span><br><span class="line">dim_info        : <span class="number">0</span></span><br><span class="line">dim             : [  <span class="number">3</span> <span class="number">192</span> <span class="number">192</span> <span class="number">160</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>]</span><br><span class="line">intent_p1       : <span class="number">0.0</span></span><br><span class="line">intent_p2       : <span class="number">0.0</span></span><br><span class="line">intent_p3       : <span class="number">0.0</span></span><br><span class="line">intent_code     : none</span><br><span class="line">datatype        : float32</span><br><span class="line">bitpix          : <span class="number">32</span></span><br><span class="line">slice_start     : <span class="number">0</span></span><br><span class="line">pixdim          : [<span class="number">1.</span>        <span class="number">1.2447063</span> <span class="number">1.2507237</span> <span class="number">1.2010667</span> <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span></span><br><span class="line"> <span class="number">1.</span>       ]</span><br><span class="line">vox_offset      : <span class="number">0.0</span></span><br><span class="line">scl_slope       : nan</span><br><span class="line">scl_inter       : nan</span><br><span class="line">slice_end       : <span class="number">0</span></span><br><span class="line">slice_code      : unknown</span><br><span class="line">xyzt_units      : <span class="number">2</span></span><br><span class="line">cal_max         : <span class="number">0.0</span></span><br><span class="line">cal_min         : <span class="number">0.0</span></span><br><span class="line">slice_duration  : <span class="number">0.0</span></span><br><span class="line">toffset         : <span class="number">0.0</span></span><br><span class="line">glmax           : <span class="number">1721</span></span><br><span class="line">glmin           : <span class="number">0</span></span><br><span class="line">descrip         : <span class="string">b'MPR; GradWarp; B1 Correction; N3; Scaled'</span></span><br><span class="line">aux_file        : <span class="string">b'none'</span></span><br><span class="line">qform_code      : scanner</span><br><span class="line">sform_code      : unknown</span><br><span class="line">quatern_b       : <span class="number">0.70710677</span></span><br><span class="line">quatern_c       : <span class="number">-1.0713779e-09</span></span><br><span class="line">quatern_d       : <span class="number">-0.70710677</span></span><br><span class="line">qoffset_x       : <span class="number">94.87749</span></span><br><span class="line">qoffset_y       : <span class="number">165.8339</span></span><br><span class="line">qoffset_z       : <span class="number">115.27711</span></span><br><span class="line">srow_x          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_y          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">srow_z          : [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">intent_name     : <span class="string">b''</span></span><br><span class="line">magic           : <span class="string">b'n+1'</span></span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/11/30/ADNI模态数据概念整理/show" alt="show slice image" title="slice">                </div>                <div class="image-caption">slice</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;【阅读时间】XXX min XXX words&lt;br&gt;【阅读内容】……&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
